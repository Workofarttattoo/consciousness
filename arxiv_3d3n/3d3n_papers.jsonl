{"arxiv_id": "2510.20822v1", "title": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video   Narratives", "summary": "State-of-the-art text-to-video models excel at generating isolated clips but fall short of creating the coherent, multi-shot narratives, which are the essence of storytelling. We bridge this \"narrative gap\" with HoloCine, a model that generates entire scenes holistically to ensure global consistency from the first shot to the last. Our architecture achieves precise directorial control through a Window Cross-Attention mechanism that localizes text prompts to specific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within shots but sparse between them) ensures the efficiency required for minute-scale generation. Beyond setting a new state-of-the-art in narrative coherence, HoloCine develops remarkable emergent abilities: a persistent memory for characters and scenes, and an intuitive grasp of cinematic techniques. Our work marks a pivotal shift from clip synthesis towards automated filmmaking, making end-to-end cinematic creation a tangible future. Our code is available at: https://holo-cine.github.io/.", "published": "2025-10-23T17:59:59Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:04.199913"}
{"arxiv_id": "2510.20821v1", "title": "Efficient analytic approximation for small-scale non-cold relic   perturbations", "summary": "We develop a highly accurate analytic approximation for small-scale non-cold relic perturbations by solving the collisionless Boltzmann equation in the quasi-stationary regime. The approximation is implemented in CLASSIER (CLASS Integral Equation Revision), a modified version of the Boltzmann solver CLASS that replaces the traditional truncated Boltzmann hierarchy of non cold relic multipoles with a small set of integral equations solved iteratively. Applying it to massive neutrinos yields a factor-of-two reduction in total runtime relative to CLASSIER without the approximation. Compared to standard CLASS runs (with $\\ell_{\\rm max}^{\\rm NCDM}=40$ and no late-time massive neutrino fluid approximation) under the same precision setting, CLASSIER with this approximation is faster by a factor of 3-6. The approximation faithfully reproduces the late-time behavior of massive neutrino perturbations and preserves sub-$0.1\\%$ accuracy in the matter power spectrum today up to comoving wavenumber $k=100\\,{\\rm Mpc}^{-1}$. With this approximation, massive-neutrino perturbations are no longer the computational bottleneck on small scales for linear-theory predictions. The approach can be readily extendable to non-standard dark-matter models, and offers prospects for further efficiency gains in high-precision cosmological analyses.", "published": "2025-10-23T17:59:58Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:04.200551"}
{"arxiv_id": "2510.20820v1", "title": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered   Canvas", "summary": "Despite their impressive visual fidelity, existing personalized generative models lack interactive control over spatial composition and scale poorly to multiple subjects. To address these limitations, we present LayerComposer, an interactive framework for personalized, multi-subject text-to-image generation. Our approach introduces two main contributions: (1) a layered canvas, a novel representation in which each subject is placed on a distinct layer, enabling occlusion-free composition; and (2) a locking mechanism that preserves selected layers with high fidelity while allowing the remaining layers to adapt flexibly to the surrounding context. Similar to professional image-editing software, the proposed layered canvas allows users to place, resize, or lock input subjects through intuitive layer manipulation. Our versatile locking mechanism requires no architectural changes, relying instead on inherent positional embeddings combined with a new complementary data sampling strategy. Extensive experiments demonstrate that LayerComposer achieves superior spatial control and identity preservation compared to the state-of-the-art methods in multi-subject personalized image generation.", "published": "2025-10-23T17:59:55Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:04.200734"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "brain computer interface", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:04.200989"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:04.201174"}
{"arxiv_id": "2510.20813v1", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic   Manipulation", "summary": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.", "published": "2025-10-23T17:59:26Z", "query": "brain computer interface", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:04.201370"}
{"arxiv_id": "2510.20814v1", "title": "SpectraMorph: Structured Latent Learning for Self-Supervised   Hyperspectral Super-Resolution", "summary": "Hyperspectral sensors capture dense spectra per pixel but suffer from low spatial resolution, causing blurred boundaries and mixed-pixel effects. Co-registered companion sensors such as multispectral, RGB, or panchromatic cameras provide high-resolution spatial detail, motivating hyperspectral super-resolution through the fusion of hyperspectral and multispectral images (HSI-MSI). Existing deep learning based methods achieve strong performance but rely on opaque regressors that lack interpretability and often fail when the MSI has very few bands. We propose SpectraMorph, a physics-guided self-supervised fusion framework with a structured latent space. Instead of direct regression, SpectraMorph enforces an unmixing bottleneck: endmember signatures are extracted from the low-resolution HSI, and a compact multilayer perceptron predicts abundance-like maps from the MSI. Spectra are reconstructed by linear mixing, with training performed in a self-supervised manner via the MSI sensor's spectral response function. SpectraMorph produces interpretable intermediates, trains in under a minute, and remains robust even with a single-band (pan-chromatic) MSI. Experiments on synthetic and real-world datasets show SpectraMorph consistently outperforming state-of-the-art unsupervised/self-supervised baselines while remaining very competitive against supervised baselines.", "published": "2025-10-23T17:59:26Z", "query": "brain computer interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:04.201561"}
{"arxiv_id": "2510.20812v1", "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via   Speculation", "summary": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict", "published": "2025-10-23T17:59:21Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:04.201713"}
{"arxiv_id": "2510.20810v1", "title": "On the Detectability of LLM-Generated Text: What Exactly Is   LLM-Generated Text?", "summary": "With the widespread use of large language models (LLMs), many researchers have turned their attention to detecting text generated by them. However, there is no consistent or precise definition of their target, namely \"LLM-generated text\". Differences in usage scenarios and the diversity of LLMs further increase the difficulty of detection. What is commonly regarded as the detecting target usually represents only a subset of the text that LLMs can potentially produce. Human edits to LLM outputs, together with the subtle influences that LLMs exert on their users, are blurring the line between LLM-generated and human-written text. Existing benchmarks and evaluation approaches do not adequately address the various conditions in real-world detector applications. Hence, the numerical results of detectors are often misunderstood, and their significance is diminishing. Therefore, detectors remain useful under specific conditions, but their results should be interpreted only as references rather than decisive indicators.", "published": "2025-10-23T17:59:06Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:04.201933"}
{"arxiv_id": "2510.20809v1", "title": "Real Deep Research for AI, Robotics and Beyond", "summary": "With the rapid growth of research in AI and robotics now producing over 10,000 papers annually it has become increasingly difficult for researchers to stay up to date. Fast evolving trends, the rise of interdisciplinary work, and the need to explore domains beyond one's expertise all contribute to this challenge. To address these issues, we propose a generalizable pipeline capable of systematically analyzing any research area: identifying emerging trends, uncovering cross domain opportunities, and offering concrete starting points for new inquiry. In this work, we present Real Deep Research (RDR) a comprehensive framework applied to the domains of AI and robotics, with a particular focus on foundation models and robotics advancements. We also briefly extend our analysis to other areas of science. The main paper details the construction of the RDR pipeline, while the appendix provides extensive results across each analyzed topic. We hope this work sheds light for researchers working in the field of AI and beyond.", "published": "2025-10-23T17:59:05Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:04.202100"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.870428"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:07.871191"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:07.871491"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.871804"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.872214"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "BCI neural interface", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:07.872630"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.872888"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.873174"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:07.873399"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:07.873579"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "BCI neural interface", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.873816"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.873975"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.874186"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "BCI neural interface", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:07.874395"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "BCI neural interface", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:07.874589"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.874795"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:07.874985"}
{"arxiv_id": "2510.20690v1", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "summary": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. Inspired by portfolio theory, where uncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination probability is bounded by representational correlation: $P(H) \\leq f(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language models need an optimal amount of neurodiversity. To validate this, we introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces hallucinations by up to 25.6% (and 14.6% on average) without degrading general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational analyses indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different amounts of optimal neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.", "published": "2025-10-23T16:03:07Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.875528"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "BCI neural interface", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:07.875873"}
{"arxiv_id": "2510.20677v1", "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice   Conversion", "summary": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.", "published": "2025-10-23T15:52:03Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:07.876232"}
{"arxiv_id": "2510.20673v1", "title": "Efficient Multi-bit Quantization Network Training via Weight Bias   Correction and Bit-wise Coreset Sampling", "summary": "Multi-bit quantization networks enable flexible deployment of deep neural networks by supporting multiple precision levels within a single model. However, existing approaches suffer from significant training overhead as full-dataset updates are repeated for each supported bit-width, resulting in a cost that scales linearly with the number of precisions. Additionally, extra fine-tuning stages are often required to support additional or intermediate precision options, further compounding the overall training burden. To address this issue, we propose two techniques that greatly reduce the training overhead without compromising model utility: (i) Weight bias correction enables shared batch normalization and eliminates the need for fine-tuning by neutralizing quantization-induced bias across bit-widths and aligning activation distributions; and (ii) Bit-wise coreset sampling strategy allows each child model to train on a compact, informative subset selected via gradient-based importance scores by exploiting the implicit knowledge transfer phenomenon. Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and ViT architectures demonstrate that our method achieves competitive or superior accuracy while reducing training time up to 7.88x. Our code is released at https://github.com/a2jinhee/EMQNet_jk.", "published": "2025-10-23T15:49:02Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.876469"}
{"arxiv_id": "2510.20671v1", "title": "GRACE: GRaph-based Addiction Care prEdiction", "summary": "Determining the appropriate locus of care for addiction patients is one of the most critical clinical decisions that affects patient treatment outcomes and effective use of resources. With a lack of sufficient specialized treatment resources, such as inpatient beds or staff, there is an unmet need to develop an automated framework for the same. Current decision-making approaches suffer from severe class imbalances in addiction datasets. To address this limitation, we propose a novel graph neural network (GRACE) framework that formalizes locus of care prediction as a structured learning problem. Further, we perform extensive feature engineering and propose a new approach of obtaining an unbiased meta-graph to train a GNN to overcome the class imbalance problem. Experimental results in real-world data show an improvement of 11-35% in terms of the F1 score of the minority class over competitive baselines. The codes and note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.", "published": "2025-10-23T15:48:01Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.876659"}
{"arxiv_id": "2510.20669v1", "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing   Maps and Spiking Dynamics for Waste Classification", "summary": "Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.", "published": "2025-10-23T15:47:09Z", "query": "BCI neural interface", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:07.876975"}
{"arxiv_id": "2510.20666v1", "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of   Experts", "summary": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming, particularly in urban areas where multipath and shadowing distort received power. Previous data-driven approaches achieved reasonable localization but poorly reconstructed the received signal strength (RSS) field due to limited spatial context. We propose a hybrid Bayesian mixture-of-experts framework that fuses a physical path-loss (PL) model and a convolutional neural network (CNN) through log-linear pooling. The PL expert ensures physical consistency, while the CNN leverages building-height maps to capture urban propagation effects. Bayesian inference with Laplace approximation provides posterior uncertainty over both the jammer position and RSS field. Experiments on urban ray-tracing data show that localization accuracy improves and uncertainty decreases with more training points, while uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive.", "published": "2025-10-23T15:45:45Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.877169"}
{"arxiv_id": "2510.20659v1", "title": "Kinetics of Peierls dimerization transition: Machine learning   force-field approach", "summary": "We present a machine learning (ML) force-field framework for simulating the non-equilibrium dynamics of charge-density-wave (CDW) order driven by the Peierls instability. Since the Peierls distortion arises from the coupling between lattice displacements and itinerant electrons, evaluating the adiabatic forces during time evolution is computationally intensive, particularly for large systems. To overcome this bottleneck, we develop a generalized Behler-Parrinello neural-network architecture -- originally formulated for ab initio molecular dynamics -- to accurately and efficiently predict forces from local structural environments. Using the locality of electronic responses, the resulting ML force field achieves linear scaling efficiency while maintaining quantitative accuracy. Large-scale dynamical simulations using this framework uncover a two-stage coarsening behavior of CDW domains: an early-time regime characterized by a power-law growth $L \\sim t^{\\alpha}$ with an effective exponent $\\alpha \\approx 0.7$, followed by a crossover to the Allen-Cahn scaling $L \\sim \\sqrt{t}$ at late times. The enhanced early-time coarsening is attributed to anisotropic domain-wall motion arising from electron-mediated directional interactions. This work demonstrates the promise of ML-based force fields for multiscale dynamical modeling of condensed-matter lattice models.", "published": "2025-10-23T15:33:31Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:07.877396"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural prosthetics", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:11.392746"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:11.393345"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.393746"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.393993"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural prosthetics", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:11.394248"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural prosthetics", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.394524"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.394809"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:11.395064"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.395298"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.395585"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "neural prosthetics", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:11.395773"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "neural prosthetics", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:11.396002"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.396181"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:11.396405"}
{"arxiv_id": "2510.20690v1", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "summary": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. Inspired by portfolio theory, where uncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination probability is bounded by representational correlation: $P(H) \\leq f(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language models need an optimal amount of neurodiversity. To validate this, we introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces hallucinations by up to 25.6% (and 14.6% on average) without degrading general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational analyses indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different amounts of optimal neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.", "published": "2025-10-23T16:03:07Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.396618"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "neural prosthetics", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:11.396814"}
{"arxiv_id": "2510.20677v1", "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice   Conversion", "summary": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.", "published": "2025-10-23T15:52:03Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:11.397006"}
{"arxiv_id": "2510.20673v1", "title": "Efficient Multi-bit Quantization Network Training via Weight Bias   Correction and Bit-wise Coreset Sampling", "summary": "Multi-bit quantization networks enable flexible deployment of deep neural networks by supporting multiple precision levels within a single model. However, existing approaches suffer from significant training overhead as full-dataset updates are repeated for each supported bit-width, resulting in a cost that scales linearly with the number of precisions. Additionally, extra fine-tuning stages are often required to support additional or intermediate precision options, further compounding the overall training burden. To address this issue, we propose two techniques that greatly reduce the training overhead without compromising model utility: (i) Weight bias correction enables shared batch normalization and eliminates the need for fine-tuning by neutralizing quantization-induced bias across bit-widths and aligning activation distributions; and (ii) Bit-wise coreset sampling strategy allows each child model to train on a compact, informative subset selected via gradient-based importance scores by exploiting the implicit knowledge transfer phenomenon. Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and ViT architectures demonstrate that our method achieves competitive or superior accuracy while reducing training time up to 7.88x. Our code is released at https://github.com/a2jinhee/EMQNet_jk.", "published": "2025-10-23T15:49:02Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.397179"}
{"arxiv_id": "2510.20671v1", "title": "GRACE: GRaph-based Addiction Care prEdiction", "summary": "Determining the appropriate locus of care for addiction patients is one of the most critical clinical decisions that affects patient treatment outcomes and effective use of resources. With a lack of sufficient specialized treatment resources, such as inpatient beds or staff, there is an unmet need to develop an automated framework for the same. Current decision-making approaches suffer from severe class imbalances in addiction datasets. To address this limitation, we propose a novel graph neural network (GRACE) framework that formalizes locus of care prediction as a structured learning problem. Further, we perform extensive feature engineering and propose a new approach of obtaining an unbiased meta-graph to train a GNN to overcome the class imbalance problem. Experimental results in real-world data show an improvement of 11-35% in terms of the F1 score of the minority class over competitive baselines. The codes and note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.", "published": "2025-10-23T15:48:01Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.397322"}
{"arxiv_id": "2510.20669v1", "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing   Maps and Spiking Dynamics for Waste Classification", "summary": "Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.", "published": "2025-10-23T15:47:09Z", "query": "neural prosthetics", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:11.397500"}
{"arxiv_id": "2510.20666v1", "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of   Experts", "summary": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming, particularly in urban areas where multipath and shadowing distort received power. Previous data-driven approaches achieved reasonable localization but poorly reconstructed the received signal strength (RSS) field due to limited spatial context. We propose a hybrid Bayesian mixture-of-experts framework that fuses a physical path-loss (PL) model and a convolutional neural network (CNN) through log-linear pooling. The PL expert ensures physical consistency, while the CNN leverages building-height maps to capture urban propagation effects. Bayesian inference with Laplace approximation provides posterior uncertainty over both the jammer position and RSS field. Experiments on urban ray-tracing data show that localization accuracy improves and uncertainty decreases with more training points, while uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive.", "published": "2025-10-23T15:45:45Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.397694"}
{"arxiv_id": "2510.20659v1", "title": "Kinetics of Peierls dimerization transition: Machine learning   force-field approach", "summary": "We present a machine learning (ML) force-field framework for simulating the non-equilibrium dynamics of charge-density-wave (CDW) order driven by the Peierls instability. Since the Peierls distortion arises from the coupling between lattice displacements and itinerant electrons, evaluating the adiabatic forces during time evolution is computationally intensive, particularly for large systems. To overcome this bottleneck, we develop a generalized Behler-Parrinello neural-network architecture -- originally formulated for ab initio molecular dynamics -- to accurately and efficiently predict forces from local structural environments. Using the locality of electronic responses, the resulting ML force field achieves linear scaling efficiency while maintaining quantitative accuracy. Large-scale dynamical simulations using this framework uncover a two-stage coarsening behavior of CDW domains: an early-time regime characterized by a power-law growth $L \\sim t^{\\alpha}$ with an effective exponent $\\alpha \\approx 0.7$, followed by a crossover to the Allen-Cahn scaling $L \\sim \\sqrt{t}$ at late times. The enhanced early-time coarsening is attributed to anisotropic domain-wall motion arising from electron-mediated directional interactions. This work demonstrates the promise of ML-based force fields for multiscale dynamical modeling of condensed-matter lattice models.", "published": "2025-10-23T15:33:31Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.397900"}
{"arxiv_id": "2510.20653v1", "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During   Inference-Time LLM Reflection", "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.", "published": "2025-10-23T15:26:18Z", "query": "neural prosthetics", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:11.398122"}
{"arxiv_id": "2510.20644v1", "title": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound   for Representation Learning", "summary": "Mutual Information (MI) is a fundamental measure of statistical dependence widely used in representation learning. While direct optimization of MI via its definition as a Kullback-Leibler divergence (KLD) is often intractable, many recent methods have instead maximized alternative dependence measures, most notably, the Jensen-Shannon divergence (JSD) between joint and product of marginal distributions via discriminative losses. However, the connection between these surrogate objectives and MI remains poorly understood. In this work, we bridge this gap by deriving a new, tight, and tractable lower bound on KLD as a function of JSD in the general case. By specializing this bound to joint and marginal distributions, we demonstrate that maximizing the JSD-based information increases a guaranteed lower bound on mutual information. Furthermore, we revisit the practical implementation of JSD-based objectives and observe that minimizing the cross-entropy loss of a binary classifier trained to distinguish joint from marginal pairs recovers a known variational lower bound on the JSD. Extensive experiments demonstrate that our lower bound is tight when applied to MI estimation. We compared our lower bound to state-of-the-art neural estimators of variational lower bound across a range of established reference scenarios. Our lower bound estimator consistently provides a stable, low-variance estimate of a tight lower bound on MI. We also demonstrate its practical usefulness in the context of the Information Bottleneck framework. Taken together, our results provide new theoretical justifications and strong empirical evidence for using discriminative learning in MI-based representation learning.", "published": "2025-10-23T15:18:12Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.398359"}
{"arxiv_id": "2510.20611v1", "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast   Cancer Detection", "summary": "Breast cancer is considered the most critical and frequently diagnosed cancer in women worldwide, leading to an increase in cancer-related mortality. Early and accurate detection is crucial as it can help mitigate possible threats while improving survival rates. In terms of prediction, conventional diagnostic methods are often limited by variability, cost, and, most importantly, risk of misdiagnosis. To address these challenges, machine learning (ML) has emerged as a powerful tool for computer-aided diagnosis, with feature selection playing a vital role in improving model performance and interpretability. This research study proposes an integrated framework that incorporates customized Particle Swarm Optimization (PSO) for feature selection. This framework has been evaluated on a comprehensive set of 29 different models, spanning classical classifiers, ensemble techniques, neural networks, probabilistic algorithms, and instance-based algorithms. To ensure interpretability and clinical relevance, the study uses cross-validation in conjunction with explainable AI methods. Experimental evaluation showed that the proposed approach achieved a superior score of 99.1\\% across all performance metrics, including accuracy and precision, while effectively reducing dimensionality and providing transparent, model-agnostic explanations. The results highlight the potential of combining swarm intelligence with explainable ML for robust, trustworthy, and clinically meaningful breast cancer diagnosis.", "published": "2025-10-23T14:42:50Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.398577"}
{"arxiv_id": "2510.20591v1", "title": "Transferable Graph Learning for Transmission Congestion Management via   Busbar Splitting", "summary": "Network topology optimization (NTO) via busbar splitting can mitigate transmission grid congestion and reduce redispatch costs. However, solving this mixed-integer non-linear problem for large-scale systems in near-real-time is currently intractable with existing solvers. Machine learning (ML) approaches have emerged as a promising alternative, but they have limited generalization to unseen topologies, varying operating conditions, and different systems, which limits their practical applicability. This paper formulates NTO for congestion management problem considering linearized AC PF, and proposes a graph neural network (GNN)-accelerated approach. We develop a heterogeneous edge-aware message passing NN to predict effective busbar splitting actions as candidate NTO solutions. The proposed GNN captures local flow patterns, achieves generalization to unseen topology changes, and improves transferability across systems. Case studies show up to 4 orders-of-magnitude speed-up, delivering AC-feasible solutions within one minute and a 2.3% optimality gap on the GOC 2000-bus system. These results demonstrate a significant step toward near-real-time NTO for large-scale systems with topology and cross-system generalization.", "published": "2025-10-23T14:16:23Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.398770"}
{"arxiv_id": "2510.20575v1", "title": "Local Density of States as a Probe of Multifractality in Quasiperiodic   Moir\u00e9 Materials", "summary": "Quasiperiodic moir\\'e materials provide a new platform for realizing critical electronic states, yet a direct and experimentally practical method to characterize this criticality has been lacking. We show that a multifractal analysis of the local density of states (LDOS), accessible via scanning tunneling microscopy, offers an unambiguous signature of criticality from a single experimental sample. Applying this approach to a one-dimensional quasiperiodic model, a stringent test case due to its fractal energy spectrum, we find a clear distinction between the broad singularity spectra $f\\left(\\alpha\\right)$ of critical states and the point-like spectra of extended states. We further demonstrate that these multifractal signatures remain robust over a wide range of energy broadenings relevant to experiments. Our results establish a model-independent, experimentally feasible framework for identifying and probing multifractality in the growing family of quasiperiodic and moir\\'e materials.", "published": "2025-10-23T14:00:49Z", "query": "neural prosthetics", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.398924"}
{"arxiv_id": "2510.20558v1", "title": "From Far and Near: Perceptual Evaluation of Crowd Representations Across   Levels of Detail", "summary": "In this paper, we investigate how users perceive the visual quality of crowd character representations at different levels of detail (LoD) and viewing distances. Each representation: geometric meshes, image-based impostors, Neural Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between visual fidelity and computational performance. Our qualitative and quantitative results provide insights to guide the design of perceptually optimized LoD strategies for crowd rendering.", "published": "2025-10-23T13:39:18Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:11.399012"}
{"arxiv_id": "2510.20556v1", "title": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph   Metrics", "summary": "Graph rewiring has emerged as a key technique to alleviate over-squashing in Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph topology to improve information flow. While effective, rewiring inherently alters the graph's structure, raising the risk of distorting important topology-dependent signals. Yet, despite the growing use of rewiring, little is known about which structural properties must be preserved to ensure both performance gains and structural fidelity. In this work, we provide the first systematic analysis of how rewiring affects a range of graph structural metrics, and how these changes relate to downstream task performance. We study seven diverse rewiring strategies and correlate changes in local and global graph properties with node classification accuracy. Our results reveal a consistent pattern: successful rewiring methods tend to preserve local structure while allowing for flexibility in global connectivity. These findings offer new insights into the design of effective rewiring strategies, bridging the gap between graph theory and practical GNN optimization.", "published": "2025-10-23T13:38:41Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:11.399127"}
{"arxiv_id": "2510.20551v1", "title": "Time-series Random Process Complexity Ranking Using a Bound on   Conditional Differential Entropy", "summary": "Conditional differential entropy provides an intuitive measure for relatively ranking time-series complexity by quantifying uncertainty in future observations given past context. However, its direct computation for high-dimensional processes from unknown distributions is often intractable. This paper builds on the information theoretic prediction error bounds established by Fang et al. \\cite{fang2019generic}, which demonstrate that the conditional differential entropy \\textbf{$h(X_k \\mid X_{k-1},...,X_{k-m})$} is upper bounded by a function of the determinant of the covariance matrix of next-step prediction errors for any next step prediction model. We add to this theoretical framework by further increasing this bound by leveraging Hadamard's inequality and the positive semi-definite property of covariance matrices.   To see if these bounds can be used to rank the complexity of time series, we conducted two synthetic experiments: (1) controlled linear autoregressive processes with additive Gaussian noise, where we compare ordinary least squares prediction error entropy proxies to the true entropies of various additive noises, and (2) a complexity ranking task of bio-inspired synthetic audio data with unknown entropy, where neural network prediction errors are used to recover the known complexity ordering.   This framework provides a computationally tractable method for time-series complexity ranking using prediction errors from next-step prediction models, that maintains a theoretical foundation in information theory.", "published": "2025-10-23T13:36:04Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:11.399295"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:14.861991"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.862409"}
{"arxiv_id": "2510.20817v1", "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "summary": "It is commonly believed that optimizing the reverse KL divergence results in \"mode seeking\", while optimizing forward KL results in \"mass covering\", with the latter being preferred if the goal is to sample from multiple diverse modes. We show -- mathematically and empirically -- that this intuition does not necessarily transfer well to doing reinforcement learning with reverse/forward KL regularization (e.g. as commonly used with language models). Instead, the choice of reverse/forward KL determines the family of optimal target distributions, parameterized by the regularization coefficient. Mode coverage depends primarily on other factors, such as regularization strength, and relative scales between rewards and reference probabilities. Further, we show commonly used settings such as low regularization strength and equal verifiable rewards tend to specify unimodal target distributions, meaning the optimization objective is, by construction, non-diverse. We leverage these insights to construct a simple, scalable, and theoretically justified algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a target distribution which puts high probability over all high-quality sampling modes. In experiments, this simple modification works to post-train both Large Language Models and Chemical Language Models to have higher solution quality and diversity, without any external signals of diversity, and works with both forward and reverse KL when using either naively fails.", "published": "2025-10-23T17:59:40Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:14.862604"}
{"arxiv_id": "2510.20811v1", "title": "Simulation-calibrated Bayesian inference for progenitor properties of   the microquasar SS 433", "summary": "SS\\,433 is one of the most extreme Galactic X-ray binaries, exhibiting semi-relativistic jets and super-critical accretion, and harboring a compact object, likely a black hole. Despite decades of observation and modeling, the precise nature of its progenitor binary remains uncertain. To estimate the zero-age main sequence (ZAMS) properties of binaries that evolve into SS\\,433-like systems, we apply simulation-based calibration to Bayesian inference and convolve a multivariate Gaussian likelihood constructed from six measured binary parameters of SS\\,433 with the isolated binary evolution model \\textsc{COSMIC}. Employing the dynamic nested sampler of \\texttt{dynesty}, we perform posterior inference over a ten-dimensional progenitor parameter space defined by the masses, orbital parameters, mass transfer possibilities, and natal kick velocity. We find that SS\\,433-like systems arise from specific regions of binary evolution parameter space depending on key assumptions, such as the mass transfer rate and uncertainty taken from observations. Our simulation-based calibration framework, implemented with a suite of machine learning algorithms and scored by a heuristic reliability metric, allows us to iteratively build posterior distributions of the progenitors of SS\\,433-like systems. This analysis reveals 90\\% confidence intervals for the ZAMS primary mass $(8, 11)$ M$_\\odot$, secondary mass $(32, 40)$ M$_\\odot $, orbital period $(136, 2259)$ days, eccentricity $(0.26, 0.6)$, common envelope evolution efficiency $(0.44, 0.76)$, accreted fraction in stable mass transfer $(0.22, 0.6)$, and black hole natal kick velocity magnitude $(5, 68)$ km/s. These results demonstrate the feasibility of direct probabilistic inference of X-ray binary progenitors to offer new insights into the evolution of high-accretion-rate systems such as SS\\,433.", "published": "2025-10-23T17:59:09Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:14.862790"}
{"arxiv_id": "2510.20810v1", "title": "On the Detectability of LLM-Generated Text: What Exactly Is   LLM-Generated Text?", "summary": "With the widespread use of large language models (LLMs), many researchers have turned their attention to detecting text generated by them. However, there is no consistent or precise definition of their target, namely \"LLM-generated text\". Differences in usage scenarios and the diversity of LLMs further increase the difficulty of detection. What is commonly regarded as the detecting target usually represents only a subset of the text that LLMs can potentially produce. Human edits to LLM outputs, together with the subtle influences that LLMs exert on their users, are blurring the line between LLM-generated and human-written text. Existing benchmarks and evaluation approaches do not adequately address the various conditions in real-world detector applications. Hence, the numerical results of detectors are often misunderstood, and their significance is diminishing. Therefore, detectors remain useful under specific conditions, but their results should be interpreted only as references rather than decisive indicators.", "published": "2025-10-23T17:59:06Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.862967"}
{"arxiv_id": "2510.20809v1", "title": "Real Deep Research for AI, Robotics and Beyond", "summary": "With the rapid growth of research in AI and robotics now producing over 10,000 papers annually it has become increasingly difficult for researchers to stay up to date. Fast evolving trends, the rise of interdisciplinary work, and the need to explore domains beyond one's expertise all contribute to this challenge. To address these issues, we propose a generalizable pipeline capable of systematically analyzing any research area: identifying emerging trends, uncovering cross domain opportunities, and offering concrete starting points for new inquiry. In this work, we present Real Deep Research (RDR) a comprehensive framework applied to the domains of AI and robotics, with a particular focus on foundation models and robotics advancements. We also briefly extend our analysis to other areas of science. The main paper details the construction of the RDR pipeline, while the appendix provides extensive results across each analyzed topic. We hope this work sheds light for researchers working in the field of AI and beyond.", "published": "2025-10-23T17:59:05Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.863130"}
{"arxiv_id": "2510.20808v1", "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "summary": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.", "published": "2025-10-23T17:58:53Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.863318"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:14.863564"}
{"arxiv_id": "2510.20800v1", "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient   Step on 100 Samples", "summary": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank reduction (LASER) which demonstrated that pruning high-order components of carefully chosen LLM's weight matrices can boost downstream accuracy -- without any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each requiring full-dataset forward passes) makes it impractical for rapid deployment. We demonstrate that this overhead can be removed and find that: (i) Only a small, carefully chosen subset of matrices needs to be inspected -- eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's singular values pinpoints which matrices merit reduction, (iii) Increasing the factorization search space by allowing matrices rows to cluster around multiple subspaces and then decomposing each cluster separately further reduces overfitting on the original training data and further lifts accuracy by up to 24.6 percentage points, and finally, (iv) we discover that evaluating on just 100 samples rather than the full training data -- both for computing the indicative gradients and for measuring the final accuracy -- suffices to further reduce the search time; we explain that as adaptation to downstream tasks is dominated by prompting style, not dataset size. As a result, we show that combining these findings yields a fast and robust adaptation algorithm for downstream tasks. Overall, with a single gradient step on 100 examples and a quick scan of the top candidate layers and factorization techniques, we can adapt LLMs to new datasets -- entirely without fine-tuning.", "published": "2025-10-23T17:58:01Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.864004"}
{"arxiv_id": "2510.20798v1", "title": "Analog Quantum Feature Selection with Neutral-Atom Quantum Processors", "summary": "We present a quantum-native approach to quantum feature selection (QFS) based on analog quantum simulation with neutral atom arrays, adaptable to a variety of academic and industrial applications. In our method, feature relevance-measured via mutual information with the target-is encoded as local detuning amplitudes, while feature redundancy is embedded through distance-dependent van der Waals interactions, constrained by the Rydberg blockade radius. The system is evolved adiabatically toward low-energy configurations, and the resulting measurement bitstrings are used to extract physically consistent subsets of features. The protocol is evaluated through simulations on three benchmark binary classification datasets: Adult Income, Bank Marketing, and Telco Churn. Compared to classical methods such as mutual information ranking and Boruta, combined with XGBoost and Random Forest classifiers, our quantum-computing approach achieves competitive or superior performance. In particular, for compact subsets of 2-5 features, analog QFS improves mean AUC scores by 1.5-2.3% while reducing the number of features by 75-84%, offering interpretable, low-redundancy solutions. These results demonstrate that programmable Rydberg arrays offer a viable platform for intelligent feature selection with practical relevance in machine learning pipelines, capable of transforming computational quantum advantage into industrial quantum usefulness.", "published": "2025-10-23T17:57:34Z", "query": "brain machine interface", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:14.864255"}
{"arxiv_id": "2510.20797v1", "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "summary": "A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean-pooling approach that consistently outperforms the widely used compression-tokens architecture, and study training the same compressor to output multiple compression ratios. We conduct extensive experiments across in-domain and out-of-domain QA datasets, as well as across model families, scales, and compression ratios. Overall, our simple mean-pooling approach achieves the strongest performance, with a relatively small drop when training for multiple compression ratios. More broadly though, across architectures and training regimes the trade-offs are more nuanced, illustrating the complex landscape of compression methods.", "published": "2025-10-23T17:57:23Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:14.864403"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "brain machine interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.864571"}
{"arxiv_id": "2510.20792v1", "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for   Text-Guided Graph Generation", "summary": "The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method targeting latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.", "published": "2025-10-23T17:54:17Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.864739"}
{"arxiv_id": "2510.20787v1", "title": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention   and Contextualized Learnable Token Eviction", "summary": "Linear-attention models that compress the entire input sequence into a fixed-size recurrent state offer an efficient alternative to Transformers, but their finite memory induces forgetfulness that harms retrieval-intensive tasks. To mitigate the issue, we explore a series of hybrid models that restore direct access to past tokens. We interleave token mixers with intermediate time and space complexity between linear and full attention, including sparse attention with token eviction, and the query-aware native sparse attention. Particularly, we propose a novel learnable token eviction approach. Combined with sliding-window attention, an end-to-end trainable lightweight CNN aggregates information from both past and future adjacent tokens to adaptively retain a limited set of critical KV-pairs per head, maintaining linear attention's constant time and space complexity. Efficient Triton kernels for the sparse attention mechanisms are provided. Empirical evaluations on retrieval-intensive benchmarks support the effectiveness of our approaches.", "published": "2025-10-23T17:53:03Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:14.864880"}
{"arxiv_id": "2510.20784v1", "title": "A Coherence-Based Measure of AGI", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized \\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of proficiencies across cognitive domains derived from the Cattell--Horn--Carroll (CHC) model of human cognition. While elegant, this definition assumes \\textit{compensability} -- that exceptional ability in some domains can offset failure in others. True general intelligence, however, should reflect \\textit{coherent sufficiency}: balanced competence across all essential domains. We propose a coherence-aware measure of AGI based on the integral of generalized means over a continuum of compensability exponents. This formulation spans arithmetic, geometric, and harmonic regimes, and the resulting \\textit{area under the curve} (AUC) quantifies robustness under varying compensability assumptions. Unlike the arithmetic mean, which rewards specialization, the AUC penalizes imbalance and captures inter-domain dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5, the coherence-adjusted AUC reveals that both systems remain far from general competence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating the generalized mean thus yields a principled, interpretable, and stricter foundation for measuring genuine progress toward AGI.", "published": "2025-10-23T17:51:42Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:14.865023"}
{"arxiv_id": "2510.20783v1", "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "summary": "Chess is a canonical example of a task that requires rigorous reasoning and long-term planning. Modern decision Transformers - trained similarly to LLMs - are able to learn competent gameplay, but it is unclear to what extent they truly capture the rules of chess. To investigate this, we train a 270M parameter chess Transformer and test it on out-of-distribution scenarios, designed to reveal failures of systematic generalization. Our analysis shows that Transformers exhibit compositional generalization, as evidenced by strong rule extrapolation: they adhere to fundamental syntactic rules of the game by consistently choosing valid moves even in situations very different from the training data. Moreover, they also generate high-quality moves for OOD puzzles. In a more challenging test, we evaluate the models on variants including Chess960 (Fischer Random Chess) - a variant of chess where starting positions of pieces are randomized. We found that while the model exhibits basic strategy adaptation, they are inferior to symbolic AI algorithms that perform explicit search, but gap is smaller when playing against users on Lichess. Moreover, the training dynamics revealed that the model initially learns to move only its own pieces, suggesting an emergent compositional understanding of the game.", "published": "2025-10-23T17:51:28Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.865261"}
{"arxiv_id": "2510.20780v1", "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and   Performance Boost", "summary": "Recent advancements in large reasoning models (LRMs) have introduced an intermediate \"thinking\" process prior to generating final answers, improving their reasoning capabilities on complex downstream tasks. However, the potential of LRMs as evaluators for machine translation (MT) quality remains underexplored. We provides the first systematic analysis of LRM-as-a-judge in MT evaluation. We identify key challenges, revealing LRMs require tailored evaluation materials, tend to \"overthink\" simpler instances and have issues with scoring mechanisms leading to overestimation. To address these, we propose to calibrate LRM thinking by training them on synthetic, human-like thinking trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this approach largely reduces thinking budgets by ~35x while concurrently improving evaluation performance across different LRM scales from 7B to 32B (e.g., R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These findings highlight the potential of efficiently calibrated LRMs to advance fine-grained automatic MT evaluation.", "published": "2025-10-23T17:48:36Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.865411"}
{"arxiv_id": "2510.20771v1", "title": "AlphaFlow: Understanding and Improving MeanFlow Models", "summary": "MeanFlow has recently emerged as a powerful framework for few-step generative modeling trained from scratch, but its success is not yet fully understood. In this work, we show that the MeanFlow objective naturally decomposes into two parts: trajectory flow matching and trajectory consistency. Through gradient analysis, we find that these terms are strongly negatively correlated, causing optimization conflict and slow convergence. Motivated by these insights, we introduce $\\alpha$-Flow, a broad family of objectives that unifies trajectory flow matching, Shortcut Model, and MeanFlow under one formulation. By adopting a curriculum strategy that smoothly anneals from trajectory flow matching to MeanFlow, $\\alpha$-Flow disentangles the conflicting objectives, and achieves better convergence. When trained from scratch on class-conditional ImageNet-1K 256x256 with vanilla DiT backbones, $\\alpha$-Flow consistently outperforms MeanFlow across scales and settings. Our largest $\\alpha$-Flow-XL/2+ model achieves new state-of-the-art results using vanilla DiT backbones, with FID scores of 2.58 (1-NFE) and 2.15 (2-NFE).", "published": "2025-10-23T17:45:06Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:14.865518"}
{"arxiv_id": "2510.20769v1", "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble   Precipitation Forecasting", "summary": "Accurate medium-range precipitation forecasting is crucial for hydrometeorological risk management and disaster mitigation, yet remains challenging for current numerical weather prediction (NWP) systems. Traditional ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to maintain high skill, especially for moderate and heavy rainfall at extended lead times. This study develops a deep learning-based ensemble framework for multi-step precipitation prediction through joint modeling of a comprehensive set of atmospheric variables. The model is trained on ERA5 reanalysis data at 0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's Integrated Multi-satellite Retrievals for Global Precipitation Measurement (GPM) constellation (IMERG), incorporating 57 input variables, including upper-air and surface predictors. The architecture employs a patch-based Swin Transformer backbone with periodic convolutions to handle longitudinal continuity and integrates time and noise embeddings through conditional layer normalization. A dual-branch decoder predicts total precipitation and other variables, with targeted freezing of encoder-decoder pathways for specialized training. Training minimizes a hybrid loss combining the Continuous Ranked Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE), balancing probabilistic accuracy and magnitude fidelity. During inference, the model ingests real-time Global Forecast System (GFS) initial conditions to generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG data demonstrates higher Critical Success Index (CSI) scores at precipitation thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance for moderate to heavy rainfall.", "published": "2025-10-23T17:43:38Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:14.865684"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "brain machine interface", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:14.865801"}
{"arxiv_id": "2510.20755v1", "title": "Incomplete U-Statistics of Equireplicate Designs: Berry-Esseen Bound and   Efficient Construction", "summary": "U-statistics are a fundamental class of estimators that generalize the sample mean and underpin much of nonparametric statistics. Although extensively studied in both statistics and probability, key challenges remain: their high computational cost - addressed partly through incomplete U-statistics - and their non-standard asymptotic behavior in the degenerate case, which typically requires resampling methods for hypothesis testing. This paper presents a novel perspective on U-statistics, grounded in hypergraph theory and combinatorial designs. Our approach bypasses the traditional Hoeffding decomposition, the main analytical tool in this literature but one highly sensitive to degeneracy. By characterizing the dependence structure of a U-statistic, we derive a Berry-Esseen bound that applies to all incomplete U-statistics of deterministic designs, yielding conditions under which Gaussian limiting distributions can be established even in the degenerate case and when the order diverges. We also introduce efficient algorithms to construct incomplete U-statistics of equireplicate designs, a subclass of deterministic designs that, in certain cases, achieve minimum variance. Finally, we apply our framework to kernel-based tests that use Maximum Mean Discrepancy (MMD) and Hilbert-Schmidt Independence Criterion. In a real data example with CIFAR-10, our permutation-free MMD test delivers substantial computational gains while retaining power and type I error control.", "published": "2025-10-23T17:21:54Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.865975"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:14.866119"}
{"arxiv_id": "2510.20751v1", "title": "Black Hole-Host Galaxy Correlations with Machine Learning: A Comparative   Study of Illustris, TNG, and EAGLE", "summary": "Supermassive black holes (SMBHs) are known to correlate with many properties of their host galaxies, but we do not fully understand these correlations. The strengths (tightness) of these correlations have also been widely debated. In this work, we explore SMBH-host relations in three state-of-the-art cosmological simulations: Illustris, TNG, and EAGLE. Using a variety of machine learning regressors, we measure the scaling relations between black hole mass ($M_{\\rm BH}$) and galaxy properties including stellar velocity dispersion ($\\sigma$), stellar mass ($M_{\\star}$), dark matter halo mass ($M_{\\rm Halo}$), and the Sersic index. We find that machine learning regressors provide predictive capabilities superior to linear regression in many scaling relations in simulations, and Multi-layer Perceptron (MLP) regressor has the strongest performance. SMBH-host relations have different strengths in different simulations as a result of their sub-grid models. Similar to the observations, the $M_{\\rm BH} $-$\\sigma$ relation is a strong correlation in all simulations, but in TNG, the $M_{\\rm BH} $-$M_{\\star}$ relation is even tighter than $M_{\\rm BH} $-$\\sigma$. EAGLE produces the weakest SMBH-host correlations among all simulations. Low mass SMBHs tend to be poorly correlated with their host galaxies, but including them can still help machines better grasp the correlations in Illustris and TNG. Combining galaxy properties that strongly correlate with $M_{\\rm BH} $ but poorly correlate with each other can improve MLP's performance. $M_{\\rm BH} $ is most accurately predicted when all galaxy properties are included in the training, suggesting that SMBH-host correlations are fundamentally multi-dimensional in these simulations.", "published": "2025-10-23T17:17:23Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.866309"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:14.866480"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "brain machine interface", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.866637"}
{"arxiv_id": "2510.20742v1", "title": "Bayesian Prediction under Moment Conditioning", "summary": "Prediction is a central task of statistics and machine learning, yet many inferential settings provide only partial information, typically in the form of moment constraints or estimating equations. We develop a finite, fully Bayesian framework for propagating such partial information through predictive distributions. Building on de Finetti's representation theorem, we construct a curvature-adaptive version of exchangeable updating that operates directly under finite constraints, yielding an explicit discrete-Gaussian mixture that quantifies predictive uncertainty. The resulting finite-sample bounds depend on the smallest eigenvalue of the information-geometric Hessian, which measures the curvature and identification strength of the constraint manifold. This approach unifies empirical likelihood, Bayesian empirical likelihood, and generalized method-of-moments estimation within a common predictive geometry. On the operational side, it provides computable curvature-sensitive uncertainty bounds for constrained prediction; on the theoretical side, it recovers de Finetti's coherence, Doob's martingale convergence and local asymptotic normality as limiting cases of the same finite mechanism. Our framework thus offers a constructive bridge between partial information and full Bayesian prediction.", "published": "2025-10-23T17:03:17Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:14.866789"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "brain machine interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.866948"}
{"arxiv_id": "2510.20736v1", "title": "Amplifying Prominent Representations in Multimodal Learning via   Variational Dirichlet Process", "summary": "Developing effective multimodal fusion approaches has become increasingly essential in many real-world scenarios, such as health care and finance. The key challenge is how to preserve the feature expressiveness in each modality while learning cross-modal interactions. Previous approaches primarily focus on the cross-modal alignment, while over-emphasis on the alignment of marginal distributions of modalities may impose excess regularization and obstruct meaningful representations within each modality. The Dirichlet process (DP) mixture model is a powerful Bayesian non-parametric method that can amplify the most prominent features by its richer-gets-richer property, which allocates increasing weights to them. Inspired by this unique characteristic of DP, we propose a new DP-driven multimodal learning framework that automatically achieves an optimal balance between prominent intra-modal representation learning and cross-modal alignment. Specifically, we assume that each modality follows a mixture of multivariate Gaussian distributions and further adopt DP to calculate the mixture weights for all the components. This paradigm allows DP to dynamically allocate the contributions of features and select the most prominent ones, leveraging its richer-gets-richer property, thus facilitating multimodal feature fusion. Extensive experiments on several multimodal datasets demonstrate the superior performance of our model over other competitors. Ablation analysis further validates the effectiveness of DP in aligning modality distributions and its robustness to changes in key hyperparameters. Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git", "published": "2025-10-23T16:53:24Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.867144"}
{"arxiv_id": "2510.20733v1", "title": "Thought Communication in Multiagent Collaboration", "summary": "Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, thought communication, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.", "published": "2025-10-23T16:48:02Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.867343"}
{"arxiv_id": "2510.20727v1", "title": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related   Toxicities from Clinical Notes Using Natural Language Processing", "summary": "Objective: Fluoropyrimidines are widely prescribed for colorectal and breast cancers, but are associated with toxicities such as hand-foot syndrome and cardiotoxicity. Since toxicity documentation is often embedded in clinical notes, we aimed to develop and evaluate natural language processing (NLP) methods to extract treatment and toxicity information.   Materials and Methods: We constructed a gold-standard dataset of 236 clinical notes from 204,165 adult oncology patients. Domain experts annotated categories related to treatment regimens and toxicities. We developed rule-based, machine learning-based (Random Forest, Support Vector Machine [SVM], Logistic Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language models (LLM)-based NLP approaches (zero-shot and error-analysis prompting). Models used an 80:20 train-test split.   Results: Sufficient data existed to train and evaluate 5 annotated categories. Error-analysis prompting achieved optimal precision, recall, and F1 scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot prompting reached F1=1.000 for treatment and F1=0.876 for toxicities extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods served as our baseline with F1 scores of 0.857 in treatment and 0.858 in toxicities.   Discussion: LMM-based approaches outperformed all others, followed by machine learning methods. Machine and deep learning approaches were limited by small training data and showed limited generalizability, particularly for rare categories.   Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine treatment and toxicity information from clinical notes, and has strong potential to support oncology research and pharmacovigilance.", "published": "2025-10-23T16:44:39Z", "query": "brain machine interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:14.867544"}
{"arxiv_id": "2510.02979v1", "title": "Towards Electrophysiological and Histological Mapping of Upper Limb   Nerves in Pigs Using Epineural Stimulation", "summary": "Understanding the relationship between nerve anatomy and the functional outcomes of electrical stimulation is critical for optimizing neural interface design. In this study, we conducted acute experiments on four pigs in which epineural cuff electrodes with multiple contacts were placed around upper limb nerves. A subset of electrical stimulation configurations -- previously identified via computational study -- was applied, and the resulting evoked electromyographic (EMG) responses were recorded from target muscles. Muscle recruitment curves were extracted and analysed offline to quantify activation patterns. Following the electrophysiological experiments, the stimulated nerves were harvested and processed for histological analysis to visualize fascicular organization and distribution. This work presents preliminary results from the combined analysis of muscle activation profiles and fascicle anatomy in one animal. Our findings aim to inform the design of stimulation strategies by linking electrode configuration to selective muscle recruitment, ultimately contributing to more effective neuromodulation and neuroprosthetic applications.", "published": "2025-10-03T13:12:53Z", "query": "neuroprosthetics", "relevance": 0.49999999999999994, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.401727"}
{"arxiv_id": "2509.19957v1", "title": "Interactive Semantic Segmentation for Phosphene Vision Neuroprosthetics", "summary": "Visual impairments present significant challenges to individuals worldwide, impacting daily activities and quality of life. Visual neuroprosthetics offer a promising solution, leveraging advancements in technology to provide a simplified visual sense through devices comprising cameras, computers, and implanted electrodes. This study investigates user-centered design principles for a phosphene vision algorithm, utilizing feedback from visually impaired individuals to guide the development of a gaze-controlled semantic segmentation system. We conducted interviews revealing key design principles. These principles informed the implementation of a gaze-guided semantic segmentation algorithm using the Segment Anything Model (SAM). In a simulated phosphene vision environment, participants performed object detection tasks under SAM, edge detection, and normal vision conditions. SAM improved identification accuracy over edge detection, remained effective in complex scenes, and was particularly robust for specific object shapes. These findings demonstrate the value of user feedback and the potential of gaze-guided semantic segmentation to enhance neuroprosthetic vision.", "published": "2025-09-24T10:08:18Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.402365"}
{"arxiv_id": "2507.14339v1", "title": "Fiduciary AI for the Future of Brain-Technology Interactions", "summary": "Brain foundation models represent a new frontier in AI: instead of processing text or images, these models interpret real-time neural signals from EEG, fMRI, and other neurotechnologies. When integrated with brain-computer interfaces (BCIs), they may enable transformative applications-from thought controlled devices to neuroprosthetics-by interpreting and acting on brain activity in milliseconds. However, these same systems pose unprecedented risks, including the exploitation of subconscious neural signals and the erosion of cognitive liberty. Users cannot easily observe or control how their brain signals are interpreted, creating power asymmetries that are vulnerable to manipulation. This paper proposes embedding fiduciary duties-loyalty, care, and confidentiality-directly into BCI-integrated brain foundation models through technical design. Drawing on legal traditions and recent advancements in AI alignment techniques, we outline implementable architectural and governance mechanisms to ensure these systems act in users' best interests. Placing brain foundation models on a fiduciary footing is essential to realizing their potential without compromising self-determination.", "published": "2025-07-18T19:34:08Z", "query": "neuroprosthetics", "relevance": 0.9000000000000001, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:18.402954"}
{"arxiv_id": "2506.13400v1", "title": "Realtime-Capable Hybrid Spiking Neural Networks for Neural Decoding of   Cortical Activity", "summary": "Intra-cortical brain-machine interfaces (iBMIs) present a promising solution to restoring and decoding brain activity lost due to injury. However, patients with such neuroprosthetics suffer from permanent skull openings resulting from the devices' bulky wiring. This drives the development of wireless iBMIs, which demand low power consumption and small device footprint. Most recently, spiking neural networks (SNNs) have been researched as potential candidates for low-power neural decoding. In this work, we present the next step of utilizing SNNs for such tasks, building on the recently published results of the 2024 Grand Challenge on Neural Decoding Challenge for Motor Control of non-Human Primates. We optimize our model architecture to exceed the existing state of the art on the Primate Reaching dataset while maintaining similar resource demand through various compression techniques. We further focus on implementing a realtime-capable version of the model and discuss the implications of this architecture. With this, we advance one step towards latency-free decoding of cortical spike trains using neuromorphic technology, ultimately improving the lives of millions of paralyzed patients.", "published": "2025-06-16T12:08:08Z", "query": "neuroprosthetics", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.403379"}
{"arxiv_id": "2504.21427v1", "title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of   Clustering-Based Classifiers", "summary": "Accurate classification of EEG signals is crucial for brain-computer interfaces (BCIs) and neuroprosthetic applications, yet many existing methods fail to account for the non-Euclidean, manifold structure of EEG data, resulting in suboptimal performance. Preserving this manifold information is essential to capture the true geometry of EEG signals, but traditional classification techniques largely overlook this need. To this end, we propose MPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers), that introduces two key innovations: (1) a feature engineering phase that combines covariance matrices and Radial Basis Function (RBF) kernels to capture both linear and non-linear relationships among EEG channels, and (2) a clustering phase that employs a modified K-means algorithm tailored for the Riemannian manifold space, ensuring local geometric sensitivity. Ensembling multiple clustering-based classifiers, MPEC achieves superior results, validated by significant improvements on the BCI Competition IV dataset 2a.", "published": "2025-04-30T08:34:15Z", "query": "neuroprosthetics", "relevance": 0.7000000000000001, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:18.403681"}
{"arxiv_id": "2504.11936v3", "title": "Mind2Matter: Creating 3D Models from EEG Signals", "summary": "The reconstruction of 3D objects from brain signals has gained significant attention in brain-computer interface (BCI) research. Current research predominantly utilizes functional magnetic resonance imaging (fMRI) for 3D reconstruction tasks due to its excellent spatial resolution. Nevertheless, the clinical utility of fMRI is limited by its prohibitive costs and inability to support real-time operations. In comparison, electroencephalography (EEG) presents distinct advantages as an affordable, non-invasive, and mobile solution for real-time brain-computer interaction systems. While recent advances in deep learning have enabled remarkable progress in image generation from neural data, decoding EEG signals into structured 3D representations remains largely unexplored. In this paper, we propose a novel framework that translates EEG recordings into 3D object reconstructions by leveraging neural decoding techniques and generative models. Our approach involves training an EEG encoder to extract spatiotemporal visual features, fine-tuning a large language model to interpret these features into descriptive multimodal outputs, and leveraging generative 3D Gaussians with layout-guided control to synthesize the final 3D structures. Experiments demonstrate that our model captures salient geometric and semantic features, paving the way for applications in brain-computer interfaces (BCIs), virtual reality, and neuroprosthetics. Our code is available in https://github.com/sddwwww/Mind2Matter.", "published": "2025-04-16T10:16:03Z", "query": "neuroprosthetics", "relevance": 1.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.403998"}
{"arxiv_id": "2502.06672v2", "title": "Efficient Spatial Estimation of Perceptual Thresholds for Retinal   Implants via Gaussian Process Regression", "summary": "Retinal prostheses restore vision by electrically stimulating surviving neurons, but calibrating perceptual thresholds (i.e., the minimum stimulus intensity required for perception) remains a time-intensive challenge, especially for high-electrode-count devices. Since neighboring electrodes exhibit spatial correlations, we propose a Gaussian Process Regression (GPR) framework to predict thresholds at unsampled locations while leveraging uncertainty estimates to guide adaptive sampling. Using perceptual threshold data from four Argus II users, we show that GPR with a Matern kernel provides more accurate threshold predictions than a Radial Basis Function (RBF) kernel (p &lt; .001, Wilcoxon signed-rank test). In addition, spatially optimized sampling yielded lower prediction error than uniform random sampling for Participants 1 and 3 (p &lt; .05). While adaptive sampling dynamically selects electrodes based on model uncertainty, its accuracy gains over spatial sampling were not statistically significant (p &gt; .05), though it approached significance for Participant 1 (p = .074). These findings establish GPR with spatial sampling as a scalable, efficient approach to retinal prosthesis calibration, minimizing patient burden while maintaining predictive accuracy. More broadly, this framework offers a generalizable solution for adaptive calibration in neuroprosthetic devices with spatially structured stimulation thresholds, paving the way for faster, more personalized system fitting in future high-channel-count implants. Clinical relevance: Gaussian Progress Regression offers a scalable path toward faster, more personalized calibration procedures for future high-channel-count neuroprosthetic devices.", "published": "2025-02-10T16:59:15Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.404320"}
{"arxiv_id": "2502.05554v1", "title": "Evaluating Cross-Subject and Cross-Device Consistency in Visual Fixation   Prediction", "summary": "Understanding cross-subject and cross-device consistency in visual fixation prediction is essential for advancing eye-tracking applications, including visual attention modeling and neuroprosthetics. This study evaluates fixation consistency using an embedded eye tracker integrated into regular-sized glasses, comparing its performance with high-end standalone eye-tracking systems. Nine participants viewed 300 images from the MIT1003 dataset in subjective experiments, allowing us to analyze cross-device and cross-subject variations in fixation patterns with various evaluation metrics. Our findings indicate that average visual fixations can be reliably transferred across devices for relatively simple stimuli. However, individual-to-average consistency remains weak, highlighting the challenges of predicting individual fixations across devices. These results provide an empirical foundation for leveraging predicted average visual fixation data to enhance neuroprosthetic applications.", "published": "2025-02-08T12:54:00Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.404512"}
{"arxiv_id": "2501.08025v2", "title": "Analysis of Power Losses and the Efficacy of Power Minimization   Strategies in Multichannel Electrical Stimulation Systems", "summary": "Neuroprosthetic devices require multichannel stimulator systems with an increasing number of channels. However, there are inherent power losses in typical multichannel stimulation circuits caused by a mismatch between the power supply voltage and the voltage required at each electrode to successfully stimulate tissue. This imposes a bottleneck towards high-channel-count devices, which is particularly severe in wirelessly-powered devices. Hence, advances in the power efficiency of stimulation systems are critical. To support these advances, this paper presents a methodology to identify and quantify power losses associated with different power supply scaling strategies in multichannel stimulation systems. The proposed methodology utilizes distributions of stimulation amplitudes and electrode impedances to calculate power losses in multichannel systems. Experimental data from previously published studies spanning various stimulation applications were analyzed to evaluate the performance of fixed, global, and stepped supply scaling methods, focusing on their impact on power dissipation and efficiency. Variability in output conditions results in low power efficiency in multichannel stimulation systems across all applications. Stepped voltage scaling demonstrated substantial efficiency improvements, achieving an increase of 67 % to 146 %, particularly in high-channel-count applications with significant variability in tissue impedance. Global scaling, by contrast, was more advantageous for systems with fewer channels. The findings highlight the importance of tailoring power management strategies to specific applications to optimize efficiency while minimizing system complexity. The proposed methodology offers a framework for evaluating efficiency-complexity trade-offs, advancing the design of scalable neurostimulation systems.", "published": "2025-01-14T11:28:02Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:18.404776"}
{"arxiv_id": "2409.04428v2", "title": "Hybrid Spiking Neural Networks for Low-Power Intra-Cortical   Brain-Machine Interfaces", "summary": "Intra-cortical brain-machine interfaces (iBMIs) have the potential to dramatically improve the lives of people with paraplegia by restoring their ability to perform daily activities. However, current iBMIs suffer from scalability and mobility limitations due to bulky hardware and wiring. Wireless iBMIs offer a solution but are constrained by a limited data rate. To overcome this challenge, we are investigating hybrid spiking neural networks for embedded neural decoding in wireless iBMIs. The networks consist of a temporal convolution-based compression followed by recurrent processing and a final interpolation back to the original sequence length. As recurrent units, we explore gated recurrent units (GRUs), leaky integrate-and-fire (LIF) neurons, and a combination of both - spiking GRUs (sGRUs) and analyze their differences in terms of accuracy, footprint, and activation sparsity. To that end, we train decoders on the \"Nonhuman Primate Reaching with Multichannel Sensorimotor Cortex Electrophysiology\" dataset and evaluate it using the NeuroBench framework, targeting both tracks of the IEEE BioCAS Grand Challenge on Neural Decoding. Our approach achieves high accuracy in predicting velocities of primate reaching movements from multichannel primary motor cortex recordings while maintaining a low number of synaptic operations, surpassing the current baseline models in the NeuroBench framework. This work highlights the potential of hybrid neural networks to facilitate wireless iBMIs with high decoding precision and a substantial increase in the number of monitored neurons, paving the way toward more advanced neuroprosthetic technologies.", "published": "2024-09-06T17:48:44Z", "query": "neuroprosthetics", "relevance": 0.44999999999999996, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.404935"}
{"arxiv_id": "2408.01729v1", "title": "A Survey on Robotic Prosthetics: Neuroprosthetics, Soft Actuators, and   Control Strategies", "summary": "The field of robotics is a quickly evolving feat of technology that accepts contributions from various genres of science. Neuroscience, Physiology, Chemistry, Material science, Computer science, and the wide umbrella of mechatronics have all simultaneously contributed to many innovations in the prosthetic applications of robotics. This review begins with a discussion of the scope of the term robotic prosthetics and discusses the evolving domain of Neuroprosthetics. The discussion is then constrained to focus on various actuation and control strategies for robotic prosthetic limbs. This review discusses various soft robotic actuators such as EAP, SMA, FFA, etc., and the merits of such actuators over conventional hard robotic actuators. Options in control strategies for robotic prosthetics, that are in various states of research and development, are reviewed. This paper concludes the discussion with an analysis regarding the prospective direction in which this field of robotic prosthetics is evolving in terms of actuation, control, and other features relevant to artificial limbs. This paper intends to review some of the emerging research and development trends in the field of robotic prosthetics and summarize many tangents that are represented under this broad domain in an approachable manner.", "published": "2024-08-03T10:01:44Z", "query": "neuroprosthetics", "relevance": 0.2, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.405084"}
{"arxiv_id": "2407.14020v1", "title": "NeuroBind: Towards Unified Multimodal Representations for Neural Signals", "summary": "Understanding neural activity and information representation is crucial for advancing knowledge of brain function and cognition. Neural activity, measured through techniques like electrophysiology and neuroimaging, reflects various aspects of information processing. Recent advances in deep neural networks offer new approaches to analyzing these signals using pre-trained models. However, challenges arise due to discrepancies between different neural signal modalities and the limited scale of high-quality neural data. To address these challenges, we present NeuroBind, a general representation that unifies multiple brain signal types, including EEG, fMRI, calcium imaging, and spiking data. To achieve this, we align neural signals in these image-paired neural datasets to pre-trained vision-language embeddings. Neurobind is the first model that studies different neural modalities interconnectedly and is able to leverage high-resource modality models for various neuroscience tasks. We also showed that by combining information from different neural signal modalities, NeuroBind enhances downstream performance, demonstrating the effectiveness of the complementary strengths of different neural modalities. As a result, we can leverage multiple types of neural signals mapped to the same space to improve downstream tasks, and demonstrate the complementary strengths of different neural modalities. This approach holds significant potential for advancing neuroscience research, improving AI systems, and developing neuroprosthetics and brain-computer interfaces.", "published": "2024-07-19T04:42:52Z", "query": "neuroprosthetics", "relevance": 0.6, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:18.405343"}
{"arxiv_id": "2407.09166v1", "title": "68-Channel Highly-Integrated Neural Signal Processing PSoC with On-Chip   Feature Extraction, Compression, and Hardware Accelerators for   Neuroprosthetics in 22nm FDSOI", "summary": "Multi-channel electrophysiology systems for recording of neuronal activity face significant data throughput limitations, hampering real-time, data-informed experiments. These limitations impact both experimental neurobiology research and next-generation neuroprosthetics. We present a novel solution that leverages the high integration density of 22nm FDSOI CMOS technology to address these challenges. The proposed highly integrated programmable System-on-Chip comprises 68-channel 0.41 \\textmu W/Ch recording frontends, spike detectors, 16-channel 0.87-4.39 \\textmu W/Ch action potential and 8-channel 0.32 \\textmu W/Ch local field potential codecs, as well as a MAC-assisted power-efficient processor operating at 25 MHz (5.19 \\textmu W/MHz). The system supports on-chip training processes for compression, training and inference for neural spike sorting. The spike sorting achieves an average accuracy of 91.48% or 94.12% depending on the utilized features. The proposed PSoC is optimized for reduced area (9 mm2) and power. On-chip processing and compression capabilities free up the data bottlenecks in data transmission (up to 91% space saving ratio), and moreover enable a fully autonomous yet flexible processor-driven operation. Combined, these design considerations overcome data-bottlenecks by allowing on-chip feature extraction and subsequent compression.", "published": "2024-07-12T11:00:52Z", "query": "neuroprosthetics", "relevance": 0.39999999999999997, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:18.405730"}
{"arxiv_id": "2402.09447v2", "title": "Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and   Natural Grasp Types", "summary": "This research aims to decode hand grasps from Electroencephalograms (EEGs) for dexterous neuroprosthetic development and Brain-Computer Interface (BCI) applications, especially for patients with motor disorders. Particularly, it focuses on distinguishing two complex natural power and precision grasps in addition to a neutral condition as a no-movement condition using a new EEG-based BCI platform and wavelet signal processing. Wavelet analysis involved generating time-frequency and topographic maps from wavelet power coefficients. Then, by using machine learning techniques with novel wavelet features, we achieved high average accuracies: 85.16% for multiclass, 95.37% for No-Movement vs Power, 95.40% for No-Movement vs Precision, and 88.07% for Power vs Precision, demonstrating the effectiveness of these features in EEG-based grasp differentiation. In contrast to previous studies, a critical part of our study was permutation feature importance analysis, which highlighted key features for grasp classification. It revealed that the most crucial brain activities during grasping occur in the motor cortex, within the alpha and beta frequency bands. These insights demonstrate the potential of wavelet features in real-time neuroprosthetic technology and BCI applications.", "published": "2024-01-31T23:13:38Z", "query": "neuroprosthetics", "relevance": 0.8500000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.406153"}
{"arxiv_id": "2312.06956v1", "title": "Robotics Applications in Neurology: A Review of Recent Advancements and   Future Directions", "summary": "Robotic technology has the potential to revolutionize the field of neurology by providing new methods for diagnosis, treatment, and rehabilitation of neurological disorders. In recent years, there has been an increasing interest in the development of robotics applications for neurology, driven by advances in sensing, actuation, and control systems. This review paper provides a comprehensive overview of the recent advancements in robotics technology for neurology, with a focus on three main areas: diagnosis, treatment, and rehabilitation. In the area of diagnosis, robotics has been used for developing new imaging techniques and tools for more accurate and non-invasive mapping of brain structures and functions. For treatment, robotics has been used for developing minimally invasive surgical procedures, including stereotactic and endoscopic approaches, as well as for the delivery of therapeutic agents to specific targets in the brain. In rehabilitation, robotics has been used for developing assistive devices and platforms for motor and cognitive training of patients with neurological disorders. The paper also discusses the challenges and limitations of current robotics technology for neurology, including the need for more reliable and precise sensing and actuation systems, the development of better control algorithms, and the ethical implications of robotic interventions in the human brain. Finally, the paper outlines future directions and opportunities for robotics applications in neurology, including the integration of robotics with other emerging technologies, such as neuroprosthetics, artificial intelligence, and virtual reality. Overall, this review highlights the potential of robotics technology to transform the field of neurology and improve the lives of patients with neurological disorders.", "published": "2023-12-12T03:32:34Z", "query": "neuroprosthetics", "relevance": 0.39999999999999997, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.406664"}
{"arxiv_id": "2306.13104v2", "title": "Human-in-the-Loop Optimization for Deep Stimulus Encoding in Visual   Prostheses", "summary": "Neuroprostheses show potential in restoring lost sensory function and enhancing human capabilities, but the sensations produced by current devices often seem unnatural or distorted. Exact placement of implants and differences in individual perception lead to significant variations in stimulus response, making personalized stimulus optimization a key challenge. Bayesian optimization could be used to optimize patient-specific stimulation parameters with limited noisy observations, but is not feasible for high-dimensional stimuli. Alternatively, deep learning models can optimize stimulus encoding strategies, but typically assume perfect knowledge of patient-specific variations. Here we propose a novel, practically feasible approach that overcomes both of these fundamental limitations. First, a deep encoder network is trained to produce optimal stimuli for any individual patient by inverting a forward model mapping electrical stimuli to visual percepts. Second, a preferential Bayesian optimization strategy utilizes this encoder to optimize patient-specific parameters for a new patient, using a minimal number of pairwise comparisons between candidate stimuli. We demonstrate the viability of this approach on a novel, state-of-the-art visual prosthesis model. We show that our approach quickly learns a personalized stimulus encoder, leads to dramatic improvements in the quality of restored vision, and is robust to noisy patient feedback and misspecifications in the underlying forward model. Overall, our results suggest that combining the strengths of deep learning and Bayesian optimization could significantly improve the perceptual experience of patients fitted with visual prostheses and may prove a viable solution for a range of neuroprosthetic technologies.", "published": "2023-06-16T18:49:51Z", "query": "neuroprosthetics", "relevance": 0.5499999999999999, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.406854"}
{"arxiv_id": "2305.04588v1", "title": "Hardware implementation of the ring generator with tunable frequency   based on electronic neurons", "summary": "Constructing electronic models of neurons has several applications including reproducing dynamics of biological neurons and their networks and neuroprosthetics. In the brain, most neurons themselves are in a non-oscillatory mode, and brain rhythms arise due to their collective dynamics. In this case, very small ensembles of neurons can act as rhythm generators. such ensembles can be constructed and study within the framework of a radiophysical experiment. In this work, a circuit of a ring rhythm generator was created from several (from two to eight) FitzHugh--Nagumo electronic oscillators with electronic synapses (sigmoid coupling function and delay were implemented). Oscillatory modes were shown to be possible in this circuit as a result of collective dynamics, with the frequency being controlled by means of a delay in the synapse and/or changing the number of elements in the ring. For some parameter values, there were multistability modes, when the implementation of a specific oscillatory regime was determined by initial conditions or could be achieved by a short-term external driving. The constructed generator well models the switching of the main frequency in brain local field potentials at limbic epilepsy, but can be used independently as well.", "published": "2023-05-08T09:56:44Z", "query": "neuroprosthetics", "relevance": 0.2, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.407014"}
{"arxiv_id": "2210.11478v2", "title": "Neural Co-Processors for Restoring Brain Function: Results from a   Cortical Model of Grasping", "summary": "Objective: A major challenge in designing closed-loop brain-computer interfaces is finding optimal stimulation patterns as a function of ongoing neural activity for different subjects and objectives. Approach: To achieve goal-directed closed-loop neurostimulation, we propose \"neural co-processors\" which use artificial neural networks and deep learning to learn optimal closed-loop stimulation policies, shaping neural activity and bridging injured neural circuits for targeted repair and rehabilitation. The co-processor adapts the stimulation policy as the biological circuit itself adapts to the stimulation, achieving a form of brain-device co-adaptation. Here we use simulations to lay the groundwork for future in vivo tests of neural co-processors. We leverage a cortical model of grasping, to which we applied various forms of simulated lesions, allowing us to develop the critical learning algorithms and study adaptations to non-stationarity. Main results: Our simulations show the ability of a neural co-processor to learn a stimulation policy using a supervised learning approach, and to adapt that policy as the underlying brain and sensors change. Our co-processor successfully co-adapted with the simulated brain to accomplish the reach-and-grasp task after a variety of lesions were applied, achieving recovery towards healthy function. Significance: Our results provide the first proof-of-concept demonstration of a co-processor for adaptive activity-dependent closed-loop neurostimulation, optimizing for a rehabilitation goal. While a gap remains between simulations and applications, our results provide insights on how co-processors may be developed for learning complex adaptive stimulation policies for a variety of neural rehabilitation and neuroprosthetic applications.", "published": "2022-10-19T04:13:33Z", "query": "neuroprosthetics", "relevance": 0.6, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.407174"}
{"arxiv_id": "2209.08020v1", "title": "Ferroelectricity and resistive switching in BaTiO$_3$ thin films with   liquid electrolyte top contact for bioelectronic devices", "summary": "We investigate ferroelectric- and resistive switching behavior in 18-nm-thick epitaxial BaTiO$_3$ (BTO) films in a model electrolyte-ferroelectric-semiconductor (EFS) configuration. The system is explored for its potential as a ferroelectric microelectrode in bioelectronics. The BTO films are grown by pulsed laser deposition (PLD) on semiconducting Nb-doped (0.5 wt\\%) SrTiO$_{3}$ (Nb:STO) single crystal substrates. The ferroelectric properties of the bare BTO films are demonstrated by piezoresponse force microscopy (PFM) measurements. Cyclic voltammetry (CV) measurements in EFS configuration, with phosphate buffered saline (PBS) acting as the liquid electrolyte top contact, indicate characteristic ferroelectric switching peaks in the bipolar current-voltage loop. The ferroelectric nature of the observed switching peaks is confirmed by analyzing the current response of the EFS devices to unipolar voltage signals. Moreover, electrochemical impedance spectroscopy (EIS) measurements indicate bipolar resisitive switching behavior of the EFS devices, which is controlled by the remanent polarization state of the BTO layer. Our results represent a constitutive step towards the realization of neuroprosthetic implants and hybrid neurocomputational systems based on ferroelectric microelectrodes.", "published": "2022-09-16T16:06:36Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:18.407349"}
{"arxiv_id": "2205.13623v2", "title": "Hybrid Neural Autoencoders for Stimulus Encoding in Visual and Other   Sensory Neuroprostheses", "summary": "Sensory neuroprostheses are emerging as a promising technology to restore lost sensory function or augment human capabilities. However, sensations elicited by current devices often appear artificial and distorted. Although current models can predict the neural or perceptual response to an electrical stimulus, an optimal stimulation strategy solves the inverse problem: what is the required stimulus to produce a desired response? Here, we frame this as an end-to-end optimization problem, where a deep neural network stimulus encoder is trained to invert a known and fixed forward model that approximates the underlying biological system. As a proof of concept, we demonstrate the effectiveness of this Hybrid Neural Autoencoder (HNA) in visual neuroprostheses. We find that HNA produces high-fidelity patient-specific stimuli representing handwritten digits and segmented images of everyday objects, and significantly outperforms conventional encoding strategies across all simulated patients. Overall this is an important step towards the long-standing challenge of restoring high-quality vision to people living with incurable blindness and may prove a promising solution for a variety of neuroprosthetic technologies.", "published": "2022-05-26T20:52:00Z", "query": "neuroprosthetics", "relevance": 0.25, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.407472"}
{"arxiv_id": "2205.10723v2", "title": "Stochastic Models of Neuronal Growth", "summary": "Neuronal circuits arise as axons and dendrites extend, navigate, and connect to target cells. Axonal growth, in particular, integrates deterministic guidance from substrate mechanics and geometry with stochastic fluctuations generated by signaling, molecular detection, cytoskeletal assembly, and growth cone dynamics. A comprehensive quantitative description of this process remains incomplete. We review stochastic models in which Langevin dynamics and the associates Fokker-Planck equation capture axonal motion and turning under combined biases and noise. Paired with experiments, these models yield key parameters, including effective diffusion (motility) coefficients, speed and angle distributions, mean-square displacement, and mechanical measures of cell-substrate coupling, thereby linking single-cell biophysics and intercellular interactions to collective growth statistics and network formation. We further couple the Fokker-Planck description to a mechanochemical actin-myosin-clutch model and perform a linear stability analysis of the resulting dynamics. Routh--Hurwitz criteria identify regimes of steady extension, damped oscillations, and Hopf bifurcations that generate sustained limit cycles. Together, these results clarify the mechanisms that govern axonal guidance and connectivity and inform the design of engineered substrates and neuroprosthetic scaffolds aimed at enhancing nerve repair and regeneration.", "published": "2022-05-22T03:21:54Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:18.407638"}
{"arxiv_id": "2203.08648v1", "title": "Artificial Intelligence Enables Real-Time and Intuitive Control of   Prostheses via Nerve Interface", "summary": "Objective: The next generation prosthetic hand that moves and feels like a real hand requires a robust neural interconnection between the human minds and machines. Methods: Here we present a neuroprosthetic system to demonstrate that principle by employing an artificial intelligence (AI) agent to translate the amputee's movement intent through a peripheral nerve interface. The AI agent is designed based on the recurrent neural network (RNN) and could simultaneously decode six degree-of-freedom (DOF) from multichannel nerve data in real-time. The decoder's performance is characterized in motor decoding experiments with three human amputees. Results: First, we show the AI agent enables amputees to intuitively control a prosthetic hand with individual finger and wrist movements up to 97-98% accuracy. Second, we demonstrate the AI agent's real-time performance by measuring the reaction time and information throughput in a hand gesture matching task. Third, we investigate the AI agent's long-term uses and show the decoder's robust predictive performance over a 16-month implant duration. Conclusion &amp; significance: Our study demonstrates the potential of AI-enabled nerve technology, underling the next generation of dexterous and intuitive prosthetic hands.", "published": "2022-03-16T14:33:38Z", "query": "neuroprosthetics", "relevance": 0.2, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.407776"}
{"arxiv_id": "2103.13452v1", "title": "A Portable, Self-Contained Neuroprosthetic Hand with Deep Learning-Based   Finger Control", "summary": "Objective: Deep learning-based neural decoders have emerged as the prominent approach to enable dexterous and intuitive control of neuroprosthetic hands. Yet few studies have materialized the use of deep learning in clinical settings due to its high computational requirements. Methods: Recent advancements of edge computing devices bring the potential to alleviate this problem. Here we present the implementation of a neuroprosthetic hand with embedded deep learning-based control. The neural decoder is designed based on the recurrent neural network (RNN) architecture and deployed on the NVIDIA Jetson Nano - a compacted yet powerful edge computing platform for deep learning inference. This enables the implementation of the neuroprosthetic hand as a portable and self-contained unit with real-time control of individual finger movements. Results: The proposed system is evaluated on a transradial amputee using peripheral nerve signals (ENG) with implanted intrafascicular microelectrodes. The experiment results demonstrate the system's capabilities of providing robust, high-accuracy (95-99%) and low-latency (50-120 msec) control of individual finger movements in various laboratory and real-world environments. Conclusion: Modern edge computing platforms enable the effective use of deep learning-based neural decoders for neuroprosthesis control as an autonomous system. Significance: This work helps pioneer the deployment of deep neural networks in clinical applications underlying a new class of wearable biomedical devices with embedded artificial intelligence.", "published": "2021-03-24T19:11:58Z", "query": "neuroprosthetics", "relevance": 0.25, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.407938"}
{"arxiv_id": "2103.00592v1", "title": "Stochastic Memristive Interface between Electronic FitzHugh-Nagumo   Neurons", "summary": "The dynamics of memristive device in response to neuron-like signals and coupling electronic neurons via memristive device has been investigated theoretically and experimentally. The simplest experimental system consists of electronic circuit based on the FitzHugh-Nagumo model and metal-oxide memristive device. The hardware-software complex based on commercial data acquisition system is implemented for the imitation of signal from presynaptic neuron`s membrane and synaptic signal transmission between neurons. The main advantage of our system is that it uses real time dynamics of memristive device. Electrical response of memristive device shows its behavioral flexibility that allows presenting a memristive device as an active synapse. This means an internal adjustment of the parameters of memristive device that leads to modulation of neuron-like signals. Physics-based dynamical model of memristor is developed in MATLAB for numerical simulation of such a memristive interface to describe and predict experimentally observed regularities of synchronization of neuron-like oscillators. FitzHugh-Nagumo circuits time series with a linear or stepwise increase in the signal amplitude are used to study the memristor response and coupling of neuron-like oscillators taking into account the stochasticity of memristor model to compare the numerical and experimental data. The observed forced synchronization modes characterize the dynamic complexity of the memristive device, which requires further description using high-order dynamical models. The developed memristive interface will provide high efficiency in the imitation of the synaptic connection due to its stochastic nature and can be used to increase the flexibility of neuronal connections for neuroprosthetic challenges.", "published": "2021-02-28T19:13:31Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:18.408222"}
{"arxiv_id": "2009.09909v1", "title": "Analysing and Measuring the Performance ofMemristive Integrating   Amplifiers", "summary": "Recording reliably extracellular neural activities isan essential prerequisite for the development of bioelectronicsand neuroprosthetic applications. Recently, a fully differential,2-stage, integrating pre-amplifier was proposed for amplifyingand then digitising neural signals. The amplifier featured a finelytuneable offset that was used as a variable threshold detector.Given that the amplifier is integrating, the DC operating pointkeeps changing during integration, rendering traditional analysis(AC/DC) unsuitable. In this work, we analyse the operation ofthis circuit and propose alternative definitions for validating thenecessary key performance metrics, including: gain, bandwidth,offset tuning range and offset sensitivity with respect to thememory states of the employed memristors. The amplificationprocess is analysed largely through investigating the transientbehaviour during the integration phase. This benchmarkingapproach is finally leveraged for providing useful insights anddesign trade-offs of the memristor-based integrating amplifier.", "published": "2020-09-21T14:27:18Z", "query": "neuroprosthetics", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.408391"}
{"arxiv_id": "2009.03272v1", "title": "Graph Convolutional Networks Reveal Neural Connections Encoding   Prosthetic Sensation", "summary": "Extracting stimulus features from neuronal ensembles is of great interest to the development of neuroprosthetics that project sensory information directly to the brain via electrical stimulation. Machine learning strategies that optimize stimulation parameters as the subject learns to interpret the artificial input could improve device efficacy, increase prosthetic performance, ensure stability of evoked sensations, and improve power consumption by eliminating extraneous input. Recent advances extending deep learning techniques to non-Euclidean graph data provide a novel approach to interpreting neuronal spiking activity. For this study, we apply graph convolutional networks (GCNs) to infer the underlying functional relationship between neurons that are involved in the processing of artificial sensory information. Data was collected from a freely behaving rat using a four infrared (IR) sensor, ICMS-based neuroprosthesis to localize IR light sources. We use GCNs to predict the stimulation frequency across four stimulating channels in the prosthesis, which encode relative distance and directional information to an IR-emitting reward port. Our GCN model is able to achieve a peak performance of 73.5% on a modified ordinal regression performance metric in a multiclass classification problem consisting of 7 classes, where chance is 14.3%. Additionally, the inferred adjacency matrix provides a adequate representation of the underlying neural circuitry encoding the artificial sensation.", "published": "2020-08-23T01:43:46Z", "query": "neuroprosthetics", "relevance": 0.44999999999999996, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:18.408568"}
{"arxiv_id": "1811.11876v2", "title": "Towards Neural Co-Processors for the Brain: Combining Decoding and   Encoding in Brain-Computer Interfaces", "summary": "The field of brain-computer interfaces is poised to advance from the traditional goal of controlling prosthetic devices using brain signals to combining neural decoding and encoding within a single neuroprosthetic device. Such a device acts as a \"co-processor\" for the brain, with applications ranging from inducing Hebbian plasticity for rehabilitation after brain injury to reanimating paralyzed limbs and enhancing memory. We review recent progress in simultaneous decoding and encoding for closed-loop control and plasticity induction. To address the challenge of multi-channel decoding and encoding, we introduce a unifying framework for developing brain co-processors based on artificial neural networks and deep learning. These \"neural co-processors\" can be used to jointly optimize cost functions with the nervous system to achieve desired behaviors ranging from targeted neuro-rehabilitation to augmentation of brain function.", "published": "2018-11-28T23:13:24Z", "query": "neuroprosthetics", "relevance": 0.9000000000000001, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:18.408692"}
{"arxiv_id": "1809.00346v1", "title": "A Real-time Control Approach for Unmanned Aerial Vehicles using   Brain-computer Interface", "summary": "Brain-computer interfacing (BCI) is a technology that is almost four decades old and it was developed solely for the purpose of developing and enhancing the impact of neuroprosthetics. However, in the recent times, with the commercialization of non-invasive electroencephalogram (EEG) headsets, the technology has seen a wide variety of applications like home automation, wheelchair control, vehicle steering etc. One of the latest developed applications is the mind-controlled quadrotor unmanned aerial vehicle. These applications, how- ever, do not require a very high-speed response and give satisfactory results when standard classification methods like Support Vector Machine (SVM) and Multi-Layer Perceptron (MLPC). Issues are faced when there is a requirement for high-speed control in the case of fixed-wing unmanned aerial vehicles where such methods are rendered unreliable due to the low speed of classification. Such an application requires the system to classify data at high speeds in order to retain the con- trollability of the vehicle. This paper proposes a novel method of classification which uses a combination of Common Spatial Paradigm and Linear Discriminant Analysis that provides an improved classification accuracy in real time. A non-linear SVM based classification technique has also been discussed. Further, this paper discusses the implementation of the proposed method on a fixed-wing and VTOL unmanned aerial vehicles.", "published": "2018-09-02T14:29:43Z", "query": "neuroprosthetics", "relevance": 0.7000000000000001, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:18.408839"}
{"arxiv_id": "1707.08772v1", "title": "Spike sorting using non-volatile metal-oxide memristors", "summary": "Electrophysiological techniques have improved substantially over the past years to the point that neuroprosthetics applications are becoming viable. This evolution has been fuelled by the advancement of implantable microelectrode technologies that have followed their own version of Moore's scaling law. Similarly to electronics, however, excessive data-rates and strained power budgets require the development of more efficient computation paradigms for handling neural data in-situ, in particular the computationally heavy task of events classification. Here, we demonstrate how the intrinsic analogue programmability of memristive devices can be exploited to perform spike-sorting. We then show how combining memristors with standard logic enables efficient in-silico template matching. Leveraging the physical properties of nanoscale memristors allows us to implement ultra-compact analogue circuits for neural signal processing at the power cost of digital.", "published": "2017-07-27T08:18:06Z", "query": "neuroprosthetics", "relevance": 0.44999999999999996, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:18.408964"}
{"arxiv_id": "1702.06251v1", "title": "Electrocorticographic Dynamics Predict Visually Guided Motor Imagery of   Grasp Shaping", "summary": "Identification of intended movement type and movement phase of hand grasp shaping are critical features for the control of volitional neuroprosthetics. We demonstrate that neural dynamics during visually-guided imagined grasp shaping can encode intended movement. We apply Procrustes analysis and LASSO regression to achieve 72% accuracy (chance = 25%) in distinguishing between visually-guided imagined grasp trajectories. Further, we can predict the stage of grasp shaping in the form of elapsed time from start of trial (R2=0.4). Our approach contributes to more accurate single-trial decoding of higher-level movement goals and the phase of grasping movements in individuals not trained with brain-computer interfaces. We also find that the overall time-varying trajectory structure of imagined movements tend to be consistent within individuals, and that transient trajectory deviations within trials return to the task-dependent trajectory mean. These overall findings may contribute to the further understanding of the cortical dynamics of human motor imagery.", "published": "2017-02-21T03:19:37Z", "query": "neuroprosthetics", "relevance": 0.25, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:18.409078"}
{"arxiv_id": "2510.20823v1", "title": "Doubling the Number of Blue Large-Amlitude Pulsators: Final Results of   Searches for BLAPs in the OGLE Inner Galactic Bulge Fields", "summary": "Blue Large-Amplitude Pulsators (BLAPs) are rare short-period ($\\lesssim$80 min) pulsating variable stars exhibiting large-amplitude brightness variations (typically between 0.1 and 0.4 mag). As a recently discovered class of radial-mode pulsators, the origin and nature of these variables remain the subject of ongoing investigations. Here, we present a comprehensive summary of all BLAPs identified in the data of the Optical Gravitational Lensing Experiment (OGLE), including the discovery of 88 new BLAPs in the inner Galactic bulge fields. We performed a systematic search for periodic signals in the $I$-band light curves of more than 400 milion stars with magnitudes down to $I = 21$. Our search effectively doubles the number of these variables to almost 200. The detected BLAPs exhibit pulsation periods between roughly 5 and 76 minutes. The analyzed dataset covers a timespan from 2001 to 2024, with some stars observed up to 20,000 times, providing the temporal coverage needed to study period and amplitude variations. We report on three objects that show enormous period changes, at a rate of $10^{-5}$ yr$^{-1}$, which could provide important clues to the evolutionary status of BLAPs. Full dataset is incorporated into the publicly available OGLE Collection of Variable Stars (OCVS), enabling future studies of these enigmatic objects.", "published": "2025-10-23T17:59:59Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.900359"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:21.900860"}
{"arxiv_id": "2510.20817v1", "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "summary": "It is commonly believed that optimizing the reverse KL divergence results in \"mode seeking\", while optimizing forward KL results in \"mass covering\", with the latter being preferred if the goal is to sample from multiple diverse modes. We show -- mathematically and empirically -- that this intuition does not necessarily transfer well to doing reinforcement learning with reverse/forward KL regularization (e.g. as commonly used with language models). Instead, the choice of reverse/forward KL determines the family of optimal target distributions, parameterized by the regularization coefficient. Mode coverage depends primarily on other factors, such as regularization strength, and relative scales between rewards and reference probabilities. Further, we show commonly used settings such as low regularization strength and equal verifiable rewards tend to specify unimodal target distributions, meaning the optimization objective is, by construction, non-diverse. We leverage these insights to construct a simple, scalable, and theoretically justified algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a target distribution which puts high probability over all high-quality sampling modes. In experiments, this simple modification works to post-train both Large Language Models and Chemical Language Models to have higher solution quality and diversity, without any external signals of diversity, and works with both forward and reverse KL when using either naively fails.", "published": "2025-10-23T17:59:40Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.901152"}
{"arxiv_id": "2510.20815v1", "title": "Generative Reasoning Recommendation via LLMs", "summary": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.", "published": "2025-10-23T17:59:31Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:21.901563"}
{"arxiv_id": "2510.20812v1", "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via   Speculation", "summary": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict", "published": "2025-10-23T17:59:21Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.902016"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.902379"}
{"arxiv_id": "2510.20805v1", "title": "Bilevel Analysis of Cost and Emissions Externalities from Data Center   Load Shifting", "summary": "Data centers are emerging as large, flexible electricity consumers capable of shifting computational workloads across locations in response to economic and environmental signals. While this flexibility has potential for emissions reduction, its impact on power system operations depends critically on how such behavior interacts with network constraints and market signals. We develop a bilevel optimization framework in which a data center minimizes a weighted combination of electricity cost and marginal emissions intensity (LME), while the system operator clears economic dispatch under transmission and generation constraints. Focusing on a stylized three-bus power system, we derive closed-form, piecewise-linear expressions for both the data center and system-wide objectives as functions of the data centers' load shift. These expressions capture threshold-driven regime changes due to congestion and renewable saturation. We identify sufficient conditions under which the data center's decentralized decisions align with or diverge from socially optimal behavior and characterize the resulting externalities. Our results reveal how system topology and generator asymmetry affect incentive alignment and provide insight into when marginal price or emissions signals may fail to guide flexible loads toward socially beneficial outcomes. Our results offer a tractable starting point for analyzing decentralized flexibility under carbon-aware incentives and suggest directions for improving coordination between flexible loads and system operations.", "published": "2025-10-23T17:58:31Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.902661"}
{"arxiv_id": "2510.20803v1", "title": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model", "summary": "We propose a novel AutoRegressive Generation-based paradigm for image Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level perception within a unified framework. Prior works integrating image segmentation into multimodal large language models (MLLMs) typically employ either boundary points representation or dedicated segmentation heads. These methods rely on discrete representations or semantic prompts fed into task-specific decoders, which limits the ability of the MLLM to capture fine-grained visual details. To address these challenges, we introduce a segmentation framework for MLLM based on image generation, which naturally produces dense masks for target objects. We leverage MLLM to output visual tokens and detokenize them into images using an universal VQ-VAE, making the segmentation fully dependent on the pixel-level understanding of the MLLM. To reduce inference latency, we employ a next-scale-prediction strategy to generate required visual tokens in parallel. Extensive experiments demonstrate that our method surpasses prior state-of-the-art approaches on multiple segmentation datasets with a remarkable boost in inference speed, while maintaining strong understanding capabilities.", "published": "2025-10-23T17:58:26Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.902912"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:21.903190"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural signal decoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.903476"}
{"arxiv_id": "2510.20794v1", "title": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common   Feature", "summary": "This paper presents a Multi-Object Tracking (MOT) framework that fuses radar and camera data to enhance tracking efficiency while minimizing manual interventions. Contrary to many studies that underutilize radar and assign it a supplementary role--despite its capability to provide accurate range/depth information of targets in a world 3D coordinate system--our approach positions radar in a crucial role. Meanwhile, this paper utilizes common features to enable online calibration to autonomously associate detections from radar and camera. The main contributions of this work include: (1) the development of a radar-camera fusion MOT framework that exploits online radar-camera calibration to simplify the integration of detection results from these two sensors, (2) the utilization of common features between radar and camera data to accurately derive real-world positions of detected objects, and (3) the adoption of feature matching and category-consistency checking to surpass the limitations of mere position matching in enhancing sensor association accuracy. To the best of our knowledge, we are the first to investigate the integration of radar-camera common features and their use in online calibration for achieving MOT. The efficacy of our framework is demonstrated by its ability to streamline the radar-camera mapping process and improve tracking precision, as evidenced by real-world experiments conducted in both controlled environments and actual traffic scenarios. Code is available at https://github.com/radar-lab/Radar_Camera_MOT", "published": "2025-10-23T17:54:57Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.903779"}
{"arxiv_id": "2510.20785v1", "title": "Debiasing cosmological parameters from large-scale foreground   contamination in Cosmic Microwave Background data", "summary": "Current and future Cosmic Microwave Background (CMB) experiments aim to achieve high-precision reconstruction of the CMB polarization signal, with the most ambitious objective being the detection of primordial $B$ modes sourced by cosmic inflation. Given the expected low amplitude of the signal, its estimate, parametrized by the tensor-to-scalar ratio $r$, is highly susceptible to contamination from Galactic foreground residuals that remain after component separation. In this work, we introduce an agnostic, model-independent procedure to construct a spectral template of residual foreground contamination in the observed angular power spectrum. Specifically, a cleaned multifrequency set of foreground-emission maps is blindly reconstructed from the observed data using the Generalized Needlet Internal Linear Combination (GNILC) technique. These maps are then combined with the weights adopted for CMB reconstruction, yielding an estimate of the spatial distribution of foreground residuals after component separation. The power spectrum of this residual map, after proper noise debiasing, is incorporated into the spectral model of the cosmological likelihood, thereby enabling unbiased inference of cosmological parameters. We validate the method on realistic simulations of a LiteBIRD-like experiment, focusing on constraints on the tensor-to-scalar ratio. We demonstrate that including the residual template in the likelihood yields unbiased estimates of $r$, regardless of its input value, the assumed foreground model, or the adopted masking strategy, thus proving the robustness of the proposed procedure. The pipeline has been made publicly available as part of the BROOM Python package (https://github.com/alecarones/broom).", "published": "2025-10-23T17:52:40Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.904042"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.904273"}
{"arxiv_id": "2510.20769v1", "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble   Precipitation Forecasting", "summary": "Accurate medium-range precipitation forecasting is crucial for hydrometeorological risk management and disaster mitigation, yet remains challenging for current numerical weather prediction (NWP) systems. Traditional ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to maintain high skill, especially for moderate and heavy rainfall at extended lead times. This study develops a deep learning-based ensemble framework for multi-step precipitation prediction through joint modeling of a comprehensive set of atmospheric variables. The model is trained on ERA5 reanalysis data at 0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's Integrated Multi-satellite Retrievals for Global Precipitation Measurement (GPM) constellation (IMERG), incorporating 57 input variables, including upper-air and surface predictors. The architecture employs a patch-based Swin Transformer backbone with periodic convolutions to handle longitudinal continuity and integrates time and noise embeddings through conditional layer normalization. A dual-branch decoder predicts total precipitation and other variables, with targeted freezing of encoder-decoder pathways for specialized training. Training minimizes a hybrid loss combining the Continuous Ranked Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE), balancing probabilistic accuracy and magnitude fidelity. During inference, the model ingests real-time Global Forecast System (GFS) initial conditions to generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG data demonstrates higher Critical Success Index (CSI) scores at precipitation thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance for moderate to heavy rainfall.", "published": "2025-10-23T17:43:38Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:21.904502"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural signal decoding", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.904676"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.904935"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural signal decoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.905140"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:21.905369"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "neural signal decoding", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.905570"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural signal decoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.905756"}
{"arxiv_id": "2510.20734v1", "title": "MIMO-Zak-OTFS with Superimposed Spread Pilots", "summary": "In this paper, we consider the problem of spread pilot design and effective channel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS) with superimposed spread pilots, where data and spread pilot signals are superimposed in the same frame. To achieve good estimation performance in a MIMO setting, the spread pilots at different transmit antennas need to be effectively separated at the receiver. Towards this, we propose a spread pilot design that separates the pilot sequences in the cross-ambiguity domain and enables the estimation of the effective channel taps by a simple read-off operation. To further alleviate the effect of pilot-data interference on performance, we carry out turbo iterations between channel estimation and detection. Simulation results for $2\\times 2$ and $3\\times 3$ MIMO-Zak-OTFS with Gaussian-sinc pulse shaping filter for vehicular-A channel model show that the proposed pilot design and estimation scheme with three turbo iterations can achieve very good estimation/detection performance.", "published": "2025-10-23T16:48:42Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.905906"}
{"arxiv_id": "2510.20724v1", "title": "Phonon Polaritons and Epsilon Near Zero Modes in Sapphire Nanostructures", "summary": "Surface phonon polaritons (SPhPs) are promising candidates for enhanced light--matter interactions due to their efficient and low-loss light confinement features. In this work, we present unique light-matter interactions in saphhire within its Reststrahlen bands (RBs) across the long-wave infrared (LWIR) spectrum ($\\omega = 385$-$1050~\\mathrm{cm}^{-1}$). Particularly, we investigated the nanocone-patterned sapphire resonator array, with specific attention to its in-plane and out-of-plane permittivity components. Through Fourier transform infrared spectroscopy measurement and full-wave photonic simulations, we identified a range of optical excitations in the RBs, including three SPhPs, two hyperbolic volume phonon polaritons (HVPhPs), and one epsilon-near-zero (ENZ) mode. The depth-resolved confocal Raman spectroscopy revealed strongly enhanced Raman signals on the nanostructured surface, suggesting the mode coupling between phonons and phonon-polaritons, which was further confirmed by the finite element modeling of polarizability. This exploratory study provides in-depth insights into the dynamics of LWIR phonon polaritons and ENZ modes in the nanostructured sapphire, indicating its great potential for innovative nanophotonic applications.", "published": "2025-10-23T16:41:52Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:21.906157"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.906509"}
{"arxiv_id": "2510.20715v1", "title": "Iskay2: Signal Extraction of the Kinematic Sunyaev-Zel'dovich Effect   Through The Pairwise Estimator. Pipeline and Validation", "summary": "The peculiar motions of massive halos probe the distribution of matter in the universe, the gravitational potential, and the history of cosmic structure growth. The kinematic Sunyaev-Zeldovich (kSZ) effect offers a robust observational window into these properties. The pairwise kSZ estimator probes the pairwise momentum of groups of galaxies by cross-correlating cosmic microwave background (CMB) maps with spectroscopic galaxy catalogs, using galaxies to trace the positions of dark matter halos. This note introduces iskay2, an efficient pipeline designed to apply the pairwise kSZ estimator to maps of the CMB and large galaxy catalogs. Pairwise kSZ measurements obtained using this pipeline are compared to previously published results and are shown to be consistent within statistical expectations. This pipeline will enable high-precision measurements of the pairwise kSZ utilizing galaxy catalogs like DESI combined with past, current and next-generation high-resolution CMB experiments such as ACT, SPT and the Simons Observatory.", "published": "2025-10-23T16:31:43Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.906712"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "neural signal decoding", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:21.906910"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "neural signal decoding", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:21.907157"}
{"arxiv_id": "2510.20705v1", "title": "Measuring cosmic dipole with the GRB luminosity-time relation", "summary": "We present a new analysis of cosmic dipole anisotropy using gamma-ray bursts (GRBs) as high-redshift standardizable candles. GRBs are ideal probes for testing the cosmological principle thanks to their high luminosity, wide redshift range, and nearly isotropic sky coverage. For the first time, we employ the luminosity-time (L-T) relation, known in the literature as the bidimensional X-ray Dainotti relation, corrected for redshift evolution, to standardize a sample of 176 long GRBs detected by \\textit{Swift}. We test for dipolar modulations in the GRB Hubble diagram using both the Dipole Fit Method and a new approach introduced here, the Anisotropic Residual Analysis Method. Both methods yield consistent results: a dipole amplitude of $A_d \\simeq 0.6 \\pm 0.2$ pointing towards (RA, DEC) $\\approx (134^\\circ \\pm 30^{\\circ}, -36^\\circ \\pm 21^{\\circ})$ (equatorial coordinates). As shown in the Appendix, this corresponds to a boost velocity of the observer with respect to the GRB rest-frame in the antipodal direction from the dipole direction. Extensive isotropy tests and 20,000 Monte Carlo simulations confirm that the detected signal cannot be explained by chance alignments or by the angular distribution of the GRB sample. We also show how, by incorporating a dipole term, residual correlations are eliminated, showing that the dipole model provides a better fit than standard isotropic $\\Lambda$CDM.", "published": "2025-10-23T16:17:11Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:21.907376"}
{"arxiv_id": "2510.20700v1", "title": "Structure-Conditional Minimum Bayes Risk Decoding", "summary": "Minimum Bayes Risk (MBR) decoding has seen renewed interest as an alternative to traditional generation strategies. While MBR has proven effective in machine translation, where the variability of a language model's outcome space is naturally constrained, it may face challenges in more open-ended tasks such as dialogue or instruction-following. We hypothesise that in such settings, applying MBR with standard similarity-based utility functions may result in selecting responses that are broadly representative of the model's distribution, yet sub-optimal with respect to any particular grouping of generations that share an underlying latent structure. In this work, we introduce three lightweight adaptations to the utility function, designed to make MBR more sensitive to structural variability in the outcome space. To test our hypothesis, we curate a dataset capturing three representative types of latent structure: dialogue act, emotion, and response structure (e.g., a sentence, a paragraph, or a list). We further propose two metrics to evaluate the structural optimality of MBR. Our analysis demonstrates that common similarity-based utility functions fall short by these metrics. In contrast, our proposed adaptations considerably improve structural optimality. Finally, we evaluate our approaches on real-world instruction-following benchmarks, AlpacaEval and MT-Bench, and show that increased structural sensitivity improves generation quality by up to 13.7 percentage points in win rate.", "published": "2025-10-23T16:13:49Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:21.907557"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "neural signal decoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:21.907706"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:21.907889"}
{"arxiv_id": "2510.20823v1", "title": "Doubling the Number of Blue Large-Amlitude Pulsators: Final Results of   Searches for BLAPs in the OGLE Inner Galactic Bulge Fields", "summary": "Blue Large-Amplitude Pulsators (BLAPs) are rare short-period ($\\lesssim$80 min) pulsating variable stars exhibiting large-amplitude brightness variations (typically between 0.1 and 0.4 mag). As a recently discovered class of radial-mode pulsators, the origin and nature of these variables remain the subject of ongoing investigations. Here, we present a comprehensive summary of all BLAPs identified in the data of the Optical Gravitational Lensing Experiment (OGLE), including the discovery of 88 new BLAPs in the inner Galactic bulge fields. We performed a systematic search for periodic signals in the $I$-band light curves of more than 400 milion stars with magnitudes down to $I = 21$. Our search effectively doubles the number of these variables to almost 200. The detected BLAPs exhibit pulsation periods between roughly 5 and 76 minutes. The analyzed dataset covers a timespan from 2001 to 2024, with some stars observed up to 20,000 times, providing the temporal coverage needed to study period and amplitude variations. We report on three objects that show enormous period changes, at a rate of $10^{-5}$ yr$^{-1}$, which could provide important clues to the evolutionary status of BLAPs. Full dataset is incorporated into the publicly available OGLE Collection of Variable Stars (OCVS), enabling future studies of these enigmatic objects.", "published": "2025-10-23T17:59:59Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.381121"}
{"arxiv_id": "2510.20817v1", "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "summary": "It is commonly believed that optimizing the reverse KL divergence results in \"mode seeking\", while optimizing forward KL results in \"mass covering\", with the latter being preferred if the goal is to sample from multiple diverse modes. We show -- mathematically and empirically -- that this intuition does not necessarily transfer well to doing reinforcement learning with reverse/forward KL regularization (e.g. as commonly used with language models). Instead, the choice of reverse/forward KL determines the family of optimal target distributions, parameterized by the regularization coefficient. Mode coverage depends primarily on other factors, such as regularization strength, and relative scales between rewards and reference probabilities. Further, we show commonly used settings such as low regularization strength and equal verifiable rewards tend to specify unimodal target distributions, meaning the optimization objective is, by construction, non-diverse. We leverage these insights to construct a simple, scalable, and theoretically justified algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a target distribution which puts high probability over all high-quality sampling modes. In experiments, this simple modification works to post-train both Large Language Models and Chemical Language Models to have higher solution quality and diversity, without any external signals of diversity, and works with both forward and reverse KL when using either naively fails.", "published": "2025-10-23T17:59:40Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.381473"}
{"arxiv_id": "2510.20815v1", "title": "Generative Reasoning Recommendation via LLMs", "summary": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.", "published": "2025-10-23T17:59:31Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:25.381755"}
{"arxiv_id": "2510.20805v1", "title": "Bilevel Analysis of Cost and Emissions Externalities from Data Center   Load Shifting", "summary": "Data centers are emerging as large, flexible electricity consumers capable of shifting computational workloads across locations in response to economic and environmental signals. While this flexibility has potential for emissions reduction, its impact on power system operations depends critically on how such behavior interacts with network constraints and market signals. We develop a bilevel optimization framework in which a data center minimizes a weighted combination of electricity cost and marginal emissions intensity (LME), while the system operator clears economic dispatch under transmission and generation constraints. Focusing on a stylized three-bus power system, we derive closed-form, piecewise-linear expressions for both the data center and system-wide objectives as functions of the data centers' load shift. These expressions capture threshold-driven regime changes due to congestion and renewable saturation. We identify sufficient conditions under which the data center's decentralized decisions align with or diverge from socially optimal behavior and characterize the resulting externalities. Our results reveal how system topology and generator asymmetry affect incentive alignment and provide insight into when marginal price or emissions signals may fail to guide flexible loads toward socially beneficial outcomes. Our results offer a tractable starting point for analyzing decentralized flexibility under carbon-aware incentives and suggest directions for improving coordination between flexible loads and system operations.", "published": "2025-10-23T17:58:31Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.381906"}
{"arxiv_id": "2510.20804v1", "title": "Anomalous Hall effect in rhombohedral graphene", "summary": "Motivated by recent experiments on rhombohedral stacked multilayer graphene and the observation of the anomalous Hall effect in a spontaneous spin-valley polarized quarter metal state, we calculate the anomalous Hall conductivity for this system in the presence of two types of impurities: weak and dense as well as sparse and strong. Our calculation of $\\sigma_{xy}$ is based on the Kubo-Streda diagrammatic approach. In a model with Gaussian disorder applicable to weak dense impurities, this involves all non-crossing diagrams (intrinsic, side-jump and Gaussian skew-scattering contributions) and additionally diagrams with two intersecting impurities, X and $\\Psi$, representing diffractive skew-scattering processes. A \"Mercedes star\" diagram (non-Gaussian skew scattering) is furthermore included to treat in the case of strong, sparse impurities. We supplement our asymptotically exact analytical solutions for an isotropic model without warping effects by semi-numerical calculations accounting perturbatively for warping, which plays a crucial role in the low-energy band structure.", "published": "2025-10-23T17:58:28Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.382061"}
{"arxiv_id": "2510.20794v1", "title": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common   Feature", "summary": "This paper presents a Multi-Object Tracking (MOT) framework that fuses radar and camera data to enhance tracking efficiency while minimizing manual interventions. Contrary to many studies that underutilize radar and assign it a supplementary role--despite its capability to provide accurate range/depth information of targets in a world 3D coordinate system--our approach positions radar in a crucial role. Meanwhile, this paper utilizes common features to enable online calibration to autonomously associate detections from radar and camera. The main contributions of this work include: (1) the development of a radar-camera fusion MOT framework that exploits online radar-camera calibration to simplify the integration of detection results from these two sensors, (2) the utilization of common features between radar and camera data to accurately derive real-world positions of detected objects, and (3) the adoption of feature matching and category-consistency checking to surpass the limitations of mere position matching in enhancing sensor association accuracy. To the best of our knowledge, we are the first to investigate the integration of radar-camera common features and their use in online calibration for achieving MOT. The efficacy of our framework is demonstrated by its ability to streamline the radar-camera mapping process and improve tracking precision, as evidenced by real-world experiments conducted in both controlled environments and actual traffic scenarios. Code is available at https://github.com/radar-lab/Radar_Camera_MOT", "published": "2025-10-23T17:54:57Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.382249"}
{"arxiv_id": "2510.20790v1", "title": "Trapping, manipulating and probing ultracold atoms: a quantum   technologies tutorial", "summary": "Engineered ultracold atomic systems are a valuable platform for fundamental quantum mechanics studies and the development of quantum technologies. At near zero absolute temperature, atoms exhibit macroscopic phase coherence and collective quantum behavior, enabling their use in precision metrology, quantum simulation, and even information processing. This review provides an introductory overview of the key techniques used to trap, manipulate, and detect ultracold atoms, while highlighting the main applications of each method. We outline the principles of laser cooling, magnetic and optical trapping, and the most widely used techniques, including optical lattices and tweezers. Next, we discuss the manipulation methods of atomic internal and external degrees of freedom, and we present atom interferometry techniques and how to leverage and control interatomic interactions. Next, we review common ensemble detection strategies, including absorption and fluorescence imaging, state-selective readout, correlation and quantum non-demolition measurements and conclude with high-resolution approaches. This review aims to provide newcomers to the field with a broad understanding of the experimental toolkit that underpins research in ultracold atom physics and its applications across quantum science and technology.", "published": "2025-10-23T17:54:06Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.382375"}
{"arxiv_id": "2510.20785v1", "title": "Debiasing cosmological parameters from large-scale foreground   contamination in Cosmic Microwave Background data", "summary": "Current and future Cosmic Microwave Background (CMB) experiments aim to achieve high-precision reconstruction of the CMB polarization signal, with the most ambitious objective being the detection of primordial $B$ modes sourced by cosmic inflation. Given the expected low amplitude of the signal, its estimate, parametrized by the tensor-to-scalar ratio $r$, is highly susceptible to contamination from Galactic foreground residuals that remain after component separation. In this work, we introduce an agnostic, model-independent procedure to construct a spectral template of residual foreground contamination in the observed angular power spectrum. Specifically, a cleaned multifrequency set of foreground-emission maps is blindly reconstructed from the observed data using the Generalized Needlet Internal Linear Combination (GNILC) technique. These maps are then combined with the weights adopted for CMB reconstruction, yielding an estimate of the spatial distribution of foreground residuals after component separation. The power spectrum of this residual map, after proper noise debiasing, is incorporated into the spectral model of the cosmological likelihood, thereby enabling unbiased inference of cosmological parameters. We validate the method on realistic simulations of a LiteBIRD-like experiment, focusing on constraints on the tensor-to-scalar ratio. We demonstrate that including the residual template in the likelihood yields unbiased estimates of $r$, regardless of its input value, the assumed foreground model, or the adopted masking strategy, thus proving the robustness of the proposed procedure. The pipeline has been made publicly available as part of the BROOM Python package (https://github.com/alecarones/broom).", "published": "2025-10-23T17:52:40Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.382573"}
{"arxiv_id": "2510.20780v1", "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and   Performance Boost", "summary": "Recent advancements in large reasoning models (LRMs) have introduced an intermediate \"thinking\" process prior to generating final answers, improving their reasoning capabilities on complex downstream tasks. However, the potential of LRMs as evaluators for machine translation (MT) quality remains underexplored. We provides the first systematic analysis of LRM-as-a-judge in MT evaluation. We identify key challenges, revealing LRMs require tailored evaluation materials, tend to \"overthink\" simpler instances and have issues with scoring mechanisms leading to overestimation. To address these, we propose to calibrate LRM thinking by training them on synthetic, human-like thinking trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this approach largely reduces thinking budgets by ~35x while concurrently improving evaluation performance across different LRM scales from 7B to 32B (e.g., R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These findings highlight the potential of efficiently calibrated LRMs to advance fine-grained automatic MT evaluation.", "published": "2025-10-23T17:48:36Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.382728"}
{"arxiv_id": "2510.20776v1", "title": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "summary": "This work proposes a new generation-based 3D reconstruction method, named Cupid, that accurately infers the camera pose, 3D shape, and texture of an object from a single 2D image. Cupid casts 3D reconstruction as a conditional sampling process from a learned distribution of 3D objects, and it jointly generates voxels and pixel-voxel correspondences, enabling robust pose and shape estimation under a unified generative framework. By representing both input camera poses and 3D shape as a distribution in a shared 3D latent space, Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that produces initial 3D geometry with associated 2D projections for pose recovery; and (2) a refinement stage that integrates pose-aligned image features to enhance structural fidelity and appearance details. Extensive experiments demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3 dB PSNR gain and an over 10% Chamfer Distance reduction, while matching monocular estimators on pose accuracy and delivering superior visual fidelity over baseline 3D generative models. For an immersive view of the 3D results generated by Cupid, please visit cupid3d.github.io.", "published": "2025-10-23T17:47:38Z", "query": "brain signal processing", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.382837"}
{"arxiv_id": "2510.20766v1", "title": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion", "summary": "Diffusion Transformer models can generate images with remarkable fidelity and detail, yet training them at ultra-high resolutions remains extremely costly due to the self-attention mechanism's quadratic scaling with the number of image tokens. In this paper, we introduce Dynamic Position Extrapolation (DyPE), a novel, training-free method that enables pre-trained diffusion transformers to synthesize images at resolutions far beyond their training data, with no additional sampling cost. DyPE takes advantage of the spectral progression inherent to the diffusion process, where low-frequency structures converge early, while high-frequencies take more steps to resolve. Specifically, DyPE dynamically adjusts the model's positional encoding at each diffusion step, matching their frequency spectrum with the current stage of the generative process. This approach allows us to generate images at resolutions that exceed the training resolution dramatically, e.g., 16 million pixels using FLUX. On multiple benchmarks, DyPE consistently improves performance and achieves state-of-the-art fidelity in ultra-high-resolution image generation, with gains becoming even more pronounced at higher resolutions. Project page is available at https://noamissachar.github.io/DyPE/.", "published": "2025-10-23T17:42:14Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:25.382976"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "brain signal processing", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.383090"}
{"arxiv_id": "2510.20747v1", "title": "Dynamical entropy of charged black objects", "summary": "We develop a general framework for electromagnetic potential-charge contributions to the first law of black hole mechanics, applicable to dynamical first-order perturbations of stationary black objects with possibly non-compact bifurcate Killing horizons. Working in the covariant phase space formalism, we derive both comparison and physical process versions of the first law. We consider generic diffeomorphism-invariant theories of gravity in $D$ spacetime dimensions, containing non-minimally coupled abelian $p$-form gauge fields. The pullback of the gauge field to the horizon is allowed to diverge while its field strength remains smooth, yielding gauge-invariant electric potential-charge pairs in the first law. We further extend the construction to include magnetic charges by developing a bundle-covariant, gauge-invariant prescription that fixes the Jacobson-Kang-Myers ambiguity in the improved Noether charge. Electric and magnetic charges are, respectively, associated with non-trivial $(D - p - 1)$- and $(p + 1)$-cycles of the horizon cross-section, whose homology classes determine the number of independent potential-charge pairs through the Betti numbers $b_{D - p - 1}$ and $b_{p + 1}$. Further, the dynamical gravitational entropy entering the first law is identified with the gauge-invariant part of the improved Noether charge, giving a gauge-invariant extension of the recent proposal by Hollands, Wald and Zhang. We illustrate our framework with dyonic AdS black holes, dipole black rings, and charged black branes.", "published": "2025-10-23T17:10:01Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.383272"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "brain signal processing", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.383431"}
{"arxiv_id": "2510.20736v1", "title": "Amplifying Prominent Representations in Multimodal Learning via   Variational Dirichlet Process", "summary": "Developing effective multimodal fusion approaches has become increasingly essential in many real-world scenarios, such as health care and finance. The key challenge is how to preserve the feature expressiveness in each modality while learning cross-modal interactions. Previous approaches primarily focus on the cross-modal alignment, while over-emphasis on the alignment of marginal distributions of modalities may impose excess regularization and obstruct meaningful representations within each modality. The Dirichlet process (DP) mixture model is a powerful Bayesian non-parametric method that can amplify the most prominent features by its richer-gets-richer property, which allocates increasing weights to them. Inspired by this unique characteristic of DP, we propose a new DP-driven multimodal learning framework that automatically achieves an optimal balance between prominent intra-modal representation learning and cross-modal alignment. Specifically, we assume that each modality follows a mixture of multivariate Gaussian distributions and further adopt DP to calculate the mixture weights for all the components. This paradigm allows DP to dynamically allocate the contributions of features and select the most prominent ones, leveraging its richer-gets-richer property, thus facilitating multimodal feature fusion. Extensive experiments on several multimodal datasets demonstrate the superior performance of our model over other competitors. Ablation analysis further validates the effectiveness of DP in aligning modality distributions and its robustness to changes in key hyperparameters. Code is anonymously available at https://github.com/HKU-MedAI/DPMM.git", "published": "2025-10-23T16:53:24Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.383625"}
{"arxiv_id": "2510.20735v1", "title": "Magnetic tunnel junction as a real-time entropy source:   Field-Programmable Gate Array based random bit generation without   post-processing", "summary": "We demonstrate a method to generate application-ready truly random bits from a magnetic tunnel junction driven by a Field-Programmable Gate Array (FPGA). We implement a real-time feedback loop that stabilizes the switching probability near 50\\% and apply an XOR operation, both on the FPGA, to suppress short-term correlations, together mitigating long-term drift and bias in the bitstream. This combined approach enables NIST-compliant random bit generation at 5~Mb/s without post-processing, providing a practical hardware solution for fast and reliable true random number generation. Beyond cryptographic applications, these capabilities open opportunities for stochastic hardware accelerators, probabilistic computing, and large-scale modeling where real-time access to unbiased randomness is essential.", "published": "2025-10-23T16:50:51Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:25.383758"}
{"arxiv_id": "2510.20734v1", "title": "MIMO-Zak-OTFS with Superimposed Spread Pilots", "summary": "In this paper, we consider the problem of spread pilot design and effective channel estimation in multiple-input multiple-output Zak-OTFS (MIMO-Zak-OTFS) with superimposed spread pilots, where data and spread pilot signals are superimposed in the same frame. To achieve good estimation performance in a MIMO setting, the spread pilots at different transmit antennas need to be effectively separated at the receiver. Towards this, we propose a spread pilot design that separates the pilot sequences in the cross-ambiguity domain and enables the estimation of the effective channel taps by a simple read-off operation. To further alleviate the effect of pilot-data interference on performance, we carry out turbo iterations between channel estimation and detection. Simulation results for $2\\times 2$ and $3\\times 3$ MIMO-Zak-OTFS with Gaussian-sinc pulse shaping filter for vehicular-A channel model show that the proposed pilot design and estimation scheme with three turbo iterations can achieve very good estimation/detection performance.", "published": "2025-10-23T16:48:42Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.383898"}
{"arxiv_id": "2510.20733v1", "title": "Thought Communication in Multiagent Collaboration", "summary": "Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, thought communication, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.", "published": "2025-10-23T16:48:02Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.384079"}
{"arxiv_id": "2510.20727v1", "title": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related   Toxicities from Clinical Notes Using Natural Language Processing", "summary": "Objective: Fluoropyrimidines are widely prescribed for colorectal and breast cancers, but are associated with toxicities such as hand-foot syndrome and cardiotoxicity. Since toxicity documentation is often embedded in clinical notes, we aimed to develop and evaluate natural language processing (NLP) methods to extract treatment and toxicity information.   Materials and Methods: We constructed a gold-standard dataset of 236 clinical notes from 204,165 adult oncology patients. Domain experts annotated categories related to treatment regimens and toxicities. We developed rule-based, machine learning-based (Random Forest, Support Vector Machine [SVM], Logistic Regression [LR]), deep learning-based (BERT, ClinicalBERT), and large language models (LLM)-based NLP approaches (zero-shot and error-analysis prompting). Models used an 80:20 train-test split.   Results: Sufficient data existed to train and evaluate 5 annotated categories. Error-analysis prompting achieved optimal precision, recall, and F1 scores (F1=1.000) for treatment and toxicities extraction, whereas zero-shot prompting reached F1=1.000 for treatment and F1=0.876 for toxicities extraction.LR and SVM ranked second for toxicities (F1=0.937). Deep learning underperformed, with BERT (F1=0.873 treatment; F1= 0.839 toxicities) and ClinicalBERT (F1=0.873 treatment; F1 = 0.886 toxicities). Rule-based methods served as our baseline with F1 scores of 0.857 in treatment and 0.858 in toxicities.   Discussion: LMM-based approaches outperformed all others, followed by machine learning methods. Machine and deep learning approaches were limited by small training data and showed limited generalizability, particularly for rare categories.   Conclusion: LLM-based NLP most effectively extracted fluoropyrimidine treatment and toxicity information from clinical notes, and has strong potential to support oncology research and pharmacovigilance.", "published": "2025-10-23T16:44:39Z", "query": "brain signal processing", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.384285"}
{"arxiv_id": "2510.20726v1", "title": "AutoScape: Geometry-Consistent Long-Horizon Scene Generation", "summary": "This paper proposes AutoScape, a long-horizon driving scene generation framework. At its core is a novel RGB-D diffusion model that iteratively generates sparse, geometrically consistent keyframes, serving as reliable anchors for the scene's appearance and geometry. To maintain long-range geometric consistency, the model 1) jointly handles image and depth in a shared latent space, 2) explicitly conditions on the existing scene geometry (i.e., rendered point clouds) from previously generated keyframes, and 3) steers the sampling process with a warp-consistent guidance. Given high-quality RGB-D keyframes, a video diffusion model then interpolates between them to produce dense and coherent video frames. AutoScape generates realistic and geometrically consistent driving videos of over 20 seconds, improving the long-horizon FID and FVD scores over the prior state-of-the-art by 48.6\\% and 43.0\\%, respectively.", "published": "2025-10-23T16:44:34Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.384417"}
{"arxiv_id": "2510.20725v1", "title": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes   with Gaussian Processes", "summary": "Thompson sampling (TS) is a powerful and widely used strategy for sequential decision-making, with applications ranging from Bayesian optimization to reinforcement learning (RL). Despite its success, the theoretical foundations of TS remain limited, particularly in settings with complex temporal structure such as RL. We address this gap by establishing no-regret guarantees for TS using models with Gaussian marginal distributions. Specifically, we consider TS in episodic RL with joint Gaussian process (GP) priors over rewards and transitions. We prove a regret bound of $\\mathcal{\\tilde{O}}(\\sqrt{KH\\Gamma(KH)})$ over $K$ episodes of horizon $H$, where $\\Gamma(\\cdot)$ captures the complexity of the GP model. Our analysis addresses several challenges, including the non-Gaussian nature of value functions and the recursive structure of Bellman updates, and extends classical tools such as the elliptical potential lemma to multi-output settings. This work advances the understanding of TS in RL and highlights how structural assumptions and model uncertainty shape its performance in finite-horizon Markov Decision Processes.", "published": "2025-10-23T16:44:31Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.384561"}
{"arxiv_id": "2510.20724v1", "title": "Phonon Polaritons and Epsilon Near Zero Modes in Sapphire Nanostructures", "summary": "Surface phonon polaritons (SPhPs) are promising candidates for enhanced light--matter interactions due to their efficient and low-loss light confinement features. In this work, we present unique light-matter interactions in saphhire within its Reststrahlen bands (RBs) across the long-wave infrared (LWIR) spectrum ($\\omega = 385$-$1050~\\mathrm{cm}^{-1}$). Particularly, we investigated the nanocone-patterned sapphire resonator array, with specific attention to its in-plane and out-of-plane permittivity components. Through Fourier transform infrared spectroscopy measurement and full-wave photonic simulations, we identified a range of optical excitations in the RBs, including three SPhPs, two hyperbolic volume phonon polaritons (HVPhPs), and one epsilon-near-zero (ENZ) mode. The depth-resolved confocal Raman spectroscopy revealed strongly enhanced Raman signals on the nanostructured surface, suggesting the mode coupling between phonons and phonon-polaritons, which was further confirmed by the finite element modeling of polarizability. This exploratory study provides in-depth insights into the dynamics of LWIR phonon polaritons and ENZ modes in the nanostructured sapphire, indicating its great potential for innovative nanophotonic applications.", "published": "2025-10-23T16:41:52Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.384670"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "brain signal processing", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.384869"}
{"arxiv_id": "2510.20715v1", "title": "Iskay2: Signal Extraction of the Kinematic Sunyaev-Zel'dovich Effect   Through The Pairwise Estimator. Pipeline and Validation", "summary": "The peculiar motions of massive halos probe the distribution of matter in the universe, the gravitational potential, and the history of cosmic structure growth. The kinematic Sunyaev-Zeldovich (kSZ) effect offers a robust observational window into these properties. The pairwise kSZ estimator probes the pairwise momentum of groups of galaxies by cross-correlating cosmic microwave background (CMB) maps with spectroscopic galaxy catalogs, using galaxies to trace the positions of dark matter halos. This note introduces iskay2, an efficient pipeline designed to apply the pairwise kSZ estimator to maps of the CMB and large galaxy catalogs. Pairwise kSZ measurements obtained using this pipeline are compared to previously published results and are shown to be consistent within statistical expectations. This pipeline will enable high-precision measurements of the pairwise kSZ utilizing galaxy catalogs like DESI combined with past, current and next-generation high-resolution CMB experiments such as ACT, SPT and the Simons Observatory.", "published": "2025-10-23T16:31:43Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.385008"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "brain signal processing", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:25.385188"}
{"arxiv_id": "2510.20708v1", "title": "ALICE-LRI: A General Method for Lossless Range Image Generation for   Spinning LiDAR Sensors without Calibration Metadata", "summary": "3D LiDAR sensors are essential for autonomous navigation, environmental monitoring, and precision mapping in remote sensing applications. To efficiently process the massive point clouds generated by these sensors, LiDAR data is often projected into 2D range images that organize points by their angular positions and distances. While these range image representations enable efficient processing, conventional projection methods suffer from fundamental geometric inconsistencies that cause irreversible information loss, compromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR Intrinsic Calibration Estimation for Lossless Range Images), the first general, sensor-agnostic method that achieves lossless range image generation from spinning LiDAR point clouds without requiring manufacturer metadata or calibration files. Our algorithm automatically reverse-engineers the intrinsic geometry of any spinning LiDAR sensor by inferring critical parameters including laser beam configuration, angular distributions, and per-beam calibration corrections, enabling lossless projection and complete point cloud reconstruction with zero point loss. Comprehensive evaluation across the complete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect point preservation, with zero points lost across all point clouds. Geometric accuracy is maintained well within sensor precision limits, establishing geometric losslessness with real-time performance. We also present a compression case study that validates substantial downstream benefits, demonstrating significant quality improvements in practical applications. This paradigm shift from approximate to lossless LiDAR projections opens new possibilities for high-precision remote sensing applications requiring complete geometric preservation.", "published": "2025-10-23T16:22:58Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:25.385389"}
{"arxiv_id": "2510.20707v1", "title": "Mixing Importance with Diversity: Joint Optimization for KV Cache   Compression in Large Vision-Language Models", "summary": "Recent large vision-language models (LVLMs) demonstrate remarkable capabilities in processing extended multi-modal sequences, yet the resulting key-value (KV) cache expansion creates a critical memory bottleneck that fundamentally limits deployment scalability. While existing KV cache compression methods focus on retaining high-importance KV pairs to minimize storage, they often overlook the modality-specific semantic redundancy patterns that emerge distinctively in multi-modal KV caches. In this work, we first analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying levels of redundancy across attention heads. We show that relying solely on importance can only cover a subset of the full KV cache information distribution, leading to potential loss of semantic coverage. To address this, we propose \\texttt{MixKV}, a novel method that mixes importance with diversity for optimized KV cache compression in LVLMs. \\texttt{MixKV} adapts to head-wise semantic redundancy, selectively balancing diversity and importance when compressing KV pairs. Extensive experiments demonstrate that \\texttt{MixKV} consistently enhances existing methods across multiple LVLMs. Under extreme compression (budget=64), \\texttt{MixKV} improves baseline methods by an average of \\textbf{5.1\\%} across five multi-modal understanding benchmarks and achieves remarkable gains of \\textbf{8.0\\%} and \\textbf{9.0\\%} for SnapKV and AdaKV on GUI grounding tasks, all while maintaining comparable inference efficiency. Furthermore, \\texttt{MixKV} extends seamlessly to LLMs with comparable performance gains. Our code is available at \\href{https://github.com/xuyang-liu16/MixKV}{\\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.", "published": "2025-10-23T16:17:47Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:25.385565"}
{"arxiv_id": "2510.20705v1", "title": "Measuring cosmic dipole with the GRB luminosity-time relation", "summary": "We present a new analysis of cosmic dipole anisotropy using gamma-ray bursts (GRBs) as high-redshift standardizable candles. GRBs are ideal probes for testing the cosmological principle thanks to their high luminosity, wide redshift range, and nearly isotropic sky coverage. For the first time, we employ the luminosity-time (L-T) relation, known in the literature as the bidimensional X-ray Dainotti relation, corrected for redshift evolution, to standardize a sample of 176 long GRBs detected by \\textit{Swift}. We test for dipolar modulations in the GRB Hubble diagram using both the Dipole Fit Method and a new approach introduced here, the Anisotropic Residual Analysis Method. Both methods yield consistent results: a dipole amplitude of $A_d \\simeq 0.6 \\pm 0.2$ pointing towards (RA, DEC) $\\approx (134^\\circ \\pm 30^{\\circ}, -36^\\circ \\pm 21^{\\circ})$ (equatorial coordinates). As shown in the Appendix, this corresponds to a boost velocity of the observer with respect to the GRB rest-frame in the antipodal direction from the dipole direction. Extensive isotropy tests and 20,000 Monte Carlo simulations confirm that the detected signal cannot be explained by chance alignments or by the angular distribution of the GRB sample. We also show how, by incorporating a dipole term, residual correlations are eliminated, showing that the dipole model provides a better fit than standard isotropic $\\Lambda$CDM.", "published": "2025-10-23T16:17:11Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:25.385711"}
{"arxiv_id": "2510.20701v1", "title": "Real-time dynamics of VCMA-assisted switching of magnetic tunnel   junctions", "summary": "Voltage control of magnetic anisotropy (VCMA) induced by charge accumulation is typically considered as an ultrafast process, enabling energy-efficient and high-speed magnetization switching in spintronic devices. In this work, we investigate the real-time dynamics of VCMA-assisted switching of magnetic tunnel junctions via relaxation in a magnetic field. We show that device-dependent charging effects and magnetic granularity in the free layer limit the switching speed at applied voltages close to the critical switching threshold. Increasing the voltage or the applied magnetic field reduces the incubation delay and total switching time to below a few ns. Micromagnetic simulations incorporating the finite charging times of the tunnel junction and the granularity of the magnetic film reproduce the experimental results, providing critical insights into optimizing VCMA-driven magnetization control for memory and logic applications.", "published": "2025-10-23T16:13:59Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:25.385810"}
{"arxiv_id": "2510.20691v1", "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over   Knowledge Graphs", "summary": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.", "published": "2025-10-23T16:04:13Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:25.385994"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:28.857323"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:28.857799"}
{"arxiv_id": "2510.20798v1", "title": "Analog Quantum Feature Selection with Neutral-Atom Quantum Processors", "summary": "We present a quantum-native approach to quantum feature selection (QFS) based on analog quantum simulation with neutral atom arrays, adaptable to a variety of academic and industrial applications. In our method, feature relevance-measured via mutual information with the target-is encoded as local detuning amplitudes, while feature redundancy is embedded through distance-dependent van der Waals interactions, constrained by the Rydberg blockade radius. The system is evolved adiabatically toward low-energy configurations, and the resulting measurement bitstrings are used to extract physically consistent subsets of features. The protocol is evaluated through simulations on three benchmark binary classification datasets: Adult Income, Bank Marketing, and Telco Churn. Compared to classical methods such as mutual information ranking and Boruta, combined with XGBoost and Random Forest classifiers, our quantum-computing approach achieves competitive or superior performance. In particular, for compact subsets of 2-5 features, analog QFS improves mean AUC scores by 1.5-2.3% while reducing the number of features by 75-84%, offering interpretable, low-redundancy solutions. These results demonstrate that programmable Rydberg arrays offer a viable platform for intelligent feature selection with practical relevance in machine learning pipelines, capable of transforming computational quantum advantage into industrial quantum usefulness.", "published": "2025-10-23T17:57:34Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:28.858094"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:28.858363"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.858654"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.858903"}
{"arxiv_id": "2510.20769v1", "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble   Precipitation Forecasting", "summary": "Accurate medium-range precipitation forecasting is crucial for hydrometeorological risk management and disaster mitigation, yet remains challenging for current numerical weather prediction (NWP) systems. Traditional ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to maintain high skill, especially for moderate and heavy rainfall at extended lead times. This study develops a deep learning-based ensemble framework for multi-step precipitation prediction through joint modeling of a comprehensive set of atmospheric variables. The model is trained on ERA5 reanalysis data at 0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's Integrated Multi-satellite Retrievals for Global Precipitation Measurement (GPM) constellation (IMERG), incorporating 57 input variables, including upper-air and surface predictors. The architecture employs a patch-based Swin Transformer backbone with periodic convolutions to handle longitudinal continuity and integrates time and noise embeddings through conditional layer normalization. A dual-branch decoder predicts total precipitation and other variables, with targeted freezing of encoder-decoder pathways for specialized training. Training minimizes a hybrid loss combining the Continuous Ranked Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE), balancing probabilistic accuracy and magnitude fidelity. During inference, the model ingests real-time Global Forecast System (GFS) initial conditions to generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG data demonstrates higher Critical Success Index (CSI) scores at precipitation thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance for moderate to heavy rainfall.", "published": "2025-10-23T17:43:38Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:28.859158"}
{"arxiv_id": "2510.20766v1", "title": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion", "summary": "Diffusion Transformer models can generate images with remarkable fidelity and detail, yet training them at ultra-high resolutions remains extremely costly due to the self-attention mechanism's quadratic scaling with the number of image tokens. In this paper, we introduce Dynamic Position Extrapolation (DyPE), a novel, training-free method that enables pre-trained diffusion transformers to synthesize images at resolutions far beyond their training data, with no additional sampling cost. DyPE takes advantage of the spectral progression inherent to the diffusion process, where low-frequency structures converge early, while high-frequencies take more steps to resolve. Specifically, DyPE dynamically adjusts the model's positional encoding at each diffusion step, matching their frequency spectrum with the current stage of the generative process. This approach allows us to generate images at resolutions that exceed the training resolution dramatically, e.g., 16 million pixels using FLUX. On multiple benchmarks, DyPE consistently improves performance and achieves state-of-the-art fidelity in ultra-high-resolution image generation, with gains becoming even more pronounced at higher resolutions. Project page is available at https://noamissachar.github.io/DyPE/.", "published": "2025-10-23T17:42:14Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:28.859361"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural encoding", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:28.859525"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.859871"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.860073"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:28.860301"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.860518"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.860783"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "neural encoding", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:28.860992"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "neural encoding", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:28.861234"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.861427"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:28.861652"}
{"arxiv_id": "2510.20691v1", "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over   Knowledge Graphs", "summary": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.", "published": "2025-10-23T16:04:13Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:28.861890"}
{"arxiv_id": "2510.20690v1", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "summary": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. Inspired by portfolio theory, where uncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination probability is bounded by representational correlation: $P(H) \\leq f(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language models need an optimal amount of neurodiversity. To validate this, we introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces hallucinations by up to 25.6% (and 14.6% on average) without degrading general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational analyses indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different amounts of optimal neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.", "published": "2025-10-23T16:03:07Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.862097"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "neural encoding", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:28.862296"}
{"arxiv_id": "2510.20677v1", "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice   Conversion", "summary": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.", "published": "2025-10-23T15:52:03Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:28.862496"}
{"arxiv_id": "2510.20673v1", "title": "Efficient Multi-bit Quantization Network Training via Weight Bias   Correction and Bit-wise Coreset Sampling", "summary": "Multi-bit quantization networks enable flexible deployment of deep neural networks by supporting multiple precision levels within a single model. However, existing approaches suffer from significant training overhead as full-dataset updates are repeated for each supported bit-width, resulting in a cost that scales linearly with the number of precisions. Additionally, extra fine-tuning stages are often required to support additional or intermediate precision options, further compounding the overall training burden. To address this issue, we propose two techniques that greatly reduce the training overhead without compromising model utility: (i) Weight bias correction enables shared batch normalization and eliminates the need for fine-tuning by neutralizing quantization-induced bias across bit-widths and aligning activation distributions; and (ii) Bit-wise coreset sampling strategy allows each child model to train on a compact, informative subset selected via gradient-based importance scores by exploiting the implicit knowledge transfer phenomenon. Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and ViT architectures demonstrate that our method achieves competitive or superior accuracy while reducing training time up to 7.88x. Our code is released at https://github.com/a2jinhee/EMQNet_jk.", "published": "2025-10-23T15:49:02Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.862699"}
{"arxiv_id": "2510.20671v1", "title": "GRACE: GRaph-based Addiction Care prEdiction", "summary": "Determining the appropriate locus of care for addiction patients is one of the most critical clinical decisions that affects patient treatment outcomes and effective use of resources. With a lack of sufficient specialized treatment resources, such as inpatient beds or staff, there is an unmet need to develop an automated framework for the same. Current decision-making approaches suffer from severe class imbalances in addiction datasets. To address this limitation, we propose a novel graph neural network (GRACE) framework that formalizes locus of care prediction as a structured learning problem. Further, we perform extensive feature engineering and propose a new approach of obtaining an unbiased meta-graph to train a GNN to overcome the class imbalance problem. Experimental results in real-world data show an improvement of 11-35% in terms of the F1 score of the minority class over competitive baselines. The codes and note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.", "published": "2025-10-23T15:48:01Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.862874"}
{"arxiv_id": "2510.20669v1", "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing   Maps and Spiking Dynamics for Waste Classification", "summary": "Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.", "published": "2025-10-23T15:47:09Z", "query": "neural encoding", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:28.863085"}
{"arxiv_id": "2510.20666v1", "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of   Experts", "summary": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming, particularly in urban areas where multipath and shadowing distort received power. Previous data-driven approaches achieved reasonable localization but poorly reconstructed the received signal strength (RSS) field due to limited spatial context. We propose a hybrid Bayesian mixture-of-experts framework that fuses a physical path-loss (PL) model and a convolutional neural network (CNN) through log-linear pooling. The PL expert ensures physical consistency, while the CNN leverages building-height maps to capture urban propagation effects. Bayesian inference with Laplace approximation provides posterior uncertainty over both the jammer position and RSS field. Experiments on urban ray-tracing data show that localization accuracy improves and uncertainty decreases with more training points, while uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive.", "published": "2025-10-23T15:45:45Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.863269"}
{"arxiv_id": "2510.20659v1", "title": "Kinetics of Peierls dimerization transition: Machine learning   force-field approach", "summary": "We present a machine learning (ML) force-field framework for simulating the non-equilibrium dynamics of charge-density-wave (CDW) order driven by the Peierls instability. Since the Peierls distortion arises from the coupling between lattice displacements and itinerant electrons, evaluating the adiabatic forces during time evolution is computationally intensive, particularly for large systems. To overcome this bottleneck, we develop a generalized Behler-Parrinello neural-network architecture -- originally formulated for ab initio molecular dynamics -- to accurately and efficiently predict forces from local structural environments. Using the locality of electronic responses, the resulting ML force field achieves linear scaling efficiency while maintaining quantitative accuracy. Large-scale dynamical simulations using this framework uncover a two-stage coarsening behavior of CDW domains: an early-time regime characterized by a power-law growth $L \\sim t^{\\alpha}$ with an effective exponent $\\alpha \\approx 0.7$, followed by a crossover to the Allen-Cahn scaling $L \\sim \\sqrt{t}$ at late times. The enhanced early-time coarsening is attributed to anisotropic domain-wall motion arising from electron-mediated directional interactions. This work demonstrates the promise of ML-based force fields for multiscale dynamical modeling of condensed-matter lattice models.", "published": "2025-10-23T15:33:31Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.863476"}
{"arxiv_id": "2510.20653v1", "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During   Inference-Time LLM Reflection", "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.", "published": "2025-10-23T15:26:18Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:28.863650"}
{"arxiv_id": "2510.20644v1", "title": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound   for Representation Learning", "summary": "Mutual Information (MI) is a fundamental measure of statistical dependence widely used in representation learning. While direct optimization of MI via its definition as a Kullback-Leibler divergence (KLD) is often intractable, many recent methods have instead maximized alternative dependence measures, most notably, the Jensen-Shannon divergence (JSD) between joint and product of marginal distributions via discriminative losses. However, the connection between these surrogate objectives and MI remains poorly understood. In this work, we bridge this gap by deriving a new, tight, and tractable lower bound on KLD as a function of JSD in the general case. By specializing this bound to joint and marginal distributions, we demonstrate that maximizing the JSD-based information increases a guaranteed lower bound on mutual information. Furthermore, we revisit the practical implementation of JSD-based objectives and observe that minimizing the cross-entropy loss of a binary classifier trained to distinguish joint from marginal pairs recovers a known variational lower bound on the JSD. Extensive experiments demonstrate that our lower bound is tight when applied to MI estimation. We compared our lower bound to state-of-the-art neural estimators of variational lower bound across a range of established reference scenarios. Our lower bound estimator consistently provides a stable, low-variance estimate of a tight lower bound on MI. We also demonstrate its practical usefulness in the context of the Information Bottleneck framework. Taken together, our results provide new theoretical justifications and strong empirical evidence for using discriminative learning in MI-based representation learning.", "published": "2025-10-23T15:18:12Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:28.863861"}
{"arxiv_id": "2510.20639v1", "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D   Medical Imaging", "summary": "Recent progress in vision-language modeling for 3D medical imaging has been fueled by large-scale computed tomography (CT) corpora with paired free-text reports, stronger architectures, and powerful pretrained models. This has enabled applications such as automated report generation and text-conditioned 3D image synthesis. Yet, current approaches struggle with high-resolution, long-sequence volumes: contrastive pretraining often yields vision encoders that are misaligned with clinical language, and slice-wise tokenization blurs fine anatomy, reducing diagnostic performance on downstream tasks. We introduce BTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder that unifies 2D and 3D training and inference while producing compact, frequency-aware volumetric tokens. A three-stage training curriculum enables (i) local reconstruction, (ii) overlapping-window tiling, and (iii) long-context decoder refinement, during which the model learns from short slice excerpts yet generalizes to scans exceeding 300 slices without additional memory overhead. BTB3D sets a new state-of-the-art on two key tasks: it improves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and Merlin for report generation; and it reduces FID by 75% and halves FVD compared to GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically consistent 512*512*241 volumes. These results confirm that precise three-dimensional tokenization, rather than larger language backbones alone, is essential for scalable vision-language modeling in 3D medical imaging. The codebase is available at: https://github.com/ibrahimethemhamamci/BTB3D", "published": "2025-10-23T15:13:13Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:28.864201"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "cortical decoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.287641"}
{"arxiv_id": "2510.20812v1", "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via   Speculation", "summary": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict", "published": "2025-10-23T17:59:21Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.288320"}
{"arxiv_id": "2510.20803v1", "title": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model", "summary": "We propose a novel AutoRegressive Generation-based paradigm for image Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level perception within a unified framework. Prior works integrating image segmentation into multimodal large language models (MLLMs) typically employ either boundary points representation or dedicated segmentation heads. These methods rely on discrete representations or semantic prompts fed into task-specific decoders, which limits the ability of the MLLM to capture fine-grained visual details. To address these challenges, we introduce a segmentation framework for MLLM based on image generation, which naturally produces dense masks for target objects. We leverage MLLM to output visual tokens and detokenize them into images using an universal VQ-VAE, making the segmentation fully dependent on the pixel-level understanding of the MLLM. To reduce inference latency, we employ a next-scale-prediction strategy to generate required visual tokens in parallel. Extensive experiments demonstrate that our method surpasses prior state-of-the-art approaches on multiple segmentation datasets with a remarkable boost in inference speed, while maintaining strong understanding capabilities.", "published": "2025-10-23T17:58:26Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.288628"}
{"arxiv_id": "2510.20769v1", "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble   Precipitation Forecasting", "summary": "Accurate medium-range precipitation forecasting is crucial for hydrometeorological risk management and disaster mitigation, yet remains challenging for current numerical weather prediction (NWP) systems. Traditional ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to maintain high skill, especially for moderate and heavy rainfall at extended lead times. This study develops a deep learning-based ensemble framework for multi-step precipitation prediction through joint modeling of a comprehensive set of atmospheric variables. The model is trained on ERA5 reanalysis data at 0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's Integrated Multi-satellite Retrievals for Global Precipitation Measurement (GPM) constellation (IMERG), incorporating 57 input variables, including upper-air and surface predictors. The architecture employs a patch-based Swin Transformer backbone with periodic convolutions to handle longitudinal continuity and integrates time and noise embeddings through conditional layer normalization. A dual-branch decoder predicts total precipitation and other variables, with targeted freezing of encoder-decoder pathways for specialized training. Training minimizes a hybrid loss combining the Continuous Ranked Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE), balancing probabilistic accuracy and magnitude fidelity. During inference, the model ingests real-time Global Forecast System (GFS) initial conditions to generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG data demonstrates higher Critical Success Index (CSI) scores at precipitation thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance for moderate to heavy rainfall.", "published": "2025-10-23T17:43:38Z", "query": "cortical decoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.288861"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "cortical decoding", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.289026"}
{"arxiv_id": "2510.20700v1", "title": "Structure-Conditional Minimum Bayes Risk Decoding", "summary": "Minimum Bayes Risk (MBR) decoding has seen renewed interest as an alternative to traditional generation strategies. While MBR has proven effective in machine translation, where the variability of a language model's outcome space is naturally constrained, it may face challenges in more open-ended tasks such as dialogue or instruction-following. We hypothesise that in such settings, applying MBR with standard similarity-based utility functions may result in selecting responses that are broadly representative of the model's distribution, yet sub-optimal with respect to any particular grouping of generations that share an underlying latent structure. In this work, we introduce three lightweight adaptations to the utility function, designed to make MBR more sensitive to structural variability in the outcome space. To test our hypothesis, we curate a dataset capturing three representative types of latent structure: dialogue act, emotion, and response structure (e.g., a sentence, a paragraph, or a list). We further propose two metrics to evaluate the structural optimality of MBR. Our analysis demonstrates that common similarity-based utility functions fall short by these metrics. In contrast, our proposed adaptations considerably improve structural optimality. Finally, we evaluate our approaches on real-world instruction-following benchmarks, AlpacaEval and MT-Bench, and show that increased structural sensitivity improves generation quality by up to 13.7 percentage points in win rate.", "published": "2025-10-23T16:13:49Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.289189"}
{"arxiv_id": "2510.20685v1", "title": "C-NAV: Towards Self-Evolving Continual Object Navigation in Open World", "summary": "Embodied agents are expected to perform object navigation in dynamic, open-world environments. However, existing approaches typically rely on static trajectories and a fixed set of object categories during training, overlooking the real-world requirement for continual adaptation to evolving scenarios. To facilitate related studies, we introduce the continual object navigation benchmark, which requires agents to acquire navigation skills for new object categories while avoiding catastrophic forgetting of previously learned knowledge. To tackle this challenge, we propose C-Nav, a continual visual navigation framework that integrates two key innovations: (1) A dual-path anti-forgetting mechanism, which comprises feature distillation that aligns multi-modal inputs into a consistent representation space to ensure representation consistency, and feature replay that retains temporal features within the action decoder to ensure policy consistency. (2) An adaptive sampling strategy that selects diverse and informative experiences, thereby reducing redundancy and minimizing memory overhead. Extensive experiments across multiple model architectures demonstrate that C-Nav consistently outperforms existing approaches, achieving superior performance even compared to baselines with full trajectory retention, while significantly lowering memory requirements. The code will be publicly available at https://bigtree765.github.io/C-Nav-project.", "published": "2025-10-23T15:57:43Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.289348"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "cortical decoding", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:32.289568"}
{"arxiv_id": "2510.20639v1", "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D   Medical Imaging", "summary": "Recent progress in vision-language modeling for 3D medical imaging has been fueled by large-scale computed tomography (CT) corpora with paired free-text reports, stronger architectures, and powerful pretrained models. This has enabled applications such as automated report generation and text-conditioned 3D image synthesis. Yet, current approaches struggle with high-resolution, long-sequence volumes: contrastive pretraining often yields vision encoders that are misaligned with clinical language, and slice-wise tokenization blurs fine anatomy, reducing diagnostic performance on downstream tasks. We introduce BTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder that unifies 2D and 3D training and inference while producing compact, frequency-aware volumetric tokens. A three-stage training curriculum enables (i) local reconstruction, (ii) overlapping-window tiling, and (iii) long-context decoder refinement, during which the model learns from short slice excerpts yet generalizes to scans exceeding 300 slices without additional memory overhead. BTB3D sets a new state-of-the-art on two key tasks: it improves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and Merlin for report generation; and it reduces FID by 75% and halves FVD compared to GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically consistent 512*512*241 volumes. These results confirm that precise three-dimensional tokenization, rather than larger language backbones alone, is essential for scalable vision-language modeling in 3D medical imaging. The codebase is available at: https://github.com/ibrahimethemhamamci/BTB3D", "published": "2025-10-23T15:13:13Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.289806"}
{"arxiv_id": "2510.20595v1", "title": "Diffusion Autoencoders with Perceivers for Long, Irregular and   Multimodal Astronomical Sequences", "summary": "Self-supervised learning has become a central strategy for representation learning, but the majority of architectures used for encoding data have only been validated on regularly-sampled inputs such as images, audios. and videos. In many scientific domains, data instead arrive as long, irregular, and multimodal sequences. To extract semantic information from these data, we introduce the Diffusion Autoencoder with Perceivers (daep). daep tokenizes heterogeneous measurements, compresses them with a Perceiver encoder, and reconstructs them with a Perceiver-IO diffusion decoder, enabling scalable learning in diverse data settings. To benchmark the daep architecture, we adapt the masked autoencoder to a Perceiver encoder/decoder design, and establish a strong baseline (maep) in the same architectural family as daep. Across diverse spectroscopic and photometric astronomical datasets, daep achieves lower reconstruction errors, produces more discriminative latent spaces, and better preserves fine-scale structure than both VAE and maep baselines. These results establish daep as an effective framework for scientific domains where data arrives as irregular, heterogeneous sequences.", "published": "2025-10-23T14:21:01Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.290015"}
{"arxiv_id": "2510.20535v1", "title": "ARC-Encoder: learning compressed text representations for large language   models", "summary": "Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and increased inference costs. Context compression techniques can reduce these costs, but the most effective approaches require fine-tuning the target model or even modifying its architecture. This can degrade its general abilities when not used for this specific purpose. Here we explore an alternative approach: an encoder that compresses the context into continuous representations which replace token embeddings in decoder LLMs. First, we perform a systematic study of training strategies and architecture choices for the encoder. Our findings led to the design of an Adaptable text Representations Compressor, named ARC-Encoder, which outputs $x$-times fewer continuous representations (typically $x\\!\\in\\!\\{4,8\\}$) than text tokens. We evaluate ARC-Encoder across a variety of LLM usage scenarios, ranging from in-context learning to context window extension, on both instruct and base decoders. Results show that ARC-Encoder achieves state-of-the-art performance on several benchmarks while improving computational efficiency at inference. Finally, we demonstrate that our models can be adapted to multiple decoders simultaneously, allowing a single encoder to generalize across different decoder LLMs. This makes ARC-Encoder a flexible and efficient solution for portable encoders that work seamlessly with multiple LLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder , fine-tuning dataset and pretrained models are available at https://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .", "published": "2025-10-23T13:20:57Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.290232"}
{"arxiv_id": "2510.20513v1", "title": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human   Preference Through Efficient Alignment", "summary": "Recent speech-to-speech (S2S) models generate intelligible speech but still lack natural expressiveness, largely due to the absence of a reliable evaluation metric. Existing approaches, such as subjective MOS ratings, low-level acoustic features, and emotion recognition are costly, limited, or incomplete. To address this, we present DeEAR (Decoding the Expressive Preference of eAR), a framework that converts human preference for speech expressiveness into an objective score. Grounded in phonetics and psychology, DeEAR evaluates speech across three dimensions: Emotion, Prosody, and Spontaneity, achieving strong alignment with human perception (Spearman's Rank Correlation Coefficient, SRCC = 0.86) using fewer than 500 annotated samples. Beyond reliable scoring, DeEAR enables fair benchmarking and targeted data curation. It not only distinguishes expressiveness gaps across S2S models but also selects 14K expressive utterances to form ExpressiveSpeech, which improves the expressive score (from 2.0 to 23.4 on a 100-point scale) of S2S models. Demos and codes are available at https://github.com/FreedomIntelligence/ExpressiveSpeech", "published": "2025-10-23T12:57:46Z", "query": "cortical decoding", "relevance": 0.15, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.290412"}
{"arxiv_id": "2510.20441v1", "title": "UniSE: A Unified Framework for Decoder-only Autoregressive LM-based   Speech Enhancement", "summary": "The development of neural audio codecs (NACs) has largely promoted applications of language models (LMs) to speech processing and understanding. However, there lacks the verification on the effectiveness of autoregressive (AR) LMbased models in unifying different sub-tasks of speech enhancement (SE). In this work, we propose UniSE, a unified decoder-only LM-based framework to handle different SE tasks including speech restoration, target speaker extraction and speech separation. It takes input speech features as conditions and generates discrete tokens of the target speech using AR modeling, which facilitates a compatibility between distinct learning patterns of multiple tasks. Experiments on several benchmarks indicate the proposed UniSE can achieve competitive performance compared to discriminative and generative baselines, showing the capacity of LMs in unifying SE tasks. The demo page is available here: https://github.com/hyyan2k/UniSE.", "published": "2025-10-23T11:22:24Z", "query": "cortical decoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.290599"}
{"arxiv_id": "2510.20411v1", "title": "Teacher Demonstrations in a BabyLM's Zone of Proximal Development for   Contingent Multi-Turn Interaction", "summary": "Multi-turn dialogues between a child and a caregiver are characterized by a property called contingency - that is, prompt, direct, and meaningful exchanges between interlocutors. We introduce ContingentChat, a teacher-student framework that benchmarks and improves multi-turn contingency in a BabyLM trained on 100M words. Using a novel alignment dataset for post-training, BabyLM generates responses that are more grammatical and cohesive. Experiments with adaptive teacher decoding strategies show limited additional gains. ContingentChat demonstrates the benefits of targeted post-training for dialogue quality and indicates that contingency remains a challenging goal for BabyLMs.", "published": "2025-10-23T10:29:23Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.290834"}
{"arxiv_id": "2510.20379v1", "title": "Robust Analog Lagrange Coded Computing: Theory and Algorithms via   Discrete Fourier Transforms", "summary": "Analog Lagrange Coded Computing (ALCC) is a recently proposed computational paradigm wherein certain computations over analog datasets are efficiently performed using distributed worker nodes through floating point representation. While the vanilla version of ALCC is known to preserve the privacy of the datasets from the workers and also achieve resilience against stragglers, it is not robust against Byzantine workers that return erroneous results. Highlighting this vulnerability, we propose a secure ALCC framework that is resilient against a wide range of integrity threats from the Byzantine workers. As a foundational step, we use error-correction algorithms for Discrete Fourier Transform (DFT) codes to build novel reconstruction strategies for ALCC thereby improving its computational accuracy in the presence of a bounded number of Byzantine workers. Furthermore, capitalizing on some theoretical results on the performance of the DFT decoders, we propose novel strategies for distributing the ALCC computational tasks to the workers, and show that such methods significantly improve the accuracy when the workers' trust profiles are available at the master server. Finally, we study the robustness of the proposed framework against colluding attacks, and show that interesting attack strategies can be executed by exploiting the inherent precision noise owing to floating point implementation.", "published": "2025-10-23T09:22:03Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.291005"}
{"arxiv_id": "2510.20302v1", "title": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with   Separated Temporal and Variate Modeling", "summary": "Multivariate time series forecasting requires simultaneously modeling temporal patterns and cross-variate dependencies. Channel-independent methods such as PatchTST excel at temporal modeling but ignore variable correlations, while pure variate-attention approaches such as iTransformer sacrifice temporal encoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that achieves principled separation between temporal encoding and variate-level decoding. InvDec combines a patch-based temporal encoder with an inverted decoder operating on the variate dimension through variate-wise self-attention. We introduce delayed variate embeddings that enrich variable-specific representations only after temporal encoding, preserving temporal feature integrity. An adaptive residual fusion mechanism dynamically balances temporal and variate information across datasets of varying dimensions. Instantiating InvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven benchmarks demonstrate significant gains on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and 2.7% gain on Traffic compared to PatchTST, while maintaining competitive performance on low-dimensional ETT datasets. Ablation studies validate each component, and analysis reveals that InvDec's advantage grows with dataset dimensionality, confirming that cross-variate modeling becomes critical as the number of variables increases.", "published": "2025-10-23T07:42:01Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.291173"}
{"arxiv_id": "2510.20287v1", "title": "Breakdance Video classification in the age of Generative AI", "summary": "Large Vision Language models have seen huge application in several sports use-cases recently. Most of these works have been targeted towards a limited subset of popular sports like soccer, cricket, basketball etc; focusing on generative tasks like visual question answering, highlight generation. This work analyzes the applicability of the modern video foundation models (both encoder and decoder) for a very niche but hugely popular dance sports - breakdance. Our results show that Video Encoder models continue to outperform state-of-the-art Video Language Models for prediction tasks. We provide insights on how to choose the encoder model and provide a thorough analysis into the workings of a finetuned decoder model for breakdance video classification.", "published": "2025-10-23T07:18:54Z", "query": "cortical decoding", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.291356"}
{"arxiv_id": "2510.20241v1", "title": "New Second-Order Achievability Bounds for Coding with Side Information   via Type Deviation Convergence", "summary": "We propose a framework for second-order achievability, called type deviation convergence, that is generally applicable to settings in network information theory, and is especially suitable for lossy source coding and channel coding with cost. We give a second-order achievability bound for lossy source coding with side information at the decoder (Wyner-Ziv problem) that improves upon all known bounds (e.g., Watanabe-Kuzuoka-Tan, Yassaee-Aref-Gohari and Li-Anantharam). We also give second-order achievability bounds for lossy compression where side information may be absent (Heegard-Berger problem) and channels with noncausal state information at the encoder and cost constraint (Gelfand-Pinsker problem with cost) that improve upon previous bounds.", "published": "2025-10-23T05:47:40Z", "query": "cortical decoding", "relevance": 0.15, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.291491"}
{"arxiv_id": "2510.20229v1", "title": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role   of Context", "summary": "Large Vision-Language Models (LVLMs) have made significant progress in recent years but are also prone to hallucination issues. They exhibit more hallucinations in longer, free-form responses, often attributed to accumulated uncertainties. In this paper, we ask: Does increased hallucination result solely from length-induced errors, or is there a deeper underlying mechanism? After a series of preliminary experiments and findings, we suggest that the risk of hallucinations is not caused by length itself but by the increased reliance on context for coherence and completeness in longer responses. Building on these insights, we propose a novel \"induce-detect-suppress\" framework that actively induces hallucinations through deliberately designed contexts, leverages induced instances for early detection of high-risk cases, and ultimately suppresses potential object-level hallucinations during actual decoding. Our approach achieves consistent, significant improvements across all benchmarks, demonstrating its efficacy. The strong detection and improved hallucination mitigation not only validate our framework but, more importantly, re-validate our hypothesis on context. Rather than solely pursuing performance gains, this study aims to provide new insights and serves as a first step toward a deeper exploration of hallucinations in LVLMs' longer responses.", "published": "2025-10-23T05:22:07Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.291658"}
{"arxiv_id": "2510.20208v1", "title": "Decoding-Free Sampling Strategies for LLM Marginalization", "summary": "Modern language models operate on subword-tokenized text in order to make a trade-off between model size, inference speed, and vocabulary coverage. A side effect of this is that, during inference, models are evaluated by measuring the probability of only the specific tokenization produced as the output, despite there being many possible ways to represent the same text with a subword vocabulary. Recent studies have argued instead for evaluating LLMs by marginalization - the probability mass of all tokenizations of a given text.   Marginalization is difficult due to the number of possible tokenizations of a text, so often approximate marginalization is done via sampling. However, a downside of sampling is that an expensive generation step must be performed by the LLM for each sample, which limits the number of samples that can be acquired given a runtime budget, and therefore also the accuracy of the approximation. Since computing the probability of a sequence given the tokenization is relatively cheap compared to actually generating it, we investigate sampling strategies that are decoding-free - they require no generation from the LLM, instead relying entirely on extremely cheap sampling strategies that are model and tokenizer agnostic.   We investigate the approximation quality and speed of decoding-free sampling strategies for a number of open models to find that they provide sufficiently accurate marginal estimates at a small fraction of the runtime cost and demonstrate its use on a set of downstream inference tasks.", "published": "2025-10-23T04:50:14Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.291856"}
{"arxiv_id": "2510.20195v1", "title": "Performance analysis of a Hadamard Transform Spectral Imaging system", "summary": "Hadamard Transform Spectral Imaging (HTSI) is a multiplexing technique used to recover spectra via encoding with multi-slit masks, and is particularly useful in low photon flux applications where signal-independent noise is the dominant noise source. This work focuses on the procedure that is used to recover spectra encoded with multi-slit masks generated from a Hadamard matrix; the decoding process involves multiplying the output encoded spectral images by the inverse of the Hadamard matrix, which separates any spectra that were overlapping in the target object. The output from HTSI is compared to direct measurement methods, such as single-slit scanning, to evaluate its performance and identify under which conditions it can provide an advantage or disadvantage. HTSI resulted in an increase in the average signal-to-noise (SNR) ratio of spectra when signal-independent noise, such as detector read noise, is present, and has no average net effect when signal dependent-noise, such as Poisson photon noise, is the only noise source present. The SNR of emission lines was found to be greater with HTSI than with single-slit scanning under both signal-independent and signal-dependent noise, and increases as the ratio of read-to-shot noise increases.", "published": "2025-10-23T04:28:48Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.292043"}
{"arxiv_id": "2510.20161v1", "title": "PathFormer: A Transformer with 3D Grid Constraints for Digital Twin   Robot-Arm Trajectory Generation", "summary": "Robotic arms require precise, task-aware trajectory planning, yet sequence models that ignore motion structure often yield invalid or inefficient executions. We present a Path-based Transformer that encodes robot motion with a 3-grid (where/what/when) representation and constraint-masked decoding, enforcing lattice-adjacent moves and workspace bounds while reasoning over task graphs and action order. Trained on 53,755 trajectories (80% train / 20% validation), the model aligns closely with ground truth -- 89.44% stepwise accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of paths legal by construction. Compiled to motor primitives on an xArm Lite 6 with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick success in controlled tests, and 86.7% end-to-end success across 60 language-specified tasks in cluttered scenes, absorbing slips and occlusions via local re-grounding without global re-planning. These results show that path-structured representations enable Transformers to generate accurate, reliable, and interpretable robot trajectories, bridging graph-based planning and sequence-based learning and providing a practical foundation for general-purpose manipulation and sim-to-real transfer.", "published": "2025-10-23T03:19:59Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:32.292215"}
{"arxiv_id": "2510.20148v1", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity   in Tau Propagation Through Multi-Layer Modeling", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.", "published": "2025-10-23T02:52:42Z", "query": "cortical decoding", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:32.292403"}
{"arxiv_id": "2510.20093v1", "title": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch   Generation via Visual Question Answering Feedback", "summary": "Although recent advancements in diffusion models have significantly enriched the quality of generated images, challenges remain in synthesizing pixel-based human-drawn sketches, a representative example of abstract expression. To combat these challenges, we propose StableSketcher, a novel framework that empowers diffusion models to generate hand-drawn sketches with high prompt fidelity. Within this framework, we fine-tune the variational autoencoder to optimize latent decoding, enabling it to better capture the characteristics of sketches. In parallel, we integrate a new reward function for reinforcement learning based on visual question answering, which improves text-image alignment and semantic consistency. Extensive experiments demonstrate that StableSketcher generates sketches with improved stylistic fidelity, achieving better alignment with prompts compared to the Stable Diffusion baseline. Additionally, we introduce SketchDUO, to the best of our knowledge, the first dataset comprising instance-level sketches paired with captions and question-answer pairs, thereby addressing the limitations of existing datasets that rely on image-label pairs. Our code and dataset will be made publicly available upon acceptance.", "published": "2025-10-23T00:27:32Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.292564"}
{"arxiv_id": "2510.20075v1", "title": "LLMs can hide text in other text of the same length.ipynb", "summary": "A meaningful text can be hidden inside another, completely different yet still coherent and plausible, text of the same length. For example, a tweet containing a harsh political critique could be embedded in a tweet that celebrates the same political leader, or an ordinary product review could conceal a secret manuscript. This uncanny state of affairs is now possible thanks to Large Language Models, and in this paper we present a simple and efficient protocol to achieve it. We show that even modest 8-billion-parameter open-source LLMs are sufficient to obtain high-quality results, and a message as long as this abstract can be encoded and decoded locally on a laptop in seconds. The existence of such a protocol demonstrates a radical decoupling of text from authorial intent, further eroding trust in written communication, already shaken by the rise of LLM chatbots. We illustrate this with a concrete scenario: a company could covertly deploy an unfiltered LLM by encoding its answers within the compliant responses of a safe model. This possibility raises urgent questions for AI safety and challenges our understanding of what it means for a Large Language Model to know something.", "published": "2025-10-22T23:16:50Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.292793"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "cortical decoding", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:32.293055"}
{"arxiv_id": "2510.20064v1", "title": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative   Decoding for LLMs", "summary": "Speculative decoding is widely used in accelerating large language model (LLM) inference. In this work, we focus on the online draft model selection problem in speculative decoding. We design an algorithm that provably competes with the best draft model in hindsight for each query in terms of either the token acceptance probability or expected acceptance length. In particular, we show that we can accurately evaluate all draft models, instead of only the chosen model without incurring additional queries to the target model, which allows us to improve exponentially over the existing bandit-based approach as the number of draft models increases. Our approach is generically applicable with any speculative decoding methods (single draft, multi-drafts and draft-trees). Moreover, we design system-efficient versions of online learners and demonstrate that the overhead in computation and latency can be substantially reduced. We conduct extensive experiments on open-source LLMs and diverse datasets, demonstrating that our methods substantially outperform the state-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains where specialized domain-expert drafters are available, especially when long reasoning chains are required.", "published": "2025-10-22T22:32:26Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:32.293238"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "cortical decoding", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:15:32.293449"}
{"arxiv_id": "2510.19990v1", "title": "No Compute Left Behind: Rethinking Reasoning and Sampling with Masked   Diffusion Models", "summary": "Masked diffusion language models (MDLMs) are trained to in-fill positions in randomly masked sequences, in contrast to next-token prediction models. Discussions around MDLMs focus on two benefits: (1) any-order decoding and 2) multi-token decoding. However, we observe that for math and coding tasks, any-order algorithms often underperform or behave similarly to left-to-right sampling, and standard multi-token decoding significantly degrades performance. At inference time, MDLMs compute the conditional distribution of all masked positions. A natural question is: How can we justify this additional compute when left-to-right one-token-at-a-time decoding is on par with any-order decoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs to infill a reasoning template, we can structure outputs and distinguish between reasoning and answer tokens. In turn, this enables measuring answer uncertainty during reasoning, and early exits when the model converges on an answer. Next, given an answer, reasoning-as-infilling enables sampling from the MDLM posterior over reasoning traces conditioned on the answer, providing a new source of high-quality data for post-training. On GSM8k, we observe that fine-tuning LLaDA-8B Base on its posterior reasoning traces provides a performance boost on par with fine-tuning on human-written reasoning traces. Additionally, given an answer, reasoning-as-infilling provides a method for scoring the correctness of the reasoning process at intermediate steps. Second, we propose multi-token entropy decoding (MED), a simple adaptive sampler that minimizes the error incurred by decoding positions in parallel based on the conditional entropies of those positions. MED preserves performance across benchmarks and leads to 2.7x fewer steps. Our work demonstrates that the training and compute used by MDLMs unlock many new inference and post-training methods.", "published": "2025-10-22T19:41:27Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.293697"}
{"arxiv_id": "2510.19779v1", "title": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative   Decoders", "summary": "Speculative Decoding (SD) accelerates large language model inference by employing a small draft model to generate predictions, which are then verified by a larger target model. The effectiveness of SD hinges on the alignment between these models, which is typically enhanced by Knowledge Distillation (KD). However, conventional KD methods aim to minimize the KL divergence between the draft and target models across all tokens, a goal that is misaligned with the true objective of SD, which is to maximize token acceptance rate. Therefore, draft models often struggle to fully assimilate the target model's knowledge due to capacity constraints, leading to suboptimal performance. To address this challenge, we propose AdaSPEC, a novel method that incorporates selective token filtering into the KD process. AdaSPEC utilizes a reference model to identify and filter out difficult-to-fit tokens, enabling the distillation of a draft model that better aligns with the target model on simpler tokens. This approach improves the overall token acceptance rate without compromising generation quality. We evaluate AdaSPEC across diverse tasks, including arithmetic reasoning, instruction-following, coding, and summarization, using model configurations of 31M/1.4B and 350M/2.7B parameters. Our results demonstrate that AdaSPEC consistently outperforms the state-of-the-art DistillSpec method, achieving higher acceptance rates across all tasks (up to 15\\%). The code is publicly available at https://github.com/yuezhouhu/adaspec.", "published": "2025-10-22T17:13:00Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:32.293935"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "spike train analysis", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:35.857193"}
{"arxiv_id": "2510.20817v1", "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "summary": "It is commonly believed that optimizing the reverse KL divergence results in \"mode seeking\", while optimizing forward KL results in \"mass covering\", with the latter being preferred if the goal is to sample from multiple diverse modes. We show -- mathematically and empirically -- that this intuition does not necessarily transfer well to doing reinforcement learning with reverse/forward KL regularization (e.g. as commonly used with language models). Instead, the choice of reverse/forward KL determines the family of optimal target distributions, parameterized by the regularization coefficient. Mode coverage depends primarily on other factors, such as regularization strength, and relative scales between rewards and reference probabilities. Further, we show commonly used settings such as low regularization strength and equal verifiable rewards tend to specify unimodal target distributions, meaning the optimization objective is, by construction, non-diverse. We leverage these insights to construct a simple, scalable, and theoretically justified algorithm. It makes minimal changes to reward magnitudes, yet optimizes for a target distribution which puts high probability over all high-quality sampling modes. In experiments, this simple modification works to post-train both Large Language Models and Chemical Language Models to have higher solution quality and diversity, without any external signals of diversity, and works with both forward and reverse KL when using either naively fails.", "published": "2025-10-23T17:59:40Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.857655"}
{"arxiv_id": "2510.20815v1", "title": "Generative Reasoning Recommendation via LLMs", "summary": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.", "published": "2025-10-23T17:59:31Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:35.858053"}
{"arxiv_id": "2510.20813v1", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic   Manipulation", "summary": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.", "published": "2025-10-23T17:59:26Z", "query": "spike train analysis", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.858286"}
{"arxiv_id": "2510.20814v1", "title": "SpectraMorph: Structured Latent Learning for Self-Supervised   Hyperspectral Super-Resolution", "summary": "Hyperspectral sensors capture dense spectra per pixel but suffer from low spatial resolution, causing blurred boundaries and mixed-pixel effects. Co-registered companion sensors such as multispectral, RGB, or panchromatic cameras provide high-resolution spatial detail, motivating hyperspectral super-resolution through the fusion of hyperspectral and multispectral images (HSI-MSI). Existing deep learning based methods achieve strong performance but rely on opaque regressors that lack interpretability and often fail when the MSI has very few bands. We propose SpectraMorph, a physics-guided self-supervised fusion framework with a structured latent space. Instead of direct regression, SpectraMorph enforces an unmixing bottleneck: endmember signatures are extracted from the low-resolution HSI, and a compact multilayer perceptron predicts abundance-like maps from the MSI. Spectra are reconstructed by linear mixing, with training performed in a self-supervised manner via the MSI sensor's spectral response function. SpectraMorph produces interpretable intermediates, trains in under a minute, and remains robust even with a single-band (pan-chromatic) MSI. Experiments on synthetic and real-world datasets show SpectraMorph consistently outperforming state-of-the-art unsupervised/self-supervised baselines while remaining very competitive against supervised baselines.", "published": "2025-10-23T17:59:26Z", "query": "spike train analysis", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.858517"}
{"arxiv_id": "2510.20812v1", "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via   Speculation", "summary": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict", "published": "2025-10-23T17:59:21Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.858717"}
{"arxiv_id": "2510.20811v1", "title": "Simulation-calibrated Bayesian inference for progenitor properties of   the microquasar SS 433", "summary": "SS\\,433 is one of the most extreme Galactic X-ray binaries, exhibiting semi-relativistic jets and super-critical accretion, and harboring a compact object, likely a black hole. Despite decades of observation and modeling, the precise nature of its progenitor binary remains uncertain. To estimate the zero-age main sequence (ZAMS) properties of binaries that evolve into SS\\,433-like systems, we apply simulation-based calibration to Bayesian inference and convolve a multivariate Gaussian likelihood constructed from six measured binary parameters of SS\\,433 with the isolated binary evolution model \\textsc{COSMIC}. Employing the dynamic nested sampler of \\texttt{dynesty}, we perform posterior inference over a ten-dimensional progenitor parameter space defined by the masses, orbital parameters, mass transfer possibilities, and natal kick velocity. We find that SS\\,433-like systems arise from specific regions of binary evolution parameter space depending on key assumptions, such as the mass transfer rate and uncertainty taken from observations. Our simulation-based calibration framework, implemented with a suite of machine learning algorithms and scored by a heuristic reliability metric, allows us to iteratively build posterior distributions of the progenitors of SS\\,433-like systems. This analysis reveals 90\\% confidence intervals for the ZAMS primary mass $(8, 11)$ M$_\\odot$, secondary mass $(32, 40)$ M$_\\odot $, orbital period $(136, 2259)$ days, eccentricity $(0.26, 0.6)$, common envelope evolution efficiency $(0.44, 0.76)$, accreted fraction in stable mass transfer $(0.22, 0.6)$, and black hole natal kick velocity magnitude $(5, 68)$ km/s. These results demonstrate the feasibility of direct probabilistic inference of X-ray binary progenitors to offer new insights into the evolution of high-accretion-rate systems such as SS\\,433.", "published": "2025-10-23T17:59:09Z", "query": "spike train analysis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.858924"}
{"arxiv_id": "2510.20809v1", "title": "Real Deep Research for AI, Robotics and Beyond", "summary": "With the rapid growth of research in AI and robotics now producing over 10,000 papers annually it has become increasingly difficult for researchers to stay up to date. Fast evolving trends, the rise of interdisciplinary work, and the need to explore domains beyond one's expertise all contribute to this challenge. To address these issues, we propose a generalizable pipeline capable of systematically analyzing any research area: identifying emerging trends, uncovering cross domain opportunities, and offering concrete starting points for new inquiry. In this work, we present Real Deep Research (RDR) a comprehensive framework applied to the domains of AI and robotics, with a particular focus on foundation models and robotics advancements. We also briefly extend our analysis to other areas of science. The main paper details the construction of the RDR pipeline, while the appendix provides extensive results across each analyzed topic. We hope this work sheds light for researchers working in the field of AI and beyond.", "published": "2025-10-23T17:59:05Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.859087"}
{"arxiv_id": "2510.20808v1", "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "summary": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.", "published": "2025-10-23T17:58:53Z", "query": "spike train analysis", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.859259"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.859394"}
{"arxiv_id": "2510.20806v1", "title": "Testing the AGN Paradigm, Part I: a generic SED for Seyfert 1 galaxies", "summary": "This article presents the first part of a study aimed at testing the unification paradigm for AGN (UPAGN) using the SED reconstruction code X-CIGALE. Our method consists in obtaining a generic SED for a large sample of Seyfert 1 (Sy1; part 1), then applying this SED to Seyfert 2 (Sy2; Part~II), expecting that the only difference will be the line-of-sight (LOS) angle, $i$, relative to the polar axis of the torus of gas and dust obscuring the broad line regions (BLRs). Our sample is composed of 3,896 Type 1, Sy1 at low redshifts, $ z&lt;0.4$, separated into four spectral subgroups depending on the presence or absence in their spectra of narrow emission lines, Sy1N/Sy1B, and AGN wind, Sy1Bw and Sy1Nw. The generic SED produced by X-CIGALE applies to 90\\% of the Sy1 in our sample. It includes a clumpy torus with an AGN engine seen face-on ($i \\sim 10^\\circ \\pm 5^\\circ$). Our analysis not only supports the existence of a torus in Sy1, in good agreement with UPAGN, but also reveals new facts about the accretion of matter and AGN wind: 1- a sudden accretion of matter from the BLR to the accretion disk triggered the wind, 2- matter from the wind replenishes the torus, consistent with a gradual formation of this structure by recurrent AGN winds, and 3- Sy1Bw and Sy1Nw eventually evolve as AGN without wind, leaving behind a torus as evidence of a higher AGN activity in their past.", "published": "2025-10-23T17:58:44Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.859527"}
{"arxiv_id": "2510.20805v1", "title": "Bilevel Analysis of Cost and Emissions Externalities from Data Center   Load Shifting", "summary": "Data centers are emerging as large, flexible electricity consumers capable of shifting computational workloads across locations in response to economic and environmental signals. While this flexibility has potential for emissions reduction, its impact on power system operations depends critically on how such behavior interacts with network constraints and market signals. We develop a bilevel optimization framework in which a data center minimizes a weighted combination of electricity cost and marginal emissions intensity (LME), while the system operator clears economic dispatch under transmission and generation constraints. Focusing on a stylized three-bus power system, we derive closed-form, piecewise-linear expressions for both the data center and system-wide objectives as functions of the data centers' load shift. These expressions capture threshold-driven regime changes due to congestion and renewable saturation. We identify sufficient conditions under which the data center's decentralized decisions align with or diverge from socially optimal behavior and characterize the resulting externalities. Our results reveal how system topology and generator asymmetry affect incentive alignment and provide insight into when marginal price or emissions signals may fail to guide flexible loads toward socially beneficial outcomes. Our results offer a tractable starting point for analyzing decentralized flexibility under carbon-aware incentives and suggest directions for improving coordination between flexible loads and system operations.", "published": "2025-10-23T17:58:31Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:35.859699"}
{"arxiv_id": "2510.20800v1", "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient   Step on 100 Samples", "summary": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank reduction (LASER) which demonstrated that pruning high-order components of carefully chosen LLM's weight matrices can boost downstream accuracy -- without any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each requiring full-dataset forward passes) makes it impractical for rapid deployment. We demonstrate that this overhead can be removed and find that: (i) Only a small, carefully chosen subset of matrices needs to be inspected -- eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's singular values pinpoints which matrices merit reduction, (iii) Increasing the factorization search space by allowing matrices rows to cluster around multiple subspaces and then decomposing each cluster separately further reduces overfitting on the original training data and further lifts accuracy by up to 24.6 percentage points, and finally, (iv) we discover that evaluating on just 100 samples rather than the full training data -- both for computing the indicative gradients and for measuring the final accuracy -- suffices to further reduce the search time; we explain that as adaptation to downstream tasks is dominated by prompting style, not dataset size. As a result, we show that combining these findings yields a fast and robust adaptation algorithm for downstream tasks. Overall, with a single gradient step on 100 examples and a quick scan of the top candidate layers and factorization techniques, we can adapt LLMs to new datasets -- entirely without fine-tuning.", "published": "2025-10-23T17:58:01Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.859976"}
{"arxiv_id": "2510.20797v1", "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "summary": "A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean-pooling approach that consistently outperforms the widely used compression-tokens architecture, and study training the same compressor to output multiple compression ratios. We conduct extensive experiments across in-domain and out-of-domain QA datasets, as well as across model families, scales, and compression ratios. Overall, our simple mean-pooling approach achieves the strongest performance, with a relatively small drop when training for multiple compression ratios. More broadly though, across architectures and training regimes the trade-offs are more nuanced, illustrating the complex landscape of compression methods.", "published": "2025-10-23T17:57:23Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:35.860177"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "spike train analysis", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.860423"}
{"arxiv_id": "2510.20792v1", "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for   Text-Guided Graph Generation", "summary": "The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method targeting latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.", "published": "2025-10-23T17:54:17Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.860648"}
{"arxiv_id": "2510.20791v1", "title": "A Microphysical Probe of Neutron Star Interiors: Constraining the   Equation of State with Glitch Dynamics", "summary": "Glitches in neutron stars originate from the sudden transfer of angular momentum between superfluid components and the observable crust. By modeling this glitch dynamics, including vortex motion, mutual friction, and angular momentum exchange, we can probe the dense matter equation of state. We match theoretical predictions of glitch rise times, overshoot patterns, and relaxation timescales to the well-documented observations of the 2016 Vela glitch. Our model incorporates microphysical parameters such as the mutual friction coefficient $\\mathcal{B}$, which in the core arises from electron scattering off magnetized vortices, and in the crust from Kelvin wave excitation during vortex-lattice interactions. Our Markov Chain Monte Carlo analysis of the timing residuals reveals detailed glitch dynamics: the crustal superfluid couples on timescales of $\\sim100$ seconds, the core exhibits overshoot behavior due to strong central behavior, and the inner crust shows weak entrainment, with $\\sim70\\%$ of free neutrons remaining superfluid. The modeled rise times are consistent with the observed upper limit of 12.6 seconds, and the observed overshoot requires strong crustal friction but weak core friction, supporting a spatially varying $\\mathcal{B}$.These findings highlight the importance of microphysical modeling and demonstrate the potential of future high-cadence timing observations to further constrain the internal dynamics and composition of neutron stars.", "published": "2025-10-23T17:54:13Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.860871"}
{"arxiv_id": "2510.20788v1", "title": "Predicting Protein-Nucleic Acid Flexibility Using Persistent Sheaf   Laplacians", "summary": "Understanding the flexibility of protein-nucleic acid complexes, often characterized by atomic B-factors, is essential for elucidating their structure, dynamics, and functions, such as reactivity and allosteric pathways. Traditional models such as Gaussian Network Models (GNM) and Elastic Network Models (ENM) often fall short in capturing multiscale interactions, especially in large or complex biomolecular systems. In this work, we apply the Persistent Sheaf Laplacian (PSL) framework for the B-factor prediction of protein-nucleic acid complexes. The PSL model integrates multiscale analysis, algebraic topology, combinatoric Laplacians, and sheaf theory for data representation. It reveals topological invariants in its harmonic spectra and captures the homotopic shape evolution of data with its non-harmonic spectra. Its localization enables accurate B-factor predictions. We benchmark our method on three diverse datasets, including protein-RNA and nucleic-acid-only structures, and demonstrate that PSL consistently outperforms existing models such as GNM and multiscale FRI (mFRI), achieving up to a 21% improvement in Pearson correlation coefficient for B-factor prediction. These results highlight the robustness and adaptability of PSL in modeling complex biomolecular interactions and suggest its potential utility in broader applications such as mutation impact analysis and drug design.", "published": "2025-10-23T17:53:33Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.861085"}
{"arxiv_id": "2510.20783v1", "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "summary": "Chess is a canonical example of a task that requires rigorous reasoning and long-term planning. Modern decision Transformers - trained similarly to LLMs - are able to learn competent gameplay, but it is unclear to what extent they truly capture the rules of chess. To investigate this, we train a 270M parameter chess Transformer and test it on out-of-distribution scenarios, designed to reveal failures of systematic generalization. Our analysis shows that Transformers exhibit compositional generalization, as evidenced by strong rule extrapolation: they adhere to fundamental syntactic rules of the game by consistently choosing valid moves even in situations very different from the training data. Moreover, they also generate high-quality moves for OOD puzzles. In a more challenging test, we evaluate the models on variants including Chess960 (Fischer Random Chess) - a variant of chess where starting positions of pieces are randomized. We found that while the model exhibits basic strategy adaptation, they are inferior to symbolic AI algorithms that perform explicit search, but gap is smaller when playing against users on Lichess. Moreover, the training dynamics revealed that the model initially learns to move only its own pieces, suggesting an emergent compositional understanding of the game.", "published": "2025-10-23T17:51:28Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.861284"}
{"arxiv_id": "2510.20781v1", "title": "A Weakly Nonlinear Theory for Pattern Formation in Structured Models   with Localized Solutions", "summary": "Structured models, such as PDEs structured by age or phenotype, provide a setting to study pattern formation in heterogeneous populations. Classical tools to quantify the emergence of patterns, such as linear and weakly nonlinear analyses, pose significant mathematical challenges for these models due to sharply peaked or singular steady states. Here, we present a weakly nonlinear framework that extends classical tools to structured PDE models in settings where the base state is spatially uniform, but exponentially localized in the structured variable. Our approach utilizes WKBJ asymptotics and an analysis of the Stokes phenomenon to systematically resolve the solution structure in the limit where the steady state tends to a Dirac-delta function. To demonstrate our method, we consider a chemically structured (nonlocal) model of motile bacteria that interact through quorum sensing. For this example, our analysis yields an amplitude equation that governs the solution dynamics near a linear instability, and predicts a pitchfork bifurcation. From the amplitude equation, we deduce an effective parameter grouping whose sign determines whether the pitchfork bifurcation is subcritical or supercritical. Although we demonstrate our framework for a specific example, our techniques are broadly applicable.", "published": "2025-10-23T17:48:58Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.861443"}
{"arxiv_id": "2510.20780v1", "title": "Are Large Reasoning Models Good Translation Evaluators? Analysis and   Performance Boost", "summary": "Recent advancements in large reasoning models (LRMs) have introduced an intermediate \"thinking\" process prior to generating final answers, improving their reasoning capabilities on complex downstream tasks. However, the potential of LRMs as evaluators for machine translation (MT) quality remains underexplored. We provides the first systematic analysis of LRM-as-a-judge in MT evaluation. We identify key challenges, revealing LRMs require tailored evaluation materials, tend to \"overthink\" simpler instances and have issues with scoring mechanisms leading to overestimation. To address these, we propose to calibrate LRM thinking by training them on synthetic, human-like thinking trajectories. Our experiments on WMT24 Metrics benchmarks demonstrate that this approach largely reduces thinking budgets by ~35x while concurrently improving evaluation performance across different LRM scales from 7B to 32B (e.g., R1-Distill-Qwen-7B achieves a +8.7 correlation point improvement). These findings highlight the potential of efficiently calibrated LRMs to advance fine-grained automatic MT evaluation.", "published": "2025-10-23T17:48:36Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.861587"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "spike train analysis", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.861752"}
{"arxiv_id": "2510.20777v1", "title": "Learning Optimal Power Flow with Pointwise Constraints", "summary": "Training learning parameterizations to solve optimal power flow (OPF) with pointwise constraints is proposed. In this novel training approach, a learning parameterization is substituted directly into an OPF problem with constraints required to hold over all problem instances. This is different from existing supervised learning methods in which constraints are required to hold across the average of problem instances. Training with pointwise constraints is undertaken in the dual domain with the use of augmented Lagrangian and dual gradient ascent algorithm. Numerical experiments demonstrate that training with pointwise constraints produces solutions with smaller constraint violations. Experiments further demonstrated that pointwise constraints are most effective at reducing constraint violations in corner cases - defined as those realizations in which constraints are most difficult to satisfy. Gains are most pronounced in power systems with large numbers of buses.", "published": "2025-10-23T17:48:10Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:35.861891"}
{"arxiv_id": "2510.20774v1", "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to   Field-Guided Data Generation", "summary": "Large-scale and diverse datasets are vital for training robust robotic manipulation policies, yet existing data collection methods struggle to balance scale, diversity, and quality. Simulation offers scalability but suffers from sim-to-real gaps, while teleoperation yields high-quality demonstrations with limited diversity and high labor cost. We introduce FieldGen, a field-guided data generation framework that enables scalable, diverse, and high-quality real-world data collection with minimal human supervision. FieldGen decomposes manipulation into two stages: a pre-manipulation phase, allowing trajectory diversity, and a fine manipulation phase requiring expert precision. Human demonstrations capture key contact and pose information, after which an attraction field automatically generates diverse trajectories converging to successful configurations. This decoupled design combines scalable trajectory diversity with precise supervision. Moreover, FieldGen-Reward augments generated data with reward annotations to further enhance policy learning. Experiments demonstrate that policies trained with FieldGen achieve higher success rates and improved stability compared to teleoperation-based baselines, while significantly reducing human effort in long-term real-world data collection. Webpage is available at https://fieldgen.github.io/.", "published": "2025-10-23T17:47:12Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.862050"}
{"arxiv_id": "2510.20773v1", "title": "Ill-Posedness of the 2D Euler Equations in a Logarithmically Refined   Critical Sobolev Space", "summary": "In their seminal work, Bourgain and Li establish strong ill-posedness of the 2D Euler equations for initial velocity in the critical Sobolev space $H^2(\\mathbb{R}^2)$. In this work, we extend those results by demonstrating strong ill-posedness in logarithmically regularized spaces which are strictly contained in $H^2(\\mathbb{R}^2)$ and which contain $H^s(\\mathbb{R}^2)$ for all $s&gt;2$. These spaces are constructed via application of a fractional logarithmic derivative to the critical Sobolev norm. We show that if the power $\\alpha$ of the logarithmic derivative satisfies $\\alpha\\leq 1/2$, then the 2D Euler equations are strongly ill-posed.", "published": "2025-10-23T17:46:16Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:35.862192"}
{"arxiv_id": "2510.20813v1", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic   Manipulation", "summary": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.", "published": "2025-10-23T17:59:26Z", "query": "virtual reality neuroscience", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:39.276715"}
{"arxiv_id": "2510.20808v1", "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "summary": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.", "published": "2025-10-23T17:58:53Z", "query": "virtual reality neuroscience", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:39.277193"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "virtual reality neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:39.277457"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "virtual reality neuroscience", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:39.277638"}
{"arxiv_id": "2510.20712v1", "title": "Enhancement of Curie Temperature in Ferromagnetic Insulator-Topological   Insulator Heterostructures", "summary": "We theoretically analyze the topological insulator (TI) surface state mediated interactions between local moments in a proximate 2D ferromagnetic insulator (FMI) motivated by recent experiments that show a significant increase in the Curie temperature Tc of FMI-TI heterostructures. Such interactions have been investigated earlier with a focus on dilute magnetic dopants in TIs. Our problem involves a dense set of moments for which we find that the short range Bloembergen-Rowland interaction, arising from virtual particle-hole transitions between the valence and conduction bands, dominates over the oscillatory Ruderman-Kittel-Kasuya-Yosida (RKKY) interaction. We show that the Tc enhancement is proportional to the Van Vleck susceptibility and that the spin-momentum locking of surface states leads to out-of-plane ferromagnetic order in the FMI. We investigate how the hybridization between top and bottom surfaces in a thin TI film impacts Tc enhancement, and show how our results can help understand recent experiments on atomically thin Cr2Te3-(Bi,Sb)2Te3.", "published": "2025-10-23T16:28:43Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:39.277809"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "virtual reality neuroscience", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:39.278027"}
{"arxiv_id": "2510.20602v1", "title": "Resounding Acoustic Fields with Reciprocity", "summary": "Achieving immersive auditory experiences in virtual environments requires flexible sound modeling that supports dynamic source positions. In this paper, we introduce a task called resounding, which aims to estimate room impulse responses at arbitrary emitter location from a sparse set of measured emitter positions, analogous to the relighting problem in vision. We leverage the reciprocity property and introduce Versa, a physics-inspired approach to facilitating acoustic field learning. Our method creates physically valid samples with dense virtual emitter positions by exchanging emitter and listener poses. We also identify challenges in deploying reciprocity due to emitter/listener gain patterns and propose a self-supervised learning approach to address them. Results show that Versa substantially improve the performance of acoustic field learning on both simulated and real-world datasets across different metrics. Perceptual user studies show that Versa can greatly improve the immersive spatial sound experience. Code, dataset and demo videos are available on the project website: https://waves.seas.upenn.edu/projects/versa.", "published": "2025-10-23T14:30:09Z", "query": "virtual reality neuroscience", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:15:39.278172"}
{"arxiv_id": "2510.20571v1", "title": "Phase Transitions and Virtual Exceptional Points in Quantum Emitters   Coupled to Dissipative Baths", "summary": "Controlling atom-photon interactions in engineered environments is central to quantum optics and emerging quantum technologies. Non-Hermitian (NH) photonic baths, where dissipation fundamentally reshapes spectral and dynamical properties, provide versatile platforms for such control. Here we investigate the relaxation dynamics of a single two-level quantum emitter coupled to the edge of a semi-infinite dissipative bosonic lattice with uniform loss. Despite the simplicity of this bath, we uncover rich dynamical phase transitions, i.e. qualitative changes in spontaneous emission decay as system parameters are varied. In particular, we establish the existence of an optimal dissipative environment for accelerated spontaneous emission. The phase transitions are traced to spectral restructuring of the resolvent, in some cases governed by the coalescence of resonance states on the second Riemann sheet. We identify these coalescences as virtual exceptional points (EPs) of resonance origin, providing a conceptual bridge with EP physics while highlighting distinctive features of infinite-dimensional NH systems. More broadly, our results illustrate how the specific nature of dissipation -- whether uniform losses, staggered losses, or dephasing -- can profoundly impact emitter relaxation, pointing to dissipation engineering as a versatile tool for quantum technologies.", "published": "2025-10-23T13:57:58Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:39.278321"}
{"arxiv_id": "2510.20502v1", "title": "Predicting the 3D microstructure of SOFC anodes from 2D SEM images using   stochastic microstructure modeling and CNNs", "summary": "The 3D microstructure of solid oxide fuel cell anodes significantly influences their electrochemical performance, but conventional methods for acquiring high-resolution microstructural 3D data such as focused ion beam scanning electron microscopy (FIB-SEM) are costly in both time and resources. In contrast, obtaining 2D images, such as from scanning electron microscopy (SEM), is more accessible, though typically providing insufficient information to accurately characterize the 3D microstructure. To address this challenge, we propose a novel approach that predicts the 3D microstructure from 2D SEM images. The presented method utilizes a low-parametric 3D model from stochastic geometry to generate a large number of virtual 3D microstructures and employs a physics-based SEM simulation tool to obtain the corresponding 2D SEM images. By systematically varying the underlying model parameters, a large dataset can be generated to train convolutional neural networks (CNNs). By doing so, we can statistically reconstruct the 3D microstructure from 2D SEM images by drawing realizations from the stochastic 3D model using the predicted model parameters. In addition, we conducted an error analysis on key geometrical descriptors to quantitatively evaluate the accuracy and reliability of this stereological prediction tool.", "published": "2025-10-23T12:46:10Z", "query": "virtual reality neuroscience", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:39.278500"}
{"arxiv_id": "2510.20409v1", "title": "Designing Intent Communication for Agent-Human Collaboration", "summary": "As autonomous agents, from self-driving cars to virtual assistants, become increasingly present in everyday life, safe and effective collaboration depends on human understanding of agents' intentions. Current intent communication approaches are often rigid, agent-specific, and narrowly scoped, limiting their adaptability across tasks, environments, and user preferences. A key gap remains: existing models of what to communicate are rarely linked to systematic choices of how and when to communicate, preventing the development of generalizable, multi-modal strategies. In this paper, we introduce a multidimensional design space for intent communication structured along three dimensions: Transparency (what is communicated), Abstraction (when), and Modality (how). We apply this design space to three distinct human-agent collaboration scenarios: (a) bystander interaction, (b) cooperative tasks, and (c) shared control, demonstrating its capacity to generate adaptable, scalable, and cross-domain communication strategies. By bridging the gap between intent content and communication implementation, our design space provides a foundation for designing safer, more intuitive, and more transferable agent-human interactions.", "published": "2025-10-23T10:24:28Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:39.278667"}
{"arxiv_id": "2510.20776v1", "title": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "summary": "This work proposes a new generation-based 3D reconstruction method, named Cupid, that accurately infers the camera pose, 3D shape, and texture of an object from a single 2D image. Cupid casts 3D reconstruction as a conditional sampling process from a learned distribution of 3D objects, and it jointly generates voxels and pixel-voxel correspondences, enabling robust pose and shape estimation under a unified generative framework. By representing both input camera poses and 3D shape as a distribution in a shared 3D latent space, Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that produces initial 3D geometry with associated 2D projections for pose recovery; and (2) a refinement stage that integrates pose-aligned image features to enhance structural fidelity and appearance details. Extensive experiments demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3 dB PSNR gain and an over 10% Chamfer Distance reduction, while matching monocular estimators on pose accuracy and delivering superior visual fidelity over baseline 3D generative models. For an immersive view of the 3D results generated by Cupid, please visit cupid3d.github.io.", "published": "2025-10-23T17:47:38Z", "query": "immersive VR brain", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.734408"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "immersive VR brain", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.734961"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "immersive VR brain", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:42.735484"}
{"arxiv_id": "2510.20602v1", "title": "Resounding Acoustic Fields with Reciprocity", "summary": "Achieving immersive auditory experiences in virtual environments requires flexible sound modeling that supports dynamic source positions. In this paper, we introduce a task called resounding, which aims to estimate room impulse responses at arbitrary emitter location from a sparse set of measured emitter positions, analogous to the relighting problem in vision. We leverage the reciprocity property and introduce Versa, a physics-inspired approach to facilitating acoustic field learning. Our method creates physically valid samples with dense virtual emitter positions by exchanging emitter and listener poses. We also identify challenges in deploying reciprocity due to emitter/listener gain patterns and propose a self-supervised learning approach to address them. Results show that Versa substantially improve the performance of acoustic field learning on both simulated and real-world datasets across different metrics. Perceptual user studies show that Versa can greatly improve the immersive spatial sound experience. Code, dataset and demo videos are available on the project website: https://waves.seas.upenn.edu/projects/versa.", "published": "2025-10-23T14:30:09Z", "query": "immersive VR brain", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:15:42.735778"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "immersive VR brain", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.736000"}
{"arxiv_id": "2510.20196v1", "title": "A Structured Review and Quantitative Profiling of Public Brain MRI   Datasets for Foundation Model Development", "summary": "The development of foundation models for brain MRI depends critically on the scale, diversity, and consistency of available data, yet systematic assessments of these factors remain scarce. In this study, we analyze 54 publicly accessible brain MRI datasets encompassing over 538,031 to provide a structured, multi-level overview tailored to foundation model development. At the dataset level, we characterize modality composition, disease coverage, and dataset scale, revealing strong imbalances between large healthy cohorts and smaller clinical populations. At the image level, we quantify voxel spacing, orientation, and intensity distributions across 15 representative datasets, demonstrating substantial heterogeneity that can influence representation learning. We then perform a quantitative evaluation of preprocessing variability, examining how intensity normalization, bias field correction, skull stripping, spatial registration, and interpolation alter voxel statistics and geometry. While these steps improve within-dataset consistency, residual differences persist between datasets. Finally, feature-space case study using a 3D DenseNet121 shows measurable residual covariate shift after standardized preprocessing, confirming that harmonization alone cannot eliminate inter-dataset bias. Together, these analyses provide a unified characterization of variability in public brain MRI resources and emphasize the need for preprocessing-aware and domain-adaptive strategies in the design of generalizable brain MRI foundation models.", "published": "2025-10-23T04:31:09Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:42.736284"}
{"arxiv_id": "2510.20178v1", "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic   Stereo Matching", "summary": "Temporally consistent depth estimation from stereo video is critical for real-world applications such as augmented reality, where inconsistent depth estimation disrupts the immersion of users. Despite its importance, this task remains challenging due to the difficulty in modeling long-term temporal consistency in a computationally efficient manner. Previous methods attempt to address this by aggregating spatio-temporal information but face a fundamental trade-off: limited temporal modeling provides only modest gains, whereas capturing long-range dependencies significantly increases computational cost. To address this limitation, we introduce a memory buffer for modeling long-range spatio-temporal consistency while achieving efficient dynamic stereo matching. Inspired by the two-stage decision-making process in humans, we propose a \\textbf{P}ick-and-\\textbf{P}lay \\textbf{M}emory (PPM) construction module for dynamic \\textbf{Stereo} matching, dubbed as \\textbf{PPMStereo}. PPM consists of a `pick' process that identifies the most relevant frames and a `play' process that weights the selected frames adaptively for spatio-temporal aggregation. This two-stage collaborative process maintains a compact yet highly informative memory buffer while achieving temporally consistent information aggregation. Extensive experiments validate the effectiveness of PPMStereo, demonstrating state-of-the-art performance in both accuracy and temporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the Sintel clean/final (17.3\\% \\&amp; 9.02\\% improvements over BiDAStereo) with fewer computational costs. Codes are available at \\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.", "published": "2025-10-23T03:52:39Z", "query": "immersive VR brain", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:42.736565"}
{"arxiv_id": "2510.20148v1", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity   in Tau Propagation Through Multi-Layer Modeling", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.", "published": "2025-10-23T02:52:42Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:42.736824"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "immersive VR brain", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:42.737027"}
{"arxiv_id": "2510.20037v1", "title": "Dephasing in binary black hole mergers surrounded by scalar wave dark   matter clouds", "summary": "Scalar fields of masses between $10^{-21}\\rm{eV}/c^2$ and $10^{-11} \\rm{eV}/c^2$ can exhibit enhanced gravitational interactions with black holes, and form scalar clouds around them. Such a cloud modifies the dynamics of a coalescing black-hole binary, and the resulting gravitational waves may provide a new channel to detect light scalar fields, such as axion-like particles or wave-like dark matter candidates. In this work we simulate a series of black-hole mergers with mass ratios $q=1$ and $q=1/2$, immersed in an scalar field overdensity with masses in the range $M\\mu_{\\rm{S}} \\in[0,1.0]$. To do so, we implemented a constraint-satisfying initial data solver based on the puncture method, we improved the accuracy of our open-source software Canuda to eighth order finite differences, and we reduced the initial orbital eccentricity. We investigate the impact of the scalar mass on the gravitational and scalar radiation. We find that binaries can undergo a delayed or an accelerated merger with respect to the vacuum. Our study highlights the challenge and importance of accurately modeling black-hole binaries in dark matter environments.", "published": "2025-10-22T21:30:58Z", "query": "immersive VR brain", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.737250"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "immersive VR brain", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:15:42.737441"}
{"arxiv_id": "2510.19996v1", "title": "A Fundamental Algorithm for Dependency Parsing (With Corrections)", "summary": "This paper presents a fundamental algorithm for parsing natural language sentences into dependency trees. Unlike phrase-structure (constituency) parsers, this algorithm operates one word at a time, attaching each word as soon as it can be attached, corresponding to properties claimed for the parser in the human brain. Like phrase-structure parsing, its worst-case complexity is $O(n^3)$, but in human language, the worst case occurs only for small $n$.", "published": "2025-10-22T19:48:38Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.737610"}
{"arxiv_id": "2510.19764v1", "title": "A flexible framework for structural plasticity in GPU-accelerated sparse   spiking neural networks", "summary": "The majority of research in both training Artificial Neural Networks (ANNs) and modeling learning in biological brains focuses on synaptic plasticity, where learning equates to changing the strength of existing connections. However, in biological brains, structural plasticity - where new connections are created and others removed - is also vital, not only for effective learning but also for recovery from damage and optimal resource usage. Inspired by structural plasticity, pruning is often used in machine learning to remove weak connections from trained models to reduce the computational requirements of inference. However, the machine learning frameworks typically used for backpropagation-based training of both ANNs and Spiking Neural Networks (SNNs) are optimized for dense connectivity, meaning that pruning does not help reduce the training costs of ever-larger models. The GeNN simulator already supports efficient GPU-accelerated simulation of sparse SNNs for computational neuroscience and machine learning. Here, we present a new flexible framework for implementing GPU-accelerated structural plasticity rules and demonstrate this first using the e-prop supervised learning rule and DEEP R to train efficient, sparse SNN classifiers and then, in an unsupervised learning context, to learn topographic maps. Compared to baseline dense models, our sparse classifiers reduce training time by up to 10x while the DEEP R rewiring enables them to perform as well as the original models. We demonstrate topographic map formation in faster-than-realtime simulations, provide insights into the connectivity evolution, and measure simulation speed versus network size. The proposed framework will enable further research into achieving and maintaining sparsity in network structure and neural communication, as well as exploring the computational benefits of sparsity in a range of neuromorphic applications.", "published": "2025-10-22T16:50:00Z", "query": "immersive VR brain", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.737808"}
{"arxiv_id": "2510.19747v1", "title": "Review of Tools for Zero-Code LLM Based Application Development", "summary": "Large Language Models (LLMs) are transforming software creation by enabling zero code development platforms. Our survey reviews recent platforms that let users build applications without writing code, by leveraging LLMs as the brains of the development process. We adopt a broad survey methodology, categorizing platforms based on key dimensions such as interface style, backend integration, output type, and extensibility. We analyze both dedicated LLM based app builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and general no code platforms (e.g., Bubble, Glide) that integrate LLM capabilities. We present a taxonomy categorizing these platforms by their interface (conversational, visual, etc.), supported LLM backends, output type (chatbot, full application, workflow), and degree of extensibility. Core features such as autonomous agents, memory management, workflow orchestration, and API integrations are in scope of the survey. We provide a detailed comparison, highlighting each platform's strengths and limitations. Trade offs (customizability, scalability, vendor lock-in) are discussed in comparison with traditional and low code development approaches. Finally, we outline future directions, including multimodal interfaces, on device LLMs, and improved orchestration for democratizing app creation with AI. Our findings indicate that while zero code LLM platforms greatly reduce the barrier to creating AI powered applications, they still face challenges in flexibility and reliability. Overall, the landscape is rapidly evolving, offering exciting opportunities to empower non programmers to create sophisticated software.", "published": "2025-10-22T16:41:16Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.737987"}
{"arxiv_id": "2510.19731v1", "title": "Bridging Earth and Space: A Survey on HAPS for Non-Terrestrial Networks", "summary": "HAPS are emerging as key enablers in the evolution of 6G wireless networks, bridging terrestrial and non-terrestrial infrastructures. Operating in the stratosphere, HAPS can provide wide-area coverage, low-latency, energy-efficient broadband communications with flexible deployment options for diverse applications. This survey delivers a comprehensive overview of HAPS use cases, technologies, and integration strategies within the 6G ecosystem. The roles of HAPS in extending connectivity to underserved regions, supporting dynamic backhauling, enabling massive IoT, and delivering reliable low-latency communications for autonomous and immersive services are discussed. The paper reviews state-of-the-art architectures for terrestrial and non-terrestrial network integration, highlights recent field trials. Furthermore, key enabling technologies such as channel modeling, AI-driven resource allocation, interference control, mobility management, and energy-efficient communications are examined. The paper also outlines open research challenges. By addressing existing gaps in the literature, this survey positions HAPS as a foundational component of globally integrated, resilient, and sustainable 6G networks.", "published": "2025-10-22T16:22:31Z", "query": "immersive VR brain", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:42.738175"}
{"arxiv_id": "2510.19702v1", "title": "Dictionary learning methods for brain activity mapping with MEG data", "summary": "A central goal in many brain studies is the identification of those brain regions that are activated during an observation window that may correspond to a motor task, a stimulus, or simply a resting state. While functional MRI is currently the most commonly employed modality for such task, methods based on the electromagnetic activity of the brain are valuable alternatives because of their excellent time resolution and of the fact that the measured signals are directly related to brain activation and not to a secondary effect such as the hemodynamic response. In this work we focus on the MEG modality, investigating the performance of a recently proposed Bayesian dictionary learning (BDL) algorithm for brain region identification. The partitioning of the source space into the 148 regions of interest (ROI) corresponding to parcellation of the Destrieux atlas provides a natural determination of the subdictionaries necessary for the BDL algorithm. We design a simulation protocol where a small randomly selected patch in each ROI is activated, the MEG signal is computed and the inverse problem of active brain region identification is solved using the BDL algorithm. The BDL algorithm consists of two phases, the first one comprising dictionary compression and Bayesian compression error analysis, and the second one performing dictionary coding with a deflated dictionary built on the output of the first phase, both steps relying on Bayesian sparsity promoting computations. For assessing the performance, we give a probabilistic interpretation of the confusion matrix, and consider different impurity measures for a multi-class classifier.", "published": "2025-10-22T15:53:22Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:42.738362"}
{"arxiv_id": "2510.19680v1", "title": "T2 mapping at 0.55 T using Ultra-Fast Spin Echo MRI", "summary": "Low-field T2 mapping MRI can democratize neuropediatric imaging by improving accessibility and providing quantitative biomarkers of brain development. \\textbf{Purpose:} To evaluate the feasibility of high-resolution T2 mapping using a single-shot fast spin-echo (SS-FSE) sequence at 0.55~T in a healthy control cohort. \\textbf{Study Type:} Prospective single-center study. \\textbf{Population:} In vivo: ten healthy adults (18--43~years, 5 females/5 males). In vitro: NIST Phantom. \\textbf{Field strength/sequence:} Multi-echo ultra-fast spin-echo at 0.55~T and 1.5~T. \\textbf{Assessment:} Feasibility was first assessed in vitro using the NIST Phantom, comparing T2 relaxation times to spectrometer references at 0.55~T. Acquisition and T2-fitting parameters optimized in vitro were applied in vivo. Repeatability was evaluated by atlas-based analysis of white matter (WM) and cortical grey matter (GM) regions. Coefficients of variation (CoV) were computed across runs, sessions, and subjects. \\textbf{Statistical Tests:} Wilcoxon signed-rank test with Bonferroni correction ($\\alpha = 0.05/n_{ROI}$) assessed CoV differences. Pearson correlation coefficients quantified T2 associations. \\textbf{Results:} In vitro, mono-exponential fitting under Gaussian--Rician noise yielded deviations $&lt;12\\%$ from reference values. In vivo, inter-subject CoV was 5.2\\% (WM) and 17.7\\% (GM), comparable to 1.5~T. Mean T2 times were 118~ms (WM) and 188~ms (GM) at 0.55~T, with a 16.5-minute acquisition. \\textbf{Conclusion:} A rapid, robust high-resolution T2 mapping protocol at 0.55~T for HASTE MRI is presented, employing Gaussian noise-based fitting. We report the first normative T2 values for healthy adult brains at 0.55~T, demonstrating technical feasibility and reliability.", "published": "2025-10-22T15:25:11Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.738583"}
{"arxiv_id": "2510.19625v1", "title": "Toric para-Kaehler-Einstein manifolds immersed in para-Kaehler space   forms", "summary": "A classical and long-staying problem addressed, among others, by Calabi and Chern, is that to find a complete list of mutually non-isometric Kaehler-Einstein manifolds immersed in a finite-dimensional Kaehler space form. We address the same problem in the para-Kaehler context and, then, we find a list of mutually non-isometric toric para-Kaehler manifolds analytically immersed in a finite-dimensional para-Kaehler space form", "published": "2025-10-22T14:21:58Z", "query": "immersive VR brain", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.738726"}
{"arxiv_id": "2510.19604v1", "title": "Unmanned Aerial Vehicles Control in a Digital Twin: Exploring the Effect   of Different Points of View on User Experience in Virtual Reality", "summary": "Controlling Unmanned Aerial Vehicles (UAVs) is a cognitively demanding task, with accidents often arising from insufficient situational awareness, inadequate training, and poor user experiences. Providing more intuitive and immersive visual feedback, particularly through Digital Twin technologies, offers new opportunities to enhance pilot awareness and overall experience quality. In this study, we investigate how different virtual points of view (POVs) influence user experience and performance during UAV piloting in Virtual Reality (VR), utilizing a digital twin that faithfully replicates the real-world flight environment. We developed a VR application that enables participants to control a physical DJI Mini 4 Pro drone while immersed in a digital twin with four distinct camera perspectives: Baseline View (static external), First-Person View, Chase View, and Third-Person View. Nineteen participants completed a series of ring-based obstacle courses from each perspective. In addition to objective flight data, we collected standardized subjective assessments of user experience, presence, workload, cybersickness, and situational awareness. Quantitative analyses revealed that the First-Person View was associated with significantly higher mental demand and effort, greater trajectory deviation, but smoother control inputs compared to the Third-Person and Chase perspectives. Complementing these findings, preference data indicated that the Third-Person View was most consistently favored, whereas the First-Person View elicited polarized reactions.", "published": "2025-10-22T13:56:09Z", "query": "immersive VR brain", "relevance": 0.35, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.738942"}
{"arxiv_id": "2510.19537v1", "title": "Privacy-Preserving Spiking Neural Networks: A Deep Dive into Encryption   Parameter Optimisation", "summary": "Deep learning is widely applied to modern problems through neural networks, but the growing computational and energy demands of these models have driven interest in more efficient approaches. Spiking Neural Networks (SNNs), the third generation of neural networks, mimic the brain's event-driven behaviour, offering improved performance and reduced power use. At the same time, concerns about data privacy during cloud-based model execution have led to the adoption of cryptographic methods. This article introduces BioEncryptSNN, a spiking neural network based encryption-decryption framework for secure and noise-resilient data protection. Unlike conventional algorithms, BioEncryptSNN converts ciphertext into spike trains and exploits temporal neural dynamics to model encryption and decryption, optimising parameters such as key length, spike timing, and synaptic connectivity. Benchmarked against AES-128, RSA-2048, and DES, BioEncryptSNN preserved data integrity while achieving up to 4.1x faster encryption and decryption than PyCryptodome's AES implementation. The framework demonstrates scalability and adaptability across symmetric and asymmetric ciphers, positioning SNNs as a promising direction for secure, energy-efficient computing.", "published": "2025-10-22T12:43:46Z", "query": "immersive VR brain", "relevance": 0.15000000000000002, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.739177"}
{"arxiv_id": "2510.19498v1", "title": "Energy-Efficient and Dequantization-Free Q-LLMs: A Spiking Neural   Network Approach to Salient Value Mitigation", "summary": "In the era of large language models (LLMs), weight-activation quantization helps fit models on edge device by reducing memory and compute bit-widths. However, three challenges persist for energy constrained hardware: (1) even after quantization, multiply-accumulate (MAC) operations remain unavoidable and continue to dominate energy consumption; (2) dequantization (or per-tensor/channel rescaling) introduces extra arithmetic and data movement, increasing latency and energy; (3) uniform parameters bit widths clip salient values-while intra-channel mixed precision is generally impractical on current matrix hardware and memory. In contrast, brain-inspired Spiking Neural Networks (SNNs), owing to their binary spike-based information representation and the Integrate-and-Fire (IF) paradigm, naturally support mixed-precision storage and energy-efficient computation by replacing complex MACs with temporal Accumulate (ACCs). Motivated by this property, we propose SpikeQuant, which selectively applies mixed-precision quantization to activations with salient values and re-encodes them into binary spike counts, thereby enabling dynamic mixed storage of different bitwidths. Furthermore, by embedding the quantization scale into the threshold of the IF mechanism, our approach performs energy-efficient linear transformations on weights and activations while avoiding explicit dequantization. Experimental results demonstrate that SpikeQuant consistently achieves near-FP16 perplexity under W4A4 quantization while reducing energy cost by up to 4.6 times compared to existing methods, highlighting its effectiveness for accurate and energy-efficient LLM deployment.", "published": "2025-10-22T11:50:00Z", "query": "immersive VR brain", "relevance": 0.1, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:42.739467"}
{"arxiv_id": "2510.19332v1", "title": "BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP", "summary": "Decoding images from fMRI often involves mapping brain activity to CLIP's final semantic layer. To capture finer visual details, many approaches add a parameter-intensive VAE-based pipeline. However, these approaches overlook rich object information within CLIP's intermediate layers and contradicts the brain's functionally hierarchical. We introduce BrainMCLIP, which pioneers a parameter-efficient, multi-layer fusion approach guided by human visual system's functional hierarchy, eliminating the need for such a separate VAE pathway. BrainMCLIP aligns fMRI signals from functionally distinct visual areas (low-/high-level) to corresponding intermediate and final CLIP layers, respecting functional hierarchy. We further introduce a Cross-Reconstruction strategy and a novel multi-granularity loss. Results show BrainMCLIP achieves highly competitive performance, particularly excelling on high-level semantic metrics where it matches or surpasses SOTA(state-of-the-art) methods, including those using VAE pipelines. Crucially, it achieves this with substantially fewer parameters, demonstrating a reduction of 71.7\\%(Table.\\ref{tab:compare_clip_vae}) compared to top VAE-based SOTA methods, by avoiding the VAE pathway. By leveraging intermediate CLIP features, it effectively captures visual details often missed by CLIP-only approaches, striking a compelling balance between semantic accuracy and detail fidelity without requiring a separate VAE pipeline.", "published": "2025-10-22T07:51:52Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.739698"}
{"arxiv_id": "2510.19282v1", "title": "Enhancing Early Alzheimer Disease Detection through Big Data and   Ensemble Few-Shot Learning", "summary": "Alzheimer disease is a severe brain disorder that causes harm in various brain areas and leads to memory damage. The limited availability of labeled medical data poses a significant challenge for accurate Alzheimer disease detection. There is a critical need for effective methods to improve the accuracy of Alzheimer disease detection, considering the scarcity of labeled data, the complexity of the disease, and the constraints related to data privacy. To address this challenge, our study leverages the power of big data in the form of pre-trained Convolutional Neural Networks (CNNs) within the framework of Few-Shot Learning (FSL) and ensemble learning. We propose an ensemble approach based on a Prototypical Network (ProtoNet), a powerful method in FSL, integrating various pre-trained CNNs as encoders. This integration enhances the richness of features extracted from medical images. Our approach also includes a combination of class-aware loss and entropy loss to ensure a more precise classification of Alzheimer disease progression levels. The effectiveness of our method was evaluated using two datasets, the Kaggle Alzheimer dataset and the ADNI dataset, achieving an accuracy of 99.72% and 99.86%, respectively. The comparison of our results with relevant state-of-the-art studies demonstrated that our approach achieved superior accuracy and highlighted its validity and potential for real-world applications in early Alzheimer disease detection.", "published": "2025-10-22T06:35:03Z", "query": "immersive VR brain", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:42.739865"}
{"arxiv_id": "2510.19229v1", "title": "Brain-Inspired Perspective on Configurations: Unsupervised Similarity   and Early Cognition", "summary": "Infants discover categories, detect novelty, and adapt to new contexts without supervision -- a challenge for current machine learning. We present a brain-inspired perspective on configurations, a finite-resolution clustering framework that uses a single resolution parameter and attraction-repulsion dynamics to yield hierarchical organization, novelty sensitivity, and flexible adaptation. To evaluate these properties, we introduce mheatmap, which provides proportional heatmaps and a reassignment algorithm to fairly assess multi-resolution and dynamic behavior. Across datasets, configurations are competitive on standard clustering metrics, achieve 87% AUC in novelty detection, and show 35% better stability during dynamic category evolution. These results position configurations as a principled computational model of early cognitive categorization and a step toward brain-inspired AI.", "published": "2025-10-22T04:28:23Z", "query": "immersive VR brain", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:42.740021"}
{"arxiv_id": "2510.19212v1", "title": "No Intelligence Without Statistics: The Invisible Backbone of Artificial   Intelligence", "summary": "The rapid ascent of artificial intelligence (AI) is often portrayed as a revolution born from computer science and engineering. This narrative, however, obscures a fundamental truth: the theoretical and methodological core of AI is, and has always been, statistical. This paper systematically argues that the field of statistics provides the indispensable foundation for machine learning and modern AI. We deconstruct AI into nine foundational pillars-Inference, Density Estimation, Sequential Learning, Generalization, Representation Learning, Interpretability, Causality, Optimization, and Unification-demonstrating that each is built upon century-old statistical principles. From the inferential frameworks of hypothesis testing and estimation that underpin model evaluation, to the density estimation roots of clustering and generative AI; from the time-series analysis inspiring recurrent networks to the causal models that promise true understanding, we trace an unbroken statistical lineage. While celebrating the computational engines that power modern AI, we contend that statistics provides the brain-the theoretical frameworks, uncertainty quantification, and inferential goals-while computer science provides the brawn-the scalable algorithms and hardware. Recognizing this statistical backbone is not merely an academic exercise, but a necessary step for developing more robust, interpretable, and trustworthy intelligent systems. We issue a call to action for education, research, and practice to re-embrace this statistical foundation. Ignoring these roots risks building a fragile future; embracing them is the path to truly intelligent machines. There is no machine learning without statistical learning; no artificial intelligence without statistical thought.", "published": "2025-10-22T03:47:30Z", "query": "immersive VR brain", "relevance": 0.25, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.740325"}
{"arxiv_id": "2510.19109v1", "title": "Advancing Brain Tumor Segmentation via Attention-based 3D U-Net   Architecture and Digital Image Processing", "summary": "In the realm of medical diagnostics, rapid advancements in Artificial Intelligence (AI) have significantly yielded remarkable improvements in brain tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a transformative role by effectively extracting meaningful representations in 3D brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However, standard U-Net models encounter challenges in accurately delineating tumor regions, especially when dealing with irregular shapes and ambiguous boundaries. Additionally, training robust segmentation models on high-resolution MRI data, such as the BraTS datasets, necessitates high computational resources and often faces challenges associated with class imbalance. This study proposes the integration of the attention mechanism into the 3D U-Net model, enabling the model to capture intricate details and prioritize informative regions during the segmentation process. Additionally, a tumor detection algorithm based on digital image processing techniques is utilized to address the issue of imbalanced training data and mitigate bias. This study aims to enhance the performance of brain tumor segmentation, ultimately improving the reliability of diagnosis. The proposed model is thoroughly evaluated and assessed on the BraTS 2020 dataset using various performance metrics to accomplish this goal. The obtained results indicate that the model outperformed related studies, exhibiting dice of 0.975, specificity of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed model in improving brain tumor segmentation, offering valuable insights for reliable diagnosis in clinical settings.", "published": "2025-10-21T22:11:19Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.740516"}
{"arxiv_id": "2510.19086v1", "title": "When Strings Tug at Algorithm: Human-AI Sovereignty and Entanglement in   Nomadic Improvisational Music Performance as a Decolonial Exploration", "summary": "As emergent artificial intelligence technologies increasingly assert roles as assistants within intangible cultural heritage contexts, researchers and artists observe existing questions on the theme of agency negotiation, cultural resistance, and technical critique. This research interrogates power dynamics in human-AI sovereignty and entanglement for nomadic improvisational Dutar performance, a living cultural heritage through a long-necked lute from the Central Asia region. To investigate tensions between human agency and computational hegemony, the researcher and artists examined and iterated a feedback workflow that captures live performance data, processes digital transformations, and creates a real-time interactive art experience via immersive environments. Empirical data from artists and audience reveal modulations where musicians selectively embrace or reject algorithmic suggestions to preserve creative identity. The author concludes that decolonial potential requires redesigning tools or systems for cultural survivance, where technology becomes not merely a feedback environment but a site for decolonial praxis, challenging computational hegemony in digital ecosystems.", "published": "2025-10-21T21:24:17Z", "query": "immersive VR brain", "relevance": 0.15, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:42.740685"}
{"arxiv_id": "2510.19057v1", "title": "Macroscopic EEG Reveals Discriminative Low-Frequency Oscillations in   Plan-to-Grasp Visuomotor Tasks", "summary": "The vision-based grasping brain network integrates visual perception with cognitive and motor processes for visuomotor tasks. While invasive recordings have successfully decoded localized neural activity related to grasp type planning and execution, macroscopic neural activation patterns captured by noninvasive electroencephalography (EEG) remain far less understood. We introduce a novel vision-based grasping platform to investigate grasp-type-specific (precision, power, no-grasp) neural activity across large-scale brain networks using EEG neuroimaging. The platform isolates grasp-specific planning from its associated execution phases in naturalistic visuomotor tasks, where the Filter-Bank Common Spatial Pattern (FBCSP) technique was designed to extract discriminative frequency-specific features within each phase. Support vector machine (SVM) classification discriminated binary (precision vs. power, grasp vs. no-grasp) and multiclass (precision vs. power vs. no-grasp) scenarios for each phase, and were compared against traditional Movement-Related Cortical Potential (MRCP) methods. Low-frequency oscillations (0.5-8 Hz) carry grasp-related information established during planning and maintained throughout execution, with consistent classification performance across both phases (75.3-77.8\\%) for precision vs. power discrimination, compared to 61.1\\% using MRCP. Higher-frequency activity (12-40 Hz) showed phase-dependent results with 93.3\\% accuracy for grasp vs. no-grasp classification but 61.2\\% for precision vs. power discrimination. Feature importance using SVM coefficients identified discriminative features within frontoparietal networks during planning and motor networks during execution. This work demonstrated the role of low-frequency oscillations in decoding grasp type during planning using noninvasive EEG.", "published": "2025-10-21T20:17:33Z", "query": "immersive VR brain", "relevance": 0.35, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:42.740838"}
{"arxiv_id": "2510.19031v1", "title": "CLiVR: Conversational Learning System in Virtual Reality with AI-Powered   Patients", "summary": "Simulations constitute a fundamental component of medical and nursing education and traditionally employ standardized patients (SP) and high-fidelity manikins to develop clinical reasoning and communication skills. However, these methods require substantial resources, limiting accessibility and scalability. In this study, we introduce CLiVR, a Conversational Learning system in Virtual Reality that integrates large language models (LLMs), speech processing, and 3D avatars to simulate realistic doctor-patient interactions. Developed in Unity and deployed on the Meta Quest 3 platform, CLiVR enables trainees to engage in natural dialogue with virtual patients. Each simulation is dynamically generated from a syndrome-symptom database and enhanced with sentiment analysis to provide feedback on communication tone. Through an expert user study involving medical school faculty (n=13), we assessed usability, realism, and perceived educational impact. Results demonstrated strong user acceptance, high confidence in educational potential, and valuable feedback for improvement. CLiVR offers a scalable, immersive supplement to SP-based training.", "published": "2025-10-21T19:19:55Z", "query": "immersive VR brain", "relevance": 0.3, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:42.741075"}
{"arxiv_id": "2510.19013v1", "title": "Magnetic field geometry in rotating wormhole spacetimes", "summary": "If a black hole is immersed in a magnetosphere,its rotational energy can be transferred to the electromagnetic field and escape as a Poynting flux to infinity. This process of extraction of rotational energy is known as the Blandford-Znajek mechanism. It relies on the presence of both a magnetosphere and an ergosphere surrounding the black hole. Previously, we showed that rotating wormholes are also capable of emitting a Poynting flux in the process of accreting magnetized matter. In this work, we re-examine the Blandford-Znajek mechanism in the case of a Kerr-type wormhole. For the first time, we solve the stream equation in a rotating wormhole spacetime and derive analytical expressions for the magnetic field. We then compute the associated Poynting flux. Our results indicate that the electromagnetic flux in the wormhole spacetime is weaker than in the Kerr case, and this difference becomes more pronounced as the geometries of the two spacetimes increasingly deviate.", "published": "2025-10-21T18:55:34Z", "query": "immersive VR brain", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:42.741264"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:46.214265"}
{"arxiv_id": "2510.20777v1", "title": "Learning Optimal Power Flow with Pointwise Constraints", "summary": "Training learning parameterizations to solve optimal power flow (OPF) with pointwise constraints is proposed. In this novel training approach, a learning parameterization is substituted directly into an OPF problem with constraints required to hold over all problem instances. This is different from existing supervised learning methods in which constraints are required to hold across the average of problem instances. Training with pointwise constraints is undertaken in the dual domain with the use of augmented Lagrangian and dual gradient ascent algorithm. Numerical experiments demonstrate that training with pointwise constraints produces solutions with smaller constraint violations. Experiments further demonstrated that pointwise constraints are most effective at reducing constraint violations in corner cases - defined as those realizations in which constraints are most difficult to satisfy. Gains are most pronounced in power systems with large numbers of buses.", "published": "2025-10-23T17:48:10Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:46.214824"}
{"arxiv_id": "2510.20480v1", "title": "Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization   Leveraging LiDAR-Based Robot Detections", "summary": "Accurate long-term localization using onboard sensors is crucial for robots operating in Global Navigation Satellite System (GNSS)-denied environments. While complementary sensors mitigate individual degradations, carrying all the available sensor types on a single robot significantly increases the size, weight, and power demands. Distributing sensors across multiple robots enhances the deployability but introduces challenges in fusing asynchronous, multi-modal data from independently moving platforms. We propose a novel adaptive multi-modal multi-robot cooperative localization approach using a factor-graph formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial Odometry (LIO), and 3D inter-robot detections from distinct robots in a loosely-coupled fashion. The approach adapts to changing conditions, leveraging reliable data to assist robots affected by sensory degradations. A novel interpolation-based factor enables fusion of the unsynchronized measurements. LIO degradations are evaluated based on the approximate scan-matching Hessian. A novel approach of weighting odometry data proportionally to the Wasserstein distance between the consecutive VIO outputs is proposed. A theoretical analysis is provided, investigating the cooperative localization problem under various conditions, mainly in the presence of sensory degradations. The proposed method has been extensively evaluated on real-world data gathered with heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial Vehicles (UAVs), showing that the approach provides significant improvements in localization accuracy in the presence of various sensory degradations.", "published": "2025-10-23T12:20:09Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:46.215119"}
{"arxiv_id": "2510.20131v1", "title": "Separating Pseudorandom Generators from Logarithmic Pseudorandom States", "summary": "Pseudorandom generators (PRGs) are a foundational primitive in classical cryptography, underpinning a wide range of constructions. In the quantum setting, pseudorandom quantum states (PRSs) were proposed as a potentially weaker assumption that might serve as a substitute for PRGs in cryptographic applications. Two primary size regimes of PRSs have been studied: logarithmic-size and linear-size. Interestingly, logarithmic PRSs have led to powerful cryptographic applications, such as digital signatures and quantum public-key encryption, that have not been realized from their linear counterparts. However, PRGs have only been black-box separated from linear PRSs, leaving open the fundamental question of whether PRGs are also separated from logarithmic PRSs.   In this work, we resolve this open problem. We establish a quantum black-box separation between (quantum-evaluable) PRGs and PRSs of either size regime. Specifically, we construct a unitary quantum oracle with inverse access relative to which no black-box construction of PRG from (logarithmic or linear) PRS exists. As a direct corollary, we obtain separations between PRGs and several primitives implied by logarithmic PRSs, including digital signatures and quantum public-key encryption.", "published": "2025-10-23T02:09:29Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.215379"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "sensory substitution", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:46.215516"}
{"arxiv_id": "2510.19745v1", "title": "From Substitution to Complement? Uncovering the Evolving Interplay   between Ride-hailing Services and Public Transit", "summary": "The literature on transportation network companies (TNCs), also known as ride-hailing services, has often characterized these service providers as predominantly substitutive to public transit (PT). However, as TNC markets expand and mature, the complementary and substitutive relationships with PT may shift. To explore whether such a transformation is occurring, this study collected travel data from 96,716 ride-hailing vehicles during September 2022 in Shanghai, a city characterized by an increasingly saturated TNC market. An enhanced data-driven framework is proposed to classify TNC-PT relationships into four types: first-mile complementary, last-mile complementary, substitutive, and independent. Our findings indicate comparable ratios of complementary trips (9.22%) and substitutive trips (9.06%), contrasting sharply with the findings of prior studies. Furthermore, to examine the nonlinear impact of various influential factors on these ratios, a machine learning method integrating categorical boosting (CatBoost) and Shapley additive explanations (SHAP) is proposed. The results show significant nonlinear effects in some variables, including the distance to the nearest metro station and the density of bus stops. Moreover, metro hubs and regular single-line stations exhibit distinct effects on first- or last-mile complementary ratios. These ratios' relation to the distance to single-line stations shows an inverted U-shaped pattern, with effects rising sharply within 1.5 km, remaining at the peak between 1.5 and 3 km, and then declining as the distance increases to about 15 km.", "published": "2025-10-22T16:39:33Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.215710"}
{"arxiv_id": "2510.19642v1", "title": "Manning-type potential induced by kink scatterings with phonons in   molecular chains with hyperbolic double-well substrates", "summary": "A rescaled Manning potential is obtained in the analysis of scatterings of small- amplitude excitations with a kink defect. The generic model is a nonlinear Klein- Gordon Hamiltonian describing a one-dimensional chain of identical molecules, sub- jected to an hyperbolic single-particle substrate potential. To account for isotope effects that are likely to affect characteristic equilibrium parameters of the molec- ular chain, including the lattice spacing (i.e. the characteristic intermolecuar dis- tance) and/or the barrier height, the hyperbolic substrate potential is endowed with a real parameter whose variation makes it suitable for the description of molecu- lar excitations in a broad range of systems with inversion symmetry. These include hydrogen-bonded molecular crystals, {\\alpha}-helix proteins, long polymer chains and two- state quantum-tunneling systems in general. Double-well models with deformable profiles are relevant in physical contexts where the equilibrium configurations are sensitive to atomic or molecular substitutions, dilution, solvation and so on.", "published": "2025-10-22T14:43:04Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.215884"}
{"arxiv_id": "2510.19505v2", "title": "Mechanism of the electrochemical hydrogenation of graphene", "summary": "The electrochemical hydrogenation of graphene induces a robust and reversible conductor-insulator transition, of strong interest in logic-and-memory applications. However, its mechanism remains unknown. Here we show that it proceeds as a reduction reaction in which proton adsorption competes with the formation of H2 molecules via an Eley-Rideal process. Graphene's electrochemical hydrogenation is up to $10^6$ times faster than alternative hydrogenation methods and is fully reversible via the oxidative desorption of protons. We demonstrate that the proton reduction rate in defect-free graphene can be enhanced by an order of magnitude by the introduction of nanoscale corrugations in its lattice, and that the substitution of protons for deuterons results both in lower potentials for the hydrogenation process and in a more stable compound. Our results pave the way to investigating the chemisorption of ions in 2D materials at high electric fields, opening a new avenue to control these materials' electronic properties.", "published": "2025-10-22T12:00:17Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:46.216025"}
{"arxiv_id": "2510.19391v1", "title": "Synergistic effects of rare-earth doping on the magnetic properties of   orthochromates: A machine learning approach", "summary": "Multiferroic materials, particularly rare-earth orthochromates (RECrO$_3$), have garnered significant interest due to their unique magnetic and electric-polar properties, making them promising candidates for multifunctional devices. Although extensive research has been conducted on their antiferromagnetic (AFM) transition temperature (N$\\acute{\\textrm{e}}$el temperature, $T_\\textrm{N}$), ferroelectricity, and piezoelectricity, the effects of doping and substitution of rare-earth (RE) elements on these properties remain insufficiently explored. In this study, convolutional neural networks (CNNs) were employed to predict and analyze the physical properties of RECrO$_3$ compounds under various doping scenarios. Experimental and literature data were integrated to train machine learning models, enabling accurate predictions of $T_\\textrm{N}$, besides remanent polarization ($P_\\textrm{r}$) and piezoelectric coefficients ($d_{33}$). The results indicate that doping with specific RE elements significantly impacts $T_\\textrm{N}$, with optimal doping levels identified for enhanced performance. Furthermore, high-entropy RECrO$_3$ compounds were systematically analyzed, demonstrating how the inclusion of multiple RE elements influences magnetic properties. This work establishes a robust framework for predicting and optimizing the properties of RECrO$_3$ materials, offering valuable insights into their potential applications in energy storage and sensor technologies.", "published": "2025-10-22T09:06:30Z", "query": "sensory substitution", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:46.216177"}
{"arxiv_id": "2510.19373v1", "title": "Using Temperature Sampling to Effectively Train Robot Learning Policies   on Imbalanced Datasets", "summary": "Increasingly large datasets of robot actions and sensory observations are being collected to train ever-larger neural networks. These datasets are collected based on tasks and while these tasks may be distinct in their descriptions, many involve very similar physical action sequences (e.g., 'pick up an apple' versus 'pick up an orange'). As a result, many datasets of robotic tasks are substantially imbalanced in terms of the physical robotic actions they represent. In this work, we propose a simple sampling strategy for policy training that mitigates this imbalance. Our method requires only a few lines of code to integrate into existing codebases and improves generalization. We evaluate our method in both pre-training small models and fine-tuning large foundational models. Our results show substantial improvements on low-resource tasks compared to prior state-of-the-art methods, without degrading performance on high-resource tasks. This enables more effective use of model capacity for multi-task policies. We also further validate our approach in a real-world setup on a Franka Panda robot arm across a diverse set of tasks.", "published": "2025-10-22T08:48:55Z", "query": "sensory substitution", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.216373"}
{"arxiv_id": "2510.19360v1", "title": "Multi-code rate Task-Oriented Communication for Multi-Edge Cooperative   Inference", "summary": "The integration of artificial intelligence (AI) with the internet of things (IoT) enables task-oriented communication for multi-edge cooperative inference system, where edge devices transmit extracted features of local sensory data to an edge server to perform AI-driven tasks. However, the privacy concerns and limited communication bandwidth pose fundamental challenges, since simultaneous transmission of extracted features with a single fixed compression ratio from all devices leads to severe inefficiency in communication resource utilization. To address this challenge, we propose a framework that dynamically adjusts the code rate in feature extraction based on its importance to the downstream inference task by adopting a rate-adaptive quantization (RAQ) scheme. Furthermore, to select the code rate for each edge device under limited bandwidth constraint, a dynamic programming (DP) approach is leveraged to allocate the code rate across discrete code rate options. Experiments on multi-view datasets demonstrate that the proposed frameworks significantly outperform the frameworks using fixed-rate quantization, achieving a favorable balance between communication efficiency and inference performance under limited bandwidth conditions.", "published": "2025-10-22T08:32:50Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:46.216575"}
{"arxiv_id": "2510.19182v1", "title": "Malaria Detection from Blood Cell Images Using XceptionNet", "summary": "Malaria, which primarily spreads with the bite of female anopheles mosquitos, often leads to death of people - specifically children in the age-group of 0-5 years. Clinical experts identify malaria by observing RBCs in blood smeared images with a microscope. Lack of adequate professional knowledge and skills, and most importantly manual involvement may cause incorrect diagnosis. Therefore, computer aided automatic diagnosis stands as a preferred substitute. In this paper, well-demonstrated deep networks have been applied to extract deep intrinsic features from blood cell images and thereafter classify them as malaria infected or healthy cells. Among the six deep convolutional networks employed in this work viz. AlexNet, XceptionNet, VGG-19, Residual Attention Network, DenseNet-121 and Custom-CNN. Residual Attention Network and XceptionNet perform relatively better than the rest on a publicly available malaria cell image dataset. They yield an average accuracy of 97.28% and 97.55% respectively, that surpasses other related methods on the same dataset. These findings highly encourage the reality of deep learning driven method for automatic and reliable detection of malaria while minimizing direct manual involvement.", "published": "2025-10-22T02:41:01Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.216776"}
{"arxiv_id": "2510.19117v1", "title": "A Graph Signal Processing Framework for Hallucination Detection in Large   Language Models", "summary": "Large language models achieve impressive results but distinguishing factual reasoning from hallucinations remains challenging. We propose a spectral analysis framework that models transformer layers as dynamic graphs induced by attention, with token embeddings as signals on these graphs. Through graph signal processing, we define diagnostics including Dirichlet energy, spectral entropy, and high-frequency energy ratios, with theoretical connections to computational stability. Experiments across GPT architectures suggest universal spectral patterns: factual statements exhibit consistent \"energy mountain\" behavior with low-frequency convergence, while different hallucination types show distinct signatures. Logical contradictions destabilize spectra with large effect sizes ($g&gt;1.0$), semantic errors remain stable but show connectivity drift, and substitution hallucinations display intermediate perturbations. A simple detector using spectral signatures achieves 88.75% accuracy versus 75% for perplexity-based baselines, demonstrating practical utility. These findings indicate that spectral geometry may capture reasoning patterns and error behaviors, potentially offering a framework for hallucination detection in large language models.", "published": "2025-10-21T22:35:48Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:46.216964"}
{"arxiv_id": "2510.18866v1", "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation", "summary": "Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. Experiments on LongMemEval with GPT and Qwen backbones show that LightMem outperforms strong baselines in accuracy (up to 10.9% gains) while reducing token usage by up to 117x, API calls by up to 159x, and runtime by over 12x. The code is available at https://github.com/zjunlp/LightMem.", "published": "2025-10-21T17:58:17Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:46.217180"}
{"arxiv_id": "2510.18724v1", "title": "Adapting Language Balance in Code-Switching Speech", "summary": "Despite achieving impressive results on standard benchmarks, large foundational models still struggle against code-switching test cases. When data scarcity cannot be used as the usual justification for poor performance, the reason may lie in the infrequent occurrence of code-switched moments, where the embedding of the second language appears subtly. Instead of expecting the models to learn this infrequency on their own, it might be beneficial to provide the training process with labels. Evaluating model performance on code-switching data requires careful localization of code-switching points where recognition errors are most consequential, so that the analysis emphasizes mistakes occurring at those moments. Building on this observation, we leverage the difference between the embedded and the main language to highlight those code-switching points and thereby emphasize learning at those locations. This simple yet effective differentiable surrogate mitigates context bias during generation -- the central challenge in code-switching -- thereby improving the model's robustness. Our experiments with Arabic and Chinese-English showed that the models are able to predict the switching places more correctly, reflected by the reduced substitution error.", "published": "2025-10-21T15:23:55Z", "query": "sensory substitution", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.217351"}
{"arxiv_id": "2510.18623v2", "title": "Optimal quantum learning in proximity to universality", "summary": "The boundary between classically simulable and computationally superior quantum systems is fundamental to identifying true quantum advantage. We investigate this within the framework of quantum reservoir computing by introducing a tunable $N$-qubit random circuit model, where a fraction $p$ of Clifford gates are probabilistically substituted with nonstabilizing conditional-$\\hat{T}$ gates. We establish a direct correspondence between the reservoir's performance on temporal processing tasks and its entanglement spectrum statistics and long-range nonstabilizer resource content. To assess scalability, we study the scaling of the anti-flatness of states in the large-$N$ limit at a fixed circuit depth ratio $d/N \\sim \\mathcal{O}(1)$. This is taken as a witness to concentration of measures, a known impediment to learning in thermalizing systems. We demonstrate that the learnability and scalability of the reservoir can be continuously controlled by the parameter $p$, allowing us to navigate from classically tractable to maximally expressive quantum dynamics. These architecture-agnostic results offer a general strategy for designing powerful and trainable quantum machine learning systems and clarify the physical resources underpinning quantum computational advantage.", "published": "2025-10-21T13:27:41Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.217514"}
{"arxiv_id": "2510.18602v1", "title": "Defect Landscape of Orthorhombic Ba$_2$In$_2$O$_5$ from First-Principles   Calculations: The Role of Oxygen Interstitials", "summary": "The brownmillerite-type oxide Ba$_2$In$_2$O$_5$ (BIO) is a potential candidate as an electrolyte material for mixed ionic-electronic conduction in solid oxide fuel cells. Despite its structural relation to perovskite oxides, the defect chemistry of BIO has remained largely unexplored. Using Density Functional Theory within the generalized gradient approximation, complemented by selected hybrid-functional calculations, we evaluate the formation energies, charge transition levels, and concentrations as a function of oxygen partial pressure of vacancies, oxygen interstitials, Frenkel pairs, and substitutional Cr doping. Our results reveal that oxygen vacancies and interstitials dominate the intrinsic defect landscape. Among the interstitials, we identify stable dumbbell configurations that remain neutral across the entire band gap. Other interstitial configurations show charged states and become the prevailing compensating defect at high oxygen partial pressures. For extrinsic doping, we find that Cr preferentially substitutes at the tetrahedral In site and behaves as a donor. Its negative formation energies suggest the formation of secondary phases, possibly the tetragonal Cr-doped BIO. These results provide a first picture of the thermodynamics of intrinsic and extrinsic defects in BIO and set the stage for future investigations into the tetragonal phase and the diffusion dynamics of oxygen vacancies and interstitials.", "published": "2025-10-21T12:59:43Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.217690"}
{"arxiv_id": "2510.18565v1", "title": "LENNs: Locally Enhanced Neural Networks for High-Fidelity Modeling in   Solid Mechanics", "summary": "Despite prior advances in PINNs, significant challenges remain in localized solid mechanics problems because of the limitations of single network formulations in simultaneous resolution of smooth global responses and near-tip singularities, and inadequacy in discontinuity representation, leading to unstable training and limited accuracy. To address the challenges, we propose Locally Enhanced Neural Networks (LENNs) that characterize localized discontinuities in solid mechanics via multilevel modeling. In particular, this novel framework employs a global network for the bulk solution and activates a local network in localized area for non-smooth response, coupled through a smooth window function that enables weighted superposition of local and global solutions. Moreover, the local network embeds additional functions that encode the discontinuous information into the input to capture localized non-smooth mechanical behaviors. Finally, the composite solution is substituted into the total potential energy functional for unified optimization. With this structure, the method resolves the conflict of single network in representing both smooth global and singular local fields without additional interface-loss terms and amplifies the contribution of localized critical features in energy optimization. We focus on a series of numerical experiments in solid mechanics to demonstrate the performance of the method. Results show that LENNs perform well in addressing localized discontinuous problems and provide accurate predictions for both displacement and stress fields.", "published": "2025-10-21T12:20:23Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.217882"}
{"arxiv_id": "2510.18542v1", "title": "Basis-Sensitive Quantum Typing via Realisability", "summary": "We present $\\lambda_B$, a quantum-control $\\lambda$-calculus that refines previous basis-sensitive systems by allowing abstractions to be expressed with respect to arbitrary -- possibly entangled -- bases. Each abstraction and let construct is annotated with a basis, and a new basis-dependent substitution governs the decomposition of value distributions. These extensions preserve the expressive power of earlier calculi while enabling finer reasoning about programs under basis changes. A realisability semantics connects the reduction system with the type system, yielding a direct characterisation of unitary operators and ensuring safety by construction. From this semantics we derive a validated family of typing rules, forming the foundation of a type-safe quantum programming language. We illustrate the expressive benefits of $\\lambda_B$ through examples such as Deutsch's algorithm and quantum teleportation, where basis-aware typing captures classical determinism and deferred-measurement behaviour within a uniform framework.", "published": "2025-10-21T11:42:18Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.218037"}
{"arxiv_id": "2510.18173v1", "title": "CMT-Bench: Cricket Multi-Table Generation Benchmark for Probing   Robustness in Large Language Models", "summary": "LLM Driven text-to-table (T2T) systems often rely on extensive prompt-engineering or iterative event extraction in code-parsable formats, which boosts scores but are computationally expensive and obscure how models actually reason over temporal evolving narratives to summarise key information. We present CMT-Bench, a diagnostic benchmark built from live cricket commentary that requires dynamic table generation across two evolving schemas under a dense, rule-governed policy. CMT-Bench is designed to probe robustness via three semantics-preserving dimensions: (i) extractive-cue ablation to separate extractive shortcuts from state tracking, (ii) temporal prefixing to test long-context stability, and (iii) entity-form perturbations (anonymization, outof-distribution substitutions, role-entangling paraphrases) to assess sensitivity to surface variation. Across diverse long-context stateof-the-art LLMs, we find large drops without extractive summaries, monotonic degradation with input length, and consistent accuracy drop under entity-form changes. Complementary distributional tests confirm significant shifts in numeric error patterns, indicating drift in reasoning rather than mere noise. Our results show that current LLMs are brittle in dynamic Textto-table generation, motivating robustness-first evaluation as a prerequisite for developing efficient and scalable approaches for this task.", "published": "2025-10-20T23:51:28Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.218258"}
{"arxiv_id": "2510.17799v1", "title": "Dynamic Dyck and Tree Edit Distance: Decompositions and Reductions to   String Edit Distance", "summary": "We present the first dynamic algorithms for Dyck and tree edit distances with subpolynomial update times. Dyck edit distance measures how far a parenthesis string is from a well-parenthesized expression, while tree edit distance quantifies the minimum number of node insertions, deletions, and substitutions required to transform one rooted, ordered, labeled tree into another. Despite extensive study, no prior work has addressed efficient dynamic algorithms for these problems, which naturally arise in evolving structured data such as LaTeX documents, JSON or XML files, and RNA secondary structures.   Our main contribution is a set of reductions and decompositions that transform Dyck and tree edit distance instances into efficiently maintainable string edit distance instances, which can be approximated within a $n^{o(1)}$ factor in $n^{o(1)}$ update time. For Dyck edit distance, our reduction incurs only polylogarithmic overheads in approximation and update time, yielding an $n^{o(1)}$-approximation with $n^{o(1)}$ updates. For tree edit distance, we introduce a new static reduction that improves the best-known approximation ratio from $n^{3/4}$ to $\\tilde{O}(\\sqrt{n})$ and removes the restriction to constant-degree trees. Extending this reduction dynamically achieves $n^{1/2+o(1)}$ approximation with $n^{o(1)}$ update time.   A key component is a dynamic maintenance algorithm for history-independent heavy-light decompositions, of independent interest. We also provide a novel static and dynamic decomposition achieving an $O(k \\log n)$-approximation when the tree edit distance is at most $k$. Combined with the trivial bound $k \\le n$, this yields a dynamic deterministic $O(\\sqrt{n \\log n})$-approximation. In the static setting, our algorithm runs in near-linear time; dynamically, it requires only polylogarithmic updates, improving on prior linear-time static $O(\\sqrt{n})$-approximation.", "published": "2025-10-20T17:58:25Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.218526"}
{"arxiv_id": "2510.17745v1", "title": "A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications", "summary": "Spiking Neural Networks (SNNs) have sparse, event driven processing that can leverage neuromorphic applications. In this work, we introduce a multi-threading kernel that enables neuromorphic applications running at the edge, meaning they process sensory input directly and without any up-link to or dependency on a cloud service. The kernel shows speed-up gains over single thread processing by a factor of four on moderately sized SNNs and 1.7X on a Synfire network. Furthermore, it load-balances all cores available on multi-core processors, such as ARM, which run today's mobile devices and is up to 70% more energy efficient compared to statical core assignment. The present work can enable the development of edge applications that have low Size, Weight, and Power (SWaP), and can prototype the integration of neuromorphic chips.", "published": "2025-10-20T17:01:18Z", "query": "sensory substitution", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.218713"}
{"arxiv_id": "2510.17672v1", "title": "Broad-Range Tuning of Ferroelectric Switching of LaxBi1-xFeO3 Epitaxial   Films via Digital Doping using Off-Axis Co-Sputtering", "summary": "To investigate the scope of ferroelectric behavior in La-substituted BiFeO3 films, LaxBi1-xFeO3 epitaxial films were synthesized using off-axis co-sputtering on SrTiO3(001) and DyScO3(110) substrates with a SrRuO3 bottom electrode layer. A digital-doping deposition method was used to enable precise control and continuous tuning of La concentration in high-quality LaxBi1-xFeO3 films across a wide range of x = 0.05-0.60, which was systematically investigated using piezoresponse force microscopy. Robust and reversible out-of-plane ferroelectric switching has been observed up to x = 0.35, while films with x $\\geq$ 0.37 exhibit no measurable ferroelectric behavior, indicating a sharp ferroelectric-to-paraelectric phase transition between x = 0.35 and 0.37. This represents the highest reported La concentration in LaxBi1-xFeO3 films that retains ferroelectric ordering, highlighting opportunities to engineer ferroelectric and multiferroic properties in complex oxide heterostructures.", "published": "2025-10-20T15:44:39Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.218898"}
{"arxiv_id": "2510.17427v1", "title": "AV1 Motion Vector Fidelity and Application for Efficient Optical Flow", "summary": "This paper presents a comprehensive analysis of motion vectors extracted from AV1-encoded video streams and their application in accelerating optical flow estimation. We demonstrate that motion vectors from AV1 video codec can serve as a high-quality and computationally efficient substitute for traditional optical flow, a critical but often resource-intensive component in many computer vision pipelines. Our primary contributions are twofold. First, we provide a detailed comparison of motion vectors from both AV1 and HEVC against ground-truth optical flow, establishing their fidelity. In particular we show the impact of encoder settings on motion estimation fidelity and make recommendations about the optimal settings. Second, we show that using these extracted AV1 motion vectors as a \"warm-start\" for a state-of-the-art deep learning-based optical flow method, RAFT, significantly reduces the time to convergence while achieving comparable accuracy. Specifically, we observe a four-fold speedup in computation time with only a minor trade- off in end-point error. These findings underscore the potential of reusing motion vectors from compressed video as a practical and efficient method for a wide range of motion-aware computer vision applications.", "published": "2025-10-20T11:13:36Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:46.219054"}
{"arxiv_id": "2510.17405v1", "title": "AFRICAPTION: Establishing a New Paradigm for Image Captioning in African   Languages", "summary": "Multimodal AI research has overwhelmingly focused on high-resource languages, hindering the democratization of advancements in the field. To address this, we present AfriCaption, a comprehensive framework for multilingual image captioning in 20 African languages and our contributions are threefold: (i) a curated dataset built on Flickr8k, featuring semantically aligned captions generated via a context-aware selection and translation process; (ii) a dynamic, context-preserving pipeline that ensures ongoing quality through model ensembling and adaptive substitution; and (iii) the AfriCaption model, a 0.5B parameter vision-to-text architecture that integrates SigLIP and NLLB200 for caption generation across under-represented languages. This unified framework ensures ongoing data quality and establishes the first scalable image-captioning resource for under-represented African languages, laying the groundwork for truly inclusive multimodal AI.", "published": "2025-10-20T10:44:44Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:46.219218"}
{"arxiv_id": "2510.17380v1", "title": "Optimizing Energy Management of Smart Grid using Reinforcement Learning   aided by Surrogate models built using Physics-informed Neural Networks", "summary": "Optimizing the energy management within a smart grids scenario presents significant challenges, primarily due to the complexity of real-world systems and the intricate interactions among various components. Reinforcement Learning (RL) is gaining prominence as a solution for addressing the challenges of Optimal Power Flow in smart grids. However, RL needs to iterate compulsively throughout a given environment to obtain the optimal policy. This means obtaining samples from a, most likely, costly simulator, which can lead to a sample efficiency problem. In this work, we address this problem by substituting costly smart grid simulators with surrogate models built using Phisics-informed Neural Networks (PINNs), optimizing the RL policy training process by arriving to convergent results in a fraction of the time employed by the original environment.", "published": "2025-10-20T10:17:42Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:46.219354"}
{"arxiv_id": "2510.17145v1", "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted   Feature Fusion", "summary": "Accurate assessment of fish freshness remains a major challenge in the food industry, with direct consequences for product quality, market value, and consumer health. Conventional sensory evaluation is inherently subjective, inconsistent, and difficult to standardize across contexts, often limited by subtle, species-dependent spoilage cues. To address these limitations, we propose a handcrafted feature-based approach that systematically extracts and incrementally fuses complementary descriptors, including color statistics, histograms across multiple color spaces, and texture features such as Local Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish eye images. Our method captures global chromatic variations from full images and localized degradations from ROI segments, fusing each independently to evaluate their effectiveness in assessing freshness. Experiments on the Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's effectiveness: in a standard train-test setting, a LightGBM classifier achieved 77.56% accuracy, a 14.35% improvement over the previous deep learning baseline of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached 97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results demonstrate that carefully engineered, handcrafted features, when strategically processed, yield a robust, interpretable, and reliable solution for automated fish freshness assessment, providing valuable insights for practical applications in food quality monitoring.", "published": "2025-10-20T04:36:34Z", "query": "sensory substitution", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:46.219499"}
{"arxiv_id": "2510.17129v1", "title": "Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied   Agents", "summary": "Recent advancements in Large Language Models (LLMs) have greatly enhanced natural language understanding and content generation. However, these models primarily operate in disembodied digital environments and lack interaction with the physical world. To address this limitation, Embodied Artificial Intelligence (EAI) has emerged, focusing on agents that can perceive and interact with their surroundings. Despite progress, current embodied agents face challenges in unstructured real-world environments due to insufficient semantic intelligence, which is critical for understanding and reasoning about complex tasks. This paper introduces the Semantic Intelligence-Driven Embodied (SIDE) agent framework, which integrates a hierarchical semantic cognition architecture with a semantic-driven decision-making process. This enables agents to reason about and interact with the physical world in a contextually adaptive manner. The framework is inspired by biological cognitive mechanisms and utilizes bio-inspired principles to design a semantic cognitive architecture that mimics how humans and animals integrate and process sensory information. We present this framework as a step toward developing more intelligent and versatile embodied agents.", "published": "2025-10-20T03:50:09Z", "query": "sensory substitution", "relevance": 0.1, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:46.219663"}
{"arxiv_id": "2510.17083v2", "title": "Toward a Cognitive-Affective-Systemic Framework for Art and   Sustainability", "summary": "This paper proposes a cognitive-Affective-Systemic (CAS) framework that integrates cognition, emotion, and systemic understanding to cultivate sustainability awareness through art. Drawing from eco-aesthetics, affect theory, complexity science, and posthuman ethics, the framework defines artistic practice as both epistemic and performative--a way of knowing through making and feeling. Central to this is logomotion, an aesthetic mode where comprehension and emotion move together as a unified experience. Two artworks, SPill, visualizing antimicrobial resistance through avalanche dynamics, and Echoes of the Land, modeling anthropogenic seismicity, demonstrate how systemic modeling and sensory immersion transform complex science into embodied ecological understanding. The framework offers a methodological foundation for artists, theorists, and activists to translate awareness into engagement, advancing collective creativity toward sustainable futures.", "published": "2025-10-20T01:27:43Z", "query": "sensory substitution", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:46.219778"}
{"arxiv_id": "2510.16993v1", "title": "Coherent terahertz control of metastable magnetization in FePS3", "summary": "The crystal lattice governs the emergent electronic, magnetic, and optical properties of quantum materials, making structural tuning through strain, pressure, or chemical substitution a key approach for discovering and controlling novel quantum phases. Beyond static modifications, driving specific lattice modes with ultrafast stimuli offers a dynamic route for tailoring material properties out of equilibrium. However, achieving dynamic coherent control of the nonequilibrium phases via resonant excitation of lattice coherences remains largely unexplored. Such manipulation enables non-volatile, on demand amplification and suppression of order parameters on femtosecond timescales, necessary for next generation optoelectronic ultrafast computation. In this study, we demonstrate coherent phononic control of a newly discovered, light-induced metastable magnetization in the van der Waals antiferromagnet FePS3. By using a sequence of terahertz (THz) pulses, we modulate the magnetization amplitude at the frequencies of phonon coherences, whose infrared-active nature and symmetries are further revealed by polarization- and field-strength-dependent measurements. Furthermore, our two-dimensional THz spectroscopy, in tandem with first-principles numerical simulations, shows that these phonons nonlinearly displace a Raman active phonon, which induces the metastable net magnetization. These findings not only clarify the microscopic mechanism underlying the metastable state in FePS3 but also establish vibrational coherences in solids as a powerful tool for ultrafast quantum phase control, enabling manipulation of material functionalities far from equilibrium.", "published": "2025-10-19T20:23:06Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:46.219919"}
{"arxiv_id": "2510.20816v1", "title": "Charge-density waves and stripes in quarter metals of graphene   heterostructures", "summary": "Motivated by recent experiments, here we identify valley-coherent charge-density wave (VC-CDW) order in the non-degenerate quarter-metal for the entire family of chirally-stacked $n$ layer graphene, encompassing rhombohedral multi-layer, Bernal bilayer, and monolayer cousins. Besides the hallmark broken translational symmetry, yielding a modulated charge-density over an enlarged unit-cell with a characteristic $2{\\bf K}$ periodicity, where $\\pm {\\bf K}$ are the valley momenta, this phase lacks the three-fold ($C_3$) rotational symmetry but only for even integer $n$. The VC-CDW then represents a stripe order, as observed in hexalayer graphene [arXiv:2504.05129], but preserves the $C_3$ symmetry for odd $n$ as observed in trilayer graphene [Nat. Phys. 20, 1413 (2024) and arXiv: 2411.11163]. From a universal Clifford algebraic argument, we establish that the VC-CDW and an anomalous Hall order can lift the residual valley degeneracy of an antiferromagnetically ordered spin-polarized half-metal, when these systems are subject to perpendicular displacement fields, with only the latter one displaying a hysteresis in off-diagonal resistivity, as observed in all the systems with $2 \\leq n \\leq 6$. We showcase a confluence of VC-CDW and anomalous Hall orders within the quarter-metal, generically displaying a regime of coexistence, separating the pure phases.", "published": "2025-10-23T17:59:33Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.707944"}
{"arxiv_id": "2510.20815v1", "title": "Generative Reasoning Recommendation via LLMs", "summary": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.", "published": "2025-10-23T17:59:31Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:49.708487"}
{"arxiv_id": "2510.20811v1", "title": "Simulation-calibrated Bayesian inference for progenitor properties of   the microquasar SS 433", "summary": "SS\\,433 is one of the most extreme Galactic X-ray binaries, exhibiting semi-relativistic jets and super-critical accretion, and harboring a compact object, likely a black hole. Despite decades of observation and modeling, the precise nature of its progenitor binary remains uncertain. To estimate the zero-age main sequence (ZAMS) properties of binaries that evolve into SS\\,433-like systems, we apply simulation-based calibration to Bayesian inference and convolve a multivariate Gaussian likelihood constructed from six measured binary parameters of SS\\,433 with the isolated binary evolution model \\textsc{COSMIC}. Employing the dynamic nested sampler of \\texttt{dynesty}, we perform posterior inference over a ten-dimensional progenitor parameter space defined by the masses, orbital parameters, mass transfer possibilities, and natal kick velocity. We find that SS\\,433-like systems arise from specific regions of binary evolution parameter space depending on key assumptions, such as the mass transfer rate and uncertainty taken from observations. Our simulation-based calibration framework, implemented with a suite of machine learning algorithms and scored by a heuristic reliability metric, allows us to iteratively build posterior distributions of the progenitors of SS\\,433-like systems. This analysis reveals 90\\% confidence intervals for the ZAMS primary mass $(8, 11)$ M$_\\odot$, secondary mass $(32, 40)$ M$_\\odot $, orbital period $(136, 2259)$ days, eccentricity $(0.26, 0.6)$, common envelope evolution efficiency $(0.44, 0.76)$, accreted fraction in stable mass transfer $(0.22, 0.6)$, and black hole natal kick velocity magnitude $(5, 68)$ km/s. These results demonstrate the feasibility of direct probabilistic inference of X-ray binary progenitors to offer new insights into the evolution of high-accretion-rate systems such as SS\\,433.", "published": "2025-10-23T17:59:09Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:49.708748"}
{"arxiv_id": "2510.20808v1", "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "summary": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.", "published": "2025-10-23T17:58:53Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.709024"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:49.709238"}
{"arxiv_id": "2510.20805v1", "title": "Bilevel Analysis of Cost and Emissions Externalities from Data Center   Load Shifting", "summary": "Data centers are emerging as large, flexible electricity consumers capable of shifting computational workloads across locations in response to economic and environmental signals. While this flexibility has potential for emissions reduction, its impact on power system operations depends critically on how such behavior interacts with network constraints and market signals. We develop a bilevel optimization framework in which a data center minimizes a weighted combination of electricity cost and marginal emissions intensity (LME), while the system operator clears economic dispatch under transmission and generation constraints. Focusing on a stylized three-bus power system, we derive closed-form, piecewise-linear expressions for both the data center and system-wide objectives as functions of the data centers' load shift. These expressions capture threshold-driven regime changes due to congestion and renewable saturation. We identify sufficient conditions under which the data center's decentralized decisions align with or diverge from socially optimal behavior and characterize the resulting externalities. Our results reveal how system topology and generator asymmetry affect incentive alignment and provide insight into when marginal price or emissions signals may fail to guide flexible loads toward socially beneficial outcomes. Our results offer a tractable starting point for analyzing decentralized flexibility under carbon-aware incentives and suggest directions for improving coordination between flexible loads and system operations.", "published": "2025-10-23T17:58:31Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:49.709444"}
{"arxiv_id": "2510.20804v1", "title": "Anomalous Hall effect in rhombohedral graphene", "summary": "Motivated by recent experiments on rhombohedral stacked multilayer graphene and the observation of the anomalous Hall effect in a spontaneous spin-valley polarized quarter metal state, we calculate the anomalous Hall conductivity for this system in the presence of two types of impurities: weak and dense as well as sparse and strong. Our calculation of $\\sigma_{xy}$ is based on the Kubo-Streda diagrammatic approach. In a model with Gaussian disorder applicable to weak dense impurities, this involves all non-crossing diagrams (intrinsic, side-jump and Gaussian skew-scattering contributions) and additionally diagrams with two intersecting impurities, X and $\\Psi$, representing diffractive skew-scattering processes. A \"Mercedes star\" diagram (non-Gaussian skew scattering) is furthermore included to treat in the case of strong, sparse impurities. We supplement our asymptotically exact analytical solutions for an isotropic model without warping effects by semi-numerical calculations accounting perturbatively for warping, which plays a crucial role in the low-energy band structure.", "published": "2025-10-23T17:58:28Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.709665"}
{"arxiv_id": "2510.20798v1", "title": "Analog Quantum Feature Selection with Neutral-Atom Quantum Processors", "summary": "We present a quantum-native approach to quantum feature selection (QFS) based on analog quantum simulation with neutral atom arrays, adaptable to a variety of academic and industrial applications. In our method, feature relevance-measured via mutual information with the target-is encoded as local detuning amplitudes, while feature redundancy is embedded through distance-dependent van der Waals interactions, constrained by the Rydberg blockade radius. The system is evolved adiabatically toward low-energy configurations, and the resulting measurement bitstrings are used to extract physically consistent subsets of features. The protocol is evaluated through simulations on three benchmark binary classification datasets: Adult Income, Bank Marketing, and Telco Churn. Compared to classical methods such as mutual information ranking and Boruta, combined with XGBoost and Random Forest classifiers, our quantum-computing approach achieves competitive or superior performance. In particular, for compact subsets of 2-5 features, analog QFS improves mean AUC scores by 1.5-2.3% while reducing the number of features by 75-84%, offering interpretable, low-redundancy solutions. These results demonstrate that programmable Rydberg arrays offer a viable platform for intelligent feature selection with practical relevance in machine learning pipelines, capable of transforming computational quantum advantage into industrial quantum usefulness.", "published": "2025-10-23T17:57:34Z", "query": "neural feedback systems", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:49.709875"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:49.710096"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural feedback systems", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.710431"}
{"arxiv_id": "2510.20794v1", "title": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common   Feature", "summary": "This paper presents a Multi-Object Tracking (MOT) framework that fuses radar and camera data to enhance tracking efficiency while minimizing manual interventions. Contrary to many studies that underutilize radar and assign it a supplementary role--despite its capability to provide accurate range/depth information of targets in a world 3D coordinate system--our approach positions radar in a crucial role. Meanwhile, this paper utilizes common features to enable online calibration to autonomously associate detections from radar and camera. The main contributions of this work include: (1) the development of a radar-camera fusion MOT framework that exploits online radar-camera calibration to simplify the integration of detection results from these two sensors, (2) the utilization of common features between radar and camera data to accurately derive real-world positions of detected objects, and (3) the adoption of feature matching and category-consistency checking to surpass the limitations of mere position matching in enhancing sensor association accuracy. To the best of our knowledge, we are the first to investigate the integration of radar-camera common features and their use in online calibration for achieving MOT. The efficacy of our framework is demonstrated by its ability to streamline the radar-camera mapping process and improve tracking precision, as evidenced by real-world experiments conducted in both controlled environments and actual traffic scenarios. Code is available at https://github.com/radar-lab/Radar_Camera_MOT", "published": "2025-10-23T17:54:57Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.710695"}
{"arxiv_id": "2510.20790v1", "title": "Trapping, manipulating and probing ultracold atoms: a quantum   technologies tutorial", "summary": "Engineered ultracold atomic systems are a valuable platform for fundamental quantum mechanics studies and the development of quantum technologies. At near zero absolute temperature, atoms exhibit macroscopic phase coherence and collective quantum behavior, enabling their use in precision metrology, quantum simulation, and even information processing. This review provides an introductory overview of the key techniques used to trap, manipulate, and detect ultracold atoms, while highlighting the main applications of each method. We outline the principles of laser cooling, magnetic and optical trapping, and the most widely used techniques, including optical lattices and tweezers. Next, we discuss the manipulation methods of atomic internal and external degrees of freedom, and we present atom interferometry techniques and how to leverage and control interatomic interactions. Next, we review common ensemble detection strategies, including absorption and fluorescence imaging, state-selective readout, correlation and quantum non-demolition measurements and conclude with high-resolution approaches. This review aims to provide newcomers to the field with a broad understanding of the experimental toolkit that underpins research in ultracold atom physics and its applications across quantum science and technology.", "published": "2025-10-23T17:54:06Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:49.710864"}
{"arxiv_id": "2510.20788v1", "title": "Predicting Protein-Nucleic Acid Flexibility Using Persistent Sheaf   Laplacians", "summary": "Understanding the flexibility of protein-nucleic acid complexes, often characterized by atomic B-factors, is essential for elucidating their structure, dynamics, and functions, such as reactivity and allosteric pathways. Traditional models such as Gaussian Network Models (GNM) and Elastic Network Models (ENM) often fall short in capturing multiscale interactions, especially in large or complex biomolecular systems. In this work, we apply the Persistent Sheaf Laplacian (PSL) framework for the B-factor prediction of protein-nucleic acid complexes. The PSL model integrates multiscale analysis, algebraic topology, combinatoric Laplacians, and sheaf theory for data representation. It reveals topological invariants in its harmonic spectra and captures the homotopic shape evolution of data with its non-harmonic spectra. Its localization enables accurate B-factor predictions. We benchmark our method on three diverse datasets, including protein-RNA and nucleic-acid-only structures, and demonstrate that PSL consistently outperforms existing models such as GNM and multiscale FRI (mFRI), achieving up to a 21% improvement in Pearson correlation coefficient for B-factor prediction. These results highlight the robustness and adaptability of PSL in modeling complex biomolecular interactions and suggest its potential utility in broader applications such as mutation impact analysis and drug design.", "published": "2025-10-23T17:53:33Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.711126"}
{"arxiv_id": "2510.20784v1", "title": "A Coherence-Based Measure of AGI", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized \\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of proficiencies across cognitive domains derived from the Cattell--Horn--Carroll (CHC) model of human cognition. While elegant, this definition assumes \\textit{compensability} -- that exceptional ability in some domains can offset failure in others. True general intelligence, however, should reflect \\textit{coherent sufficiency}: balanced competence across all essential domains. We propose a coherence-aware measure of AGI based on the integral of generalized means over a continuum of compensability exponents. This formulation spans arithmetic, geometric, and harmonic regimes, and the resulting \\textit{area under the curve} (AUC) quantifies robustness under varying compensability assumptions. Unlike the arithmetic mean, which rewards specialization, the AUC penalizes imbalance and captures inter-domain dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5, the coherence-adjusted AUC reveals that both systems remain far from general competence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating the generalized mean thus yields a principled, interpretable, and stricter foundation for measuring genuine progress toward AGI.", "published": "2025-10-23T17:51:42Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:49.711350"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.711608"}
{"arxiv_id": "2510.20777v1", "title": "Learning Optimal Power Flow with Pointwise Constraints", "summary": "Training learning parameterizations to solve optimal power flow (OPF) with pointwise constraints is proposed. In this novel training approach, a learning parameterization is substituted directly into an OPF problem with constraints required to hold over all problem instances. This is different from existing supervised learning methods in which constraints are required to hold across the average of problem instances. Training with pointwise constraints is undertaken in the dual domain with the use of augmented Lagrangian and dual gradient ascent algorithm. Numerical experiments demonstrate that training with pointwise constraints produces solutions with smaller constraint violations. Experiments further demonstrated that pointwise constraints are most effective at reducing constraint violations in corner cases - defined as those realizations in which constraints are most difficult to satisfy. Gains are most pronounced in power systems with large numbers of buses.", "published": "2025-10-23T17:48:10Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:49.711796"}
{"arxiv_id": "2510.20769v1", "title": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble   Precipitation Forecasting", "summary": "Accurate medium-range precipitation forecasting is crucial for hydrometeorological risk management and disaster mitigation, yet remains challenging for current numerical weather prediction (NWP) systems. Traditional ensemble systems such as the Global Ensemble Forecast System (GEFS) struggle to maintain high skill, especially for moderate and heavy rainfall at extended lead times. This study develops a deep learning-based ensemble framework for multi-step precipitation prediction through joint modeling of a comprehensive set of atmospheric variables. The model is trained on ERA5 reanalysis data at 0.25$^{\\circ}$ spatial resolution, with precipitation labels from NASA's Integrated Multi-satellite Retrievals for Global Precipitation Measurement (GPM) constellation (IMERG), incorporating 57 input variables, including upper-air and surface predictors. The architecture employs a patch-based Swin Transformer backbone with periodic convolutions to handle longitudinal continuity and integrates time and noise embeddings through conditional layer normalization. A dual-branch decoder predicts total precipitation and other variables, with targeted freezing of encoder-decoder pathways for specialized training. Training minimizes a hybrid loss combining the Continuous Ranked Probability Score (CRPS) and weighted log1p mean squared error (log1pMSE), balancing probabilistic accuracy and magnitude fidelity. During inference, the model ingests real-time Global Forecast System (GFS) initial conditions to generate 15-day forecasts autoregressively. Evaluation against GEFS using IMERG data demonstrates higher Critical Success Index (CSI) scores at precipitation thresholds of 0.1 mm, 1 mm, 10 mm, and 20 mm, highlighting improved performance for moderate to heavy rainfall.", "published": "2025-10-23T17:43:38Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:49.711991"}
{"arxiv_id": "2510.20768v1", "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines", "summary": "Retrieval-Augmented Generation (RAG) has emerged as the dominant architectural pattern to operationalize Large Language Model (LLM) usage in Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to poisoning attacks, and previously proposed defenses can fail for CTI contexts as cyber threat information is often completely new for emerging attacks, and sophisticated threat actors can mimic legitimate formats, terminology, and stylistic conventions. To address this issue, we propose that the robustness of modern RAG defenses can be accelerated by applying source credibility algorithms on corpora, using PageRank as an example. In our experiments, we demonstrate quantitatively that our algorithm applies a lower authority score to malicious documents while promoting trusted content, using the standardized MS MARCO dataset. We also demonstrate proof-of-concept performance of our algorithm on CTI documents and feeds.", "published": "2025-10-23T17:43:00Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:15:49.712140"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural feedback systems", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:49.712273"}
{"arxiv_id": "2510.20759v1", "title": "Controllable Embedding Transformation for Mood-Guided Music Retrieval", "summary": "Music representations are the backbone of modern recommendation systems, powering playlist generation, similarity search, and personalized discovery. Yet most embeddings offer little control for adjusting a single musical attribute, e.g., changing only the mood of a track while preserving its genre or instrumentation. In this work, we address the problem of controllable music retrieval through embedding-based transformation, where the objective is to retrieve songs that remain similar to a seed track but are modified along one chosen dimension. We propose a novel framework for mood-guided music embedding transformation, which learns a mapping from a seed audio embedding to a target embedding guided by mood labels, while preserving other musical attributes. Because mood cannot be directly altered in the seed audio, we introduce a sampling mechanism that retrieves proxy targets to balance diversity with similarity to the seed. We train a lightweight translation model using this sampling strategy and introduce a novel joint objective that encourages transformation and information preservation. Extensive experiments on two datasets show strong mood transformation performance while retaining genre and instrumentation far better than training-free baselines, establishing controllable embedding transformation as a promising paradigm for personalized music retrieval.", "published": "2025-10-23T17:29:13Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.712466"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.712696"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural feedback systems", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.712847"}
{"arxiv_id": "2510.20750v1", "title": "Critical Dynamics of Superfluids", "summary": "We use standard techniques of hydrodynamics to construct a relativistic effective field theory for the low energy dynamics of nearly critical superfluids. In an appropriate non-relativistic limit, our theory predicts an additional coefficient when compared and contrasted to earlier work of Khalatnikov and Lebedev. In addition, we provide an alternative derivation of the same effective theory, using the Keldysh-Schwinger framework for non-equilibrium systems. Finally, we comment on the comparison with the results of an appropriate holographic computation presented in a companion paper. This provides further evidence in support of the theory we propose and confirms the existence of the extra coefficient we identified.", "published": "2025-10-23T17:16:16Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.712982"}
{"arxiv_id": "2510.20749v1", "title": "Multipolar Decomposition of Magnetic Circular Dichroism in Arbitrarily   Shaped Magneto-Dielectric Scatterers", "summary": "Multipole expansion methods have been primarily used for analyzing the electromagnetic scattering from non-magnetic isotropic dielectric scatterers, and studies about the scattering from magnetic objects seem to be lacking. In this work, we used the multipolar expansion framework for decomposing the electromagnetic scattering by dielectric particles with magnetic properties. Magnetization current contributions were explicitly accounted for by using the vector spherical harmonics to compute the electric and magnetic multipole contributions of arbitrary order. The exact analytical expressions for the corresponding spherical multipole coefficients were employed, with the scattering efficiencies being used to distinguish the dielectric and magnetic contributions of each multipole. This enables the analysis of scattering from arbitrarily shaped, anisotropic, and inhomogeneous magnetic scatterers. It also provides a tool for studying non-reciprocal devices that exploit magnetic resonances in magnetic-dielectric materials. Calculations were made for an experimentally feasible system, namely for ferrite-based scatterers operating in the microwave regime. These materials are of interest in radio frequency (RF) applications due to their magnetic activity. We demonstrated analytically that the magnetic circular dichroism in a magnetic-dielectric scatterer in the Faraday geometry can be decomposed into individual multipole contributions. The analytical results indicate that multipole resonances associated with magnetization currents can be even stronger than multipole contributions from conventional dielectric currents. It is worth noting that these analytical results were verified through comparison with numerical results from finite element method (FEM) simulations in COMSOL Multiphysics.", "published": "2025-10-23T17:15:16Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.713212"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:49.713415"}
{"arxiv_id": "2510.20746v1", "title": "Berry Curvature Dipole-induced Non-linear Hall Effect in Oxide   Heterostructures", "summary": "The observation of non-linear Hall effects in time-reversal invariant systems has established the intriguing role of band topology beyond Berry curvature in determining transport phenomena. Many of these non-linear responses owe their origin to the Berry curvature dipole (BCD), which, like the Berry curvature (monopole), is also an electronic band structure effect, but is routinely strongly constrained by crystalline symmetries. Here, we propose non-centrosymmetric transition metal oxide heterostructures as promising platforms for realizing and tuning BCD-induced non-linear Hall effects. Specifically, we investigate superlattices of the form $(\\mathrm{Ba(Os,Ir)}\\mathrm{O}_3)_n/(\\mathrm{BaTiO}_3)_4$ ($n{=}1, 2$), comprising metallic perovskite layers ($\\mathrm{BaOsO_3}$ or $\\mathrm{BaIrO_3}$) sandwiched between insulating ferroelectric $\\mathrm{BaTiO_3}$ (BTO). The ferroelectric distortion in BTO breaks inversion symmetry of the superlattice, giving rise to a finite BCD with two symmetry-allowed components of equal magnitude and opposite sign. Our first-principles calculations demonstrate that the magnitude of the BCD -- and consequently the nonlinear Hall response -- can be effectively tuned by varying the number of metallic layers or the choice of the B-site cation in these $\\mathrm{ABO_3}$ perovskites. Since Rashba splitting and ferroelectric distortion in these systems are readily controllable via an external electric field or strain, the non-linear Hall response in these materials can be directly engineered. Our findings establish non-centrosymmetric oxide perovskite heterostructures as a versatile platform for exploring and manipulating BCD-driven non-linear transport phenomena.", "published": "2025-10-23T17:09:58Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.713639"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "neural feedback systems", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.713816"}
{"arxiv_id": "2510.20740v1", "title": "Early Evidence for Polar Orbits of Sub-Saturns Around Hot Stars", "summary": "Sub-Saturns have been reported to preferentially occupy near-polar orbits, but this conclusion has so far been based primarily on systems with cool host stars; obliquity measurements for sub-Saturns orbiting hot stars remain scarce. Expanding the census into the hot-star regime is essential to test whether the polar preference persists across the Kraft break and to diagnose the underlying excitation mechanisms. In this work, we present Rossiter-McLaughlin observations of TOI-1135 b, a sub-Saturn orbiting a hot star with $T_{\\rm eff}=6320\\pm120$ K, using WIYN/NEID. We confirm its near-polar architecture, measuring a sky-projected obliquity of $\\lambda=-68.1^{+7.5}_{-5.3}$ degrees and a true obliquity of $\\psi=72.2^{+6.4}_{-6.6}$ degrees. Coupling our new measurement with stellar-obliquity data from the literature, we find that sub-Saturns and hot Jupiters around cool stars are unlikely to be drawn from the same parent distribution at the $5.2\\sigma$ level, consistent with weaker tidal realignment induced by lower-mass planets. Of the two known misaligned sub-Saturns around hot stars, both are near-polar, suggesting that the polar preference may extend above the Kraft break. Moreover, their obliquities lie near $\\sim 65$ degrees, supporting predictions from secular resonance crossing for sub-Saturns around rapidly rotating hot stars.", "published": "2025-10-23T16:58:36Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.713998"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural feedback systems", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:49.714178"}
{"arxiv_id": "2510.20735v1", "title": "Magnetic tunnel junction as a real-time entropy source:   Field-Programmable Gate Array based random bit generation without   post-processing", "summary": "We demonstrate a method to generate application-ready truly random bits from a magnetic tunnel junction driven by a Field-Programmable Gate Array (FPGA). We implement a real-time feedback loop that stabilizes the switching probability near 50\\% and apply an XOR operation, both on the FPGA, to suppress short-term correlations, together mitigating long-term drift and bias in the bitstream. This combined approach enables NIST-compliant random bit generation at 5~Mb/s without post-processing, providing a practical hardware solution for fast and reliable true random number generation. Beyond cryptographic applications, these capabilities open opportunities for stochastic hardware accelerators, probabilistic computing, and large-scale modeling where real-time access to unbiased randomness is essential.", "published": "2025-10-23T16:50:51Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:49.714329"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "brain stimulation VR", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.235830"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "brain stimulation VR", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:53.236513"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.236825"}
{"arxiv_id": "2510.20196v1", "title": "A Structured Review and Quantitative Profiling of Public Brain MRI   Datasets for Foundation Model Development", "summary": "The development of foundation models for brain MRI depends critically on the scale, diversity, and consistency of available data, yet systematic assessments of these factors remain scarce. In this study, we analyze 54 publicly accessible brain MRI datasets encompassing over 538,031 to provide a structured, multi-level overview tailored to foundation model development. At the dataset level, we characterize modality composition, disease coverage, and dataset scale, revealing strong imbalances between large healthy cohorts and smaller clinical populations. At the image level, we quantify voxel spacing, orientation, and intensity distributions across 15 representative datasets, demonstrating substantial heterogeneity that can influence representation learning. We then perform a quantitative evaluation of preprocessing variability, examining how intensity normalization, bias field correction, skull stripping, spatial registration, and interpolation alter voxel statistics and geometry. While these steps improve within-dataset consistency, residual differences persist between datasets. Finally, feature-space case study using a 3D DenseNet121 shows measurable residual covariate shift after standardized preprocessing, confirming that harmonization alone cannot eliminate inter-dataset bias. Together, these analyses provide a unified characterization of variability in public brain MRI resources and emphasize the need for preprocessing-aware and domain-adaptive strategies in the design of generalizable brain MRI foundation models.", "published": "2025-10-23T04:31:09Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:53.237153"}
{"arxiv_id": "2510.20148v1", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity   in Tau Propagation Through Multi-Layer Modeling", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.", "published": "2025-10-23T02:52:42Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:53.237433"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:53.237629"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "brain stimulation VR", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:15:53.237838"}
{"arxiv_id": "2510.19996v1", "title": "A Fundamental Algorithm for Dependency Parsing (With Corrections)", "summary": "This paper presents a fundamental algorithm for parsing natural language sentences into dependency trees. Unlike phrase-structure (constituency) parsers, this algorithm operates one word at a time, attaching each word as soon as it can be attached, corresponding to properties claimed for the parser in the human brain. Like phrase-structure parsing, its worst-case complexity is $O(n^3)$, but in human language, the worst case occurs only for small $n$.", "published": "2025-10-22T19:48:38Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:53.237994"}
{"arxiv_id": "2510.19764v1", "title": "A flexible framework for structural plasticity in GPU-accelerated sparse   spiking neural networks", "summary": "The majority of research in both training Artificial Neural Networks (ANNs) and modeling learning in biological brains focuses on synaptic plasticity, where learning equates to changing the strength of existing connections. However, in biological brains, structural plasticity - where new connections are created and others removed - is also vital, not only for effective learning but also for recovery from damage and optimal resource usage. Inspired by structural plasticity, pruning is often used in machine learning to remove weak connections from trained models to reduce the computational requirements of inference. However, the machine learning frameworks typically used for backpropagation-based training of both ANNs and Spiking Neural Networks (SNNs) are optimized for dense connectivity, meaning that pruning does not help reduce the training costs of ever-larger models. The GeNN simulator already supports efficient GPU-accelerated simulation of sparse SNNs for computational neuroscience and machine learning. Here, we present a new flexible framework for implementing GPU-accelerated structural plasticity rules and demonstrate this first using the e-prop supervised learning rule and DEEP R to train efficient, sparse SNN classifiers and then, in an unsupervised learning context, to learn topographic maps. Compared to baseline dense models, our sparse classifiers reduce training time by up to 10x while the DEEP R rewiring enables them to perform as well as the original models. We demonstrate topographic map formation in faster-than-realtime simulations, provide insights into the connectivity evolution, and measure simulation speed versus network size. The proposed framework will enable further research into achieving and maintaining sparsity in network structure and neural communication, as well as exploring the computational benefits of sparsity in a range of neuromorphic applications.", "published": "2025-10-22T16:50:00Z", "query": "brain stimulation VR", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.238199"}
{"arxiv_id": "2510.19747v1", "title": "Review of Tools for Zero-Code LLM Based Application Development", "summary": "Large Language Models (LLMs) are transforming software creation by enabling zero code development platforms. Our survey reviews recent platforms that let users build applications without writing code, by leveraging LLMs as the brains of the development process. We adopt a broad survey methodology, categorizing platforms based on key dimensions such as interface style, backend integration, output type, and extensibility. We analyze both dedicated LLM based app builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and general no code platforms (e.g., Bubble, Glide) that integrate LLM capabilities. We present a taxonomy categorizing these platforms by their interface (conversational, visual, etc.), supported LLM backends, output type (chatbot, full application, workflow), and degree of extensibility. Core features such as autonomous agents, memory management, workflow orchestration, and API integrations are in scope of the survey. We provide a detailed comparison, highlighting each platform's strengths and limitations. Trade offs (customizability, scalability, vendor lock-in) are discussed in comparison with traditional and low code development approaches. Finally, we outline future directions, including multimodal interfaces, on device LLMs, and improved orchestration for democratizing app creation with AI. Our findings indicate that while zero code LLM platforms greatly reduce the barrier to creating AI powered applications, they still face challenges in flexibility and reliability. Overall, the landscape is rapidly evolving, offering exciting opportunities to empower non programmers to create sophisticated software.", "published": "2025-10-22T16:41:16Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.238382"}
{"arxiv_id": "2510.19702v1", "title": "Dictionary learning methods for brain activity mapping with MEG data", "summary": "A central goal in many brain studies is the identification of those brain regions that are activated during an observation window that may correspond to a motor task, a stimulus, or simply a resting state. While functional MRI is currently the most commonly employed modality for such task, methods based on the electromagnetic activity of the brain are valuable alternatives because of their excellent time resolution and of the fact that the measured signals are directly related to brain activation and not to a secondary effect such as the hemodynamic response. In this work we focus on the MEG modality, investigating the performance of a recently proposed Bayesian dictionary learning (BDL) algorithm for brain region identification. The partitioning of the source space into the 148 regions of interest (ROI) corresponding to parcellation of the Destrieux atlas provides a natural determination of the subdictionaries necessary for the BDL algorithm. We design a simulation protocol where a small randomly selected patch in each ROI is activated, the MEG signal is computed and the inverse problem of active brain region identification is solved using the BDL algorithm. The BDL algorithm consists of two phases, the first one comprising dictionary compression and Bayesian compression error analysis, and the second one performing dictionary coding with a deflated dictionary built on the output of the first phase, both steps relying on Bayesian sparsity promoting computations. For assessing the performance, we give a probabilistic interpretation of the confusion matrix, and consider different impurity measures for a multi-class classifier.", "published": "2025-10-22T15:53:22Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:53.238576"}
{"arxiv_id": "2510.19680v1", "title": "T2 mapping at 0.55 T using Ultra-Fast Spin Echo MRI", "summary": "Low-field T2 mapping MRI can democratize neuropediatric imaging by improving accessibility and providing quantitative biomarkers of brain development. \\textbf{Purpose:} To evaluate the feasibility of high-resolution T2 mapping using a single-shot fast spin-echo (SS-FSE) sequence at 0.55~T in a healthy control cohort. \\textbf{Study Type:} Prospective single-center study. \\textbf{Population:} In vivo: ten healthy adults (18--43~years, 5 females/5 males). In vitro: NIST Phantom. \\textbf{Field strength/sequence:} Multi-echo ultra-fast spin-echo at 0.55~T and 1.5~T. \\textbf{Assessment:} Feasibility was first assessed in vitro using the NIST Phantom, comparing T2 relaxation times to spectrometer references at 0.55~T. Acquisition and T2-fitting parameters optimized in vitro were applied in vivo. Repeatability was evaluated by atlas-based analysis of white matter (WM) and cortical grey matter (GM) regions. Coefficients of variation (CoV) were computed across runs, sessions, and subjects. \\textbf{Statistical Tests:} Wilcoxon signed-rank test with Bonferroni correction ($\\alpha = 0.05/n_{ROI}$) assessed CoV differences. Pearson correlation coefficients quantified T2 associations. \\textbf{Results:} In vitro, mono-exponential fitting under Gaussian--Rician noise yielded deviations $&lt;12\\%$ from reference values. In vivo, inter-subject CoV was 5.2\\% (WM) and 17.7\\% (GM), comparable to 1.5~T. Mean T2 times were 118~ms (WM) and 188~ms (GM) at 0.55~T, with a 16.5-minute acquisition. \\textbf{Conclusion:} A rapid, robust high-resolution T2 mapping protocol at 0.55~T for HASTE MRI is presented, employing Gaussian noise-based fitting. We report the first normative T2 values for healthy adult brains at 0.55~T, demonstrating technical feasibility and reliability.", "published": "2025-10-22T15:25:11Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:53.238836"}
{"arxiv_id": "2510.19604v1", "title": "Unmanned Aerial Vehicles Control in a Digital Twin: Exploring the Effect   of Different Points of View on User Experience in Virtual Reality", "summary": "Controlling Unmanned Aerial Vehicles (UAVs) is a cognitively demanding task, with accidents often arising from insufficient situational awareness, inadequate training, and poor user experiences. Providing more intuitive and immersive visual feedback, particularly through Digital Twin technologies, offers new opportunities to enhance pilot awareness and overall experience quality. In this study, we investigate how different virtual points of view (POVs) influence user experience and performance during UAV piloting in Virtual Reality (VR), utilizing a digital twin that faithfully replicates the real-world flight environment. We developed a VR application that enables participants to control a physical DJI Mini 4 Pro drone while immersed in a digital twin with four distinct camera perspectives: Baseline View (static external), First-Person View, Chase View, and Third-Person View. Nineteen participants completed a series of ring-based obstacle courses from each perspective. In addition to objective flight data, we collected standardized subjective assessments of user experience, presence, workload, cybersickness, and situational awareness. Quantitative analyses revealed that the First-Person View was associated with significantly higher mental demand and effort, greater trajectory deviation, but smoother control inputs compared to the Third-Person and Chase perspectives. Complementing these findings, preference data indicated that the Third-Person View was most consistently favored, whereas the First-Person View elicited polarized reactions.", "published": "2025-10-22T13:56:09Z", "query": "brain stimulation VR", "relevance": 0.35, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.239106"}
{"arxiv_id": "2510.19537v1", "title": "Privacy-Preserving Spiking Neural Networks: A Deep Dive into Encryption   Parameter Optimisation", "summary": "Deep learning is widely applied to modern problems through neural networks, but the growing computational and energy demands of these models have driven interest in more efficient approaches. Spiking Neural Networks (SNNs), the third generation of neural networks, mimic the brain's event-driven behaviour, offering improved performance and reduced power use. At the same time, concerns about data privacy during cloud-based model execution have led to the adoption of cryptographic methods. This article introduces BioEncryptSNN, a spiking neural network based encryption-decryption framework for secure and noise-resilient data protection. Unlike conventional algorithms, BioEncryptSNN converts ciphertext into spike trains and exploits temporal neural dynamics to model encryption and decryption, optimising parameters such as key length, spike timing, and synaptic connectivity. Benchmarked against AES-128, RSA-2048, and DES, BioEncryptSNN preserved data integrity while achieving up to 4.1x faster encryption and decryption than PyCryptodome's AES implementation. The framework demonstrates scalability and adaptability across symmetric and asymmetric ciphers, positioning SNNs as a promising direction for secure, energy-efficient computing.", "published": "2025-10-22T12:43:46Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:53.239327"}
{"arxiv_id": "2510.19498v1", "title": "Energy-Efficient and Dequantization-Free Q-LLMs: A Spiking Neural   Network Approach to Salient Value Mitigation", "summary": "In the era of large language models (LLMs), weight-activation quantization helps fit models on edge device by reducing memory and compute bit-widths. However, three challenges persist for energy constrained hardware: (1) even after quantization, multiply-accumulate (MAC) operations remain unavoidable and continue to dominate energy consumption; (2) dequantization (or per-tensor/channel rescaling) introduces extra arithmetic and data movement, increasing latency and energy; (3) uniform parameters bit widths clip salient values-while intra-channel mixed precision is generally impractical on current matrix hardware and memory. In contrast, brain-inspired Spiking Neural Networks (SNNs), owing to their binary spike-based information representation and the Integrate-and-Fire (IF) paradigm, naturally support mixed-precision storage and energy-efficient computation by replacing complex MACs with temporal Accumulate (ACCs). Motivated by this property, we propose SpikeQuant, which selectively applies mixed-precision quantization to activations with salient values and re-encodes them into binary spike counts, thereby enabling dynamic mixed storage of different bitwidths. Furthermore, by embedding the quantization scale into the threshold of the IF mechanism, our approach performs energy-efficient linear transformations on weights and activations while avoiding explicit dequantization. Experimental results demonstrate that SpikeQuant consistently achieves near-FP16 perplexity under W4A4 quantization while reducing energy cost by up to 4.6 times compared to existing methods, highlighting its effectiveness for accurate and energy-efficient LLM deployment.", "published": "2025-10-22T11:50:00Z", "query": "brain stimulation VR", "relevance": 0.1, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:53.239503"}
{"arxiv_id": "2510.19332v1", "title": "BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP", "summary": "Decoding images from fMRI often involves mapping brain activity to CLIP's final semantic layer. To capture finer visual details, many approaches add a parameter-intensive VAE-based pipeline. However, these approaches overlook rich object information within CLIP's intermediate layers and contradicts the brain's functionally hierarchical. We introduce BrainMCLIP, which pioneers a parameter-efficient, multi-layer fusion approach guided by human visual system's functional hierarchy, eliminating the need for such a separate VAE pathway. BrainMCLIP aligns fMRI signals from functionally distinct visual areas (low-/high-level) to corresponding intermediate and final CLIP layers, respecting functional hierarchy. We further introduce a Cross-Reconstruction strategy and a novel multi-granularity loss. Results show BrainMCLIP achieves highly competitive performance, particularly excelling on high-level semantic metrics where it matches or surpasses SOTA(state-of-the-art) methods, including those using VAE pipelines. Crucially, it achieves this with substantially fewer parameters, demonstrating a reduction of 71.7\\%(Table.\\ref{tab:compare_clip_vae}) compared to top VAE-based SOTA methods, by avoiding the VAE pathway. By leveraging intermediate CLIP features, it effectively captures visual details often missed by CLIP-only approaches, striking a compelling balance between semantic accuracy and detail fidelity without requiring a separate VAE pipeline.", "published": "2025-10-22T07:51:52Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.239740"}
{"arxiv_id": "2510.19282v1", "title": "Enhancing Early Alzheimer Disease Detection through Big Data and   Ensemble Few-Shot Learning", "summary": "Alzheimer disease is a severe brain disorder that causes harm in various brain areas and leads to memory damage. The limited availability of labeled medical data poses a significant challenge for accurate Alzheimer disease detection. There is a critical need for effective methods to improve the accuracy of Alzheimer disease detection, considering the scarcity of labeled data, the complexity of the disease, and the constraints related to data privacy. To address this challenge, our study leverages the power of big data in the form of pre-trained Convolutional Neural Networks (CNNs) within the framework of Few-Shot Learning (FSL) and ensemble learning. We propose an ensemble approach based on a Prototypical Network (ProtoNet), a powerful method in FSL, integrating various pre-trained CNNs as encoders. This integration enhances the richness of features extracted from medical images. Our approach also includes a combination of class-aware loss and entropy loss to ensure a more precise classification of Alzheimer disease progression levels. The effectiveness of our method was evaluated using two datasets, the Kaggle Alzheimer dataset and the ADNI dataset, achieving an accuracy of 99.72% and 99.86%, respectively. The comparison of our results with relevant state-of-the-art studies demonstrated that our approach achieved superior accuracy and highlighted its validity and potential for real-world applications in early Alzheimer disease detection.", "published": "2025-10-22T06:35:03Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:53.239972"}
{"arxiv_id": "2510.19229v1", "title": "Brain-Inspired Perspective on Configurations: Unsupervised Similarity   and Early Cognition", "summary": "Infants discover categories, detect novelty, and adapt to new contexts without supervision -- a challenge for current machine learning. We present a brain-inspired perspective on configurations, a finite-resolution clustering framework that uses a single resolution parameter and attraction-repulsion dynamics to yield hierarchical organization, novelty sensitivity, and flexible adaptation. To evaluate these properties, we introduce mheatmap, which provides proportional heatmaps and a reassignment algorithm to fairly assess multi-resolution and dynamic behavior. Across datasets, configurations are competitive on standard clustering metrics, achieve 87% AUC in novelty detection, and show 35% better stability during dynamic category evolution. These results position configurations as a principled computational model of early cognitive categorization and a step toward brain-inspired AI.", "published": "2025-10-22T04:28:23Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:53.240301"}
{"arxiv_id": "2510.19212v1", "title": "No Intelligence Without Statistics: The Invisible Backbone of Artificial   Intelligence", "summary": "The rapid ascent of artificial intelligence (AI) is often portrayed as a revolution born from computer science and engineering. This narrative, however, obscures a fundamental truth: the theoretical and methodological core of AI is, and has always been, statistical. This paper systematically argues that the field of statistics provides the indispensable foundation for machine learning and modern AI. We deconstruct AI into nine foundational pillars-Inference, Density Estimation, Sequential Learning, Generalization, Representation Learning, Interpretability, Causality, Optimization, and Unification-demonstrating that each is built upon century-old statistical principles. From the inferential frameworks of hypothesis testing and estimation that underpin model evaluation, to the density estimation roots of clustering and generative AI; from the time-series analysis inspiring recurrent networks to the causal models that promise true understanding, we trace an unbroken statistical lineage. While celebrating the computational engines that power modern AI, we contend that statistics provides the brain-the theoretical frameworks, uncertainty quantification, and inferential goals-while computer science provides the brawn-the scalable algorithms and hardware. Recognizing this statistical backbone is not merely an academic exercise, but a necessary step for developing more robust, interpretable, and trustworthy intelligent systems. We issue a call to action for education, research, and practice to re-embrace this statistical foundation. Ignoring these roots risks building a fragile future; embracing them is the path to truly intelligent machines. There is no machine learning without statistical learning; no artificial intelligence without statistical thought.", "published": "2025-10-22T03:47:30Z", "query": "brain stimulation VR", "relevance": 0.25, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:53.240576"}
{"arxiv_id": "2510.19109v1", "title": "Advancing Brain Tumor Segmentation via Attention-based 3D U-Net   Architecture and Digital Image Processing", "summary": "In the realm of medical diagnostics, rapid advancements in Artificial Intelligence (AI) have significantly yielded remarkable improvements in brain tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a transformative role by effectively extracting meaningful representations in 3D brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However, standard U-Net models encounter challenges in accurately delineating tumor regions, especially when dealing with irregular shapes and ambiguous boundaries. Additionally, training robust segmentation models on high-resolution MRI data, such as the BraTS datasets, necessitates high computational resources and often faces challenges associated with class imbalance. This study proposes the integration of the attention mechanism into the 3D U-Net model, enabling the model to capture intricate details and prioritize informative regions during the segmentation process. Additionally, a tumor detection algorithm based on digital image processing techniques is utilized to address the issue of imbalanced training data and mitigate bias. This study aims to enhance the performance of brain tumor segmentation, ultimately improving the reliability of diagnosis. The proposed model is thoroughly evaluated and assessed on the BraTS 2020 dataset using various performance metrics to accomplish this goal. The obtained results indicate that the model outperformed related studies, exhibiting dice of 0.975, specificity of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed model in improving brain tumor segmentation, offering valuable insights for reliable diagnosis in clinical settings.", "published": "2025-10-21T22:11:19Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.240740"}
{"arxiv_id": "2510.19057v1", "title": "Macroscopic EEG Reveals Discriminative Low-Frequency Oscillations in   Plan-to-Grasp Visuomotor Tasks", "summary": "The vision-based grasping brain network integrates visual perception with cognitive and motor processes for visuomotor tasks. While invasive recordings have successfully decoded localized neural activity related to grasp type planning and execution, macroscopic neural activation patterns captured by noninvasive electroencephalography (EEG) remain far less understood. We introduce a novel vision-based grasping platform to investigate grasp-type-specific (precision, power, no-grasp) neural activity across large-scale brain networks using EEG neuroimaging. The platform isolates grasp-specific planning from its associated execution phases in naturalistic visuomotor tasks, where the Filter-Bank Common Spatial Pattern (FBCSP) technique was designed to extract discriminative frequency-specific features within each phase. Support vector machine (SVM) classification discriminated binary (precision vs. power, grasp vs. no-grasp) and multiclass (precision vs. power vs. no-grasp) scenarios for each phase, and were compared against traditional Movement-Related Cortical Potential (MRCP) methods. Low-frequency oscillations (0.5-8 Hz) carry grasp-related information established during planning and maintained throughout execution, with consistent classification performance across both phases (75.3-77.8\\%) for precision vs. power discrimination, compared to 61.1\\% using MRCP. Higher-frequency activity (12-40 Hz) showed phase-dependent results with 93.3\\% accuracy for grasp vs. no-grasp classification but 61.2\\% for precision vs. power discrimination. Feature importance using SVM coefficients identified discriminative features within frontoparietal networks during planning and motor networks during execution. This work demonstrated the role of low-frequency oscillations in decoding grasp type during planning using noninvasive EEG.", "published": "2025-10-21T20:17:33Z", "query": "brain stimulation VR", "relevance": 0.35, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.240897"}
{"arxiv_id": "2510.18812v1", "title": "A Unified Perspective on Optimization in Machine Learning and   Neuroscience: From Gradient Descent to Neural Adaptation", "summary": "Iterative optimization is central to modern artificial intelligence (AI) and provides a crucial framework for understanding adaptive systems. This review provides a unified perspective on this subject, bridging classic theory with neural network training and biological learning. Although gradient-based methods, powered by the efficient but biologically implausible backpropagation (BP), dominate machine learning, their computational demands can hinder scalability in high-dimensional settings. In contrast, derivative-free or zeroth-order (ZO) optimization feature computationally lighter approaches that rely only on function evaluations and randomness. While generally less sample efficient, recent breakthroughs demonstrate that modern ZO methods can effectively approximate gradients and achieve performance competitive with BP in neural network models. This ZO paradigm is also particularly relevant for biology. Its core principles of random exploration (probing) and feedback-guided adaptation (reinforcing) parallel key mechanisms of biological learning, offering a mathematically principled perspective on how the brain learns. In this review, we begin by categorizing optimization approaches based on the order of derivative information they utilize, ranging from first-, second-, and higher-order gradient-based to ZO methods. We then explore how these methods are adapted to the unique challenges of neural network training and the resulting learning dynamics. Finally, we build upon these insights to view biological learning through an optimization lens, arguing that a ZO paradigm leverages the brain's intrinsic noise as a computational resource. This framework not only illuminates our understanding of natural intelligence but also holds vast implications for neuromorphic hardware, helping us design fast and energy-efficient AI systems that exploit intrinsic hardware noise.", "published": "2025-10-21T17:10:15Z", "query": "brain stimulation VR", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.241066"}
{"arxiv_id": "2510.18745v1", "title": "Topoformer: brain-like topographic organization in Transformer language   models through spatial querying and reweighting", "summary": "Spatial functional organization is a hallmark of biological brains: neurons are arranged topographically according to their response properties, at multiple scales. In contrast, representations within most machine learning models lack spatial biases, instead manifesting as disorganized vector spaces that are difficult to visualize and interpret. Here, we propose a novel form of self-attention that turns Transformers into \"Topoformers\" with topographic organization. We introduce spatial querying - where keys and queries are arranged on 2D grids, and local pools of queries are associated with a given key - and spatial reweighting, where we convert the standard fully connected layer of self-attention into a locally connected layer. We first demonstrate the feasibility of our approach by training a 1-layer Topoformer on a sentiment classification task. Training with spatial querying encourages topographic organization in the queries and keys, and spatial reweighting separately encourages topographic organization in the values and self-attention outputs. We then apply the Topoformer motifs at scale, training a BERT architecture with a masked language modeling objective. We find that the topographic variant performs on par with a non-topographic control model on NLP benchmarks, yet produces interpretable topographic organization as evaluated via eight linguistic test suites. Finally, analyzing an fMRI dataset of human brain responses to a large set of naturalistic sentences, we demonstrate alignment between low-dimensional topographic variability in the Topoformer model and human brain language network. Scaling up Topoformers further holds promise for greater interpretability in NLP research, and for more accurate models of the organization of linguistic information in the human brain.", "published": "2025-10-21T15:54:57Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.241212"}
{"arxiv_id": "2510.18644v1", "title": "Impact of Surface Passivation on the Efficiency and High-speed   Modulation of III-V GaAs/AlGaAs Nanopillar Array LEDs", "summary": "III-V semiconductor nanolight sources with deep-subwavelength dimensions ($&lt;&lt;$1 ${\\mu}$m) are essential for miniaturized photonic devices such as nanoLEDs and nanolasers. However, these nanoscale emitters suffer from substantial non-radiative recombination at room temperature, resulting in low efficiency and ultrashort lifetimes ($&lt;$100 ps). Previous works have predominantly studied surface passivation of nanoLEDs under optical pumping conditions, while practical applications require electrically driven nanoLEDs. Here, we investigate the influence of surface passivation on the efficiency and high-speed modulation response of electrically pumped III-V GaAs/AlGaAs nanopillar array LEDs. Surface passivation was performed using ammonium sulphide chemical treatment followed by encapsulation with a 100 nm silicon nitride layer deposited via low-frequency plasma-enhanced chemical vapour deposition. Time-resolved electroluminescence measurements reveal differential carrier lifetimes (${\\tau}$) of ~0.61 ns for nanoarray LEDs with pillar diameters of ~440 nm, a record-long lifetime for electrically driven GaAs-based nanopillar arrays. Under low injection conditions, the devices exhibited carrier lifetimes of ~0.41 ns, indicating successful suppression of non-radiative effects and a low surface velocity, ranging from $S$~0.7$\\times$10$^4$ cm/s to 2.7$\\times$10$^4$ cm/s. This reveals a potential high internal quantum efficiency $IQE$~0.45 for our nanoLEDs operating under very high injection conditions, limited only by Auger recombination and self-heating effects at high current density. These miniaturized nanoLEDs with high radiative recombination efficiency and sub-ns modulation response pave the way for optical data communications, energy efficient optical interconnects, AR/VR displays, and neuromorphic computing applications.", "published": "2025-10-21T13:50:40Z", "query": "brain stimulation VR", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.241373"}
{"arxiv_id": "2510.18640v1", "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "summary": "Performance regressions in large-scale software systems can lead to substantial resource inefficiencies, making their early detection critical. Frequent benchmarking is essential for identifying these regressions and maintaining service-level agreements (SLAs). Performance benchmarks, however, are resource-intensive and time-consuming, which is a major challenge for integration into Continuous Integration / Continuous Deployment (CI/CD) pipelines. Although numerous benchmark optimization techniques have been proposed to accelerate benchmark execution, there is currently no practical system that integrates these optimizations seamlessly into real-world CI/CD pipelines. In this vision paper, we argue that the field of benchmark optimization remains under-explored in key areas that hinder its broader adoption. We identify three central challenges to enabling frequent and efficient benchmarking: (a) the composability of benchmark optimization strategies, (b) automated evaluation of benchmarking results, and (c) the usability and complexity of applying these strategies as part of CI/CD systems in practice. We also introduce a conceptual cloud-based benchmarking framework handling these challenges transparently. By presenting these open problems, we aim to stimulate research toward making performance regression detection in CI/CD systems more practical and effective.", "published": "2025-10-21T13:43:20Z", "query": "brain stimulation VR", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:53.241539"}
{"arxiv_id": "2510.18625v1", "title": "Effects of Virtual Controller Representation and Virtuality on Selection   Performance in Extended Reality", "summary": "We present an experiment exploring how the controller's virtual representation impacts target acquisition performance across MR and VR contexts. Participants performed selection tasks comparing four visual configurations: a virtual controller, a virtual hand, both the controller and the hand, and neither representation. We found performance comparable between VR and MR, and switching between them did not impact the user's ability to perform basic tasks. Controller representations mimicking reality enhanced performance across both modes. However, users perceived performance differently in MR, indicating the need for unique MR design considerations, particularly regarding spatial awareness.", "published": "2025-10-21T13:28:58Z", "query": "brain stimulation VR", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.241646"}
{"arxiv_id": "2510.18570v1", "title": "Electromagnetic Field Exposure Assessment and Mitigation Strategies for   Wireless Power Transfer Systems: A Review and Future Perspectives", "summary": "Wireless power transfer (WPT) technologies are increasingly being applied in fields ranging from consumer electronics and electric vehicles to space-based energy systems and medical implants. While WPT offers contactless power delivery, it introduces electromagnetic field (EMF) emissions, necessitating careful assessment to address safety and public health concerns. Exposure guidelines developed by ICNIRP and IEEE define frequency-dependent limits based on internal quantities, such as electric field strength and specific absorption rate, intended to prevent tissue nerve stimulation &lt; 100 kHz and heating &gt; 100 kHz, respectively. Complementing these guidelines, assessment standards including the International Electrotechnical Commission (IEC)/IEEE 63184 and IEC Technical Report 63377, provide practical procedures for evaluating the EMF exposure in WPT systems. This review offers a comparative overview of major WPT modalities, with a focus on recent developments in computational dosimetry and standardized assessment techniques for the complex, non-uniform fields typical of WPT environments. It also discusses electromagnetic interference with medical devices and exposure scenarios involving partial body proximity and various postures. A notable observation across modalities is the considerable variability, often spanning an order of magnitude, in the allowable transfer power, depending on the field distribution and assessment approach. Remaining challenges include the lack of harmonized guidance for intermediate frequencies and localized exposure, underscoring the importance of further coordination in international standardization efforts. Addressing these issues is essential for the safe and widespread deployment of WPT technologies.", "published": "2025-10-21T12:25:44Z", "query": "brain stimulation VR", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:15:53.241869"}
{"arxiv_id": "2510.18516v1", "title": "Decoding Dynamic Visual Experience from Calcium Imaging via   Cell-Pattern-Aware SSL", "summary": "Self-supervised learning (SSL) holds a great deal of promise for applications in neuroscience, due to the lack of large-scale, consistently labeled neural datasets. However, most neural datasets contain heterogeneous populations that mix stable, predictable cells with highly stochastic, stimulus-contingent ones, which has made it hard to identify consistent activity patterns during SSL. As a result, self-supervised pretraining has yet to show clear signs of benefits from scale on neural data. Here, we present a novel approach to self-supervised pretraining, POYO-SSL that exploits the heterogeneity of neural data to improve pre-training and achieve benefits of scale. Specifically, in POYO-SSL we pretrain only on predictable (statistically regular) neurons-identified on the pretraining split via simple higher-order statistics (skewness and kurtosis)-then we fine-tune on the unpredictable population for downstream tasks. On the Allen Brain Observatory dataset, this strategy yields approximately 12-13% relative gains over from-scratch training and exhibits smooth, monotonic scaling with model size. In contrast, existing state-of-the-art baselines plateau or destabilize as model size increases. By making predictability an explicit metric for crafting the data diet, POYO-SSL turns heterogeneity from a liability into an asset, providing a robust, biologically grounded recipe for scalable neural decoding and a path toward foundation models of neural dynamics.", "published": "2025-10-21T10:57:52Z", "query": "brain stimulation VR", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:53.242037"}
{"arxiv_id": "2510.18492v1", "title": "Electromagnetic characteristics as probes into the inner structures of   the predicted $\u039e_c^{(',*)}D^{(*)}_s$ molecular states", "summary": "In this work, we conduct a systematic investigation of the electromagnetic properties, specifically the magnetic moments and the M1 radiative decay behavior, of the predicted $\\Xi_c^{(',*)}D^{(*)}_s$-type double-charm hidden-strangeness molecular pentaquarks. The study is carried out within the framework of the constituent quark model to evaluate these electromagnetic observables, and our analysis incorporates three distinct scenarios: single-channel analysis, $S$-$D$ wave mixing analysis, and coupled-channel analysis. The calculated magnetic moments reveal characteristic patterns that reflect their underlying constituent configurations and provide sensitive probes for their quantum number assignments. Furthermore, we identify several M1 radiative decay channels with sizable widths that may offer promising signatures for future experimental detection. These M1 transitions also act as sensitive probes into their inner structures, displaying distinctive features that help differentiate between their constituent configurations and quantum number assignments. We anticipate that this study will stimulate experimental interest in exploring the electromagnetic properties of the $\\Xi_c^{(',*)}D^{(*)}_s$ molecular states, thereby advancing our structural understanding of these exotic hadronic states.", "published": "2025-10-21T10:30:12Z", "query": "brain stimulation VR", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:53.242268"}
{"arxiv_id": "2510.18396v1", "title": "Entropy-Enhanced Conformal Features from Ricci Flow for Robust   Alzheimer's Disease Classification", "summary": "Background and Objective: In brain imaging, geometric surface models are essential for analyzing the 3D shapes of anatomical structures. Alzheimer's disease (AD) is associated with significant cortical atrophy, making such shape analysis a valuable diagnostic tool. The objective of this study is to introduce and validate a novel local surface representation method for the automated and accurate diagnosis of AD. Methods: The study utilizes T1-weighted MRI scans from 160 participants (80 AD patients and 80 healthy controls) from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Cortical surface models were reconstructed from the MRI data using Freesurfer. Key geometric attributes were computed from the 3D meshes. Area distortion and conformal factor were derived using Ricci flow for conformal parameterization, while Gaussian curvature was calculated directly from the mesh geometry. Shannon entropy was applied to these three features to create compact and informative feature vectors. The feature vectors were used to train and evaluate a suite of classifiers (e.g. XGBoost, MLP, Logistic Regression, etc.). Results: Statistical significance of performance differences between classifiers was evaluated using paired Welch's t-test. The method proved highly effective in distinguishing AD patients from healthy controls. The Multi-Layer Perceptron (MLP) and Logistic Regression classifiers outperformed all others, achieving an accuracy and F$_1$ Score of 98.62%. Conclusions: This study confirms that the entropy of conformally-derived geometric features provides a powerful and robust metric for cortical morphometry. The high classification accuracy underscores the method's potential to enhance the study and diagnosis of Alzheimer's disease, offering a straightforward yet powerful tool for clinical research applications.", "published": "2025-10-21T08:16:45Z", "query": "brain stimulation VR", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:53.242515"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:56.733409"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:56.733871"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.734217"}
{"arxiv_id": "2510.20792v1", "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for   Text-Guided Graph Generation", "summary": "The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method targeting latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.", "published": "2025-10-23T17:54:17Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.734402"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.734585"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural implants", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:56.734706"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.734907"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.735043"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:56.735212"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.735371"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.735573"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "neural implants", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:56.735719"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "neural implants", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:56.735903"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.736042"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:56.736221"}
{"arxiv_id": "2510.20690v1", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "summary": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. Inspired by portfolio theory, where uncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination probability is bounded by representational correlation: $P(H) \\leq f(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language models need an optimal amount of neurodiversity. To validate this, we introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces hallucinations by up to 25.6% (and 14.6% on average) without degrading general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational analyses indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different amounts of optimal neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.", "published": "2025-10-23T16:03:07Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.736384"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "neural implants", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:15:56.736530"}
{"arxiv_id": "2510.20677v1", "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice   Conversion", "summary": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.", "published": "2025-10-23T15:52:03Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:15:56.736684"}
{"arxiv_id": "2510.20673v1", "title": "Efficient Multi-bit Quantization Network Training via Weight Bias   Correction and Bit-wise Coreset Sampling", "summary": "Multi-bit quantization networks enable flexible deployment of deep neural networks by supporting multiple precision levels within a single model. However, existing approaches suffer from significant training overhead as full-dataset updates are repeated for each supported bit-width, resulting in a cost that scales linearly with the number of precisions. Additionally, extra fine-tuning stages are often required to support additional or intermediate precision options, further compounding the overall training burden. To address this issue, we propose two techniques that greatly reduce the training overhead without compromising model utility: (i) Weight bias correction enables shared batch normalization and eliminates the need for fine-tuning by neutralizing quantization-induced bias across bit-widths and aligning activation distributions; and (ii) Bit-wise coreset sampling strategy allows each child model to train on a compact, informative subset selected via gradient-based importance scores by exploiting the implicit knowledge transfer phenomenon. Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and ViT architectures demonstrate that our method achieves competitive or superior accuracy while reducing training time up to 7.88x. Our code is released at https://github.com/a2jinhee/EMQNet_jk.", "published": "2025-10-23T15:49:02Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.736845"}
{"arxiv_id": "2510.20671v1", "title": "GRACE: GRaph-based Addiction Care prEdiction", "summary": "Determining the appropriate locus of care for addiction patients is one of the most critical clinical decisions that affects patient treatment outcomes and effective use of resources. With a lack of sufficient specialized treatment resources, such as inpatient beds or staff, there is an unmet need to develop an automated framework for the same. Current decision-making approaches suffer from severe class imbalances in addiction datasets. To address this limitation, we propose a novel graph neural network (GRACE) framework that formalizes locus of care prediction as a structured learning problem. Further, we perform extensive feature engineering and propose a new approach of obtaining an unbiased meta-graph to train a GNN to overcome the class imbalance problem. Experimental results in real-world data show an improvement of 11-35% in terms of the F1 score of the minority class over competitive baselines. The codes and note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.", "published": "2025-10-23T15:48:01Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.736979"}
{"arxiv_id": "2510.20669v1", "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing   Maps and Spiking Dynamics for Waste Classification", "summary": "Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.", "published": "2025-10-23T15:47:09Z", "query": "neural implants", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:15:56.737140"}
{"arxiv_id": "2510.20666v1", "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of   Experts", "summary": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming, particularly in urban areas where multipath and shadowing distort received power. Previous data-driven approaches achieved reasonable localization but poorly reconstructed the received signal strength (RSS) field due to limited spatial context. We propose a hybrid Bayesian mixture-of-experts framework that fuses a physical path-loss (PL) model and a convolutional neural network (CNN) through log-linear pooling. The PL expert ensures physical consistency, while the CNN leverages building-height maps to capture urban propagation effects. Bayesian inference with Laplace approximation provides posterior uncertainty over both the jammer position and RSS field. Experiments on urban ray-tracing data show that localization accuracy improves and uncertainty decreases with more training points, while uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive.", "published": "2025-10-23T15:45:45Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.737278"}
{"arxiv_id": "2510.20659v1", "title": "Kinetics of Peierls dimerization transition: Machine learning   force-field approach", "summary": "We present a machine learning (ML) force-field framework for simulating the non-equilibrium dynamics of charge-density-wave (CDW) order driven by the Peierls instability. Since the Peierls distortion arises from the coupling between lattice displacements and itinerant electrons, evaluating the adiabatic forces during time evolution is computationally intensive, particularly for large systems. To overcome this bottleneck, we develop a generalized Behler-Parrinello neural-network architecture -- originally formulated for ab initio molecular dynamics -- to accurately and efficiently predict forces from local structural environments. Using the locality of electronic responses, the resulting ML force field achieves linear scaling efficiency while maintaining quantitative accuracy. Large-scale dynamical simulations using this framework uncover a two-stage coarsening behavior of CDW domains: an early-time regime characterized by a power-law growth $L \\sim t^{\\alpha}$ with an effective exponent $\\alpha \\approx 0.7$, followed by a crossover to the Allen-Cahn scaling $L \\sim \\sqrt{t}$ at late times. The enhanced early-time coarsening is attributed to anisotropic domain-wall motion arising from electron-mediated directional interactions. This work demonstrates the promise of ML-based force fields for multiscale dynamical modeling of condensed-matter lattice models.", "published": "2025-10-23T15:33:31Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.737440"}
{"arxiv_id": "2510.20653v1", "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During   Inference-Time LLM Reflection", "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.", "published": "2025-10-23T15:26:18Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:15:56.737674"}
{"arxiv_id": "2510.20644v1", "title": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound   for Representation Learning", "summary": "Mutual Information (MI) is a fundamental measure of statistical dependence widely used in representation learning. While direct optimization of MI via its definition as a Kullback-Leibler divergence (KLD) is often intractable, many recent methods have instead maximized alternative dependence measures, most notably, the Jensen-Shannon divergence (JSD) between joint and product of marginal distributions via discriminative losses. However, the connection between these surrogate objectives and MI remains poorly understood. In this work, we bridge this gap by deriving a new, tight, and tractable lower bound on KLD as a function of JSD in the general case. By specializing this bound to joint and marginal distributions, we demonstrate that maximizing the JSD-based information increases a guaranteed lower bound on mutual information. Furthermore, we revisit the practical implementation of JSD-based objectives and observe that minimizing the cross-entropy loss of a binary classifier trained to distinguish joint from marginal pairs recovers a known variational lower bound on the JSD. Extensive experiments demonstrate that our lower bound is tight when applied to MI estimation. We compared our lower bound to state-of-the-art neural estimators of variational lower bound across a range of established reference scenarios. Our lower bound estimator consistently provides a stable, low-variance estimate of a tight lower bound on MI. We also demonstrate its practical usefulness in the context of the Information Bottleneck framework. Taken together, our results provide new theoretical justifications and strong empirical evidence for using discriminative learning in MI-based representation learning.", "published": "2025-10-23T15:18:12Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.737865"}
{"arxiv_id": "2510.20611v1", "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast   Cancer Detection", "summary": "Breast cancer is considered the most critical and frequently diagnosed cancer in women worldwide, leading to an increase in cancer-related mortality. Early and accurate detection is crucial as it can help mitigate possible threats while improving survival rates. In terms of prediction, conventional diagnostic methods are often limited by variability, cost, and, most importantly, risk of misdiagnosis. To address these challenges, machine learning (ML) has emerged as a powerful tool for computer-aided diagnosis, with feature selection playing a vital role in improving model performance and interpretability. This research study proposes an integrated framework that incorporates customized Particle Swarm Optimization (PSO) for feature selection. This framework has been evaluated on a comprehensive set of 29 different models, spanning classical classifiers, ensemble techniques, neural networks, probabilistic algorithms, and instance-based algorithms. To ensure interpretability and clinical relevance, the study uses cross-validation in conjunction with explainable AI methods. Experimental evaluation showed that the proposed approach achieved a superior score of 99.1\\% across all performance metrics, including accuracy and precision, while effectively reducing dimensionality and providing transparent, model-agnostic explanations. The results highlight the potential of combining swarm intelligence with explainable ML for robust, trustworthy, and clinically meaningful breast cancer diagnosis.", "published": "2025-10-23T14:42:50Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.738043"}
{"arxiv_id": "2510.20591v1", "title": "Transferable Graph Learning for Transmission Congestion Management via   Busbar Splitting", "summary": "Network topology optimization (NTO) via busbar splitting can mitigate transmission grid congestion and reduce redispatch costs. However, solving this mixed-integer non-linear problem for large-scale systems in near-real-time is currently intractable with existing solvers. Machine learning (ML) approaches have emerged as a promising alternative, but they have limited generalization to unseen topologies, varying operating conditions, and different systems, which limits their practical applicability. This paper formulates NTO for congestion management problem considering linearized AC PF, and proposes a graph neural network (GNN)-accelerated approach. We develop a heterogeneous edge-aware message passing NN to predict effective busbar splitting actions as candidate NTO solutions. The proposed GNN captures local flow patterns, achieves generalization to unseen topology changes, and improves transferability across systems. Case studies show up to 4 orders-of-magnitude speed-up, delivering AC-feasible solutions within one minute and a 2.3% optimality gap on the GOC 2000-bus system. These results demonstrate a significant step toward near-real-time NTO for large-scale systems with topology and cross-system generalization.", "published": "2025-10-23T14:16:23Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.738200"}
{"arxiv_id": "2510.20575v1", "title": "Local Density of States as a Probe of Multifractality in Quasiperiodic   Moir\u00e9 Materials", "summary": "Quasiperiodic moir\\'e materials provide a new platform for realizing critical electronic states, yet a direct and experimentally practical method to characterize this criticality has been lacking. We show that a multifractal analysis of the local density of states (LDOS), accessible via scanning tunneling microscopy, offers an unambiguous signature of criticality from a single experimental sample. Applying this approach to a one-dimensional quasiperiodic model, a stringent test case due to its fractal energy spectrum, we find a clear distinction between the broad singularity spectra $f\\left(\\alpha\\right)$ of critical states and the point-like spectra of extended states. We further demonstrate that these multifractal signatures remain robust over a wide range of energy broadenings relevant to experiments. Our results establish a model-independent, experimentally feasible framework for identifying and probing multifractality in the growing family of quasiperiodic and moir\\'e materials.", "published": "2025-10-23T14:00:49Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:15:56.738347"}
{"arxiv_id": "2510.20558v1", "title": "From Far and Near: Perceptual Evaluation of Crowd Representations Across   Levels of Detail", "summary": "In this paper, we investigate how users perceive the visual quality of crowd character representations at different levels of detail (LoD) and viewing distances. Each representation: geometric meshes, image-based impostors, Neural Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between visual fidelity and computational performance. Our qualitative and quantitative results provide insights to guide the design of perceptually optimized LoD strategies for crowd rendering.", "published": "2025-10-23T13:39:18Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:56.738428"}
{"arxiv_id": "2510.20556v1", "title": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph   Metrics", "summary": "Graph rewiring has emerged as a key technique to alleviate over-squashing in Graph Neural Networks (GNNs) and Graph Transformers by modifying the graph topology to improve information flow. While effective, rewiring inherently alters the graph's structure, raising the risk of distorting important topology-dependent signals. Yet, despite the growing use of rewiring, little is known about which structural properties must be preserved to ensure both performance gains and structural fidelity. In this work, we provide the first systematic analysis of how rewiring affects a range of graph structural metrics, and how these changes relate to downstream task performance. We study seven diverse rewiring strategies and correlate changes in local and global graph properties with node classification accuracy. Our results reveal a consistent pattern: successful rewiring methods tend to preserve local structure while allowing for flexibility in global connectivity. These findings offer new insights into the design of effective rewiring strategies, bridging the gap between graph theory and practical GNN optimization.", "published": "2025-10-23T13:38:41Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:15:56.738535"}
{"arxiv_id": "2510.20729v1", "title": "Nanoscale Mapping of Transition Metal Ordering in Individual   LiNi0.5Mn1.5O4 Particles Using 4D-STEM ACOM Technique", "summary": "The electrochemical performance of the spinel LiNi0.5Mn1.5O4, a high-voltage positive electrode material for Li-ion batteries, is influenced by the transition metal arrangement in the octahedral network, leading to disordered (Fd m S.G.) and ordered3 (P4332 S.G.) structures. However, widely used techniques lack the spatial resolution necessary to elucidate the ordering phenomenon at the particle scale. Using the 4D-STEM technique, we present the first direct observation of ordering distribution in individual LiNi0.5Mn1.5O4 particles with nanometric spatial resolution. We propose a quantification method for the local degree of ordering based on the ratio of ordered to disordered spinel lattices along the particle thickness extracted from electron diffraction spot intensities. In an ordered spinel LiNi0.5Mn1.5O4, the transition metal ordering is consistently observed throughout the primary particle. However, the extent of ordering in the spinel phase depends on its distribution at the particle scale, a factor influenced by the annealing conditions. The 4D-STEM analysis elucidates the boundary between highly-ordered and low-ordered LiNi0.5Mn1.5O4 particles.", "published": "2025-10-23T16:45:54Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.212691"}
{"arxiv_id": "2510.19983v1", "title": "A transmon qubit realized by exploiting the superconductor-insulator   transition", "summary": "Superconducting qubits are among the most promising platforms for realizing practical quantum computers. One requirement to create a quantum processor is nonlinearity, which in superconducting circuits is typically achieved by sandwiching a layer of aluminum oxide between two aluminum electrodes to form a Josephson junction. These junctions, however, face several limitations that hinder their scalability: the small superconducting gap of aluminum necessitates millikelvin operating temperatures, the material interfaces lead to dissipation, and the sandwich geometry adds unwelcome capacitance for high-frequency applications. In this work, we address all three limitations using a novel superconducting weak link based on the superconductor-insulator transition. By locally thinning a single film of niobium nitride, we exploit its thickness-driven superconductor-insulator transition to form a weak link employing only atomic layer deposition and atomic layer etching. We utilize our weak links to produce a transmon qubit, '$planaron$', with a measured anharmonicity of $\\alpha/2\\pi = 235$ MHz; at present, the linewidth is $\\kappa/2\\pi = 15 \\mathrm{\\: MHz}$. The high superconducting gap of niobium nitride can enable operation at elevated temperatures in future devices, and the fully planar geometry of the weak link eliminates superfluous material interfaces and capacitances. The investigation of small patches of material near the SIT can shed new light on the nature of the transition, including the role of dissipation and finite-size effects.", "published": "2025-10-22T19:29:01Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.213345"}
{"arxiv_id": "2510.19174v1", "title": "Auditory Attention Decoding from Ear-EEG Signals: A Dataset with Dynamic   Attention Switching and Rigorous Cross-Validation", "summary": "Recent promising results in auditory attention decoding (AAD) using scalp electroencephalography (EEG) have motivated the exploration of cEEGrid, a flexible and portable ear-EEG system. While prior cEEGrid-based studies have confirmed the feasibility of AAD, they often neglect the dynamic nature of attentional states in real-world contexts. To address this gap, a novel cEEGrid dataset featuring three concurrent speakers distributed across three of five distinct spatial locations is introduced. The novel dataset is designed to probe attentional tracking and switching in realistic scenarios. Nested leave-one-out validation-an approach more rigorous than conventional single-loop leave-one-out validation-is employed to reduce biases stemming from EEG's intricate temporal dynamics. Four rule-based models are evaluated: Wiener filter (WF), canonical component analysis (CCA), common spatial pattern (CSP) and Riemannian Geometry-based classifier (RGC). With a 30-second decision window, WF and CCA models achieve decoding accuracies of 41.5% and 41.4%, respectively, while CSP and RGC models yield 37.8% and 37.6% accuracies using a 10-second window. Notably, both WF and CCA successfully track attentional state switches across all experimental tasks. Additionally, higher decoding accuracies are observed for electrodes positioned at the upper cEEGrid layout and near the listener's right ear. These findings underscore the utility of dynamic, ecologically valid paradigms and rigorous validation in advancing AAD research with cEEGrid.", "published": "2025-10-22T02:20:08Z", "query": "intracortical electrodes", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:00.213648"}
{"arxiv_id": "2510.19106v1", "title": "Ab Initio Free Energy Surfaces for Coupled Ion-Electron Transfer", "summary": "The Marcus theory of electron transfer assumes that diabatic energy gaps are sampled from a single ensemble. This assumption can break down in spatially anisotropic environments, such as electrochemical interfaces or biomolecular structures, where distinct solvent ensembles arise along a collective variable describing the anisotropy. Treating this collective variable as an additional reaction coordinate linearly independent from the Marcus reaction coordinate, we develop a formalism that enables calculation of the resulting Coupled Ion-Electron Transfer (CIET) free-energy surface directly from constrained ab initio trajectories. Applied to CO2 redox on a gold electrode, this method reveals strong coupling to the anisotropy, predicting significantly different activation barriers compared to either coordinate alone.", "published": "2025-10-21T21:59:44Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.213830"}
{"arxiv_id": "2510.18389v1", "title": "Technomolecular Materials: 3D Printed 2D Nanosheets with Self Patterned   Electrodes", "summary": "Building on our prior work, where our team transcended self assembled molecular monolayers (SAMs) research from a 2D configuration to 3D structured materials and successfully introduced the molecular self assembled 3D printer to fabricate technomolecular materials hybrid carbon metal nanosheets that mimic biological self assembly through cooperative organic inorganic interactions these materials promise advances in nanotechnology by enabling seamless integration of molecular systems with metallic electrodes. Here we show that electron beam irradiation induces direct self patterning of silver fractal nanoelectrodes on the technomolecular nanosheets, with formation influenced by molecular structure: saturated variants yield localized nanoparticles, while conjugated ones produce propagated fractals via electron delocalization and cross linking. In situ transmission electron microscopy reveals dynamic diffusion aggregation mechanisms, allowing controlled circuit patterns through resist free electron beam lithography. This approach advances flexible electronics, bioelectronics, and energy conversion, including fractal antennas and unclonable identifiers.", "published": "2025-10-21T08:09:15Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.214000"}
{"arxiv_id": "2510.18384v1", "title": "Diagnostics of a Multicusp-Assisted Inductively-Coupled Radio-Frequency   Plasma Source for Plasma Immersion Ion Implantation", "summary": "In this article, we present a detailed characterisation of a multicusp-assisted inductively coupled RF plasma source for plasma immersion ion implantation (PIII). Using laser-induced fluorescence (LIF) and RF-compensated Langmuir probe diagnostics, we measured ion temperature T i and drift velocity v z in argon plasmas near an immersed electrode. The multicusp configuration enhances plasma density at low pressure, enabling stable operation down to 0.8 mTorr. Timeaveraged measurements show no detectable perturbation near the pulsed electrode, indicating full plasma recovery between high-voltage pulses. LIF-derived potential profiles match Riemann's presheath theory, and ion velocity distributions reveal acceleration consistent with sheath dynamics. These results support the use of LIF for steady-state characterisation of the bulk and presheath regions in PIII systems.", "published": "2025-10-21T08:03:30Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.214143"}
{"arxiv_id": "2510.18275v1", "title": "Spin gaps in Transition Metal Dichalcogenide Nanoribbons with atomic   Adsorbates", "summary": "Edge-functionalized Transition Metal dichalcogenide nanoribbons of the zigzag type (zTMDCNRs) are explored in terms of their spin transmission properties. Specifically, systems of the type 5-zWXYNR + nA (X, Y = S, Se; n = 0, 1, 2; A = H, B, C, N, O), involving five rows of a zWXY unit, are investigated as transmission elements between semi-infinite electrodes, to identify atomic adsorbates and adsorption conditions for maximizing the spin polarization of current traversing the ribbons. Janus counterparts of these units, asymmetric structures comprising a transition metal layer sandwiched by two different chalcogen layers, are included in this study. In all cases considered, density functional theory (DFT) modeling, involving the hybrid Heyd-Scuseria-Ernzerhof (HSE) exchange-correlation functional, is combined with the non-equilibrium Green's function (NEGF) approach to determine both spin and charge transport properties. The effect of the selected atomic absorbates on the geometric, electronic, and magnetic properties of 5-zWXYNR (X, Y = S, Se) is evaluated. A protocol to assess the spin-filtering capacity of 5-zWXYNR + nad as a function of the nature and the density of atomic adsorbates, is formulated in terms of band structure analysis of the respective electrode units. Spin gaps emerging close to the Fermi energy of the electrode are shown to provide an effective predictor for the degree of current spin polarization achieved by any of the transmission systems studied here. For any adsorbate configuration considered, ferromagnetic (FM) as well as antiferromagnetic (AFM) ordering is examined, and the impact of the magnetic phase on the spin transport properties is discussed. A spin-selective negative differential resistance effect is identified for specific nanoribbon systems.", "published": "2025-10-21T03:55:45Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.214342"}
{"arxiv_id": "2510.17672v1", "title": "Broad-Range Tuning of Ferroelectric Switching of LaxBi1-xFeO3 Epitaxial   Films via Digital Doping using Off-Axis Co-Sputtering", "summary": "To investigate the scope of ferroelectric behavior in La-substituted BiFeO3 films, LaxBi1-xFeO3 epitaxial films were synthesized using off-axis co-sputtering on SrTiO3(001) and DyScO3(110) substrates with a SrRuO3 bottom electrode layer. A digital-doping deposition method was used to enable precise control and continuous tuning of La concentration in high-quality LaxBi1-xFeO3 films across a wide range of x = 0.05-0.60, which was systematically investigated using piezoresponse force microscopy. Robust and reversible out-of-plane ferroelectric switching has been observed up to x = 0.35, while films with x $\\geq$ 0.37 exhibit no measurable ferroelectric behavior, indicating a sharp ferroelectric-to-paraelectric phase transition between x = 0.35 and 0.37. This represents the highest reported La concentration in LaxBi1-xFeO3 films that retains ferroelectric ordering, highlighting opportunities to engineer ferroelectric and multiferroic properties in complex oxide heterostructures.", "published": "2025-10-20T15:44:39Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.214527"}
{"arxiv_id": "2510.17379v1", "title": "Interplay of spin orbit interaction and Andreev reflection in proximized   quantum dots", "summary": "We investigate a hybrid device, consisting of two quantum dots proximized by a BCS superconductor and coupled to two external normal electrodes. Assuming charge tunneling between quantum dots through the spin-flip processes, we study the molecular Andreev bound states appearing in the proximized quantum dots. We show that the spin-orbit coupling induces four quasiparticle states. For the appropriate set of model parameters, two of these internal quasiparticles merge, forming the zero-energy state. Under such circumstances, we obtain fully spin-polarized versions of the Majorana quasiparticles, localized on different quantum dots. This situation occurs solely when the spin-orbit interaction is equally strong to the magnitude of crossed Andreev reflections, i.e. in the sweet spot. Otherwise, these processes are competitive, as indicated in expectation values of the corresponding order parameters. We analyze signatures of such competition manifested under the nonequilibrium conditions, for various configurations of bias voltage. In particular, for the symmetric bias voltage between the normal electrodes and the Cooper pair splitter bias configuration we reveal duality in the transport properties. Charge transport through the zero-energy state at the sweet spot is contributed by perfectly entangled electrons with an (almost) ideal transmission. Transport studies would thus enable empirical detection of the molecular quasiparticle states and the efficiency of dissipation processes caused by the external normal electrodes.", "published": "2025-10-20T10:16:54Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.214749"}
{"arxiv_id": "2510.16548v1", "title": "NeurIPT: Foundation Model for Neural Interfaces", "summary": "Electroencephalography (EEG) has wide-ranging applications, from clinical diagnosis to brain-computer interfaces (BCIs). With the increasing volume and variety of EEG data, there has been growing interest in establishing foundation models (FMs) to scale up and generalize neural decoding. Despite showing early potential, applying FMs to EEG remains challenging due to substantial inter-subject, inter-task, and inter-condition variability, as well as diverse electrode configurations across recording setups. To tackle these open challenges, we propose NeurIPT, a foundation model developed for diverse EEG-based Neural Interfaces with a Pre-trained Transformer by capturing both homogeneous and heterogeneous spatio-temporal characteristics inherent in EEG signals. Temporally, we introduce Amplitude-Aware Masked Pretraining (AAMP), masking based on signal amplitude rather than random intervals, to learn robust representations across varying signal intensities beyond local interpolation. Moreover, this temporal representation is enhanced by a Progressive Mixture-of-Experts (PMoE) architecture, where specialized expert subnetworks are progressively introduced at deeper layers, adapting effectively to the diverse temporal characteristics of EEG signals. Spatially, NeurIPT leverages the 3D physical coordinates of electrodes, enabling effective transfer of embedding across varying EEG settings, and develops Intra-Inter Lobe Pooling (IILP) during fine-tuning to efficiently exploit regional brain features. Empirical evaluations across eight downstream BCI datasets, via fine-tuning, demonstrated NeurIPT consistently achieved state-of-the-art performance, highlighting its broad applicability and robust generalization. Our work pushes forward the state of FMs in EEG and offers insights into scalable and generalizable neural information processing systems.", "published": "2025-10-18T15:45:00Z", "query": "intracortical electrodes", "relevance": 1.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:00.214933"}
{"arxiv_id": "2510.15737v1", "title": "Integration of Porous Graphene and 3D-printed Piezopolymer for Flexible   Ultrasound Transducers", "summary": "Ultrasound technology is crucial in diagnostic imaging, making it widely used in medical applications. However, traditional ultrasound transducers face limitations in flexibility and ease of fabrication, leading to the exploration of thin-film and flexible piezoelectric materials. Here, we present a novel approach that combines laser graphitization with 3D printing to integrate flexible laser-induced porous graphene (LIG) with poly(vinylidene fluoride-trifluoroethylene) (PVDF-TrFE), resulting in the development of flexible LIG/PVDF-TrFE ultrasound patches. The thickness of PVDF-TrFE is adjusted to tune the central frequency of the ultrasound transducer, allowing customization within a range of 10 to 28 MHz. LIG-based ultrasound transducer demonstrates a high signal amplitude of 6.72 V and a signal-to-noise ratio (SNR) of 433, along with a -6 dB bandwidth of 8.86 MHz (37%). The LIG-based transducer exhibits higher acoustic performance compared to the smooth silver-based transducer. A high-quality two-dimensional ultrasound image, including a B-mode image of a cyst phantom, demonstrates the transducer's imaging capabilities. The patterning of LIG-based electrodes facilitates the desired sensor configuration, demonstrating the suitability of our novel technique for producing flexible transducer arrays without dicing and cutting. The materials cost of our LIG/PVDF-TrFE transducer is under $5 per unit, making it a low-cost solution for ultrasound patches.", "published": "2025-10-17T15:28:28Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:00.215114"}
{"arxiv_id": "2510.15637v1", "title": "Genesis of Horizontal Membrane Electric Field by Bilayer-Embedded   Electrodes", "summary": "For over a century, the electric field of biological membranes has been treated as a one-dimensional entity, defined exclusively by the voltage across its thickness (V_VERT). Here, we challenge this conventional view by developing a device that can apply a horizontal membrane voltage (V_HORZ) across a synthetic lipid bilayer. The device consists of electrodes embedded between bilayer leaflets, allowing the steady application of V_HORZ. Applied V_HORZ selectively and reversibly accelerated the slow inactivation of a voltage-gated potassium channel. Physical considerations revealed that V_HORZ is generated from spatially inhomogeneous V_VERT in cell membranes, thus occurring ubiquitously in membrane physiological functions, such as at the action-potential wave front. Our V_HORZ system enables the generation of three-dimensional membrane electric fields, mimicking hitherto overlooked physiological membrane electric activities.", "published": "2025-10-17T13:25:21Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.215294"}
{"arxiv_id": "2510.14923v2", "title": "Finite element methods for electroneutral multicomponent electrolyte   flows", "summary": "We present a broad family of high-order finite element algorithms for simulating the flow of electroneutral electrolytes. The governing partial differential equations that we solve are the electroneutral Navier-Stokes-Onsager-Stefan-Maxwell (NSOSM) equations, which model momentum transport, multicomponent diffusion and electrical effects within the electrolyte. Our algorithms can be applied in the steady and transient settings, in two and three spatial dimensions, and under a variety of boundary conditions. Moreover, we allow for the material parameters (e.g. viscosity, diffusivities, thermodynamic factors and density) to be solution-dependent and thermodynamically non-ideal. The flexibility of our approach requires us to address subtleties that arise in the governing equations due to the interplay between boundary conditions and the equation of state. We demonstrate the algorithms in various physical configurations, including (i) electrolyte flow around a microfluidic rotating disk electrode and (ii) the flow in a Hull cell of a cosolvent electrolyte mixture used in lithium-ion batteries.", "published": "2025-10-16T17:40:04Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.215485"}
{"arxiv_id": "2510.14091v1", "title": "Low-Power Temperature Control by Chiral Ferroelectric Nematic Liquid   Crystal Windows", "summary": "Low power consumption is critical for smart windows for temperature control and privacy. The recently discovered ferroelectric nematic liquid crystals exhibit strong coupling of the ferroelectric polarization with electric fields, making them promising candidates for energy-efficient electrochromic devices. Here we investigate the electrochromic properties of a room temperature chiral ferroelectric nematic liquid crystal in films with in-plane electrodes, where the electric field is perpendicular to the helical axis. We demonstrate that smart windows based on this material can regulate interior temperatures within a 10 Celsius range using only 50 milliwatt per square meter specific power, achieving fifty percent larger temperature modulation and 50-100 times lower power consumption than polymer dispersed and polymer stabilized liquid crystal windows. These findings suggest that chiral ferroelectric nematic liquid crystals offer a highly efficient approach for smart window applications, potentially surpassing existing electrochromic technologies in energy efficiency and thermal regulation.", "published": "2025-10-15T20:59:34Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:00.215660"}
{"arxiv_id": "2510.13608v1", "title": "Electronic-Photonic Interface for Multiuser Optical Wireless   Communication", "summary": "We demonstrate an electronic-photonic (EP) interface for multiuser optical wireless communication (OWC), consisting of a multibeam optical phased array (MBOPA) along with co-integrated electro-optic (EO) modulators and high-speed CMOS drivers. The MBOPA leverages a path-length difference in the optical phased array (OPA) along with wavelength-division multiplexing technology for spatial carrier aggregation and multiplexing. To generate two and four pulsed amplitude modulation signals, and transmit them to multiple users, we employ an optical digital-to-analog converter technique by using two traveling-wave electrode Mach-Zehnder modulators, which are monolithically integrated with high-speed, wide-output-swing CMOS drivers. The MBOPA and monolithic EO modulator are implemented by silica wafer through planar lightwave circuit fabrication process and a 45-nm monolithic silicon photonics technology, respectively. We measured and analyzed two-channel parallel communication at a data rate of 54 Gbps per user over the wireless distance of 1 m. To the best of our knowledge, this is the first system level demonstration of the multi-user OWC using the in-house-designed photonic and monolithically integrated chips. Finally, we suggest best modulation format for different data rate and the number of multibeams, considering effects of the proposed OPA and the monolithic modulator.", "published": "2025-10-15T14:39:00Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:00.215822"}
{"arxiv_id": "2510.13304v1", "title": "Evaluation of 3D pixel silicon sensors for the CMS Phase-2 Inner Tracker", "summary": "The high-luminosity upgrade of the CERN LHC requires the replacement of the CMS tracking detector to cope with the increased radiation fluence while maintaining its excellent performance. An extensive R\\&amp;D program, aiming at using 3D pixel silicon sensors in the innermost barrel layer of the detector, has been carried out by CMS in collaboration with the FBK (Trento, Italy) and CNM (Barcelona, Spain) foundries. The sensors will feature a pixel cell size of \\mbox{$25\\times100~\\mu m^2$}, with a centrally located electrode connected to the readout chip. The sensors are read out by the RD53A and CROCv1 chips, developed in 65~nm CMOS technology by the RD53 Collaboration, a joint effort between the ATLAS and CMS groups. This paper reports the results achieved in beam test experiments before and after irradiation, up to a fluence of approximately \\mbox{\\SI{2.6e16}{n_{eq}/\\cm^{2}}}. Measurements of assemblies irradiated to a fluence of \\mbox{\\SI{1e16}{n_{eq}/\\cm^{2}}} show a hit detection efficiency higher than 96\\% at normal incidence, with fewer than 2\\% of channels masked, across a bias voltage range greater than \\SI{50}{V}. Even after irradiation to a higher fluence of \\mbox{\\SI{1.6e16}{n_{eq}/\\cm^{2}}}, similar performance is maintained over a bias voltage range of \\SI{30}{V}, remaining well within CMS requirements.", "published": "2025-10-15T08:51:54Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.216024"}
{"arxiv_id": "2510.12910v1", "title": "Effective Connectivity-Based Unsupervised Channel Selection Method for   EEG", "summary": "Analyzing neural data such as Electroencephalography (EEG) data often involves dealing with high-dimensional datasets, where not all channels provide equally meaningful informa- tion. Selecting the most relevant channels is crucial for improving computational efficiency and ensuring robust insights into neural dynamics. This study introduces the Importance of Channels based on Effective Connectivity (ICEC) criterion for quantifying effective connectivity (EC) in each channel. Effective connectivity refers to the causal influence one neural region exerts over another, providing insights into the directional flow of information. Using this criterion, we propose an unsupervised channel selection method that accounts for the intensity of interactions among channels. To evaluate the proposed channel selection method, we applied it to three well-known EEG datasets across four categories. The assessment involved calculating the ICEC criterion using five effective connectivity metrics: partial directed coherence (PDC), generalized PDC (GPDC), renormalized PDC (RPDC), directed transfer function (DTF), and direct DTF (dDTF). To focus on the effect of channel selection, we employed the Common Spatial Pattern (CSP) algorithm for feature extraction and a Support Vector Machine (SVM) for classification across all participants. Results were compared with other CSP-based methods. The evaluation included comparing participant- specific accuracies with and without the proposed method across five effective connectivity metrics. The results showed consistent performance improvements and a significant reduction in the number of selected electrodes for all participants. Compared to state-of-the-art methods, our approach achieved the highest accuracies: 82% (13 out of 22 channels), 86.01% (29 out of 59 channels), and 87.56% (48 out of 118 channels) across three datasets.", "published": "2025-10-14T18:34:11Z", "query": "intracortical electrodes", "relevance": 0.25, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:00.216213"}
{"arxiv_id": "2510.12903v1", "title": "Towards High-Resolution Orbitrap Mass Spectrometry for Next- Generation   In-Situ Space Dust Analysis", "summary": "Cosmic and planetary dust hold vital clues to the chemical evolution of the solar system, yet in situ analysis of their molecular and elemental composition remains technically challenging. Here we present laboratory results from HANKA (High-resolution mass Analyzer for Nano-scale Kinetic Astro materials), a compact Orbitrap-based mass spectrometer developed towards the goal of a universal dust detector for space applications. Using infrared laser ablation and plasma formation under vacuum, we analyzed solid-state samples representative of Lunar, Martian, and Meteoritic material. The resulting mass spectra - recorded at resolving powers of R=60000 - reveal complex, but characteristic element mixtures. These results demonstrate the single event sensitivity of HANKA, and its mass resolution with the ability to resolve complex mass spectra and possibly differentiate geochemical signatures across planetary bodies. The dynamic range of 3-4 orders of magnitude enables even the detection of trace compounds. The minimalistic impact sampling approach enables fast, high-precision compositional mass analysis without complex sample preparation, making the instrument well-suited for orbital, surface, or flyby missions with expected dust impacts. Our system consists of an IR-laser system that simulates impacts of nano to micron sized solid-state dust and ice particles from space. It therefore allows to perform so called analogue experiments in the laboratory. We conclude that IR- laser pulses on a solid-state material are not only well suited for ice particle impact analogues but also a good analogue experiment for solid state particle impacts on a dust detector electrode in space. Moreover, the IR laser is employed only for an optimal analogue experiment simulating the impact event - it is not necessary in space on a spacecraft detecting space dust.", "published": "2025-10-14T18:23:56Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.216460"}
{"arxiv_id": "2510.12554v1", "title": "Conductance Plateaus at Quantum Hall Integer Filling Factors in   Germanium Quantum Point Contacts", "summary": "Constricting transport through a one-dimensional quantum point contact in the quantum Hall regime enables gate-tunable selection of the edge modes propagating between voltage probe electrodes. Here we investigate the quantum Hall effect in a quantum point contact fabricated on low disorder strained germanium quantum wells. For increasing magnetic field, we observe Zeeman spin-split 1D ballistic hole transport evolving to integer quantum Hall states, with well-defined quantised conductance increasing in multiples of $e^2/h$ down to the first integer filling factor $\\nu=1$. These results establish strained germanium as a viable platform for complex experiments probing many-body states and quantum phase transitions.", "published": "2025-10-14T14:17:39Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.216622"}
{"arxiv_id": "2510.12515v1", "title": "HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive   Representation", "summary": "Electroencephalography (EEG) is an essential technique for neuroscience research and brain-computer interface (BCI) applications. Recently, large-scale EEG foundation models have been developed, exhibiting robust generalization capabilities across diverse tasks and subjects. However, the heterogeneity of EEG devices not only hinders the widespread adoption of these models but also poses significant challenges to their further scaling and development. In this paper, we introduce HEAR, the first EEG foundation model explicitly designed to support heterogeneous EEG devices, accommodating varying electrode layouts and electrode counts. HEAR employs a learnable, coordinate-based spatial embedding to map electrodes with diverse layouts and varying counts into a unified representational space. This unified spatial representation is then processed by a novel spatially-guided transformer, which effectively captures spatiotemporal dependencies across electrodes. To support the development of HEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data collected from over 150 distinct electrode layouts with up to 1,132 electrodes. Experimental results demonstrate that HEAR substantially outperforms existing EEG foundation models in supporting heterogeneous EEG devices and generalizing across diverse cognitive tasks and subjects.", "published": "2025-10-14T13:42:46Z", "query": "intracortical electrodes", "relevance": 0.6, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:00.216812"}
{"arxiv_id": "2510.12467v1", "title": "Investigation of Cathode Electrolyte Interphase Formation via Coupling   Liquid Electrochemical TEM and GC/MS", "summary": "A deeper understanding of the cathode electrolyte interphase (CEI) formation mechanism is essential to elucidate battery degradation. Here, we combine Liquid Electrochemical Transmission Electron Microscopy (ec-TEM) with Gas Chromatography/Mass Spectrometry (GC/MS) to monitor CEI evolution in a realistic electrochemical environment, focusing on electrolyte behavior under high voltages. The correlation between the electrochemical response, gas and liquid analysis after cycling, and the observation of deposited species on the working electrode (WE) reveals the processes governing CEI formation, stability, and composition. Cycling between 4 and 6 V vs Li leads to dispersed particles instead of a continuous film. These are partly composed of LiF and an amorphous phase that prevents dissolution at high potential. When cycled between 2.5 and 5.5 V, an anodic current peak indicates the formation of a 36 nm amorphous thin film without crystalline LiF, attributed to EC oxidation producing HF and subsequent LiF at a higher potential. LiF dissolution appears to follow a two-step pathway: electrolyte oxidation forms soluble intermediates, which are later reduced at lower potential to yield species capable of dissolving LiF. These results provide new insights into CEI formation and dissolution mechanisms, underscoring the need for further studies across different potential windows and with non carbonate electrolytes to validate these findings.", "published": "2025-10-14T13:00:07Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:00.216991"}
{"arxiv_id": "2510.12176v1", "title": "Nanoscale surface morphology controls charge storage at stepped Pt-water   interfaces", "summary": "Platinum step edges dominate electrocatalytic activity in fuel cells and electrolysers, yet their atomistic electrochemical behaviour remains poorly understood. Here, we employ \\textit{ab initio} molecular dynamics under controlled electrode potentials to model a realistic stepped Pt--water interface incorporating experimentally observed (111)$\\times$(111) and (111)$\\times$(100) edge motifs. This allows us to resolve, for the first time, the site-specific structure, charge distribution, and electrostatics of the electric double layer at a nanostructured Pt surface. We find that differential capacitance near the potential of zero charge (PZC) arises almost entirely from potential-dependent chemisorption of water on flat (111) terraces. In contrast, step edges are saturated with chemisorbed water even below the PZC and thus do not contribute to the capacitance. Instead, edges accumulate excess positive charge and exhibit a locally elevated electrostatic potential, as revealed by spatially resolved macroscopic potential profiles. This electrostatic asymmetry implies a greater barrier for electron accumulation at step sites compared to terraces, consistent with enhanced charge localisation and reactivity. Finally, the higher-in-energy d-band centre and sharper projected density of states at edge atoms further support their role as active, positively charged centres. Together, these results provide a mechanistic explanation for the observed experimental shift of the PZC with step density and establish a predictive framework for understanding and optimising interfacial charging in nanostructured Pt electrocatalysts.", "published": "2025-10-14T06:10:23Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.217231"}
{"arxiv_id": "2510.12055v1", "title": "Quantification of Electrolyte Degradation in Lithium-ion Batteries with   Neutron Imaging Techniques", "summary": "Non-destructive characterization of lithium-ion batteries provides critical insights for optimizing performance and lifespan while preserving structural integrity. Optimizing electrolyte design in commercial LIBs requires consideration of composition, electrolyte-to-capacity ratio, spatial distribution, and associated degradation pathways. However, existing non-destructive methods for studying electrolyte infiltration, distribution, and degradation in LIBs lack the spatiotemporal resolution required for precise observation and quantification of the electrolyte. In this study, we employ neutron imaging with sufficient spatial resolution ~150 um and large field of view 20x20 cm2 to quantitatively resolve the electrolyte inventory and distribution within LiFePO4/graphite pouch cells under high-temperature accelerated aging. Quantitative standard curves based on neutron transmission attenuation reveal a clear electrolyte dry-out threshold at 3.18 g Ah-1 and the two stages evolutions of EI during cell aging were quantified. By integrating non-destructive electrochemical diagnostics, accelerated graphite material loss and liquid phase Li+ diffusion degradation is observed during pore-drying. Further analysis, including operando cyclic aging, reveals that the neutron transmission below the saturation reference is due to the enrichment of hydrogen nuclei within the solid-electrolyte interphase. Assumed pore-drying does not occur, the SEI signal of the electrodes can be quantitatively decoupled during ageing. Combined analyses with NI, TOF-SIMS, and SEM reveal that high EI cells exhibit uniform SEI growth and reduced degradation, while low EI cells show uneven SEI formation, accelerating capacity loss. This study unveils a dynamic electrolyte infiltration-consumption-dry-out process in LIBs, offering non-destructive and quantitative insights to guide sustainable and durable battery development.", "published": "2025-10-14T01:51:00Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:00.217429"}
{"arxiv_id": "2510.11994v1", "title": "62.6 GHz ScAlN Solidly Mounted Acoustic Resonators", "summary": "We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator (SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N) piezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode, positioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2 nm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and piezoelectric stack above are designed to confine a third-order thickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently transducing with thickness-field excitation. The fabricated SMR exhibits an extracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode quality factor (Q) of 51 at 63 GHz, representing the highest operating frequency reported for an SMR to date. These results establish a pathway toward mmWave SMR devices for filters and resonators in next-generation RF front ends.", "published": "2025-10-13T22:43:46Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.217649"}
{"arxiv_id": "2510.10770v1", "title": "The Cost of Simplicity: How Reducing EEG Electrodes Affects Source   Localization and BCI Accuracy", "summary": "Electrode density optimization in electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) requires balancing practical usability against signal fidelity, particularly for source localization. Reducing electrodes enhances portability but its effects on neural source reconstruction quality and source connectivity - treated as proxies to BCI performance - remain understudied. We address this gap through systematic evaluation of 62-, 32-, and 16-channel configurations using a fixed, fully automated processing pipeline applied to the well-characterized P300 potential. This approach's rationale is to minimize variability and bias inherent to EEG analysis by leveraging the P300's stimulus-locked reproducibility and pipeline standardization. Analyzing 63 sessions (31 subjects) from the Eye-BCI dataset with rigorous artifact correction and channel validation, we demonstrate: (1) Progressive degradation in source reconstruction quality with sparser configurations, including obscured deep neural generators and spatiotemporal distortions; (2) A novel sqrt(Re) scaling law linking electrode reduction ratio (Re) to localization accuracy - a previously unquantified relationship to the best of our knowledge; (3) While reduced configurations preserve basic P300 topography and may suffice for communicative BCIs, higher-density channels are essential for reliable deep source reconstruction. Overall, this study establishes a first step towards quantitative benchmarks for electrode selection, with critical implications for clinical BCIs requiring anatomical precision in applications like neurodegenerative disease monitoring, where compromised spatial resolution could mask pathological signatures. Most importantly, the sqrt(Re) scaling law may provide the first principled method to determine the minimal electrode density required based on acceptable error margins or expected effect sizes.", "published": "2025-10-12T19:13:35Z", "query": "intracortical electrodes", "relevance": 0.5499999999999999, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.217899"}
{"arxiv_id": "2510.09522v1", "title": "Is Platinum a Proton Blocking Catalyst?", "summary": "Platinum, to date, is the most widely applied electrocatalyst for hydrogen evolution reaction (HER) in acidic media. It is assumed to be a proton-blocking catalyst with only surface-limited adsorption of the reaction intermediates. Here, we critically evaluate the bulk interaction of Pt with hydrogen (H), and its heavier isotope deuterium (D), by monitoring operando mass change of the Pt electrode during galvanostatic heavy/water splitting by employing an electrochemical quartz crystal microbalance. Unexpectedly, we observe an irreversible temporal mass gain and a change in the reaction's overpotential, arising from diffusion of H/D into Pt, confirmed by atom probe tomography and thermal desorption spectroscopy. Sub-surface concentration of at least ca. 15 at. % of D in Pt was observed, diffusing down to a depth of more than 10 nm. Analytical description quantified the diffusion coefficient of D in Pt to be 3.2X10^-18 cm2Xs-1. These findings challenge the existing credence of Pt-proton interaction being limited to the surface, prompting the expansion of the catalyst design strategies to account for property-modifying bulk diffusion of H/D in the Pt matrix", "published": "2025-10-10T16:31:33Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.218105"}
{"arxiv_id": "2510.13833v1", "title": "On the nature of light", "summary": "Electromagnetism is at the heart of the Standard Model, but despite all the successes of modern theory, our basic description of light traveling in free space remains unsatisfactory. The four bosons that compose light are introduced in a rather trivial way, simply by quantizing the (scalar and vector) potential amplitudes. This leads to quite a few conceptual problems linked to the two virtual photons, the longitudinal and scalar ones. Moreover, the spin of the photon is rather poorly handled by the conventional Quantum Electro-Dynamics theory. Therefore: what if the field's Lagrangian density, to some extent, would not be properly chosen? Here we look at these questions from a completely different point of view, bypassing the problems encountered in conventional theories. We choose a pragmatic approach that relies only on basic Condensed Matter like Quantum Mechanics, and a specific gauge fixing procedure for the potential field: we propose the concept of gauge duality, which leads to an original quantization scheme. Building on the Poincar\\'e symmetries, all constants of motion are identified. Four bosons are introduced, responsible for a proper spin 1 pseudo-vector and parity and charge related operators. They emerge from scalar fields that can be viewed as generalized fluxes (in the sense of M. Devoret), with quantum conjugate virtual charges responsible for the \"confinement\" of light in space, within \"virtual electrodes\", somehow reproducing the holographic principle originally proposed for gravity. All observable properties of light in free space then arise from a specific choice of eigenstates (a procedure replacing here the Ward identity of Quantum Field Theory). Real photons are thus the \"helicity\" bosons, while virtual ones correspond to a \"parity charge\". Photon and anti-photon are (as expected) the same particle, linked through an internal gauge transformation.", "published": "2025-10-10T15:30:01Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.218374"}
{"arxiv_id": "2510.08678v2", "title": "Coherent Optical Control of Electron Dynamics in Patterned Graphene   Nanoribbons", "summary": "The field of coherent electronics aims to advance electronic functionalities by utilizing quantum coherence. Here, we demonstrate a viable and versatile methodology for controlling electron dynamics optically in graphene nanoribbons. In particular, we propose to flatten the band structure of armchair graphene nanoribbons via control electrodes, arranged periodically along the extended direction of the nanoribbon. This addresses a key mechanism for dephasing in solids, which derives from the momentum dependence of the energy gap between the valence and the conduction band. We design an optimal driving field pulse to produce collective Rabi oscillations between these bands, in their flattened configuration. As an example for coherent control, we show that these optimized pulses can be used to invert the entire electronic band population by a $\\pi$ pulse in a reversible fashion, and to create a superposition state via a $\\pi/2$ pulse, which generates an alternating photocurrent. Our proposal consists of a platform and methodological approach to optically control the electron dynamics of graphene nanoribbons, paving the way toward novel coherent electronic and quantum information processing devices in solid-state materials.", "published": "2025-10-09T18:00:01Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:00.218620"}
{"arxiv_id": "2510.08330v1", "title": "A Simultaneous Synergistic Protection Mechanism in Hybrid   Perovskite-Organic Multi-junctions Enables Long-Term Stable and Efficient   Tandem Solar Cells", "summary": "Perovskite-organic tandem solar cells (P-O TSCs) hold great promise for next-generation thin-film photovoltaics, with steadily improving power conversion efficiency (PCE). However, the development of optimal interconnecting layers (ICLs) remains one major challenge for further efficiency gains, and progress in understanding the improved long-term stability of P-O tandem configuration has been lagging. In this study, we experimentally investigate the enhanced stability of p-i-n P-O TSCs employing a simplified C60/atomic-layer-deposition (ALD) SnOx/PEDOT: PSS ICL without an additional charge recombination layer (CRL), which achieve an averaged efficiency of 25.12% and a hero efficiency of 25.5%. Our finding discovers that the recrystallization of C60, a widely used electron transport layer in perovskite photovoltaics, leads to the formation of grain boundaries during operation, which act as migration channels for the interdiffusion of halide and Ag ions. Critically, we demonstrate for the first time that the tandem device architecture, incorporating organic semiconductor layers, effectively suppresses the bi-directional ion diffusion and mitigates electrode corrosion. Thus, the P-O TSC establishes a mutual protection system: the organic layers stabilize the perovskite sub-cell by suppressing ion diffusion-induced degradation, and the perovskite layer shields the organic sub-cell from spectrally induced degradation. The simultaneous synergistic protection mechanism enables P-O TSCs to achieve exceptional long-term operational stability, retaining over 91% of their initial efficiency after 1000 hours of continuous metal-halide lamp illumination, and to exhibit minimal fatigue after 86 cycles (2067 hours) of long-term diurnal (12/12-hour) testing. These results demonstrate that tandem cells significantly outperform their single-junction counterparts in both efficiency and stability.", "published": "2025-10-09T15:18:18Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.219055"}
{"arxiv_id": "2510.07792v1", "title": "Aluminum-Based Superconducting Tunnel Junction Sensors for Nuclear   Recoil Spectroscopy", "summary": "The BeEST experiment is searching for sub-MeV sterile neutrinos by measuring nuclear recoil energies from the decay of $^7$Be implanted into superconducting tunnel junction (STJ) sensors. The recoil spectra are affected by interactions between the radioactive implants and the sensor materials. We are therefore developing aluminum-based STJs (Al-STJs) as an alternative to existing tantalum devices (Ta-STJs) to investigate how to separate material effects in the recoil spectrum from potential signatures of physics beyond the Standard Model. Three iterations of Al-STJs were fabricated. The first had electrode thicknesses similar to existing Ta-STJs. They had low responsivity and reduced resolution, but were used successfully to measure $^7$Be nuclear recoil spectra. The second iteration had STJs suspended on thin SiN membranes by backside etching. These devices had low leakage current, but also low yield. The final iteration was not backside etched, and the Al-STJs had thinner electrodes and thinner tunnel barriers to increase signal amplitudes. These devices achieved 2.96 eV FWHM energy resolution at 50 eV using a pulsed 355 nm (~3.5 eV) laser. These results establish Al-STJs as viable detectors for systematic material studies in the BeEST experiment.", "published": "2025-10-09T05:11:47Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:00.219294"}
{"arxiv_id": "2510.20798v1", "title": "Analog Quantum Feature Selection with Neutral-Atom Quantum Processors", "summary": "We present a quantum-native approach to quantum feature selection (QFS) based on analog quantum simulation with neutral atom arrays, adaptable to a variety of academic and industrial applications. In our method, feature relevance-measured via mutual information with the target-is encoded as local detuning amplitudes, while feature redundancy is embedded through distance-dependent van der Waals interactions, constrained by the Rydberg blockade radius. The system is evolved adiabatically toward low-energy configurations, and the resulting measurement bitstrings are used to extract physically consistent subsets of features. The protocol is evaluated through simulations on three benchmark binary classification datasets: Adult Income, Bank Marketing, and Telco Churn. Compared to classical methods such as mutual information ranking and Boruta, combined with XGBoost and Random Forest classifiers, our quantum-computing approach achieves competitive or superior performance. In particular, for compact subsets of 2-5 features, analog QFS improves mean AUC scores by 1.5-2.3% while reducing the number of features by 75-84%, offering interpretable, low-redundancy solutions. These results demonstrate that programmable Rydberg arrays offer a viable platform for intelligent feature selection with practical relevance in machine learning pipelines, capable of transforming computational quantum advantage into industrial quantum usefulness.", "published": "2025-10-23T17:57:34Z", "query": "microelectrode arrays", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:03.753795"}
{"arxiv_id": "2510.20793v1", "title": "Addressing Synchrotron Challenges for CMB Observations: ELFS-SA   Collaboration for Robust Foreground Removal", "summary": "Upcoming cosmic microwave background (CMB) experiments aim to detect primordial gravitational waves with unprecedented sensitivity. Effective foreground removal is essential to avoid biases in the measurement of the tensor-to-scalar ratio ($r$) in this high-precision regime. Recent analyses highlight the unexpected complexity of synchrotron emission at low frequencies, underscoring the need for more sensitive low-frequency data. To address this challenge, the European Low-Frequency Survey (ELFS) initiative and the Simons Array collaboration propose installing two European low-frequency receivers on one of the Simons Array telescopes. These receivers will enable measurements in the Southern Hemisphere between $6$ and $20$,GHz, complementary to those of current and proposed experiments targeting the measurement of cosmological gravitational waves. In this work, we study the benefits of combining these low-frequency observations with a representative future CMB experiment operating from the Southern Hemisphere. We find that the extra information can improve the knowledge of the underlying synchrotron spectral energy distribution (SED), with positive impacts on the robustness of measurement of the tensor-to-scalar ratio, $r$, against the complexity of low-frequency foregrounds.", "published": "2025-10-23T17:54:50Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.754182"}
{"arxiv_id": "2510.20735v1", "title": "Magnetic tunnel junction as a real-time entropy source:   Field-Programmable Gate Array based random bit generation without   post-processing", "summary": "We demonstrate a method to generate application-ready truly random bits from a magnetic tunnel junction driven by a Field-Programmable Gate Array (FPGA). We implement a real-time feedback loop that stabilizes the switching probability near 50\\% and apply an XOR operation, both on the FPGA, to suppress short-term correlations, together mitigating long-term drift and bias in the bitstream. This combined approach enables NIST-compliant random bit generation at 5~Mb/s without post-processing, providing a practical hardware solution for fast and reliable true random number generation. Beyond cryptographic applications, these capabilities open opportunities for stochastic hardware accelerators, probabilistic computing, and large-scale modeling where real-time access to unbiased randomness is essential.", "published": "2025-10-23T16:50:51Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:03.754449"}
{"arxiv_id": "2510.20724v1", "title": "Phonon Polaritons and Epsilon Near Zero Modes in Sapphire Nanostructures", "summary": "Surface phonon polaritons (SPhPs) are promising candidates for enhanced light--matter interactions due to their efficient and low-loss light confinement features. In this work, we present unique light-matter interactions in saphhire within its Reststrahlen bands (RBs) across the long-wave infrared (LWIR) spectrum ($\\omega = 385$-$1050~\\mathrm{cm}^{-1}$). Particularly, we investigated the nanocone-patterned sapphire resonator array, with specific attention to its in-plane and out-of-plane permittivity components. Through Fourier transform infrared spectroscopy measurement and full-wave photonic simulations, we identified a range of optical excitations in the RBs, including three SPhPs, two hyperbolic volume phonon polaritons (HVPhPs), and one epsilon-near-zero (ENZ) mode. The depth-resolved confocal Raman spectroscopy revealed strongly enhanced Raman signals on the nanostructured surface, suggesting the mode coupling between phonons and phonon-polaritons, which was further confirmed by the finite element modeling of polarizability. This exploratory study provides in-depth insights into the dynamics of LWIR phonon polaritons and ENZ modes in the nanostructured sapphire, indicating its great potential for innovative nanophotonic applications.", "published": "2025-10-23T16:41:52Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.754589"}
{"arxiv_id": "2510.20664v1", "title": "Niebla: an open-source code for modelling the extragalactic background   light", "summary": "Extragalactic very high-energy (VHE; $E&gt;100\\,$GeV) gamma rays suffer absorption in interactions with photons of the Extragalactic Background Light (EBL). The EBL is an isotropic diffuse photon field from optical to infrared wavelengths, which is difficult to measure directly due to strong foreground emission. We present niebla, the first open-source code to compute the EBL using a forward-folding approach that accepts fully customizable inputs. This software enables a detailed modelling of the influence of EBL opacities on VHE observations and facilitates the distinction between different dust reemission models. The code models the optical background primarily from stellar emission, by evolving the spectrum of a single stellar population as a function of redshift, considering mean metallicity evolution and star formation rate density. Additional sources to the EBL can be provided by the user. The code already includes optional contributions from, e.g., stripped stars, intra-halo light, or the decay of axion dark matter. The optical emissivity is then absorbed by interstellar dust and reemitted in the infrared regime. We provide multiple prescriptions to model this process, using spectral dust templates or a combination of blackbodies. We provide three EBL models calculated with different dust reemission prescriptions, which have been fitted to various observational data sets. In addition, we showcase the versatility of our model through a simulated observation of the blazar Markarian 501 in a high-flux state with the Large High Altitude Air Shower Observatory array. We find that the simulated VHE spectrum is highly sensitive to the EBL opacity coming from the infrared. Our model will therefore allow the community to distinguish between different dust reemission models and constrain EBL parameters with future observations.", "published": "2025-10-23T15:39:01Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.754743"}
{"arxiv_id": "2510.20589v1", "title": "Scaler data from the Pierre Auger Observatory as a proxy of solar   activity", "summary": "Solar activity variations strongly impact the modulation of the flux of low-energy Galactic Cosmic Rays (GCRs) reaching the Earth. The secondary particles, which originate from the interaction of GCRs with the atmosphere, can be revealed by an array of ground detectors. We show that the low-threshold rate (scaler) time series recorded over 16 years of operation by the surface detectors of the Pierre Auger Observatory in Malarg\\\"ue (Argentina) strongly reflects solar activity and can be considered as a new proxy of solar variability. To achieve this result, we apply advanced spectral methods to this time series and to the classical solar sunspot number and sunspot area series. We detect and compare highly significant variations with periods ranging from the decadal to the daily scale and identify the origin of each variability mode. In conclusion, we show that the Auger scaler data, thanks to the very low noise level and high statistical significance related to the very high count rates ($\\sim 10^6$ counts per second), allow for a thorough and detailed investigation of the GCR flux variations in the heliosphere.", "published": "2025-10-23T14:13:52Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:03.754889"}
{"arxiv_id": "2510.20557v1", "title": "Nontrivial topological phases in \"Zig-Zag\" arrays of polarization   transmons", "summary": "In recent years, quantum simulators of topological models have been extensively studied across a variety of platforms and regimes. A new promising research direction makes use of meta-atoms with multiple intrinsic degrees of freedom, which to date have been predominantly studied in the classical regime. Here, we propose a superconducting quantum simulator to study an extension of the well-known \"Zig-Zag\" model with long-range cross-polarization couplings using polarization transmons hosting degenerate dipole orbitals. We map the phase transitions of the extended \"Zig-Zag\" model both numerically and analytically using inverse participation ratios and topological invariants. We demonstrate the existence of in-gap localized trivial and Tamm edge states. With linearized meta-atoms, we show via electromagnetic modeling that the proposed arrangement closely reproduces the extended \"Zig-Zag\" model. This work paves the way towards experimental investigation of the previously inaccessible topological quantum many-body phenomena.", "published": "2025-10-23T13:39:07Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.755037"}
{"arxiv_id": "2510.20522v1", "title": "Detection of ultra-high-energy cosmic rays in the southern hemisphere   with FAST: data acquisition and preliminary results", "summary": "Ultra-high-energy cosmic rays (UHECRs) remain one of the greatest mysteries in astroparticle physics. The Fluorescence detector Array of Single-pixel Telescopes (FAST) is a next-generation cosmic ray experiment which utilizes ground-based fluorescence telescopes designed to detect these extremely rare particles at energies exceeding 30 EeV. FAST offers a cost-effective and low-maintenance solution to cover the huge detection areas required for UHECR observation. FAST telescopes are currently installed and remotely operated in both hemispheres, at the Pierre Auger Observatory and the Telescope Array experiment. To enable fully autonomous operation, a sophisticated trigger for data acquisition is essential. In this paper, we present two novel triggering algorithms inspired by those used at the largest observatories, but improved to meet the specific requirements imposed by the FAST design. Their performance is validated using Monte Carlo simulations of extensive air showers and UHECR events detected by the FAST telescope in the southern hemisphere. Finally, we present the sensitivity analysis estimate for FAST.", "published": "2025-10-23T13:04:31Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.755195"}
{"arxiv_id": "2510.20491v1", "title": "Metallic island array as synthetic quantum matter: fractionalized   entropy and thermal transport", "summary": "The surprisingly rich physics of a single Coulomb-blockaded metallic island, when coupled to quantum Hall edge channels, is now well established -- giving rise to charge fractionalization and multi-channel quantum impurity behavior. Here, we show that qualitatively new physics emerges in arrays of such elements. We consider a 1D chain of $N$ metallic islands, focusing on thermodynamic signatures such as quantized entropy and anomalous thermal conductance. Universal and robust behavior emerges for energy scales smaller than the charging energy of the islands. In particular, we demonstrate that for the bulk filling factor of $\\nu=1$, the islands could support a finite heat flow without temperature difference between them. Upon pinching the array with a quantum point contact, we predict an entropy change that scales with the number of islands as $\\Delta S = \\frac{1}{2}k_B \\log (N+1)$, which can be measured using charge detection. This fractional entropy suggests the emergence of a novel type of excitations in the array.", "published": "2025-10-23T12:31:34Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.755340"}
{"arxiv_id": "2510.20484v1", "title": "Validation of NANOGrav 15-year data and ACT data by modified inflation   in entropic cosmology", "summary": "Recent evidences of stochastic gravitational wave background (SGWB) through Pulsar Time Array (PTA) observations hint towards an alternative inflationary scenario, compared to the usual inflation, for describing the early stage of the universe in order to be compatible with the PTA data. Moreover, currently the Atacama Cosmology Telescope (combined with the Planck 2018 and BAO) refines the constraint on inflationary observables, compared to the only-Planck 2018 measurements. In the present work, we simultaneously address these two issues by incorporating certain modification during inflation over the usual inflationary scenario. Such modification amplifies the primordial tensor perturbation over the modes that are sensitive to the NANOGrav frequency region. For this purpose, we take the thermodynamic route of cosmology where the entropy of the apparent horizon is given by a generalized form of entropy that is able to generalize the other known form of horizon entropies for suitable representations. The constraints on the model parameters coming from the ACT data also fit the NANOGrav 15-year data (based on numerical analysis), which reveal the model's compatibility with both the ACT and the PTA data.", "published": "2025-10-23T12:24:01Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.755607"}
{"arxiv_id": "2510.20374v1", "title": "Elliptical-rod geometries enhance photonic band gaps in disordered   stealthy hyperuniform photonic crystals", "summary": "We study two-dimensional photonic crystals composed of elliptical dielectric rods arranged according to stealthy hyperuniform point patterns. These patterns are characterized by the structure factor, which vanishes for 0 &lt; |k| &lt;= K, where k is the wave number and K denotes the cutoff wave number specifying the stealthiness of the pattern. The optical properties of the photonic crystals are analyzed by applying the plane-wave expansion method to Maxwell's equations. We demonstrate that photonic crystals composed of elliptical dielectric rods can exhibit larger photonic band gaps than those with cylindrical rods when both the rod orientation and aspect ratio are properly optimized. This behavior contrasts with that of periodic lattices such as triangular or square arrays. These findings shed light on the crucial role of structural anisotropy and aperiodic structure in enhancing photonic band-gap formation.", "published": "2025-10-23T09:15:19Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.755840"}
{"arxiv_id": "2510.20277v1", "title": "A Location-Aware Hybrid Deep Learning Framework for Dynamic Near-Far   Field Channel Estimation in Low-Altitude UAV Communications", "summary": "In low altitude UAV communications, accurate channel estimation remains challenging due to the dynamic nature of air to ground links, exacerbated by high node mobility and the use of large scale antenna arrays, which introduce hybrid near and far field propagation conditions. While conventional estimation methods rely on far field assumptions, they fail to capture the intricate channel variations in near-field scenarios and overlook valuable geometric priors such as real-time transceiver positions. To overcome these limitations, this paper introduces a unified channel estimation framework based on a location aware hybrid deep learning architecture. The proposed model synergistically combines convolutional neural networks (CNNs) for spatial feature extraction, bidirectional long short term memory (BiLSTM) networks for modeling temporal evolution, and a multihead self attention mechanism to enhance focus on discriminative channel components. Furthermore, real-time transmitter and receiver locations are embedded as geometric priors, improving sensitivity to distance under near field spherical wavefronts and boosting model generalization. Extensive simulations validate the effectiveness of the proposed approach, showing that it outperforms existing benchmarks by a significant margin, achieving at least a 30.25% reduction in normalized mean square error (NMSE) on average.", "published": "2025-10-23T07:04:12Z", "query": "microelectrode arrays", "relevance": 0.39999999999999997, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:03.756012"}
{"arxiv_id": "2510.20274v1", "title": "Near-Field 3D Localization and MIMO Channel Estimation with   Sub-Connected Planar Arrays", "summary": "This paper investigates the design of channel estimation and 3D localization algorithms in a challenging scenario, where a sub-connected planar extremely large-scale multiple-input multiple-output (XL-MIMO) communicates with multi-antenna users. In the near field, the uplink MIMO channel is of full column rank and therefore can not be estimated effectively by applying existing codebooks that are designed for the far-field case or for the near-field case but limited to single antenna users. To solve this problem, we propose a three-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse Bayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into subarrays and use OMP to solve the compressed sensing (CS) problem about subarray channel estimation with the Discrete Fourier Transform (DFT)-based dictionary matrix. Secondly, exploiting the estimated subarray channels and employing one-dimensional multiple signal classification (MUSIC), we estimate the central location of the user array under the Least Squares (LS) criterion. Finally, we utilize the estimated central location to construct a refined location-aided dictionary matrix and obtain the MIMO channel estimation using SBL. Results exhibit the significant superiority of the proposed algorithm compared with several benchmarks, in terms of both the pilot overhead and estimation accuracy.", "published": "2025-10-23T06:59:48Z", "query": "microelectrode arrays", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:03.756165"}
{"arxiv_id": "2510.20132v1", "title": "Inverse Image-Based Rendering for Light Field Generation from Single   Images", "summary": "A concept of light-fields computed from multiple view images on regular grids has proven its benefit for scene representations, and supported realistic renderings of novel views and photographic effects such as refocusing and shallow depth of field. In spite of its effectiveness of light flow computations, obtaining light fields requires either computational costs or specialized devices like a bulky camera setup and a specialized microlens array. In an effort to broaden its benefit and applicability, in this paper, we propose a novel view synthesis method for light field generation from only single images, named inverse image-based rendering. Unlike previous attempts to implicitly rebuild 3D geometry or to explicitly represent objective scenes, our method reconstructs light flows in a space from image pixels, which behaves in the opposite way to image-based rendering. To accomplish this, we design a neural rendering pipeline to render a target ray in an arbitrary viewpoint. Our neural renderer first stores the light flow of source rays from the input image, then computes the relationships among them through cross-attention, and finally predicts the color of the target ray based on these relationships. After the rendering pipeline generates the first novel view from a single input image, the generated out-of-view contents are updated to the set of source rays. This procedure is iteratively performed while ensuring the consistent generation of occluded contents. We demonstrate that our inverse image-based rendering works well with various challenging datasets without any retraining or finetuning after once trained on synthetic dataset, and outperforms relevant state-of-the-art novel view synthesis methods.", "published": "2025-10-23T02:12:45Z", "query": "microelectrode arrays", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.756361"}
{"arxiv_id": "2510.20122v1", "title": "Active Localization of Close-range Adversarial Acoustic Sources for   Underwater Data Center Surveillance", "summary": "Underwater data infrastructures offer natural cooling and enhanced physical security compared to terrestrial facilities, but are susceptible to acoustic injection attacks that can disrupt data integrity and availability. This work presents a comprehensive surveillance framework for localizing and tracking close-range adversarial acoustic sources targeting offshore infrastructures, particularly underwater data centers (UDCs). We propose a heterogeneous receiver configuration comprising a fixed hydrophone mounted on the facility and a mobile hydrophone deployed on a dedicated surveillance robot. While using enough arrays of static hydrophones covering large infrastructures is not feasible in practice, off-the-shelf approaches based on time difference of arrival (TDOA) and frequency difference of arrival (FDOA) filtering fail to generalize for this dynamic configuration. To address this, we formulate a Locus-Conditioned Maximum A-Posteriori (LC-MAP) scheme to generate acoustically informed and geometrically consistent priors, ensuring a physically plausible initial state for a joint TDOA-FDOA filtering. We integrate this into an unscented Kalman filtering (UKF) pipeline, which provides reliable convergence under nonlinearity and measurement noise. Extensive Monte Carlo analyses, Gazebo-based physics simulations, and field trials demonstrate that the proposed framework can reliably estimate the 3D position and velocity of an adversarial acoustic attack source in real time. It achieves sub-meter localization accuracy and over 90% success rates, with convergence times nearly halved compared to baseline methods. Overall, this study establishes a geometry-aware, real-time approach for acoustic threat localization, advancing autonomous surveillance capabilities of underwater infrastructures.", "published": "2025-10-23T01:52:05Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.756564"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "microelectrode arrays", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:03.756717"}
{"arxiv_id": "2510.19977v1", "title": "Towards Strong Certified Defense with Universal Asymmetric Randomization", "summary": "Randomized smoothing has become essential for achieving certified adversarial robustness in machine learning models. However, current methods primarily use isotropic noise distributions that are uniform across all data dimensions, such as image pixels, limiting the effectiveness of robustness certification by ignoring the heterogeneity of inputs and data dimensions. To address this limitation, we propose UCAN: a novel technique that \\underline{U}niversally \\underline{C}ertifies adversarial robustness with \\underline{A}nisotropic \\underline{N}oise. UCAN is designed to enhance any existing randomized smoothing method, transforming it from symmetric (isotropic) to asymmetric (anisotropic) noise distributions, thereby offering a more tailored defense against adversarial attacks. Our theoretical framework is versatile, supporting a wide array of noise distributions for certified robustness in different $\\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the classifier's prediction over perturbed inputs with provable robustness bounds through tailored noise injection. Additionally, we develop a novel framework equipped with three exemplary noise parameter generators (NPGs) to optimally fine-tune the anisotropic noise parameters for different data dimensions, allowing for pursuing different levels of robustness enhancements in practice.Empirical evaluations underscore the significant leap in UCAN's performance over existing state-of-the-art methods, demonstrating up to $182.6\\%$ improvement in certified accuracy at large certified radii on MNIST, CIFAR10, and ImageNet datasets.\\footnote{Code is anonymously available at \\href{https://github.com/youbin2014/UCAN/}{https://github.com/youbin2014/UCAN/}}", "published": "2025-10-22T19:14:26Z", "query": "microelectrode arrays", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:03.756903"}
{"arxiv_id": "2510.19911v1", "title": "On-sky Demonstration of Subdiffraction-limited Astronomical Measurement   Using a Photonic Lantern", "summary": "Resolving fine details of astronomical objects provides critical insights into their underlying physical processes. This drives in part the desire to construct ever-larger telescopes and interferometer arrays and to observe at shorter wavelength to lower the diffraction limit of angular resolution. Alternatively, one can aim to overcome the diffraction limit by extracting more information from a single telescope's aperture. A promising way to do this is spatial mode-based imaging, which projects focal-plane field onto a set of spatial modes before detection, retaining focal-plane phase information crucial at small angular scales but typically lost in intensity imaging. However, the practical implementation of mode-based imaging in astronomy from the ground has been challenged by atmospheric turbulence. Here, we present the first on-sky demonstration of a subdiffraction-limited, mode-based measurement using a photonic lantern (PL)-fed spectrometer installed on the SCExAO instrument at the Subaru Telescope. We introduce a novel calibration strategy that mitigates time-varying wavefront error and misalignment effects, leveraging simultaneously recorded focal-plane images and using a spectral-differential technique that self-calibrates the data. Observing the classical Be star $\\beta$ CMi, we detected spectral-differential spatial signals and reconstructed images of its H$\\alpha$-emitting disk. We achieved an unprecedented H$\\alpha$ photocenter precision of 50$\\mu$as in about 10-minute observation with a single telescope, measuring the disk's near-far side asymmetry for the first time. This work demonstrates the high precision, efficiency, and practicality of photonic mode-based imaging techniques to recover subdiffraction-limited information, opening new avenues for high angular resolution spectroscopic studies in astronomy.", "published": "2025-10-22T18:00:01Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.757047"}
{"arxiv_id": "2510.19820v1", "title": "Tight Lower Bounds for Central String Queries in Compressed Space", "summary": "In this work, we study the limits of compressed data structures, i.e., structures that support various queries on an input text $T\\in\\Sigma^n$ using space proportional to the size of $T$ in compressed form. Nearly all fundamental queries can currently be efficiently supported in $O(\\delta(T)\\log^{O(1)}n)$ space, where $\\delta(T)$ is the substring complexity, a strong compressibility measure that lower-bounds the optimal space to represent the text [Kociumaka, Navarro, Prezza, IEEE Trans. Inf. Theory 2023]. However, optimal query time has been characterized only for random access.   We address this gap by developing tight lower bounds for nearly all other fundamental queries: (1) We prove that suffix array (SA), inverse suffix array (SA$^{-1}$), longest common prefix (LCP) array, and longest common extension (LCE) queries all require $\\Omega(\\log n/\\log\\log n)$ time within $O(\\delta(T)\\log^{O(1)}n)$ space, matching known upper bounds. (2) We further show that other common queries, currently supported in $O(\\log\\log n)$ time and $O(\\delta(T)\\log^{O(1)}n)$ space, including the Burrows-Wheeler Transform (BWT), permuted longest common prefix (PLCP) array, Last-to-First (LF), inverse LF, lexicographic predecessor ($\\Phi$), and inverse $\\Phi$ queries, all require $\\Omega(\\log\\log n)$ time, yielding another set of tight bounds.   Our lower bounds hold even for texts over a binary alphabet. This work establishes a clean dichotomy: the optimal time complexity to support central string queries in compressed space is either $\\Theta(\\log n/\\log\\log n)$ or $\\Theta(\\log\\log n)$. This completes the theoretical foundation of compressed indexing, closing a crucial gap between upper and lower bounds and providing a clear target for future data structures: seeking either the optimal time in the smallest space or the fastest time in the optimal space, both of which are now known for central string queries.", "published": "2025-10-22T17:57:36Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.757244"}
{"arxiv_id": "2510.19816v1", "title": "Single Sr Atoms in Optical Tweezer Arrays for Quantum Simulation", "summary": "We report on the realization of a platform for trapping and manipulating individual $^{88}$Sr atoms in optical tweezers. A first cooling stage based on a blue magneto-optical trap (MOT) operating on the $^1S_0$ -&gt; $^1P_1$ transition at 461 nm enables us to trap approximately $4\\times 10^6$ atoms at a temperature of 8 mK. Further cooling is achieved in a narrow-line red MOT using the $^1S_0$ -&gt; $^3P_1$ intercombination transition at 689 nm, bringing $4\\times 10^5$ atoms down to 5 uK and reaching a density of $\\approx 10^{10}$ cm$^{-3}$. Atoms are then loaded into 813 nm tweezer arrays generated by crossed acousto-optic deflectors and tightly focused onto the atoms with a high-numerical-aperture objective. Through light-assisted collision processes we achieve the collisional blockade, which leads to single-atom occupancy with a probability of about $50\\%$. The trapped atoms are detected via fluorescence imaging with a fidelity of $99.986(6)\\%$, while maintaining a survival probability of $97(1)\\%$. The release-and-recapture measurement provides a temperature of $12.92(5)$ uK for the atoms in the tweezers, and the ultra-high-vacuum environment ensures a vacuum lifetime higher than 7 minutes. These results demonstrate a robust alkaline-earth tweezer platform that combines efficient loading, cooling, and high-fidelity detection, providing the essential building blocks for scalable quantum simulation and quantum information processing with Sr atoms.", "published": "2025-10-22T17:53:02Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.757366"}
{"arxiv_id": "2510.19815v1", "title": "Explaining the Inherent Tradeoffs for Suffix Array Functionality:   Equivalences between String Problems and Prefix Range Queries", "summary": "We study the fundamental question of how efficiently suffix array entries can be accessed when the array cannot be stored explicitly. The suffix array $SA_T[1..n]$ of a text $T$ of length $n$ encodes the lexicographic order of its suffixes and underlies numerous applications in pattern matching, data compression, and bioinformatics. Previous work established one-way reductions showing how suffix array queries can be answered using, for example, rank queries on the Burrows-Wheeler Transform. More recently, a new class of prefix queries was introduced, together with reductions that, among others, transform a simple tradeoff for prefix-select queries into a suffix array tradeoff matching state-of-the-art space and query-time bounds, while achieving sublinear construction time. For binary texts, the resulting data structure achieves space $O(n)$ bits, preprocessing time $O(n / \\sqrt{\\log n})$, preprocessing space of $O(n)$ bits, and query time $O(\\log^{\\epsilon} n)$ for any constant $\\epsilon &gt; 0$. However, whether these bounds could be improved using different techniques has remained open.   We resolve this question by presenting the first bidirectional reduction showing that suffix array queries are, up to an additive $O(\\log\\log n)$ term in query time, equivalent to prefix-select queries in all parameters. This result unifies prior approaches and shows that essentially all efficient suffix array representations can be expressed via prefix-select structures. Moreover, we prove analogous equivalences for inverse suffix array queries, pattern ranking, lexicographic range, and SA-interval queries, identifying six core problem pairs that connect string and prefix query models. Our framework thus provides a unified foundation for analyzing and improving the efficiency of fundamental string-processing problems through the lens of prefix queries.", "published": "2025-10-22T17:52:05Z", "query": "microelectrode arrays", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:03.757565"}
{"arxiv_id": "2510.19776v1", "title": "Exoplanetary radio emission predictions and detectability in the SKA era", "summary": "Radio observations provide a window into a planet's interior and play a crucial role in studying its atmosphere and surface, key factors to find potential habitability. The discovery of thousands of exoplanets, together with advances in radio astronomy through the Square Kilometre Array (SKA), motivates the search for planetary-scale radio emissions. Here, we employ the radiometric Bode's law (RBL) and machine learning techniques to analyze a dataset of 1330 confirmed exoplanets, aiming to estimate their potential radio emission. Permutation Importance (PI) and SHapley Additive exPlanations (SHAP) analyses indicate that a planet's mass, radius, orbital semi-major axis, and distance from Earth are sufficient to dependably forecast its radio flux and frequency. The random forest model accurately reproduces these radio characteristics, confirming its reliability for exoplanetary radio predictions. Considering observational constraints, we find that 64 exoplanets could generate signals detectable by the SKA, 52 of which remain observable in the intermediate AA* deployment. Among these, MASCARA-1 b stands out with a predicted flux of 7.209 mJy at 135.1 MHz, making it an excellent SKA-Low target. Meanwhile, WASP-18 b, with a flux of 18.638 mJy peaking at 812.9 MHz, is the most promising candidate for SKA-Mid. These results show that the SKA can detect gas giants, such as MASCARA-1 b (SNR&gt;400) and WASP-18 b (SNR&gt;4236), within feasible integration times. Additionally, we identify four candidates (HATS-18 b, WASP-12 b, WASP-103 b, and WASP-121 b) that are likely affected by radio quenching, highlighting the importance of considering this effect in target selection for observation campaigns.", "published": "2025-10-22T17:11:09Z", "query": "microelectrode arrays", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.757752"}
{"arxiv_id": "2510.19888v1", "title": "Joint neutrino oscillation analysis from the T2K and NOvA experiments", "summary": "The landmark discovery that neutrinos have mass and can change type (or \"flavor\") as they propagate -- a process called neutrino oscillation -- has opened up a rich array of theoretical and experimental questions being actively pursued today. Neutrino oscillation remains the most powerful experimental tool for addressing many of these questions, including whether neutrinos violate charge-parity (CP) symmetry, which has possible connections to the unexplained preponderance of matter over antimatter in the universe. Oscillation measurements also probe the mass-squared differences between the different neutrino mass states ($\\Delta m^2$), whether there are two light states and a heavier one (normal ordering) or vice versa (inverted ordering), and the structure of neutrino mass and flavor mixing. Here, we carry out the first joint analysis of data sets from NOvA and T2K, the two currently operating long-baseline neutrino oscillation experiments (hundreds of kilometers of neutrino travel distance), taking advantage of our complementary experimental designs and setting new constraints on several neutrino sector parameters. This analysis provides new precision on the $\\Delta m^2_{32}$ mass difference, finding $2.43^{+0.04}_{-0.03}\\ \\left(-2.48^{+0.03}_{-0.04}\\right)\\times 10^{-3}~\\mathrm{eV}^2$ in the normal (inverted) ordering, as well as a $3\\sigma$ interval on $\\delta_{\\rm CP}$ of $[-1.38\\pi,\\ 0.30\\pi]$ $\\left([-0.92\\pi,\\ -0.04\\pi]\\right)$ in the normal (inverted) ordering. The data show no strong preference for either mass ordering, but notably if inverted ordering were assumed true within the three-flavor mixing paradigm, then our results would provide evidence of CP symmetry violation in the lepton sector.", "published": "2025-10-22T16:27:07Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.757942"}
{"arxiv_id": "2510.19697v1", "title": "High Uniformity GaN Micro-pyramids and Platelets by Selective Area   Growth", "summary": "The development of uniform GaN micro-pyramids and platelets via selective area growth is a critical step toward advancing III-nitride device technologies, particularly for micro-light-emitting diode applications. This work investigates the origins of morphological non-uniformity in micro-pyramids and micro-platelets grown by metal-organic chemical vapor deposition (MOCVD). We observe that a direct one-step growth approach leads to significant growth rate inhomogeneity across arrays. To shed light on this issue, we examine the mechanisms driving non-uniformity and explore process modifications aimed at mitigating these effects. Building on these insights, we propose a controlled multi-step growth strategy that combines sequen-tial growth and thermal treatment phases. This approach is demonstrated to enhance surface morphology and structural regularity. The work contributes to the broader objective of enabling scalable, high-precision GaN microstructure fabrication for next-generation optoelectronic applications.", "published": "2025-10-22T15:47:20Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.758046"}
{"arxiv_id": "2510.19309v1", "title": "Neuromorphic computing for anomaly detection in a laser powder bed   fusion process", "summary": "This study is the first application of spiking neural networks (SNNs) for anomaly detection in the Laser Powder Bed Fusion (LPBF) additive manufacturing process. The neural networks were used to identify print processing anomalies generated by dropping of laser energy during the printing of individual layers in a Ti-6Al-4V alloy lattice structures. Associated changes in the laser generated melt pool were observed using an in-process photodiode monitoring technique. photodiode sensors capturing plasma and infrared radiations reflected from the print bed of the metal 3D printer were utilized to detect sudden changes caused by anomalies during the printing process. The algorithm is first implemented on non-neuromorphic hardware including a central processing unit (CPU), on Field Programmable Gate Arrays (FPGA) and then on neuromorphic Intel's Loihi chip. Improved detection of anomalies is achieved by adjusting the spike latency of the neural network, which reduces masking of information by noise within the monitored temporal signal. The work demonstrates the possibility of using low-power neuromorphic chips within an edge framework for anomaly detection in additive manufacturing and creates a framework for the process.", "published": "2025-10-22T07:13:31Z", "query": "microelectrode arrays", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.758196"}
{"arxiv_id": "2510.19260v1", "title": "Res-DPU: Resource-shared Digital Processing-in-memory Unit for Edge-AI   Workloads", "summary": "Processing-in-memory (PIM) has emerged as the go to solution for addressing the von Neumann bottleneck in edge AI accelerators. However, state-of-the-art (SoTA) digital PIM approaches suffer from low compute density, primarily due to the use of bulky bit cells and transistor-heavy adder trees, which impose limitations on macro scalability and energy efficiency. This work introduces Res-DPU, a resource-shared digital PIM unit, with a dual-port 5T SRAM latch and shared 2T AND compute logic. This reflects the per-bit multiplication cost to just 5.25T and reduced the transistor count of the PIM array by up to 56% over the SoTA works. Furthermore, a Transistor-Reduced 2D Interspersed Adder Tree (TRAIT) with FA-7T and PG-FA-26T helps reduce the power consumption of the adder tree by up to 21.35% and leads to improved energy efficiency by 59% compared to conventional 28T RCA designs. We propose a Cycle-controlled Iterative Approximate-Accurate Multiplication (CIA2M) approach, enabling run-time accuracy-latency trade-offs without requiring error-correction circuitry. The 16 KB REP-DPIM macro achieves 0.43 TOPS throughput and 87.22 TOPS/W energy efficiency in TSMC 65nm CMOS, with 96.85% QoR for ResNet-18 or VGG-16 on CIFAR-10, including 30% pruning. The proposed results establish a Res-DPU module for highly scalable and energy-efficient real-time edge AI accelerators.", "published": "2025-10-22T05:32:07Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:03.758351"}
{"arxiv_id": "2510.19132v2", "title": "Evidence of Energy Injection in the Short and Distant GRB 250221A", "summary": "We present the photometric and spectroscopic analysis of the short-duration GRB 250221A ($T_{90}=1.80\\pm0.32$ s), using a data set from the optical facilities COLIBR\\'I, the Harlingten 50 cm Telescope, and the Very Large Telescope. We complement these observations with data from the \\textit{Neil Gehrels Swift Observatory} and the \\textit{Einstein Probe}, as well as radio observations from the Very Large Array. GRB 250221A is among the few short GRBs with direct afterglow spectroscopy, which gives a secure redshift determination of $z=0.768$ and allows the unambiguous identification of the host as a galaxy with a star-formation rate of $\\sim3\\,M_\\odot\\,{\\rm yr}^{-1}$. The X-ray and optical light curves up to $T_0+10$ ks (where $T_0$ refers to the GRB trigger time) are well described by forward-shock synchrotron emission in the slow-cooling regime within the standard fireball framework. However, at $T_0+0.6$ days, both the X-ray and optical bands exhibit an excess over the same interval, which we interpret as evidence of energy injection into a jet with a half-opening angle of $\\theta_j=11.5^{\\circ}$ through a refreshed shock powered by late central engine activity or a radially stratified ejecta. The burst properties (duration, spectral hardness, peak energy, and location in the Amati plane) all favour a compact binary merger origin. However, our modelling of the afterglow suggests a dense circumburst medium ($n\\sim80$ cm$^{-3}$), which is more typical of a Collapsar environment. This tension over the classification of this burst (short-hard vs. long-soft) as inferred from the prompt and afterglow emissions makes GRB~250221A an unusual event and underscores the limitations of duration-based classifications and the importance of multi-wavelength, time-resolved follow-up observations.", "published": "2025-10-21T23:44:55Z", "query": "microelectrode arrays", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.758487"}
{"arxiv_id": "2510.19071v1", "title": "Modeling atmospheric phase corruptions in high-frequency VLBI using   Gaussian processes", "summary": "Using very long baseline interferometry (VLBI) observations at (sub)millimeter wavelengths, the Event Horizon Telescope (EHT) currently achieves the finest angular resolution of any astronomical facility, necessary for imaging the horizon-scale structure around supermassive black holes. A significant calibration challenge for high-frequency VLBI stems from rapid variations in the atmospheric water vapor content above each telescope in the array, which induce corresponding fluctuations in the phase of the correlated signal that limit the coherent integration time and thus the achievable sensitivity. In this paper, we introduce a model that describes station-based phase corruptions jointly with a parameterization for the source structure. We adopt a Gaussian Process (GP) prescription for the time evolution of these phase corruptions, which provides sufficient flexibility to capture even highly erratic phase behavior. The use of GPs permits the application of a Kalman filtering algorithm for numerical marginalization of these phase corruptions, which permits efficient exploration of the remaining parameter space. Our model also removes the need to specify an arbitrary ``reference station'' during calibration, instead establishing a global phase zeropoint by enforcing the GPs at all stations to have fixed mean and finite variance. We validate our method using a real EHT observation of the blazar 3C 279, demonstrating that our approach yields calibration solutions that are consistent with those determined by the EHT Collaboration. The model presented here can be straightforwardly extended to incorporate frequency-dependent phase behavior, such as is relevant for the frequency phase transfer calibration technique.", "published": "2025-10-21T20:51:04Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:03.758677"}
{"arxiv_id": "2510.19046v1", "title": "Near-field enhancement by a metasurface at octupole plasmon resonance in   periodic disc dimers", "summary": "Local intensity enhancement by plasmonic nanoparticles is widely used in optics and photonics. However, the effect is usually based on dipole resonances in the particles. Recently, it has been shown that quadrupole and octupole resonances can exhibit comparable, or even higher near-field enhancement. In this work, we focus on the near-field enhancement by a metasurface composed of gold-disc dimers arranged in a rectangular array. We find that, owing to an octupole plasmon resonance coupled to a surface lattice resonance, exceptionally high near-field enhancement in the dimer gaps can be achieved in the visible spectral range. To gain insight into the effect, we develop an analytical model for the effective dipole and octupole polarizabilities of the particles in an array, and discover, that at decreasing array periods, the dipole polarizability tends to vanish, while the octupole polarizability rapidly increases. Hence, octupole resonances can find applications in high-density arrays of plasmonic resonators. We propose a method to numerically evaluate multipole polarizabilities of a single particle, applying it to the gold dimer that we consider. The influence of the array on the effective polarizabilities is then verified by numerical calculations and a good agreement is obtained. Our results may open new avenues for investigating the properties of periodic plasmonic structures based on higher-order multipole resonances and their applications.", "published": "2025-10-21T20:04:00Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:03.758804"}
{"arxiv_id": "2510.18957v1", "title": "Galaxy Activity, Torus and Outflow Survey (GATOS) X: Molecular gas   clumpiness under the influence of AGN", "summary": "The distribution of molecular gas on small scales regulates star formation and the growth of supermassive black holes in galaxy centers, yet the role of active galactic nuclei (AGN) feedback in shaping this distribution remains poorly constrained. We investigate how AGN influence the small-scale structure of molecular gas in galaxy centers, by measuring the clumpiness of CO(3 - 2) emission observed with the Atacama Large Millimeter/submillimeter Array (ALMA) in the nuclear regions (50 - 200 pc from the AGN) of 16 nearby Seyfert galaxies from the Galaxy Activity, Torus, and Outflow Survey (GATOS). To quantify clumpiness, we apply three different methods: (1) the median of the pixel-by-pixel contrast between the original and smoothed maps; (2) the ratio of the total excess flux to the total flux, after substracting the background smoothed emission; and (3) the fraction of total flux coming from clumpy regions, interpreted as the mass fraction in clumps. We find a negative correlation between molecular gas clumpiness and AGN X-ray luminosity (L_X), suggesting that higher AGN activity is associated with smoother gas distributions. All methods reveal a turnover in this relation around L_X = 10^{42} erg/s, possibly indicating a threshold above which AGN feedback becomes efficient at dispersing dense molecular structures and suppressing future star formation. Our findings provide new observational evidence that AGN feedback can smooth out dense gas structures in galaxy centers.", "published": "2025-10-21T18:00:01Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:03.758970"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.393251"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "optogenetics interface", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.393818"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:07.394139"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "optogenetics interface", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.394406"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "optogenetics interface", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:07.394662"}
{"arxiv_id": "2510.20560v1", "title": "Super-robust telecommunications enabled by topological half-supermodes", "summary": "Topological photonics offers transformative potential for robust integrated waveguide devices due to their backscattering-immune properties. However, their integration faces two fundamental challenges: mode symmetry mismatch with conventional waveguides and prohibitive dimensions. We successfully overcome these two critical challenges by introducing a novel valley-ridge gap waveguide based on topological half-supermode engineering. By strategically hybridizing ridge waveguide modes and valley kink states, we create an exotic odd-symmetric supermode enabling robust propagation and ultra-compact operation. The further implementation of a perfect electric conductor boundary halves lateral dimensions while eliminating radiation loss. Crucially, our proposed valley-ridge interface achieves direct transverse electric mode matching with standard waveguides without transition structures, enabling seamless integration. Experimental results demonstrate reflection losses lower than -15 dB in realistic telecommunication scenarios with super-robust signal propagation through sharp bends. This work innovatively conceptualizes topological half-supermodes and pioneers their practical applications for integrated waveguide devices, establishing a completely new waveguide class that uniquely combines robust backscattering immunity with deep subwavelength compactness.", "published": "2025-10-23T13:41:49Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.394937"}
{"arxiv_id": "2510.20559v1", "title": "High-Resolution Echelle Spectroscopy for Solar System Planets: A   Planet-as-Point-Source Analogy", "summary": "Transmission spectroscopy has proven to be an effective technique for characterizing exoplanet atmospheres. However, transmission spectroscopy requires planetary transits, which occur for only a small fraction of planetary systems due to geometric alignment constraints; hence, characterizing exoplanets through their reflected spectrum of host stars will be helpful for a large number of exoplanets. The upcoming extremely large telescopes (ELTs) will be able to study the reflected spectra of exoplanets. Here, we present a preliminary optical design and a detailed throughput analysis of the instrumentation that interfaces the 2.34 m Vainu Bappu Telescope prime focus to an existing high-resolution echelle spectrograph with disk-integrated light from solar system objects. One of the primary objectives is to obtain high-resolution, high signal-to-noise reflected spectra from the solar system objects.", "published": "2025-10-23T13:40:33Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.395084"}
{"arxiv_id": "2510.20463v1", "title": "Suspension-Free Integrated Cavity Brillouin Optomechanics on a Chip", "summary": "Cavity optomechanical systems enable coherent photon-phonon interactions essential for quantum technologies, yet high-performance devices have been limited to suspended structures. Here, we overcome this limitation by demonstrating cavity Brillouin optomechanics in a suspension-free racetrack microring resonator on a lithium-niobate-on-sapphire chip, a platform that merits high stability and scalability. We demonstrate coherent coupling between telecom-band optical modes and a 9.6-GHz phonon mode, achieving a maximum cooperativity of $0.41$ and a phonon quality-factor-frequency product of $10^{13}\\,\\mathrm{Hz}$. The momentum-matching condition inherent to traveling-wave Brillouin interactions establishes a one-to-one mapping between optical wavelength and phonon frequency, enabling multi-channel parallel operations across nearly $300\\,\\mathrm{MHz}$ in phonon frequency and $40\\,\\mathrm{nm}$ in optical wavelength. Our suspension-free architecture provides a coherent photon-phonon interface compatible with wafer-scale integration, opening pathways toward hybrid quantum circuits that unite photonic, phononic, and superconducting components on a single chip.", "published": "2025-10-23T11:59:39Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.395260"}
{"arxiv_id": "2510.20416v1", "title": "Learning Coupled Earth System Dynamics with GraphDOP", "summary": "Interactions between different components of the Earth System (e.g. ocean, atmosphere, land and cryosphere) are a crucial driver of global weather patterns. Modern Numerical Weather Prediction (NWP) systems typically run separate models of the different components, explicitly coupled across their interfaces to additionally model exchanges between the different components. Accurately representing these coupled interactions remains a major scientific and technical challenge of weather forecasting. GraphDOP is a graph-based machine learning model that learns to forecast weather directly from raw satellite and in-situ observations, without reliance on reanalysis products or traditional physics-based NWP models. GraphDOP simultaneously embeds information from diverse observation sources spanning the full Earth system into a shared latent space. This enables predictions that implicitly capture cross-domain interactions in a single model without the need for any explicit coupling. Here we present a selection of case studies which illustrate the capability of GraphDOP to forecast events where coupled processes play a particularly key role. These include rapid sea-ice freezing in the Arctic, mixing-induced ocean surface cooling during Hurricane Ian and the severe European heat wave of 2022. The results suggest that learning directly from Earth System observations can successfully characterise and propagate cross-component interactions, offering a promising path towards physically consistent end-to-end data-driven Earth System prediction with a single model.", "published": "2025-10-23T10:36:20Z", "query": "optogenetics interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.395486"}
{"arxiv_id": "2510.20389v1", "title": "Symmetry in Software Platforms as an Architectural Principle", "summary": "Software platforms often act as structure preserving systems. They provide consistent interfaces and behaviors that remain stable under specific transformations that we denote as symmetries. This paper explores the idea that architectural robustness emerges from enforcing such structural regularities", "published": "2025-10-23T09:38:32Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.395611"}
{"arxiv_id": "2510.20338v1", "title": "Comparative Analysis of Thermal Models for Test Masses in   Next-Generation Gravitational Wave Interferometers", "summary": "Accurate thermal modeling of Terminal Test Masses (TTMs) is crucial for optimizing the sensitivity of gravitational wave interferometers like Virgo. In fact, in such gravitational wave detectors even minimal laser power absorption can induce performance-limiting thermal effects. This paper presents a detailed investigation into the steady-state thermal behavior of TTMs. In particular, future scenarios of increased intracavity laser beam power and optical coating absorption are considered. We develop and compare two numerical models: a comprehensive model incorporating volumetric heat absorption in both the multilayer coating and the bulk substrate, and a simplified reduced model where the coating's thermal impact is represented as an effective surface boundary condition on the substrate. Our simulations were focused on a ternary coating design, which is a candidate for use in next-generation detectors. Results reveal that higher coating absorption localizes peak temperatures near the coating--vacuum interface. Importantly, the comparative analysis demonstrates that temperature predictions from the reduced model differ from the detailed model by only milli-Kelvins, a discrepancy often within the experimental uncertainties of the system's thermo-physical parameters. This finding suggests that computationally efficient reduced models can provide sufficiently accurate results for thermal management and first-order distortion analyses. Moreover, the critical role of accurately characterizing the total power absorbed by the coating is emphasized.", "published": "2025-10-23T08:37:47Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.395846"}
{"arxiv_id": "2510.20333v1", "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in   Dynamic On-Device Environments?", "summary": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.", "published": "2025-10-23T08:33:24Z", "query": "optogenetics interface", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.396028"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "optogenetics interface", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.396200"}
{"arxiv_id": "2510.20211v1", "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a \"source-of-truth\" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors.   We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$ improvement).", "published": "2025-10-23T04:57:00Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.396395"}
{"arxiv_id": "2510.20184v1", "title": "A Unified and Scalable Method for Optimization over Graphs of Convex   Sets", "summary": "A Graph of Convex Sets (GCS) is a graph in which vertices are associated with convex programs and edges couple pairs of programs through additional convex costs and constraints. Any optimization problem over an ordinary weighted graph (e.g., the shortest-path, the traveling-salesman, and the minimum-spanning-tree problems) can be naturally generalized to a GCS, yielding a new class of problems at the interface of combinatorial and convex optimization with numerous applications. In this paper, we introduce a unified method for solving any such problem. Starting from an integer linear program that models an optimization problem over a weighted graph, our method automatically produces an efficient mixed-integer convex formulation of the corresponding GCS problem. This formulation is based on homogenization (perspective) transformations, and the resulting program is solved to global optimality using off-the-shelf branch-and-bound solvers. We implement this framework in GCSOPT, an open-source and easy-to-use Python library designed for fast prototyping. We illustrate the versatility and scalability of our approach through multiple numerical examples and comparisons.", "published": "2025-10-23T04:08:39Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.396593"}
{"arxiv_id": "2510.20128v1", "title": "A Full Stack Framework for High Performance Quantum-Classical Computing", "summary": "To address the growing needs for scalable High Performance Computing (HPC) and Quantum Computing (QC) integration, we present our HPC-QC full stack framework and its hybrid workload development capability with modular hardware/device-agnostic software integration approach. The latest development in extensible interfaces for quantum programming, dispatching, and compilation within existing mature HPC programming environment are demonstrated. Our HPC-QC full stack enables high-level, portable invocation of quantum kernels from commercial quantum SDKs within HPC meta-program in compiled languages (C/C++ and Fortran) as well as Python through a quantum programming interface library extension. An adaptive circuit knitting hypervisor is being developed to partition large quantum circuits into sub-circuits that fit on smaller noisy quantum devices and classical simulators. At the lower-level, we leverage Cray LLVM-based compilation framework to transform and consume LLVM IR and Quantum IR (QIR) from commercial quantum software frontends in a retargetable fashion to different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU and GPU workloads (including solving linear system of equations, quantum optimization, and simulating quantum phase transitions) have been demonstrated on HPE EX supercomputers to illustrate functionality and execution viability for all three components developed so far. This work provides the framework for a unified quantum-classical programming environment built upon classical HPC software stack (compilers, libraries, parallel runtime and process scheduling).", "published": "2025-10-23T02:07:29Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:07.396814"}
{"arxiv_id": "2510.20114v1", "title": "Fabrication and Structural Analysis of Trilayers for Tantalum Josephson   Junctions with Ta$_2$O$_5$ Barriers", "summary": "Tantalum (Ta) has recently emerged as a promising low-loss material, enabling record coherence times in superconducting qubits. This enhanced performance is largely attributed to its stable native oxide, which is believed to host fewer two-level system (TLS) defects key $-$ contributors to decoherence in superconducting circuits. Nevertheless, aluminum oxide (AlO$_x$) remains the predominant choice for Josephson junction barriers in most qubit architectures. In this study, we systematically investigate various techniques for forming high-quality oxide layers on $\\alpha$-phase tantalum ($\\alpha$-Ta) thin films, aiming to develop effective Josephson junction barriers. We explore thermal oxidation in a tube furnace, rapid thermal annealing, as well as plasma oxidation of both room-temperature and heated Ta films, and propose a mechanistic picture of the underlying oxidation mechanisms. All methods yield Ta$_2$O$_5$, the same compound as tantalum's native oxide. Among these, plasma oxidation produces the smoothest and highest-quality oxide layers, making it particularly well-suited for Josephson junction fabrication. Furthermore, we demonstrate the successful epitaxial growth of $\\alpha$-Ta atop oxidized $\\alpha$-Ta films, paving the way for the realization of trilayer Ta/Ta-O/Ta Josephson junctions with clean, low-loss interfaces.", "published": "2025-10-23T01:35:14Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.397021"}
{"arxiv_id": "2510.20088v1", "title": "RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling", "summary": "Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves to desired directions to enhance signal coverage and/or improve signal-to-noise ratio (SNR) at the user equipment (UE). We present the design, implementation, and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2 millimeter wave (mmWave) frequency band. We first introduce the design of 1,024 element (32 $\\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2 interface can be leveraged to dynamically control RIS configurations without modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G system, we conducted extensive field trials in both indoor and outdoor environments. The results of the O-RAN link coverage trials show that the deployed RIS provides substantial received signal power gains, ranging from 9 to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively. Handling UE mobility in RIS-assisted systems is challenging due to the need for joint RIS and UE beam management. For that, we develop two UE mobility management algorithms and evaluate them in real-time operation using the RIS O-RAN testbed. These algorithms leverage the received signal power at the UE to jointly track and adapt the RIS and UE beams in real time as the UE moves. The findings draw important insights into the practical feasibility of integrating RIS into O-RAN systems to enhance coverage, mobility support, and link reliability in next-generation cellular networks.", "published": "2025-10-23T00:09:57Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.397204"}
{"arxiv_id": "2510.19983v1", "title": "A transmon qubit realized by exploiting the superconductor-insulator   transition", "summary": "Superconducting qubits are among the most promising platforms for realizing practical quantum computers. One requirement to create a quantum processor is nonlinearity, which in superconducting circuits is typically achieved by sandwiching a layer of aluminum oxide between two aluminum electrodes to form a Josephson junction. These junctions, however, face several limitations that hinder their scalability: the small superconducting gap of aluminum necessitates millikelvin operating temperatures, the material interfaces lead to dissipation, and the sandwich geometry adds unwelcome capacitance for high-frequency applications. In this work, we address all three limitations using a novel superconducting weak link based on the superconductor-insulator transition. By locally thinning a single film of niobium nitride, we exploit its thickness-driven superconductor-insulator transition to form a weak link employing only atomic layer deposition and atomic layer etching. We utilize our weak links to produce a transmon qubit, '$planaron$', with a measured anharmonicity of $\\alpha/2\\pi = 235$ MHz; at present, the linewidth is $\\kappa/2\\pi = 15 \\mathrm{\\: MHz}$. The high superconducting gap of niobium nitride can enable operation at elevated temperatures in future devices, and the fully planar geometry of the weak link eliminates superfluous material interfaces and capacitances. The investigation of small patches of material near the SIT can shed new light on the nature of the transition, including the role of dissipation and finite-size effects.", "published": "2025-10-22T19:29:01Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.397424"}
{"arxiv_id": "2510.19968v1", "title": "Q-RAN: Quantum-Resilient O-RAN Architecture", "summary": "The telecommunications industry faces a dual transformation: the architectural shift toward Open Radio Access Networks (O-RAN) and the emerging threat from quantum computing. O-RAN disaggregated, multi-vendor architecture creates a larger attack surface vulnerable to crypt-analytically relevant quantum computers(CRQCs) that will break current public key cryptography. The Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate, as adversaries can intercept encrypted data today for future decryption. This paper presents Q-RAN, a comprehensive quantum-resistant security framework for O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204), integrated with Quantum Random Number Generators (QRNG) for cryptographic entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate Authority (PQ-CA) within the SMO framework. This work provides a complete roadmap for securing disaggregated O-RAN ecosystems against quantum adversaries.", "published": "2025-10-22T18:57:44Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.397610"}
{"arxiv_id": "2510.19949v1", "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "summary": "Building agents that generalize across web, desktop, and mobile environments remains an open challenge, as prior systems rely on environment-specific interfaces that limit cross-platform deployment. We introduce Surfer 2, a unified architecture operating purely from visual observations that achieves state-of-the-art performance across all three environments. Surfer 2 integrates hierarchical context management, decoupled planning and execution, and self-verification with adaptive recovery, enabling reliable operation over long task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior systems without task-specific fine-tuning. With multiple attempts, Surfer 2 exceeds human performance on all benchmarks. These results demonstrate that systematic orchestration amplifies foundation model capabilities and enables general-purpose computer control through visual interaction alone, while calling for a next-generation vision language model to achieve Pareto-optimal cost-efficiency.", "published": "2025-10-22T18:21:52Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.397751"}
{"arxiv_id": "2510.19923v1", "title": "Novel Defect Universality Classes from Interacting RG Interfaces", "summary": "We search for new defect universality classes by considering localised interactions placed on an RG interface separating two interacting multiscalar CFTs in $4-\\varepsilon$ dimensions. Studying interactions spread throughout the entire interface as well as defects restricted to lines and surfaces within the interface, we find that this setup leads to a great number of additional physical fixed points in the space of conformal defects. At one loop it is possible to interpret these fixed points as coming from defects placed within a single bulk whose interaction is an average of the two sides. This averaging means that it is possible to identify conformal defects with considerably less global symmetry than was possible beforehand. We finally compute conformal data for this setup, and find the free energy associated with these RG interfaces.", "published": "2025-10-22T18:00:04Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.397915"}
{"arxiv_id": "2510.19747v1", "title": "Review of Tools for Zero-Code LLM Based Application Development", "summary": "Large Language Models (LLMs) are transforming software creation by enabling zero code development platforms. Our survey reviews recent platforms that let users build applications without writing code, by leveraging LLMs as the brains of the development process. We adopt a broad survey methodology, categorizing platforms based on key dimensions such as interface style, backend integration, output type, and extensibility. We analyze both dedicated LLM based app builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and general no code platforms (e.g., Bubble, Glide) that integrate LLM capabilities. We present a taxonomy categorizing these platforms by their interface (conversational, visual, etc.), supported LLM backends, output type (chatbot, full application, workflow), and degree of extensibility. Core features such as autonomous agents, memory management, workflow orchestration, and API integrations are in scope of the survey. We provide a detailed comparison, highlighting each platform's strengths and limitations. Trade offs (customizability, scalability, vendor lock-in) are discussed in comparison with traditional and low code development approaches. Finally, we outline future directions, including multimodal interfaces, on device LLMs, and improved orchestration for democratizing app creation with AI. Our findings indicate that while zero code LLM platforms greatly reduce the barrier to creating AI powered applications, they still face challenges in flexibility and reliability. Overall, the landscape is rapidly evolving, offering exciting opportunities to empower non programmers to create sophisticated software.", "published": "2025-10-22T16:41:16Z", "query": "optogenetics interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.398081"}
{"arxiv_id": "2510.19721v1", "title": "An active-flux-type scheme for ideal MHD with provable positivity and   discrete divergence-free property", "summary": "We develop a positivity-preserving (PP) PAMPA (Point-Average-Moment PolynomiAl-interpreted) scheme that enforces a discrete divergence-free (DDF) magnetic field for ideal MHD on Cartesian grids. Extending our 1D invariant-domain-preserving (IDP) PAMPA framework (Abgrall, Jiao, Liu, Wu, SIAM J. Sci. Comput., to appear) to multidimensional, multiwave MHD, the method combines a limiter-free PP update of interface point values via a new nonconservative reformulation with a local DDF projection. Cell averages are provably PP under a mild a~priori positivity condition on one cell-centered state, using: (i) DDF-constrained interface values, (ii) a PP limiter only at the cell center, (iii) a PP flux with appropriate wave-speed bounds, and (iv) a suitable discretization of the Godunov--Powell source term. The PP proof employs geometric quasi-linearization (GQL; Wu &amp; Shu, SIAM Review, 2023), which linearizes the pressure constraint. The scheme avoids explicit polynomial reconstructions, is compatible with arbitrarily high-order strong-stability-preserving (SSP) time integration, and is simple to implement. Robustness and resolution are enhanced by a problem-independent Lax-type entropy troubled-cell indicator using only two characteristic speeds and a convex oscillation elimination (COE) mechanism with a new intercell-difference norm. Tests -- including a blast wave with plasma $\\beta \\approx 2.51\\times 10^{-6}$ and jets up to Mach $10^{4}$ -- show high-order accuracy, sharp MHD-structure resolution, and strong-shock robustness. To our knowledge, this is the first active-flux-type ideal-MHD method rigorously PP for both cell averages and interface point values while maintaining DDF throughout.", "published": "2025-10-22T16:07:03Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.398315"}
{"arxiv_id": "2510.19682v1", "title": "M5 branes on ADE singularities: BPS spectrum and partition functions", "summary": "The dynamics of a stack of M5 branes probing a transverse multi-centered Taub-NUT space are described by a class of 6d $\\mathcal{N}=(1,0)$ superconformal field theories known as the M-string orbifold SCFTs. We determine the equivariant partition functions for this class of theories on a geometric background of type $T^2\\times\\mathbb{C}^2/\\Gamma$, where $\\Gamma \\in\\{\\mathcal{C}_N,\\mathcal{Q}_N, \\mathcal{T},\\mathcal{O},\\mathcal{I}\\}$ is an arbitrary finite subgroup of $SU(2)$. The partition functions are built out of contributions from BPS strings as well as BPS particles that arise upon putting the 6d theory on a circle. We find that BPS particle contributions can be expressed in terms of $\\Gamma$-covariant Hilbert series which count holomorphic sections of vector bundles on the orbifold singularity with monodromy specified by an irreducible representation of $\\Gamma$. The BPS string contributions, on the other hand, are given by the elliptic genera of 2d $\\mathcal{N}=(0,4)$ $\\Gamma$-dressed quiver gauge theories, obtained by stacking Kronheimer-Nakajima quivers of type $\\Gamma$ between interfaces that support current algebras for the McKay dual affine Lie algebra $\\widehat{\\mathfrak{g}}$. We obtain explicit expressions for the elliptic genera of arbitrary BPS string configurations corresponding to fractional instanton strings on $\\mathbb{C}^2/\\Gamma$, and for the case of star-shaped quivers of type $\\Gamma\\in\\{\\mathcal{Q}_4,\\mathcal{T},\\mathcal{O},\\mathcal{I}\\}$ we give a prescription to compute the elliptic genera by gluing 2d analogues of Gaiotto and Witten's $T[SU(N)]$ theories.", "published": "2025-10-22T15:27:43Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.398536"}
{"arxiv_id": "2510.19582v1", "title": "From Interface Dynamics to Darcy Scale Description of Multiphase Flow in   Porous Media", "summary": "An outstanding characteristic of porous media, desired in many applications, is the large surface area, which facilitates solid-fluid interactions, making porous media an extreme case in colloid and interface science. In two-fluid systems, wetting and the balance of capillary and viscous forces control fluid displacement processes, leading to a wide range of complex flow regimes with rich spatio-temporal dynamics. Macroscopic two-phase flow is historically described through the phenomenological extensions of Darcy's law. Besides many other shortcomings and inconsistencies, it covers only connected pathway flow in the capillary-dominated flow regime in a rigorous manner while other flow regimes with moving interfaces and associated topological changes are entirely implicit. Given the lack of adequate descriptions, upscaling multiphase flow from pore to Darcy scale represents a long-standing challenge paving into the fields of thermodynamics, statistical mechanics and integral geometry. In this review, we compare novel concepts which have been largely motivated by experimental insights, enabled by significant advances in pore-scale imaging and modeling over the last decade.", "published": "2025-10-22T13:34:16Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.398690"}
{"arxiv_id": "2510.19554v1", "title": "Observation of counterion binding in the inner Helmholtz layer at the   ionic surfactant-water interface", "summary": "Understanding specific ion adsorption within the inner Helmholtz layer remains central to electrochemistry yet experimentally elusive. Here we directly quantify counterion adsorption and extract the associated thermodynamic parameters within the inner Helmholtz layer using phase-sensitive sum-frequency vibrational spectroscopy (PS-SFVS). Using sodium dodecyl sulfate (SDS) as a model ionic surfactant, we determine the Na+ and DS- surface densities by simultaneously analyzing interfacial free OH response and the diffuse-layer SF signal, from which the adsorption thermodynamic parameters are derived. We then construct an adsorption phase diagram that maps the evolution of Na+ and DS- species in the compact layer as functions of bulk NaCl and SDS concentrations, revealing a continuous increase in surface ion pairing. The DS-: Na+ pairing ratio gradually decreases with increasing NaCl and approaches 2.8 at the supersaturation state prior to surface nucleation. These results establish PS-SFVS as a quantitative probe of ion-headgroup correlations in charged interfaces and reveal the thermodynamic mechanism underlying counterion-mediated interfacial ordering, with broad implications for electrolyte design, biomembrane stability, and soft-matter assembly.", "published": "2025-10-22T13:07:52Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.398881"}
{"arxiv_id": "2510.19551v1", "title": "4d Maxwell on the Edge: Global Aspects of Boundary Conditions and   Duality", "summary": "We revisit Maxwell theory in 4d with a boundary, with particular attention to the global properties of the boundary conditions, both in the free (topological) and interacting (conformal) cases. We analyze the fate of Wilson-'t Hooft lines, identifying the subset that is trivialized on the boundary and the ones that become topological, thus generating a boundary 1-form symmetry. We further study how the boundary conditions are mapped to each other by 3d topological interfaces implementing bulk dualities and rescalings of the coupling. Together, these interfaces generate an $SL(2,\\mathbb{Q})$ action on the bulk complexified coupling $\\tau$, and they generalize the usual $SL(2,\\mathbb{Z})$ action on 3d CFTs by including both topological and non-topological manipulations within a unified framework. We then show how to recover our results in a streamlined way from a SymTFT picture in 5d with corners. Finally, we comment on the possible inclusion of non-compact 3d edge modes.", "published": "2025-10-22T13:04:03Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:07.399019"}
{"arxiv_id": "2510.19514v1", "title": "From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals   for Multivariate Time-Series Multi-class Classification", "summary": "In eXplainable Artificial Intelligence (XAI), instance-based explanations for time series have gained increasing attention due to their potential for actionable and interpretable insights in domains such as healthcare. Addressing the challenges of explainability of state-of-the-art models, we propose a prototype-driven framework for generating sparse counterfactual explanations tailored to 12-lead ECG classification models. Our method employs SHAP-based thresholds to identify critical signal segments and convert them into interval rules, uses Dynamic Time Warping (DTW) and medoid clustering to extract representative prototypes, and aligns these prototypes to query R-peaks for coherence with the sample being explained. The framework generates counterfactuals that modify only 78% of the original signal while maintaining 81.3% validity across all classes and achieving 43% improvement in temporal stability. We evaluate three variants of our approach, Original, Sparse, and Aligned Sparse, with class-specific performance ranging from 98.9% validity for myocardial infarction (MI) to challenges with hypertrophy (HYP) detection (13.2%). This approach supports near realtime generation (&lt; 1 second) of clinically valid counterfactuals and provides a foundation for interactive explanation platforms. Our findings establish design principles for physiologically-aware counterfactual explanations in AI-based diagnosis systems and outline pathways toward user-controlled explanation interfaces for clinical deployment.", "published": "2025-10-22T12:09:50Z", "query": "optogenetics interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.399151"}
{"arxiv_id": "2510.19512v1", "title": "Design Considerations for Human Oversight of AI: Insights from Co-Design   Workshops and Work Design Theory", "summary": "As AI systems become increasingly capable and autonomous, domain experts' roles are shifting from performing tasks themselves to overseeing AI-generated outputs. Such oversight is critical, as undetected errors can have serious consequences or undermine the benefits of AI. Effective oversight, however, depends not only on detecting and correcting AI errors but also on the motivation and engagement of the oversight personnel and the meaningfulness they see in their work. Yet little is known about how domain experts approach and experience the oversight task and what should be considered to design effective and motivational interfaces that support human oversight. To address these questions, we conducted four co-design workshops with domain experts from psychology and computer science. We asked them to first oversee an AI-based grading system, and then discuss their experiences and needs during oversight. Finally, they collaboratively prototyped interfaces that could support them in their oversight task. Our thematic analysis revealed four key user requirements: understanding tasks and responsibilities, gaining insight into the AI's decision-making, contributing meaningfully to the process, and collaborating with peers and the AI. We integrated these empirical insights with the SMART model of work design to develop a generalizable framework of twelve design considerations. Our framework links interface characteristics and user requirements to the psychological processes underlying effective and satisfying work. Being grounded in work design theory, we expect these considerations to be applicable across domains and discuss how they extend existing guidelines for human-AI interaction and theoretical frameworks for effective human oversight by providing concrete guidance on the design of engaging and meaningful interfaces that support human oversight of AI systems.", "published": "2025-10-22T12:05:51Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:07.399299"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural recording technology", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:10.808662"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.434099"}
{"arxiv_id": "2510.20794v1", "title": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common   Feature", "summary": "This paper presents a Multi-Object Tracking (MOT) framework that fuses radar and camera data to enhance tracking efficiency while minimizing manual interventions. Contrary to many studies that underutilize radar and assign it a supplementary role--despite its capability to provide accurate range/depth information of targets in a world 3D coordinate system--our approach positions radar in a crucial role. Meanwhile, this paper utilizes common features to enable online calibration to autonomously associate detections from radar and camera. The main contributions of this work include: (1) the development of a radar-camera fusion MOT framework that exploits online radar-camera calibration to simplify the integration of detection results from these two sensors, (2) the utilization of common features between radar and camera data to accurately derive real-world positions of detected objects, and (3) the adoption of feature matching and category-consistency checking to surpass the limitations of mere position matching in enhancing sensor association accuracy. To the best of our knowledge, we are the first to investigate the integration of radar-camera common features and their use in online calibration for achieving MOT. The efficacy of our framework is demonstrated by its ability to streamline the radar-camera mapping process and improve tracking precision, as evidenced by real-world experiments conducted in both controlled environments and actual traffic scenarios. Code is available at https://github.com/radar-lab/Radar_Camera_MOT", "published": "2025-10-23T17:54:57Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.434626"}
{"arxiv_id": "2510.20784v1", "title": "A Coherence-Based Measure of AGI", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized \\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of proficiencies across cognitive domains derived from the Cattell--Horn--Carroll (CHC) model of human cognition. While elegant, this definition assumes \\textit{compensability} -- that exceptional ability in some domains can offset failure in others. True general intelligence, however, should reflect \\textit{coherent sufficiency}: balanced competence across all essential domains. We propose a coherence-aware measure of AGI based on the integral of generalized means over a continuum of compensability exponents. This formulation spans arithmetic, geometric, and harmonic regimes, and the resulting \\textit{area under the curve} (AUC) quantifies robustness under varying compensability assumptions. Unlike the arithmetic mean, which rewards specialization, the AUC penalizes imbalance and captures inter-domain dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5, the coherence-adjusted AUC reveals that both systems remain far from general competence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating the generalized mean thus yields a principled, interpretable, and stricter foundation for measuring genuine progress toward AGI.", "published": "2025-10-23T17:51:42Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.434843"}
{"arxiv_id": "2510.20776v1", "title": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "summary": "This work proposes a new generation-based 3D reconstruction method, named Cupid, that accurately infers the camera pose, 3D shape, and texture of an object from a single 2D image. Cupid casts 3D reconstruction as a conditional sampling process from a learned distribution of 3D objects, and it jointly generates voxels and pixel-voxel correspondences, enabling robust pose and shape estimation under a unified generative framework. By representing both input camera poses and 3D shape as a distribution in a shared 3D latent space, Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that produces initial 3D geometry with associated 2D projections for pose recovery; and (2) a refinement stage that integrates pose-aligned image features to enhance structural fidelity and appearance details. Extensive experiments demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3 dB PSNR gain and an over 10% Chamfer Distance reduction, while matching monocular estimators on pose accuracy and delivering superior visual fidelity over baseline 3D generative models. For an immersive view of the 3D results generated by Cupid, please visit cupid3d.github.io.", "published": "2025-10-23T17:47:38Z", "query": "cognitive enhancement neuroscience", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.434992"}
{"arxiv_id": "2510.20774v1", "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to   Field-Guided Data Generation", "summary": "Large-scale and diverse datasets are vital for training robust robotic manipulation policies, yet existing data collection methods struggle to balance scale, diversity, and quality. Simulation offers scalability but suffers from sim-to-real gaps, while teleoperation yields high-quality demonstrations with limited diversity and high labor cost. We introduce FieldGen, a field-guided data generation framework that enables scalable, diverse, and high-quality real-world data collection with minimal human supervision. FieldGen decomposes manipulation into two stages: a pre-manipulation phase, allowing trajectory diversity, and a fine manipulation phase requiring expert precision. Human demonstrations capture key contact and pose information, after which an attraction field automatically generates diverse trajectories converging to successful configurations. This decoupled design combines scalable trajectory diversity with precise supervision. Moreover, FieldGen-Reward augments generated data with reward annotations to further enhance policy learning. Experiments demonstrate that policies trained with FieldGen achieve higher success rates and improved stability compared to teleoperation-based baselines, while significantly reducing human effort in long-term real-world data collection. Webpage is available at https://fieldgen.github.io/.", "published": "2025-10-23T17:47:12Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.435179"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "cognitive enhancement neuroscience", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.435366"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:14.435526"}
{"arxiv_id": "2510.20724v1", "title": "Phonon Polaritons and Epsilon Near Zero Modes in Sapphire Nanostructures", "summary": "Surface phonon polaritons (SPhPs) are promising candidates for enhanced light--matter interactions due to their efficient and low-loss light confinement features. In this work, we present unique light-matter interactions in saphhire within its Reststrahlen bands (RBs) across the long-wave infrared (LWIR) spectrum ($\\omega = 385$-$1050~\\mathrm{cm}^{-1}$). Particularly, we investigated the nanocone-patterned sapphire resonator array, with specific attention to its in-plane and out-of-plane permittivity components. Through Fourier transform infrared spectroscopy measurement and full-wave photonic simulations, we identified a range of optical excitations in the RBs, including three SPhPs, two hyperbolic volume phonon polaritons (HVPhPs), and one epsilon-near-zero (ENZ) mode. The depth-resolved confocal Raman spectroscopy revealed strongly enhanced Raman signals on the nanostructured surface, suggesting the mode coupling between phonons and phonon-polaritons, which was further confirmed by the finite element modeling of polarizability. This exploratory study provides in-depth insights into the dynamics of LWIR phonon polaritons and ENZ modes in the nanostructured sapphire, indicating its great potential for innovative nanophotonic applications.", "published": "2025-10-23T16:41:52Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.435642"}
{"arxiv_id": "2510.20714v1", "title": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of   EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "summary": "In this study we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models on JHFRAT assessment data and additional electronic health record (EHR) variables. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labelling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.", "published": "2025-10-23T16:31:09Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.435928"}
{"arxiv_id": "2510.20712v1", "title": "Enhancement of Curie Temperature in Ferromagnetic Insulator-Topological   Insulator Heterostructures", "summary": "We theoretically analyze the topological insulator (TI) surface state mediated interactions between local moments in a proximate 2D ferromagnetic insulator (FMI) motivated by recent experiments that show a significant increase in the Curie temperature Tc of FMI-TI heterostructures. Such interactions have been investigated earlier with a focus on dilute magnetic dopants in TIs. Our problem involves a dense set of moments for which we find that the short range Bloembergen-Rowland interaction, arising from virtual particle-hole transitions between the valence and conduction bands, dominates over the oscillatory Ruderman-Kittel-Kasuya-Yosida (RKKY) interaction. We show that the Tc enhancement is proportional to the Van Vleck susceptibility and that the spin-momentum locking of surface states leads to out-of-plane ferromagnetic order in the FMI. We investigate how the hybridization between top and bottom surfaces in a thin TI film impacts Tc enhancement, and show how our results can help understand recent experiments on atomically thin Cr2Te3-(Bi,Sb)2Te3.", "published": "2025-10-23T16:28:43Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.436085"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "cognitive enhancement neuroscience", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.436275"}
{"arxiv_id": "2510.20707v1", "title": "Mixing Importance with Diversity: Joint Optimization for KV Cache   Compression in Large Vision-Language Models", "summary": "Recent large vision-language models (LVLMs) demonstrate remarkable capabilities in processing extended multi-modal sequences, yet the resulting key-value (KV) cache expansion creates a critical memory bottleneck that fundamentally limits deployment scalability. While existing KV cache compression methods focus on retaining high-importance KV pairs to minimize storage, they often overlook the modality-specific semantic redundancy patterns that emerge distinctively in multi-modal KV caches. In this work, we first analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying levels of redundancy across attention heads. We show that relying solely on importance can only cover a subset of the full KV cache information distribution, leading to potential loss of semantic coverage. To address this, we propose \\texttt{MixKV}, a novel method that mixes importance with diversity for optimized KV cache compression in LVLMs. \\texttt{MixKV} adapts to head-wise semantic redundancy, selectively balancing diversity and importance when compressing KV pairs. Extensive experiments demonstrate that \\texttt{MixKV} consistently enhances existing methods across multiple LVLMs. Under extreme compression (budget=64), \\texttt{MixKV} improves baseline methods by an average of \\textbf{5.1\\%} across five multi-modal understanding benchmarks and achieves remarkable gains of \\textbf{8.0\\%} and \\textbf{9.0\\%} for SnapKV and AdaKV on GUI grounding tasks, all while maintaining comparable inference efficiency. Furthermore, \\texttt{MixKV} extends seamlessly to LLMs with comparable performance gains. Our code is available at \\href{https://github.com/xuyang-liu16/MixKV}{\\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.", "published": "2025-10-23T16:17:47Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.436498"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "cognitive enhancement neuroscience", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.436667"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.436852"}
{"arxiv_id": "2510.20680v1", "title": "Atomic state interferometry for complex vector light", "summary": "Features of complex vector light become important in any interference effects, including scattering, diffraction, and non-linear processes. Here we are investigating the role of polarization-structured light in atomic state interferometers. Unlike optical or atomic path interferometers, these facilitate local interference between atomic transition amplitudes and hence the orthogonal optical polarization components driving these transitions. We develop a fully analytical description for the inter action of generalized structured light with an atomic four state system, that is multiply connected via optical as well as magnetic transitions. Our model allows us to identify spatially dependent dark states, associated with spatially structured absorption coefficients, which are defined by the geometry of the polarization state and the magnetic field direction. We illustrate this for a range of optical beams including polarization vortices, optical skyrmions and polarization lattices. This results in a new interpretation and an enhanced understanding of atomic state interferometry, and a versatile mechanism to modify and control optical absorption as a function of polarization and magnetic field alignment.", "published": "2025-10-23T15:53:03Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.436969"}
{"arxiv_id": "2510.20677v1", "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice   Conversion", "summary": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.", "published": "2025-10-23T15:52:03Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.437126"}
{"arxiv_id": "2510.20669v1", "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing   Maps and Spiking Dynamics for Waste Classification", "summary": "Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.", "published": "2025-10-23T15:47:09Z", "query": "cognitive enhancement neuroscience", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:14.437291"}
{"arxiv_id": "2510.20661v1", "title": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale   High-Quality Dataset", "summary": "Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable progress. However, two key challenges remain : 1) the absence of a large-scale high-quality UHR T2I dataset, and (2) the neglect of tailored training strategies for fine-grained detail synthesis in UHR scenarios. To tackle the first challenge, we introduce \\textbf{UltraHR-100K}, a high-quality dataset of 100K UHR images with rich captions, offering diverse content and strong visual fidelity. Each image exceeds 3K resolution and is rigorously curated based on detail richness, content complexity, and aesthetic quality. To tackle the second challenge, we propose a frequency-aware post-training method that enhances fine-detail generation in T2I diffusion models. Specifically, we design (i) \\textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning on detail-critical denoising steps, and (ii) \\textit{Soft-Weighting Frequency Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to softly constrain frequency components, encouraging high-frequency detail preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks demonstrate that our approach significantly improves the fine-grained detail quality and overall fidelity of UHR image generation. The code is available at \\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.", "published": "2025-10-23T15:34:53Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.437499"}
{"arxiv_id": "2510.20659v1", "title": "Kinetics of Peierls dimerization transition: Machine learning   force-field approach", "summary": "We present a machine learning (ML) force-field framework for simulating the non-equilibrium dynamics of charge-density-wave (CDW) order driven by the Peierls instability. Since the Peierls distortion arises from the coupling between lattice displacements and itinerant electrons, evaluating the adiabatic forces during time evolution is computationally intensive, particularly for large systems. To overcome this bottleneck, we develop a generalized Behler-Parrinello neural-network architecture -- originally formulated for ab initio molecular dynamics -- to accurately and efficiently predict forces from local structural environments. Using the locality of electronic responses, the resulting ML force field achieves linear scaling efficiency while maintaining quantitative accuracy. Large-scale dynamical simulations using this framework uncover a two-stage coarsening behavior of CDW domains: an early-time regime characterized by a power-law growth $L \\sim t^{\\alpha}$ with an effective exponent $\\alpha \\approx 0.7$, followed by a crossover to the Allen-Cahn scaling $L \\sim \\sqrt{t}$ at late times. The enhanced early-time coarsening is attributed to anisotropic domain-wall motion arising from electron-mediated directional interactions. This work demonstrates the promise of ML-based force fields for multiscale dynamical modeling of condensed-matter lattice models.", "published": "2025-10-23T15:33:31Z", "query": "cognitive enhancement neuroscience", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.437710"}
{"arxiv_id": "2510.20657v1", "title": "Risk Psychology &amp; Cyber-Attack Tactics", "summary": "We examine whether measured cognitive processes predict cyber-attack behavior. We analyzed data that included psychometric scale responses and labeled attack behaviors from cybersecurity professionals who conducted red-team operations against a simulated enterprise network. We employed multilevel mixed-effects Poisson regression with technique counts nested within participants to test whether cognitive processes predicted technique-specific usage. The scales significantly predicted technique use, but effects varied by technique rather than operating uniformly. Neither expertise level nor experimental treatment condition significantly predicted technique patterns, indicating that cognitive processes may be stronger drivers of technique selection than training or experience. These findings demonstrate that individual cognitive differences shape cyber-attack behavior and support the development of psychology-informed defense strategies.", "published": "2025-10-23T15:31:47Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.437925"}
{"arxiv_id": "2510.20653v1", "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During   Inference-Time LLM Reflection", "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.", "published": "2025-10-23T15:26:18Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:14.438146"}
{"arxiv_id": "2510.20647v1", "title": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI", "summary": "Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the language of the question. Our evaluation spans two tasks: MGSM and GPQA Diamond. Beyond measuring answer accuracy, we also analyze cognitive attributes in the reasoning traces. We find that English reasoning traces exhibit a substantially higher presence of these cognitive behaviors, and that reasoning in English generally yields higher final-answer accuracy, with the performance gap increasing as tasks become more complex. However, this English-centric strategy is susceptible to a key failure mode - getting \"Lost in Translation,\" where translation steps lead to errors that would have been avoided by question's language reasoning.", "published": "2025-10-23T15:22:00Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.438314"}
{"arxiv_id": "2510.20641v1", "title": "Integrating Machine Learning into Belief-Desire-Intention Agents:   Current Advances and Open Challenges", "summary": "Thanks to the remarkable human-like capabilities of machine learning (ML) models in perceptual and cognitive tasks, frameworks integrating ML within rational agent architectures are gaining traction. Yet, the landscape remains fragmented and incoherent, often focusing on embedding ML into generic agent containers while overlooking the expressive power of rational architectures--such as Belief-Desire-Intention (BDI) agents. This paper presents a fine-grained systematisation of existing approaches, using the BDI paradigm as a reference. Our analysis illustrates the fast-evolving literature on rational agents enhanced by ML, and identifies key research opportunities and open challenges for designing effective rational ML agents.", "published": "2025-10-23T15:15:45Z", "query": "cognitive enhancement neuroscience", "relevance": 0.1, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:14.438452"}
{"arxiv_id": "2510.20640v1", "title": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in   Cloud Systems", "summary": "In this paper, we present DiRecGNN, an attention-enhanced entity recommendation framework for monitoring cloud services at Microsoft. We provide insights on the usefulness of this feature as perceived by the cloud service owners and lessons learned from deployment. Specifically, we introduce the problem of recommending the optimal subset of attributes (dimensions) that should be tracked by an automated watchdog (monitor) for cloud services. To begin, we construct the monitor heterogeneous graph at production-scale. The interaction dynamics of these entities are often characterized by limited structural and engagement information, resulting in inferior performance of state-of-the-art approaches. Moreover, traditional methods fail to capture the dependencies between entities spanning a long range due to their homophilic nature. Therefore, we propose an attention-enhanced entity ranking model inspired by transformer architectures. Our model utilizes a multi-head attention mechanism to focus on heterogeneous neighbors and their attributes, and further attends to paths sampled using random walks to capture long-range dependencies. We also employ multi-faceted loss functions to optimize for relevant recommendations while respecting the inherent sparsity of the data. Empirical evaluations demonstrate significant improvements over existing methods, with our model achieving a 43.1% increase in MRR. Furthermore, product teams who consumed these features perceive the feature as useful and rated it 4.5 out of 5.", "published": "2025-10-23T15:14:09Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.438591"}
{"arxiv_id": "2510.20635v1", "title": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language   Model", "summary": "Curiosity serves as a pivotal conduit for human beings to discover and learn new knowledge. Recent advancements of large language models (LLMs) in natural language processing have sparked discussions regarding whether these models possess capability of curiosity-driven learning akin to humans. In this paper, starting from the human curiosity assessment questionnaire Five-Dimensional Curiosity scale Revised (5DCR), we design a comprehensive evaluation framework that covers dimensions such as Information Seeking, Thrill Seeking, and Social Curiosity to assess the extent of curiosity exhibited by LLMs. The results demonstrate that LLMs exhibit a stronger thirst for knowledge than humans but still tend to make conservative choices when faced with uncertain environments. We further investigated the relationship between curiosity and thinking of LLMs, confirming that curious behaviors can enhance the model's reasoning and active learning abilities. These findings suggest that LLMs have the potential to exhibit curiosity similar to that of humans, providing experimental support for the future development of learning capabilities and innovative research in LLMs.", "published": "2025-10-23T15:05:17Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.438751"}
{"arxiv_id": "2510.20633v1", "title": "Systematic study of multi-magnon binding energies in the FM-AFM   $J_1$-$J_2$ chain", "summary": "We present a systematic study of multi-magnon bound states (MBSs) in the spin-$\\tfrac{1}{2}$ FM-AFM $J_1$-$J_2$ chain under magnetic fields using the density-matrix renormalization group method. As a quantitative measure of stability, we compute the magnon binding energy $E_{\\rm b}(M,p)$ for bound clusters of size $p$ over wide ranges of the frustration ratio $J_2/|J_1|$ and the normalized magnetization $M/M_{\\rm s}$. Near saturation, we benchmark our data against the analytic two-magnon result and map out a clear hierarchy of $p$-magnon states, whose phase boundaries follow an empirical scaling $J_{2,{\\rm c}}(p;p\\!+\\!1)/|J_1|\\!\\approx\\!0.34\\,p^{-2.3}$ for large $p$. We further quantify the relation between the most stable $p$ and the zero-field pitch angle $\\theta$, verifying the conjectured inequality $1/p&gt;\\theta/\\pi&gt;1/(p+1)$ up to $p \\lesssim 9$. The binding energy shows pronounced suppression as $J_2/|J_1|\\!\\to\\!1/4^+$ and, for some frustration values, attains a maximum below full saturation, indicating that partial depolarization enhances bound-magnon mobility. Close to the FM instability, $E_{\\rm b}(M_{\\rm s},p)$ exhibits an empirical power-law vanishing consistent with a quantum-Lifshitz scenario. Our results provide a comprehensive, experimentally relevant map of MBS stability across field and frustration, offering concrete guidance for inelastic probes in quasi-one-dimensional magnets.", "published": "2025-10-23T15:04:56Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.438928"}
{"arxiv_id": "2510.20630v1", "title": "Quantum Processing Unit (QPU) processing time Prediction with Machine   Learning", "summary": "This paper explores the application of machine learning (ML) techniques in predicting the QPU processing time of quantum jobs. By leveraging ML algorithms, this study introduces predictive models that are designed to enhance operational efficiency in quantum computing systems. Using a dataset of about 150,000 jobs that follow the IBM Quantum schema, we employ ML methods based on Gradient-Boosting (LightGBM) to predict the QPU processing times, incorporating data preprocessing methods to improve model accuracy. The results demonstrate the effectiveness of ML in forecasting quantum jobs. This improvement can have implications on improving resource management and scheduling within quantum computing frameworks. This research not only highlights the potential of ML in refining quantum job predictions but also sets a foundation for integrating AI-driven tools in advanced quantum computing operations.", "published": "2025-10-23T15:04:18Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.439075"}
{"arxiv_id": "2510.20615v1", "title": "MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure   Elucidation", "summary": "Mass spectrometry (MS) plays a critical role in molecular identification, significantly advancing scientific discovery. However, structure elucidation from MS data remains challenging due to the scarcity of annotated spectra. While large-scale pretraining has proven effective in addressing data scarcity in other domains, applying this paradigm to mass spectrometry is hindered by the complexity and heterogeneity of raw spectral signals. To address this, we propose MS-BART, a unified modeling framework that maps mass spectra and molecular structures into a shared token vocabulary, enabling cross-modal learning through large-scale pretraining on reliably computed fingerprint-molecule datasets. Multi-task pretraining objectives further enhance MS-BART's generalization by jointly optimizing denoising and translation task. The pretrained model is subsequently transferred to experimental spectra through finetuning on fingerprint predictions generated with MIST, a pre-trained spectral inference model, thereby enhancing robustness to real-world spectral variability. While finetuning alleviates the distributional difference, MS-BART still suffers molecular hallucination and requires further alignment. We therefore introduce a chemical feedback mechanism that guides the model toward generating molecules closer to the reference structure. Extensive evaluations demonstrate that MS-BART achieves SOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is faster by one order of magnitude than competing diffusion-based methods, while comprehensive ablation studies systematically validate the model's effectiveness and robustness.", "published": "2025-10-23T14:45:28Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:14.439264"}
{"arxiv_id": "2510.20614v1", "title": "Performance of an open-source image-based history matching framework for   CO$_2$ storage", "summary": "We present a history matching (HM) workflow applied to the International FluidFlower benchmark study dataset, which features high-resolution images of CO$_2$ storage in a meter-scale, geologically complex reservoir. The dataset provides dense spatial and temporal observations of fluid displacement, offering a rare opportunity to validate and enhance HM techniques for geological carbon storage (GCS). The combination of detailed experimental data and direct visual observation of flow behavior at this scale is novel and valuable. This study explores the potential and limitations of using experimental data to calibrate standard models for GCS simulation. By leveraging high-resolution images and resulting interpretations of fluid phase distributions, we adjust uncertain parameters and reduce the mismatch between simulation results and observed data. Simulations are performed using the open-source OPM Flow simulator, while the open-source Everest decision-making tool is employed to conduct the HM. After the HM process, the final simulation results show good agreement with the experimental CO$_2$ storage data. This suggests that the system can be effectively described using standard flow equations, conventional saturation functions, and typical PVT properties for CO$_2$-brine mixtures. Our results demonstrate that the Wasserstein distance is a particularly effective metric for matching multi-phase, multi-component flow data. The entire workflow is implemented in a Python package named pofff (Python OPM Flow FluidFlower), which organizes all functionality through a single input file. This design ensures reproducibility and facilitates future extensions of the study.", "published": "2025-10-23T14:45:07Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:14.439402"}
{"arxiv_id": "2510.20611v1", "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast   Cancer Detection", "summary": "Breast cancer is considered the most critical and frequently diagnosed cancer in women worldwide, leading to an increase in cancer-related mortality. Early and accurate detection is crucial as it can help mitigate possible threats while improving survival rates. In terms of prediction, conventional diagnostic methods are often limited by variability, cost, and, most importantly, risk of misdiagnosis. To address these challenges, machine learning (ML) has emerged as a powerful tool for computer-aided diagnosis, with feature selection playing a vital role in improving model performance and interpretability. This research study proposes an integrated framework that incorporates customized Particle Swarm Optimization (PSO) for feature selection. This framework has been evaluated on a comprehensive set of 29 different models, spanning classical classifiers, ensemble techniques, neural networks, probabilistic algorithms, and instance-based algorithms. To ensure interpretability and clinical relevance, the study uses cross-validation in conjunction with explainable AI methods. Experimental evaluation showed that the proposed approach achieved a superior score of 99.1\\% across all performance metrics, including accuracy and precision, while effectively reducing dimensionality and providing transparent, model-agnostic explanations. The results highlight the potential of combining swarm intelligence with explainable ML for robust, trustworthy, and clinically meaningful breast cancer diagnosis.", "published": "2025-10-23T14:42:50Z", "query": "cognitive enhancement neuroscience", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:14.439586"}
{"arxiv_id": "2510.20797v1", "title": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "summary": "A common strategy to reduce the computational costs of using long contexts in retrieval-augmented generation (RAG) with large language models (LLMs) is soft context compression, where the input sequence is transformed into a shorter continuous representation. We develop a lightweight and simple mean-pooling approach that consistently outperforms the widely used compression-tokens architecture, and study training the same compressor to output multiple compression ratios. We conduct extensive experiments across in-domain and out-of-domain QA datasets, as well as across model families, scales, and compression ratios. Overall, our simple mean-pooling approach achieves the strongest performance, with a relatively small drop when training for multiple compression ratios. More broadly though, across architectures and training regimes the trade-offs are more nuanced, illustrating the complex landscape of compression methods.", "published": "2025-10-23T17:57:23Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.986939"}
{"arxiv_id": "2510.20777v1", "title": "Learning Optimal Power Flow with Pointwise Constraints", "summary": "Training learning parameterizations to solve optimal power flow (OPF) with pointwise constraints is proposed. In this novel training approach, a learning parameterization is substituted directly into an OPF problem with constraints required to hold over all problem instances. This is different from existing supervised learning methods in which constraints are required to hold across the average of problem instances. Training with pointwise constraints is undertaken in the dual domain with the use of augmented Lagrangian and dual gradient ascent algorithm. Numerical experiments demonstrate that training with pointwise constraints produces solutions with smaller constraint violations. Experiments further demonstrated that pointwise constraints are most effective at reducing constraint violations in corner cases - defined as those realizations in which constraints are most difficult to satisfy. Gains are most pronounced in power systems with large numbers of buses.", "published": "2025-10-23T17:48:10Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.987245"}
{"arxiv_id": "2510.20774v1", "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to   Field-Guided Data Generation", "summary": "Large-scale and diverse datasets are vital for training robust robotic manipulation policies, yet existing data collection methods struggle to balance scale, diversity, and quality. Simulation offers scalability but suffers from sim-to-real gaps, while teleoperation yields high-quality demonstrations with limited diversity and high labor cost. We introduce FieldGen, a field-guided data generation framework that enables scalable, diverse, and high-quality real-world data collection with minimal human supervision. FieldGen decomposes manipulation into two stages: a pre-manipulation phase, allowing trajectory diversity, and a fine manipulation phase requiring expert precision. Human demonstrations capture key contact and pose information, after which an attraction field automatically generates diverse trajectories converging to successful configurations. This decoupled design combines scalable trajectory diversity with precise supervision. Moreover, FieldGen-Reward augments generated data with reward annotations to further enhance policy learning. Experiments demonstrate that policies trained with FieldGen achieve higher success rates and improved stability compared to teleoperation-based baselines, while significantly reducing human effort in long-term real-world data collection. Webpage is available at https://fieldgen.github.io/.", "published": "2025-10-23T17:47:12Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:17.987443"}
{"arxiv_id": "2510.20768v1", "title": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines", "summary": "Retrieval-Augmented Generation (RAG) has emerged as the dominant architectural pattern to operationalize Large Language Model (LLM) usage in Cyber Threat Intelligence (CTI) systems. However, this design is susceptible to poisoning attacks, and previously proposed defenses can fail for CTI contexts as cyber threat information is often completely new for emerging attacks, and sophisticated threat actors can mimic legitimate formats, terminology, and stylistic conventions. To address this issue, we propose that the robustness of modern RAG defenses can be accelerated by applying source credibility algorithms on corpora, using PageRank as an example. In our experiments, we demonstrate quantitatively that our algorithm applies a lower authority score to malicious documents while promoting trusted content, using the standardized MS MARCO dataset. We also demonstrate proof-of-concept performance of our algorithm on CTI documents and feeds.", "published": "2025-10-23T17:43:00Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.987587"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "brain augmentation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:17.987708"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "brain augmentation", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:17.987883"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "brain augmentation", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:17.988036"}
{"arxiv_id": "2510.20674v1", "title": "Analyticup E-commerce Product Search Competition Technical Report from   Team Tredence_AICOE", "summary": "This study presents the multilingual e-commerce search system developed by the Tredence_AICOE team. The competition features two multilingual relevance tasks: Query-Category (QC) Relevance, which evaluates how well a user's search query aligns with a product category, and Query-Item (QI) Relevance, which measures the match between a multilingual search query and an individual product listing. To ensure full language coverage, we performed data augmentation by translating existing datasets into languages missing from the development set, enabling training across all target languages. We fine-tuned Gemma-3 12B and Qwen-2.5 14B model for both tasks using multiple strategies. The Gemma-3 12B (4-bit) model achieved the best QC performance using original and translated data, and the best QI performance using original, translated, and minority class data creation. These approaches secured 4th place on the final leaderboard, with an average F1-score of 0.8857 on the private test set.", "published": "2025-10-23T15:49:20Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:17.988178"}
{"arxiv_id": "2510.20668v1", "title": "From Masks to Worlds: A Hitchhiker's Guide to World Models", "summary": "This is not a typical survey of world models; it is a guide for those who want to build worlds. We do not aim to catalog every paper that has ever mentioned a ``world model\". Instead, we follow one clear road: from early masked models that unified representation learning across modalities, to unified architectures that share a single paradigm, then to interactive generative models that close the action-perception loop, and finally to memory-augmented systems that sustain consistent worlds over time. We bypass loosely related branches to focus on the core: the generative heart, the interactive loop, and the memory system. We show that this is the most promising path towards true world models.", "published": "2025-10-23T15:46:44Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.988290"}
{"arxiv_id": "2510.20548v1", "title": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering   via Reinforcement Learning", "summary": "Reinforcement learning has recently shown promise in improving retrieval-augmented generation (RAG). Despite these advances, its effectiveness in multi-hop question answering (QA) remains limited by two fundamental limitations: (i) global planning absence to structure multi-step reasoning, and (ii) unfaithful execution, which hinders effective query formulation and consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement learning framework designed to enhance global reasoning in multi-hop QA. GlobalRAG decomposes questions into subgoals, coordinates retrieval with reasoning, and refines evidence iteratively. To guide this process, we introduce Planning Quality Reward and SubGoal Completion Reward, which encourage coherent planning and reliable subgoal execution. In addition, a progressive weight annealing strategy balances process-oriented and outcome-based objectives. Extensive experiments on both in-domain and out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms strong baselines while using only 8k training data (42% of the training data used by strong baselines), achieving average improvements of 14.2% in both EM and F1.", "published": "2025-10-23T13:35:02Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.988435"}
{"arxiv_id": "2510.20535v1", "title": "ARC-Encoder: learning compressed text representations for large language   models", "summary": "Recent techniques such as retrieval-augmented generation or chain-of-thought reasoning have led to longer contexts and increased inference costs. Context compression techniques can reduce these costs, but the most effective approaches require fine-tuning the target model or even modifying its architecture. This can degrade its general abilities when not used for this specific purpose. Here we explore an alternative approach: an encoder that compresses the context into continuous representations which replace token embeddings in decoder LLMs. First, we perform a systematic study of training strategies and architecture choices for the encoder. Our findings led to the design of an Adaptable text Representations Compressor, named ARC-Encoder, which outputs $x$-times fewer continuous representations (typically $x\\!\\in\\!\\{4,8\\}$) than text tokens. We evaluate ARC-Encoder across a variety of LLM usage scenarios, ranging from in-context learning to context window extension, on both instruct and base decoders. Results show that ARC-Encoder achieves state-of-the-art performance on several benchmarks while improving computational efficiency at inference. Finally, we demonstrate that our models can be adapted to multiple decoders simultaneously, allowing a single encoder to generalize across different decoder LLMs. This makes ARC-Encoder a flexible and efficient solution for portable encoders that work seamlessly with multiple LLMs. We release a training code at https://github.com/kyutai-labs/ARC-Encoder , fine-tuning dataset and pretrained models are available at https://huggingface.co/collections/kyutai/arc-encoders-68ee18787301407d60a57047 .", "published": "2025-10-23T13:20:57Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:17.988594"}
{"arxiv_id": "2510.20505v1", "title": "Hierarchical Sequence Iteration for Heterogeneous Question Answering", "summary": "Retrieval-augmented generation (RAG) remains brittle on multi-step questions and heterogeneous evidence sources, trading accuracy against latency and token/tool budgets. This paper introducesHierarchical Sequence (HSEQ) Iteration for Heterogeneous Question Answering, a unified framework that (i) linearize documents, tables, and knowledge graphs into a reversible hierarchical sequence with lightweight structural tags, and (ii) perform structure-aware iteration to collect just-enough evidence before answer synthesis. A Head Agent provides guidance that leads retrieval, while an Iteration Agent selects and expands HSeq via structure-respecting actions (e.g., parent/child hops, table row/column neighbors, KG relations); Finally the head agent composes canonicalized evidence to genearte the final answer, with an optional refinement loop to resolve detected contradictions. Experiments on HotpotQA (text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1 gains over strong single-pass, multi-hop, and agentic RAG baselines with high efficiency. Besides, HSEQ exhibits three key advantages: (1) a format-agnostic unification that enables a single policy to operate across text, tables, and KGs without per-dataset specialization; (2) guided, budget-aware iteration that reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and (3) evidence canonicalization for reliable QA, improving answers consistency and auditability.", "published": "2025-10-23T12:48:18Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.988757"}
{"arxiv_id": "2510.20504v1", "title": "Speaking Clearly: A Simplified Whisper-Based Codec for Low-Bitrate   Speech Coding", "summary": "Speech codecs serve as bridges between continuous speech signals and large language models, yet face an inherent conflict between acoustic fidelity and semantic preservation. To mitigate this conflict, prevailing methods augment acoustic codecs with complex semantic supervision. We explore the opposite direction: a semantic-first approach that starts from a semantically-capable model and adapts it for high-fidelity acoustic reconstruction. Through empirical analysis, we discover that targeted architectural simplification can unlock the acoustic modeling potential of Whisper, a text-aligned Automatic Speech Recognition (ASR) model. Based on this finding, we propose SimWhisper-Codec, a novel codec that balances the semantic and acoustic preservation by leveraging a frozen, simplified Whisper encoder without requiring external supervision. Experimental results demonstrate that SimWhisper-Codec achieves superior performance in both semantic preservation and acoustic quality compared to semantically-supervised codecs such as Mimi Codec and SpeechTokenizer at similar bitrates, validating the effectiveness of our semantic-first approach. Code is available at https://github.com/ZhangXinWhut/SimWhisper-Codec.", "published": "2025-10-23T12:47:35Z", "query": "brain augmentation", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:17.988992"}
{"arxiv_id": "2510.20449v1", "title": "LM-mixup: Text Data Augmentation via Language Model based Mixup", "summary": "Instruction tuning is crucial for aligning Large Language Models (LLMs), yet the quality of instruction-following data varies significantly. While high-quality data is paramount, it is often scarce; conversely, abundant low-quality data is frequently discarded, leading to substantial information loss. Existing data augmentation methods struggle to augment this low-quality data effectively, and the evaluation of such techniques remains poorly defined. To address this, we formally define the task of Instruction Distillation: distilling multiple low-quality and redundant inputs into high-quality and coherent instruction-output pairs. Specifically, we introduce a comprehensive data construction pipeline to create MIXTURE, a 144K-sample dataset pairing low-quality or semantically redundant imperfect instruction clusters with their high-quality distillations. We then introduce LM-Mixup, by first performing supervised fine-tuning on MIXTURE and then optimizing it with reinforcement learning. This process uses three complementary reward signals: quality, semantic alignment, and format compliance, via Group Relative Policy Optimization (GRPO). We demonstrate that LM-Mixup effectively augments imperfect datasets: fine-tuning LLMs on its distilled data, which accounts for only about 3% of the entire dataset, not only surpasses full-dataset training but also competes with state-of-the-art high-quality data selection methods across multiple benchmarks. Our work establishes that low-quality data is a valuable resource when properly distilled and augmented with LM-Mixup, significantly enhancing the efficiency and performance of instruction-tuned LLMs.", "published": "2025-10-23T11:33:35Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.989274"}
{"arxiv_id": "2510.20385v1", "title": "Positional Encoding Field", "summary": "Diffusion Transformers (DiTs) have emerged as the dominant architecture for visual generation, powering state-of-the-art image and video models. By representing images as patch tokens with positional encodings (PEs), DiTs combine Transformer scalability with spatial and temporal inductive biases. In this work, we revisit how DiTs organize visual content and discover that patch tokens exhibit a surprising degree of independence: even when PEs are perturbed, DiTs still produce globally coherent outputs, indicating that spatial coherence is primarily governed by PEs. Motivated by this finding, we introduce the Positional Encoding Field (PE-Field), which extends positional encodings from the 2D plane to a structured 3D field. PE-Field incorporates depth-aware encodings for volumetric reasoning and hierarchical encodings for fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D space. Our PE-Field-augmented DiT achieves state-of-the-art performance on single-image novel view synthesis and generalizes to controllable spatial image editing.", "published": "2025-10-23T09:32:37Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:17.989633"}
{"arxiv_id": "2510.20356v1", "title": "FreeChunker: A Cross-Granularity Chunking Framework", "summary": "Chunking strategies significantly impact the effectiveness of Retrieval-Augmented Generation (RAG) systems. Existing methods operate within fixed-granularity paradigms that rely on static boundary identification, limiting their adaptability to diverse query requirements. This paper presents FreeChunker, a Cross-Granularity Encoding Framework that fundamentally transforms the traditional chunking paradigm: the framework treats sentences as atomic units and shifts from static chunk segmentation to flexible retrieval supporting arbitrary sentence combinations. This paradigm shift not only significantly reduces the computational overhead required for semantic boundary detection but also enhances adaptability to complex queries. Experimental evaluation on LongBench V2 demonstrates that FreeChunker achieves superior retrieval performance compared to traditional chunking methods, while significantly outperforming existing approaches in computational efficiency.", "published": "2025-10-23T08:57:00Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:17.989778"}
{"arxiv_id": "2510.20344v1", "title": "Neural Networks for Censored Expectile Regression Based on Data   Augmentation", "summary": "Expectile regression neural networks (ERNNs) are powerful tools for capturing heterogeneity and complex nonlinear structures in data. However, most existing research has primarily focused on fully observed data, with limited attention paid to scenarios involving censored observations. In this paper, we propose a data augmentation based ERNNs algorithm, termed DAERNN, for modeling heterogeneous censored data. The proposed DAERNN is fully data driven, requires minimal assumptions, and offers substantial flexibility. Simulation studies and real data applications demonstrate that DAERNN outperforms existing censored ERNNs methods and achieves predictive performance comparable to models trained on fully observed data. Moreover, the algorithm provides a unified framework for handling various censoring mechanisms without requiring explicit parametric model specification, thereby enhancing its applicability to practical censored data analysis.", "published": "2025-10-23T08:42:23Z", "query": "brain augmentation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:17.990007"}
{"arxiv_id": "2510.20310v1", "title": "Multi-Step Reasoning for Embodied Question Answering via Tool   Augmentation", "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments to obtain observations and answer questions related to the scene. Existing methods leverage VLMs to directly explore the environment and answer questions without explicit thinking or planning, which limits their reasoning ability and results in excessive or inefficient exploration as well as ineffective responses. In this paper, we introduce ToolEQA, an agent that integrates external tools with multi-step reasoning, where external tools can provide more useful information for completing the task, helping the model derive better exploration directions in the next step of reasoning and thus obtaining additional effective information. This enables ToolEQA to generate more accurate responses with a shorter exploration distance. To enhance the model's ability for tool-usage and multi-step reasoning, we further design a novel EQA data generation pipeline that automatically constructs large-scale EQA tasks with reasoning trajectories and corresponding answers. Based on the pipeline, we collect the EQA-RT dataset that contains about 18K tasks, divided into a training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping with the training set) and EQA-RT-Unseen (novel scenes). Experiments on EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by 9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot ToolEQA by 10% in success rate. In addition, ToolEQA also achieves state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench datasets, demonstrating its generality. Our homepage see https://tooleqa.github.io.", "published": "2025-10-23T08:02:08Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:17.990221"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "brain augmentation", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:17.990359"}
{"arxiv_id": "2510.20296v1", "title": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector   Database Perspective", "summary": "Retrieval-augmented generation (RAG) has emerged as one of the most prominent applications of vector databases. By integrating documents retrieved from a database into the prompt of a large language model (LLM), RAG enables more reliable and informative content generation. While there has been extensive research on vector databases, many open research problems remain once they are considered in the wider context of end-to-end RAG pipelines. One practical yet challenging problem is how to jointly optimize both system performance and generation quality in RAG, which is significantly more complex than it appears due to the numerous knobs on both the algorithmic side (spanning models and databases) and the systems side (from software to hardware). In this paper, we present RAG-Stack, a three-pillar blueprint for quality-performance co-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an intermediate representation that serves as an abstraction layer to decouple quality and performance aspects; (2) RAG-CM, a cost model for estimating system performance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that searches for high-quality, high-performance RAG configurations. We believe this three-pillar blueprint will become the de facto paradigm for RAG quality-performance co-optimization in the years to come.", "published": "2025-10-23T07:35:19Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.990520"}
{"arxiv_id": "2510.20291v1", "title": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal   Geo-Localization", "summary": "We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone Navigation. The task retrieves the most relevant geo-referenced image from a large multi-platform corpus (satellite/drone/ground) given a natural-language query. Two obstacles are severe inter-platform heterogeneity and a domain gap between generic training descriptions and platform-specific test queries. We mitigate these with a domain-aligned preprocessing pipeline and a Mixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite augmentation, and removal of orientation words; (ii) an LLM-based caption refinement pipeline to align textual semantics with the distinct visual characteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we train three platform experts using a progressive two-stage, hard-negative mining strategy to enhance discriminative power, and fuse their scores at inference. The system tops the official leaderboard, demonstrating robust cross-modal geo-localization under heterogeneous viewpoints.", "published": "2025-10-23T07:23:47Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:17.990627"}
{"arxiv_id": "2510.20280v1", "title": "Context-level Language Modeling by Learning Predictive Context   Embeddings", "summary": "Next-token prediction (NTP) is the cornerstone of modern large language models (LLMs) pretraining, driving their unprecedented capabilities in text generation, reasoning, and instruction following. However, the token-level prediction limits the model's capacity to capture higher-level semantic structures and long-range contextual relationships. To overcome this limitation, we introduce \\textbf{ContextLM}, a framework that augments standard pretraining with an inherent \\textbf{next-context prediction} objective. This mechanism trains the model to learn predictive representations of multi-token contexts, leveraging error signals derived from future token chunks. Crucially, ContextLM achieves this enhancement while remaining fully compatible with the standard autoregressive, token-by-token evaluation paradigm (e.g., perplexity). Extensive experiments on the GPT2 and Pythia model families, scaled up to $1.5$B parameters, show that ContextLM delivers consistent improvements in both perplexity and downstream task performance. Our analysis indicates that next-context prediction provides a scalable and efficient pathway to stronger language modeling, yielding better long-range coherence and more effective attention allocation with minimal computational overhead.", "published": "2025-10-23T07:09:45Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:17.990779"}
{"arxiv_id": "2510.20279v1", "title": "ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer   Science Research Workflows", "summary": "As large language models (LLMs) advance, the ultimate vision for their role in science is emerging: we could build an AI collaborator to effectively assist human beings throughout the entire scientific research process. We refer to this envisioned system as ResearchGPT. Given that scientific research progresses through multiple interdependent phases, achieving this vision requires rigorous benchmarks that evaluate the end-to-end workflow rather than isolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of scientific Q&amp;A pairs in computer science, built from 14k CC-licensed papers. It is constructed through a scalable, paper-grounded pipeline that combines retrieval-augmented generation (RAG) with multi-stage quality control to ensure factual grounding. From this unified corpus, we derive two complementary subsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to assist scientific research, and CS-50k, a large-scale training dataset. Extensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs into distinct capability tiers. Open models trained on CS-50k with supervised training and reinforcement learning demonstrate substantial improvements. Even 7B-scale models, when properly trained, outperform many larger proprietary systems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that making AI models better research assistants relies more on domain-aligned training with high-quality data than on pretraining scale or general benchmark performance. We release CS-4k and CS-50k in the hope of fostering AI systems as reliable collaborators in CS research.", "published": "2025-10-23T07:07:35Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.990954"}
{"arxiv_id": "2510.20260v1", "title": "Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM   Recommendation Updates", "summary": "Large Language Models (LLMs) empower recommendation systems through their advanced reasoning and planning capabilities. However, the dynamic nature of user interests and content poses a significant challenge: While initial fine-tuning aligns LLMs with domain knowledge and user preferences, it fails to capture such real-time changes, necessitating robust update mechanisms. This paper investigates strategies for updating LLM-powered recommenders, focusing on the trade-offs between ongoing fine-tuning and Retrieval-Augmented Generation (RAG). Using an LLM-powered user interest exploration system as a case study, we perform a comparative analysis of these methods across dimensions like cost, agility, and knowledge incorporation. We propose a hybrid update strategy that leverages the long-term knowledge adaptation of periodic fine-tuning with the agility of low-cost RAG. We demonstrate through live A/B experiments on a billion-user platform that this hybrid approach yields statistically significant improvements in user satisfaction, offering a practical and cost-effective framework for maintaining high-quality LLM-powered recommender systems.", "published": "2025-10-23T06:31:00Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.991102"}
{"arxiv_id": "2510.20206v1", "title": "RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via   Data Alignment and Test-Time Scaling", "summary": "Prompt design plays a crucial role in text-to-video (T2V) generation, yet user-provided prompts are often short, unstructured, and misaligned with training data, limiting the generative potential of diffusion-based T2V models. We present \\textbf{RAPO++}, a cross-stage prompt optimization framework that unifies training-data--aligned refinement, test-time iterative scaling, and large language model (LLM) fine-tuning to substantially improve T2V generation without modifying the underlying generative backbone. In \\textbf{Stage 1}, Retrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with semantically relevant modifiers retrieved from a relation graph and refactors them to match training distributions, enhancing compositionality and multi-object fidelity. \\textbf{Stage 2} introduces Sample-Specific Prompt Optimization (SSPO), a closed-loop mechanism that iteratively refines prompts using multi-source feedback -- including semantic alignment, spatial fidelity, temporal coherence, and task-specific signals such as optical flow -- yielding progressively improved video generation quality. \\textbf{Stage 3} leverages optimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing task-specific optimization patterns and enabling efficient, high-quality prompt generation even before inference. Extensive experiments across five state-of-the-art T2V models and five benchmarks demonstrate that RAPO++ achieves significant gains in semantic alignment, compositional reasoning, temporal stability, and physical plausibility, outperforming existing methods by large margins. Our results highlight RAPO++ as a model-agnostic, cost-efficient, and scalable solution that sets a new standard for prompt optimization in T2V generation. The code is available at https://github.com/Vchitect/RAPO.", "published": "2025-10-23T04:45:09Z", "query": "brain augmentation", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:17.991239"}
{"arxiv_id": "2510.20196v1", "title": "A Structured Review and Quantitative Profiling of Public Brain MRI   Datasets for Foundation Model Development", "summary": "The development of foundation models for brain MRI depends critically on the scale, diversity, and consistency of available data, yet systematic assessments of these factors remain scarce. In this study, we analyze 54 publicly accessible brain MRI datasets encompassing over 538,031 to provide a structured, multi-level overview tailored to foundation model development. At the dataset level, we characterize modality composition, disease coverage, and dataset scale, revealing strong imbalances between large healthy cohorts and smaller clinical populations. At the image level, we quantify voxel spacing, orientation, and intensity distributions across 15 representative datasets, demonstrating substantial heterogeneity that can influence representation learning. We then perform a quantitative evaluation of preprocessing variability, examining how intensity normalization, bias field correction, skull stripping, spatial registration, and interpolation alter voxel statistics and geometry. While these steps improve within-dataset consistency, residual differences persist between datasets. Finally, feature-space case study using a 3D DenseNet121 shows measurable residual covariate shift after standardized preprocessing, confirming that harmonization alone cannot eliminate inter-dataset bias. Together, these analyses provide a unified characterization of variability in public brain MRI resources and emphasize the need for preprocessing-aware and domain-adaptive strategies in the design of generalizable brain MRI foundation models.", "published": "2025-10-23T04:31:09Z", "query": "brain augmentation", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:17.991422"}
{"arxiv_id": "2510.20193v1", "title": "Multimedia-Aware Question Answering: A Review of Retrieval and   Cross-Modal Reasoning Architectures", "summary": "Question Answering (QA) systems have traditionally relied on structured text data, but the rapid growth of multimedia content (images, audio, video, and structured metadata) has introduced new challenges and opportunities for retrieval-augmented QA. In this survey, we review recent advancements in QA systems that integrate multimedia retrieval pipelines, focusing on architectures that align vision, language, and audio modalities with user queries. We categorize approaches based on retrieval methods, fusion techniques, and answer generation strategies, and analyze benchmark datasets, evaluation protocols, and performance tradeoffs. Furthermore, we highlight key challenges such as cross-modal alignment, latency-accuracy tradeoffs, and semantic grounding, and outline open problems and future research directions for building more robust and context-aware QA systems leveraging multimedia data.", "published": "2025-10-23T04:25:44Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.991548"}
{"arxiv_id": "2510.20178v1", "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic   Stereo Matching", "summary": "Temporally consistent depth estimation from stereo video is critical for real-world applications such as augmented reality, where inconsistent depth estimation disrupts the immersion of users. Despite its importance, this task remains challenging due to the difficulty in modeling long-term temporal consistency in a computationally efficient manner. Previous methods attempt to address this by aggregating spatio-temporal information but face a fundamental trade-off: limited temporal modeling provides only modest gains, whereas capturing long-range dependencies significantly increases computational cost. To address this limitation, we introduce a memory buffer for modeling long-range spatio-temporal consistency while achieving efficient dynamic stereo matching. Inspired by the two-stage decision-making process in humans, we propose a \\textbf{P}ick-and-\\textbf{P}lay \\textbf{M}emory (PPM) construction module for dynamic \\textbf{Stereo} matching, dubbed as \\textbf{PPMStereo}. PPM consists of a `pick' process that identifies the most relevant frames and a `play' process that weights the selected frames adaptively for spatio-temporal aggregation. This two-stage collaborative process maintains a compact yet highly informative memory buffer while achieving temporally consistent information aggregation. Extensive experiments validate the effectiveness of PPMStereo, demonstrating state-of-the-art performance in both accuracy and temporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the Sintel clean/final (17.3\\% \\&amp; 9.02\\% improvements over BiDAStereo) with fewer computational costs. Codes are available at \\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.", "published": "2025-10-23T03:52:39Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:17.991720"}
{"arxiv_id": "2510.20148v1", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity   in Tau Propagation Through Multi-Layer Modeling", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.", "published": "2025-10-23T02:52:42Z", "query": "brain augmentation", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:17.991914"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "brain augmentation", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:17.992033"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.683382"}
{"arxiv_id": "2510.20816v1", "title": "Charge-density waves and stripes in quarter metals of graphene   heterostructures", "summary": "Motivated by recent experiments, here we identify valley-coherent charge-density wave (VC-CDW) order in the non-degenerate quarter-metal for the entire family of chirally-stacked $n$ layer graphene, encompassing rhombohedral multi-layer, Bernal bilayer, and monolayer cousins. Besides the hallmark broken translational symmetry, yielding a modulated charge-density over an enlarged unit-cell with a characteristic $2{\\bf K}$ periodicity, where $\\pm {\\bf K}$ are the valley momenta, this phase lacks the three-fold ($C_3$) rotational symmetry but only for even integer $n$. The VC-CDW then represents a stripe order, as observed in hexalayer graphene [arXiv:2504.05129], but preserves the $C_3$ symmetry for odd $n$ as observed in trilayer graphene [Nat. Phys. 20, 1413 (2024) and arXiv: 2411.11163]. From a universal Clifford algebraic argument, we establish that the VC-CDW and an anomalous Hall order can lift the residual valley degeneracy of an antiferromagnetically ordered spin-polarized half-metal, when these systems are subject to perpendicular displacement fields, with only the latter one displaying a hysteresis in off-diagonal resistivity, as observed in all the systems with $2 \\leq n \\leq 6$. We showcase a confluence of VC-CDW and anomalous Hall orders within the quarter-metal, generically displaying a regime of coexistence, separating the pure phases.", "published": "2025-10-23T17:59:33Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.683781"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:21.683940"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:21.684114"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.684304"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.684487"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural modulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:21.684607"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.684810"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.684951"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:21.685120"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "neural modulation", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.685272"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.685446"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.685651"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "neural modulation", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:21.685797"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "neural modulation", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:21.685986"}
{"arxiv_id": "2510.20706v1", "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control   and Reinforcement Learning", "summary": "Model-free reinforcement learning (RL) has enabled adaptable and agile quadruped locomotion; however, policies often converge to a single gait, leading to suboptimal performance. Traditionally, Model Predictive Control (MPC) has been extensively used to obtain task-specific optimal policies but lacks the ability to adapt to varying environments. To address these limitations, we propose an optimization framework for real-time gait adaptation in a continuous gait space, combining the Model Predictive Path Integral (MPPI) algorithm with a Dreamer module to produce adaptive and optimal policies for quadruped locomotion. At each time step, MPPI jointly optimizes the actions and gait variables using a learned Dreamer reward that promotes velocity tracking, energy efficiency, stability, and smooth transitions, while penalizing abrupt gait changes. A learned value function is incorporated as terminal reward, extending the formulation to an infinite-horizon planner. We evaluate our framework in simulation on the Unitree Go1, demonstrating an average reduction of up to 36.48\\% in energy consumption across varying target speeds, while maintaining accurate tracking and adaptive, task-appropriate gaits.", "published": "2025-10-23T16:17:45Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:21.686206"}
{"arxiv_id": "2510.20705v1", "title": "Measuring cosmic dipole with the GRB luminosity-time relation", "summary": "We present a new analysis of cosmic dipole anisotropy using gamma-ray bursts (GRBs) as high-redshift standardizable candles. GRBs are ideal probes for testing the cosmological principle thanks to their high luminosity, wide redshift range, and nearly isotropic sky coverage. For the first time, we employ the luminosity-time (L-T) relation, known in the literature as the bidimensional X-ray Dainotti relation, corrected for redshift evolution, to standardize a sample of 176 long GRBs detected by \\textit{Swift}. We test for dipolar modulations in the GRB Hubble diagram using both the Dipole Fit Method and a new approach introduced here, the Anisotropic Residual Analysis Method. Both methods yield consistent results: a dipole amplitude of $A_d \\simeq 0.6 \\pm 0.2$ pointing towards (RA, DEC) $\\approx (134^\\circ \\pm 30^{\\circ}, -36^\\circ \\pm 21^{\\circ})$ (equatorial coordinates). As shown in the Appendix, this corresponds to a boost velocity of the observer with respect to the GRB rest-frame in the antipodal direction from the dipole direction. Extensive isotropy tests and 20,000 Monte Carlo simulations confirm that the detected signal cannot be explained by chance alignments or by the angular distribution of the GRB sample. We also show how, by incorporating a dipole term, residual correlations are eliminated, showing that the dipole model provides a better fit than standard isotropic $\\Lambda$CDM.", "published": "2025-10-23T16:17:11Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:21.686422"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.686591"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:21.686791"}
{"arxiv_id": "2510.20696v1", "title": "Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward", "summary": "Multimodal large language models (MLLMs) that integrate visual and textual reasoning leverage chain-of-thought (CoT) prompting to tackle complex visual tasks, yet continue to exhibit visual hallucinations and an over-reliance on textual priors. We present a systematic diagnosis of state-of-the-art vision-language models using a three-stage evaluation framework, uncovering key failure modes. To address these, we propose an agent-based architecture that combines LLM reasoning with lightweight visual modules, enabling fine-grained analysis and iterative refinement of reasoning chains. Our results highlight future visual reasoning models should focus on integrating a broader set of specialized tools for analyzing visual content. Our system achieves significant gains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or surpassing much larger models. We will release our framework and evaluation suite to facilitate future research.", "published": "2025-10-23T16:10:03Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:21.686900"}
{"arxiv_id": "2510.20691v1", "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over   Knowledge Graphs", "summary": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.", "published": "2025-10-23T16:04:13Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:21.687096"}
{"arxiv_id": "2510.20690v1", "title": "Neural Diversity Regularizes Hallucinations in Small Models", "summary": "Language models continue to hallucinate despite increases in parameters, compute, and data. We propose neural diversity -- decorrelated parallel representations -- as a principled mechanism that reduces hallucination rates at fixed parameter and data budgets. Inspired by portfolio theory, where uncorrelated assets reduce risk by $\\sqrt{P}$, we prove hallucination probability is bounded by representational correlation: $P(H) \\leq f(\\sigma^2((1-\\rho(P))/P + \\rho(P)), \\mu^2)$, which predicts that language models need an optimal amount of neurodiversity. To validate this, we introduce ND-LoRA (Neural Diversity Low-Rank Adaptation), combining parallel LoRA adapters with Barlow Twins regularization, and demonstrate that ND-LoRA reduces hallucinations by up to 25.6% (and 14.6% on average) without degrading general accuracy. Ablations show LoRA adapters and regularization act synergistically, causal interventions prove neurodiversity as the mediating factor and correlational analyses indicate scale: a 0.1% neural correlation increase is associated with a 3.8% hallucination increase. Finally, task-dependent optimality emerges: different tasks require different amounts of optimal neurodiversity. Together, our results highlight neural diversity as a third axis of scaling -- orthogonal to parameters and data -- to improve the reliability of language models at fixed budgets.", "published": "2025-10-23T16:03:07Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.687265"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "neural modulation", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:21.687415"}
{"arxiv_id": "2510.20677v1", "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice   Conversion", "summary": "In real-world singing voice conversion (SVC) applications, environmental noise and the demand for expressive output pose significant challenges. Conventional methods, however, are typically designed without accounting for real deployment scenarios, as both training and inference usually rely on clean data. This mismatch hinders practical use, given the inevitable presence of diverse noise sources and artifacts from music separation. To tackle these issues, we propose R2-SVC, a robust and expressive SVC framework. First, we introduce simulation-based robustness enhancement through random fundamental frequency ($F_0$) perturbations and music separation artifact simulations (e.g., reverberation, echo), substantially improving performance under noisy conditions. Second, we enrich speaker representation using domain-specific singing data: alongside clean vocals, we incorporate DNSMOS-filtered separated vocals and public singing corpora, enabling the model to preserve speaker timbre while capturing singing style nuances. Third, we integrate the Neural Source-Filter (NSF) model to explicitly represent harmonic and noise components, enhancing the naturalness and controllability of converted singing. R2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both clean and noisy conditions.", "published": "2025-10-23T15:52:03Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:21.687574"}
{"arxiv_id": "2510.20673v1", "title": "Efficient Multi-bit Quantization Network Training via Weight Bias   Correction and Bit-wise Coreset Sampling", "summary": "Multi-bit quantization networks enable flexible deployment of deep neural networks by supporting multiple precision levels within a single model. However, existing approaches suffer from significant training overhead as full-dataset updates are repeated for each supported bit-width, resulting in a cost that scales linearly with the number of precisions. Additionally, extra fine-tuning stages are often required to support additional or intermediate precision options, further compounding the overall training burden. To address this issue, we propose two techniques that greatly reduce the training overhead without compromising model utility: (i) Weight bias correction enables shared batch normalization and eliminates the need for fine-tuning by neutralizing quantization-induced bias across bit-widths and aligning activation distributions; and (ii) Bit-wise coreset sampling strategy allows each child model to train on a compact, informative subset selected via gradient-based importance scores by exploiting the implicit knowledge transfer phenomenon. Experiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and ViT architectures demonstrate that our method achieves competitive or superior accuracy while reducing training time up to 7.88x. Our code is released at https://github.com/a2jinhee/EMQNet_jk.", "published": "2025-10-23T15:49:02Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.687742"}
{"arxiv_id": "2510.20671v1", "title": "GRACE: GRaph-based Addiction Care prEdiction", "summary": "Determining the appropriate locus of care for addiction patients is one of the most critical clinical decisions that affects patient treatment outcomes and effective use of resources. With a lack of sufficient specialized treatment resources, such as inpatient beds or staff, there is an unmet need to develop an automated framework for the same. Current decision-making approaches suffer from severe class imbalances in addiction datasets. To address this limitation, we propose a novel graph neural network (GRACE) framework that formalizes locus of care prediction as a structured learning problem. Further, we perform extensive feature engineering and propose a new approach of obtaining an unbiased meta-graph to train a GNN to overcome the class imbalance problem. Experimental results in real-world data show an improvement of 11-35% in terms of the F1 score of the minority class over competitive baselines. The codes and note embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.", "published": "2025-10-23T15:48:01Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.687880"}
{"arxiv_id": "2510.20669v1", "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing   Maps and Spiking Dynamics for Waste Classification", "summary": "Accurate waste classification is vital for achieving sustainable waste management and reducing the environmental footprint of urbanization. Misclassification of recyclable materials contributes to landfill accumulation, inefficient recycling, and increased greenhouse gas emissions. To address these issues, this study introduces HybridSOMSpikeNet, a hybrid deep learning framework that integrates convolutional feature extraction, differentiable self-organization, and spiking-inspired temporal processing to enable intelligent and energy-efficient waste classification. The proposed model employs a pre-trained ResNet-152 backbone to extract deep spatial representations, followed by a Differentiable Soft Self-Organizing Map (Soft-SOM) that enhances topological clustering and interpretability. A spiking neural head accumulates temporal activations over discrete time steps, improving robustness and generalization. Trained on a ten-class waste dataset, HybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several state-of-the-art architectures while maintaining a lightweight computational profile suitable for real-world deployment. Beyond its technical innovations, the framework provides tangible environmental benefits. By enabling precise and automated waste segregation, it supports higher recycling efficiency, reduces contamination in recyclable streams, and minimizes the ecological and operational costs of waste processing. The approach aligns with global sustainability priorities, particularly the United Nations Sustainable Development Goals (SDG 11 and SDG 12), by contributing to cleaner cities, circular economy initiatives, and intelligent environmental management systems.", "published": "2025-10-23T15:47:09Z", "query": "neural modulation", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:21.688048"}
{"arxiv_id": "2510.20666v1", "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of   Experts", "summary": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming, particularly in urban areas where multipath and shadowing distort received power. Previous data-driven approaches achieved reasonable localization but poorly reconstructed the received signal strength (RSS) field due to limited spatial context. We propose a hybrid Bayesian mixture-of-experts framework that fuses a physical path-loss (PL) model and a convolutional neural network (CNN) through log-linear pooling. The PL expert ensures physical consistency, while the CNN leverages building-height maps to capture urban propagation effects. Bayesian inference with Laplace approximation provides posterior uncertainty over both the jammer position and RSS field. Experiments on urban ray-tracing data show that localization accuracy improves and uncertainty decreases with more training points, while uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive.", "published": "2025-10-23T15:45:45Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.688204"}
{"arxiv_id": "2510.20659v1", "title": "Kinetics of Peierls dimerization transition: Machine learning   force-field approach", "summary": "We present a machine learning (ML) force-field framework for simulating the non-equilibrium dynamics of charge-density-wave (CDW) order driven by the Peierls instability. Since the Peierls distortion arises from the coupling between lattice displacements and itinerant electrons, evaluating the adiabatic forces during time evolution is computationally intensive, particularly for large systems. To overcome this bottleneck, we develop a generalized Behler-Parrinello neural-network architecture -- originally formulated for ab initio molecular dynamics -- to accurately and efficiently predict forces from local structural environments. Using the locality of electronic responses, the resulting ML force field achieves linear scaling efficiency while maintaining quantitative accuracy. Large-scale dynamical simulations using this framework uncover a two-stage coarsening behavior of CDW domains: an early-time regime characterized by a power-law growth $L \\sim t^{\\alpha}$ with an effective exponent $\\alpha \\approx 0.7$, followed by a crossover to the Allen-Cahn scaling $L \\sim \\sqrt{t}$ at late times. The enhanced early-time coarsening is attributed to anisotropic domain-wall motion arising from electron-mediated directional interactions. This work demonstrates the promise of ML-based force fields for multiscale dynamical modeling of condensed-matter lattice models.", "published": "2025-10-23T15:33:31Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:21.688395"}
{"arxiv_id": "2510.20653v1", "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During   Inference-Time LLM Reflection", "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.", "published": "2025-10-23T15:26:18Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:21.688586"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "transcranial stimulation", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:25.193844"}
{"arxiv_id": "2510.18640v1", "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "summary": "Performance regressions in large-scale software systems can lead to substantial resource inefficiencies, making their early detection critical. Frequent benchmarking is essential for identifying these regressions and maintaining service-level agreements (SLAs). Performance benchmarks, however, are resource-intensive and time-consuming, which is a major challenge for integration into Continuous Integration / Continuous Deployment (CI/CD) pipelines. Although numerous benchmark optimization techniques have been proposed to accelerate benchmark execution, there is currently no practical system that integrates these optimizations seamlessly into real-world CI/CD pipelines. In this vision paper, we argue that the field of benchmark optimization remains under-explored in key areas that hinder its broader adoption. We identify three central challenges to enabling frequent and efficient benchmarking: (a) the composability of benchmark optimization strategies, (b) automated evaluation of benchmarking results, and (c) the usability and complexity of applying these strategies as part of CI/CD systems in practice. We also introduce a conceptual cloud-based benchmarking framework handling these challenges transparently. By presenting these open problems, we aim to stimulate research toward making performance regression detection in CI/CD systems more practical and effective.", "published": "2025-10-21T13:43:20Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.194195"}
{"arxiv_id": "2510.18570v1", "title": "Electromagnetic Field Exposure Assessment and Mitigation Strategies for   Wireless Power Transfer Systems: A Review and Future Perspectives", "summary": "Wireless power transfer (WPT) technologies are increasingly being applied in fields ranging from consumer electronics and electric vehicles to space-based energy systems and medical implants. While WPT offers contactless power delivery, it introduces electromagnetic field (EMF) emissions, necessitating careful assessment to address safety and public health concerns. Exposure guidelines developed by ICNIRP and IEEE define frequency-dependent limits based on internal quantities, such as electric field strength and specific absorption rate, intended to prevent tissue nerve stimulation &lt; 100 kHz and heating &gt; 100 kHz, respectively. Complementing these guidelines, assessment standards including the International Electrotechnical Commission (IEC)/IEEE 63184 and IEC Technical Report 63377, provide practical procedures for evaluating the EMF exposure in WPT systems. This review offers a comparative overview of major WPT modalities, with a focus on recent developments in computational dosimetry and standardized assessment techniques for the complex, non-uniform fields typical of WPT environments. It also discusses electromagnetic interference with medical devices and exposure scenarios involving partial body proximity and various postures. A notable observation across modalities is the considerable variability, often spanning an order of magnitude, in the allowable transfer power, depending on the field distribution and assessment approach. Remaining challenges include the lack of harmonized guidance for intermediate frequencies and localized exposure, underscoring the importance of further coordination in international standardization efforts. Addressing these issues is essential for the safe and widespread deployment of WPT technologies.", "published": "2025-10-21T12:25:44Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:25.194413"}
{"arxiv_id": "2510.18492v1", "title": "Electromagnetic characteristics as probes into the inner structures of   the predicted $\u039e_c^{(',*)}D^{(*)}_s$ molecular states", "summary": "In this work, we conduct a systematic investigation of the electromagnetic properties, specifically the magnetic moments and the M1 radiative decay behavior, of the predicted $\\Xi_c^{(',*)}D^{(*)}_s$-type double-charm hidden-strangeness molecular pentaquarks. The study is carried out within the framework of the constituent quark model to evaluate these electromagnetic observables, and our analysis incorporates three distinct scenarios: single-channel analysis, $S$-$D$ wave mixing analysis, and coupled-channel analysis. The calculated magnetic moments reveal characteristic patterns that reflect their underlying constituent configurations and provide sensitive probes for their quantum number assignments. Furthermore, we identify several M1 radiative decay channels with sizable widths that may offer promising signatures for future experimental detection. These M1 transitions also act as sensitive probes into their inner structures, displaying distinctive features that help differentiate between their constituent configurations and quantum number assignments. We anticipate that this study will stimulate experimental interest in exploring the electromagnetic properties of the $\\Xi_c^{(',*)}D^{(*)}_s$ molecular states, thereby advancing our structural understanding of these exotic hadronic states.", "published": "2025-10-21T10:30:12Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.194619"}
{"arxiv_id": "2510.18303v1", "title": "Proactive Reasoning-with-Retrieval Framework for Medical Multimodal   Large Language Models", "summary": "Incentivizing the reasoning ability of Multimodal Large Language Models (MLLMs) is essential for medical applications to transparently analyze medical scans and provide reliable diagnosis. However, existing medical MLLMs rely solely on internal knowledge during reasoning, leading to hallucinated reasoning and factual inaccuracies when encountering cases beyond their training scope. Although recent Agentic Retrieval-Augmented Generation (RAG) methods elicit the medical model's proactive retrieval ability during reasoning, they are confined to unimodal LLMs, neglecting the crucial visual information during reasoning and retrieval. Consequently, we propose the first Multimodal Medical Reasoning-with-Retrieval framework, Med-RwR, which actively retrieves external knowledge by querying observed symptoms or domain-specific medical concepts during reasoning. Specifically, we design a two-stage reinforcement learning strategy with tailored rewards that stimulate the model to leverage both visual diagnostic findings and textual clinical information for effective retrieval. Building on this foundation, we further propose a Confidence-Driven Image Re-retrieval (CDIR) method for test-time scaling when low prediction confidence is detected. Evaluation on various public medical benchmarks demonstrates Med-RwR's significant improvements over baseline models, proving the effectiveness of enhancing reasoning capabilities with external knowledge integration. Furthermore, Med-RwR demonstrates remarkable generalizability to unfamiliar domains, evidenced by 8.8% performance gain on our proposed EchoCardiography Benchmark (ECBench), despite the scarcity of echocardiography data in the training corpus. Our data, model, and codes will be made publicly available at https://github.com/xmed-lab/Med-RwR.", "published": "2025-10-21T05:18:18Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.194776"}
{"arxiv_id": "2510.18178v1", "title": "MACE Foundation Models for Lattice Dynamics: A Benchmark Study on Double   Halide Perovskites", "summary": "Recent developments in materials informatics and artificial intelligence has led to the emergence of foundational energy models for material chemistry, as represented by the suite of MACE-based foundation models, bringing a significant breakthrough in universal potentials for inorganic solids. As to all method developments in computational materials science, performance benchmarking against existing high-level data with focusing on specific applications, is critically needed to understand the limitations in the models, thus facilitating the ongoing improvements in the model development process, and occasionally, leading to significant conceptual leaps in materials theory. Here, using our own published DFT (Density Functional Theory) database of room-temperature dynamic stability and vibrational anharmonicity for $\\sim2000$ cubic halide double perovskites, we benchmarked the performances of four different variants of the MACE foundation models for screening the dynamic stabilities of inorganic solids. Our analysis shows that, as anticipated, the model accuracy improves with more training data. The dynamic stabilities of weakly anharmonic materials (as predicted by DFT) are more accurately reproduced by the foundation model, than those highly anharmonic and dynamically unstable ones. The predominant source of error in predicting the dynamic stability arises predominantly from the amplification of errors in atomic forces when predicting the harmonic phonon properties through the computation of the Hessian matrix, less so is the contribution from possible differences in the range of the configurational spaces that are sampled by DFT and the foundation model in molecular dynamics. We hope that our present findings will stimulate future works towards more physics-inspired approaches in assessing the accuracy of foundation models for atomistic modelling.", "published": "2025-10-21T00:05:41Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.195413"}
{"arxiv_id": "2510.17442v1", "title": "Modulation of Memristive Characteristics by Dynamic Nanoprecipitation   inside Conical Nanopores", "summary": "Nanofluidic memristors have demonstrated great potential for neuromorphic system applications with the advantages of low energy consumption and excellent biocompatibility. Here, an effective way is developed to regulate the memristive behavior of conical nanopores by leveraging the reversible formation and dissolution of nanoprecipitates induced by ion enrichment and depletion in nanopores under opposite voltages. Through the interplay between precipitation dynamics at the pore tip and the ion enrichment/depletion inside the nanopore, conical nanopores exhibit pronounced current hysteresis loops in the presence of CaHPO4, a slightly soluble inorganic salt. The memristive characteristics are found to be strongly dependent on the concentration of CaHPO4, besides the applied voltage amplitude and scan rate. Under the stimulation of pulse voltages, ionic current demonstrates stable learning and forgetting processes with robust switching stability and effective reset capability, which is similar to the short-term plasticity characteristics of biological synapses. Our research may provide a straightforward and tunable approach for the design of nanofluidic memristors.", "published": "2025-10-20T11:31:00Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:25.195566"}
{"arxiv_id": "2510.17365v1", "title": "Kinetic and Thermodynamic Descriptions of Open Systems of Complex   Chemical Reactions with Multiple Scales", "summary": "The general theory of a complex system of nonlinear chemical reactions is a primary language of chemistry that includes chemical engineering and cellular biochemistry. Its significance as an analytical framework, however, has not been fully appreciated outside the community of physical chemists. In this review, we discuss the latest advances in the kinetics and Gibbsian thermodynamics of chemical reactions in a spatially homogeneous aqueous solution with a multiscale perspective on complex systems. From the microscopic level of single reaction events which are purely stochastic in continuous time, one at a time among a set of molecules, to the macroscopic chemical reaction systems in bulk in terms of deterministic rate equations, the mathematical descriptions of kinetic models for chemical reactions at different levels are presented in detail, with rigorous mathematical justifications presented. In parallel with the kinetics of chemical reactions, the irreversible thermodynamics of open systems and the stochastic thermodynamics along reactions trajectories are reviewed thoroughly. As a novel feature, the mathematical theory of large deviations is shown to play a pivotal role in the thermodynamics of chemical reactions in equilibrium and in irreversible processes. This review is expected to stimulate interests in and help defining multiscale phenomena and nonequilibrium thermodynamics in many research fields on population dynamics of interacting species using chemical reactions as an analytic paradigm.", "published": "2025-10-20T10:04:52Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.195758"}
{"arxiv_id": "2510.16767v1", "title": "T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning   with Temporal Logic", "summary": "Translating natural language instructions into executable motion plans is a fundamental challenge in robotics. Traditional approaches are typically constrained by their reliance on domain-specific expertise to customize planners, and often struggle with spatio-temporal couplings that usually lead to infeasible motions or discrepancies between task planning and motion execution. Despite the proficiency of Large Language Models (LLMs) in high-level semantic reasoning, hallucination could result in infeasible motion plans. In this paper, we introduce the T3 Planner, an LLM-enabled robotic motion planning framework that self-corrects it output with formal methods. The framework decomposes spatio-temporal task constraints via three cascaded modules, each of which stimulates an LLM to generate candidate trajectory sequences and examines their feasibility via a Signal Temporal Logic (STL) verifier until one that satisfies complex spatial, temporal, and logical constraints is found.Experiments across different scenarios show that T3 Planner significantly outperforms the baselines. The required reasoning can be distilled into a lightweight Qwen3-4B model that enables efficient deployment. All supplementary materials are accessible at https://github.com/leeejia/T3_Planner.", "published": "2025-10-19T09:12:53Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.195923"}
{"arxiv_id": "2510.16280v1", "title": "Towards Smart Manufacturing Metaverse via Digital Twinning in Extended   Reality", "summary": "The rapid evolution of modern manufacturing systems is driven by the integration of emerging metaverse technologies such as artificial intelligence (AI), digital twin (DT) with different forms of extended reality (XR) like virtual reality (VR), augmented reality (AR), and mixed reality (MR). These advances confront manufacturing workers with complex and evolving environments that demand digital literacy for problem solving in the future workplace. However, manufacturing industry faces a critical shortage of skilled workforce with digital literacy in the world. Further, global pandemic has significantly changed how people work and collaborate digitally and remotely. There is an urgent need to rethink digital platformization and leverage emerging technologies to propel industrial evolution toward human-centered manufacturing metaverse (MfgVerse). This paper presents a forward-looking perspective on the development of smart MfgVerse, highlighting current efforts in learning factory, cognitive digital twinning, and the new sharing economy of manufacturing-as-a-service (MaaS). MfgVerse is converging into multiplex networks, including a social network of human stakeholders, an interconnected network of manufacturing things or agents (e.g., machines, robots, facilities, material handling systems), a network of digital twins of physical things, as well as auxiliary networks of sales, supply chain, logistics, and remanufacturing systems. We also showcase the design and development of a learning factory for workforce training in extended reality. Finally, future directions, challenges, and opportunities are discussed for human-centered manufacturing metaverse. We hope this work helps stimulate more comprehensive studies and in-depth research efforts to advance MfgVerse technologies.", "published": "2025-10-18T00:37:40Z", "query": "transcranial stimulation", "relevance": 0.2, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:25.196110"}
{"arxiv_id": "2510.14618v1", "title": "Reconfigurable on-chip vortex beam generation via Brillouin nonlinear   optical radiation", "summary": "The integrated devices that generate structural optical fields with non-trivial orbital angular momentums (OAMs) hold great potential for advanced optical applications, but are restricted to complex nanostructures and static functionalities. Here, we demonstrate a reconfigurable OAM beam generator from a simple microring resonator without requiring grating-like nanostructures. Our approach harnesses Brillouin interaction between confined phonon and optical modes, where the acoustic field is excited through microwave input. The phonon stimulate the conversion from a guided optical mode into a free-space vortex beam. Under the selection rule of radiation, the OAM order of the emitted light is determined by the acousto-optic phase matching and is rapidly reconfigurable by simply tuning the microwave frequency. Furthermore, this all-microwave control scheme allows for the synthesis of arbitrary high-dimensional OAM superposition states by programming the amplitudes and phases of the driving fields. Analytical and numerical models predict a radiation efficiency over 25\\% for experimentally feasible on-chip microcavities. This work introduces a novel paradigm for chip-to-free-space interfaces, replacing fixed nanophotonic structures with programmable acousto-optic interactions for versatile structured light generation.", "published": "2025-10-16T12:24:54Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.196252"}
{"arxiv_id": "2510.16036v1", "title": "IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model   for Industrial Anomaly Detection", "summary": "The robust causal capability of Multimodal Large Language Models (MLLMs) hold the potential of detecting defective objects in Industrial Anomaly Detection (IAD). However, most traditional IAD methods lack the ability to provide multi-turn human-machine dialogues and detailed descriptions, such as the color of objects, the shape of an anomaly, or specific types of anomalies. At the same time, methods based on large pre-trained models have not fully stimulated the ability of large models in anomaly detection tasks. In this paper, we explore the combination of rich text semantics with both image-level and pixel-level information from images and propose IAD-GPT, a novel paradigm based on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate detailed anomaly prompts for specific objects. These specific prompts from the large language model (LLM) are used to activate the detection and segmentation functions of the pre-trained visual-language model (i.e., CLIP). To enhance the visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein image features interact with normal and abnormal text prompts to dynamically select enhancement pathways, which enables language models to focus on specific aspects of visual data, enhancing their ability to accurately interpret and respond to anomalies within images. Moreover, we design a Multi-Mask Fusion module to incorporate mask as expert knowledge, which enhances the LLM's perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA datasets demonstrate our state-of-the-art performance on self-supervised and few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA datasets. The codes are available at \\href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.", "published": "2025-10-16T02:48:05Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.196385"}
{"arxiv_id": "2510.13148v2", "title": "Nonparametric Identification of Spatial Treatment Effect Boundaries:   Evidence from Bank Branch Consolidation", "summary": "I develop a nonparametric framework for identifying spatial boundaries of treatment effects without imposing parametric functional form restrictions. The method employs local linear regression with data-driven bandwidth selection to flexibly estimate spatial decay patterns and detect treatment effect boundaries. Monte Carlo simulations demonstrate that the nonparametric approach exhibits lower bias and correctly identifies the absence of boundaries when none exist, unlike parametric methods that may impose spurious spatial patterns. I apply this framework to bank branch openings during 2015--2020, matching 5,743 new branches to 5.9 million mortgage applications across 14,209 census tracts. The analysis reveals that branch proximity significantly affects loan application volume (8.5\\% decline per 10 miles) but not approval rates, consistent with branches stimulating demand through local presence while credit decisions remain centralized. Examining branch survival during the digital transformation era (2010--2023), I find a non-monotonic relationship with area income: high-income areas experience more closures despite conventional wisdom. This counterintuitive pattern reflects strategic consolidation of redundant branches in over-banked wealthy urban areas rather than discrimination against poor neighborhoods. Controlling for branch density, urbanization, and competition, the direct income effect diminishes substantially, with branch density emerging as the primary determinant of survival. These findings demonstrate the necessity of flexible nonparametric methods for detecting complex spatial patterns that parametric models would miss, and challenge simplistic narratives about banking deserts by revealing the organizational complexity underlying spatial consolidation decisions.", "published": "2025-10-15T04:57:31Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.196588"}
{"arxiv_id": "2510.13019v1", "title": "Phase Matching of Orbital Angular Momentum in Rare Earth Ion Doped Solid   State Systems", "summary": "In this work, we demonstrate the generation of stimulated photon echos carrying unique topological charge that results from the temporal phase matching conditions of three independent beams spatially and spectrally overlapped in a cryogenically cooled rare earth ion doped solid state system. A sample of $Tm^{3+}:YAG$ was used to generalize the momentum phase matching condition to include the orbital angular momentum of the input fields. The input fields and corresponding photon echo were characterized via astigmatic transform, with results mapping directly to the expected behavior of traditional stimulated photon echos. These results demonstrate that rare earth ion doped systems are capable of spatial multiplexing, spatial filtering, and the generation of structured light, opening pathways towards real time optical multi-modal signal processing.", "published": "2025-10-14T22:23:11Z", "query": "transcranial stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.196695"}
{"arxiv_id": "2510.12869v1", "title": "Unified kinetic theory of induced scattering: Compton, Brillouin, and   Raman processes in magnetized electron and positron pair plasma", "summary": "We present a unified theoretical framework for induced (stimulated) scattering-parametric instabilities of electromagnetic waves, including induced Compton, stimulated Brillouin, and stimulated Raman scattering (SRS) in strongly magnetized electron-positron pair plasma. By solving the dispersion relations derived from kinetic theory, taking into account the ponderomotive force due to the beat of incident and scattered waves, we obtain analytical expressions for the linear growth rates of the ordinary, neutral, and charged modes of density fluctuations. Our results clarify which type of scattering dominates under different thermal coupling, resonance, and density conditions. In strong magnetic fields, scattering of perpendicularly polarized waves is generally suppressed, but by different powers of the cyclotron frequency. Moreover, SRS, which is forbidden in unmagnetized electron and positron pair plasma, becomes possible in the charged mode. This framework enables a comprehensive evaluation of induced scattering in extreme astrophysical and laboratory plasma, such as fast radio burst (FRB) emission and propagation in magnetar magnetospheres.", "published": "2025-10-14T18:00:00Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.196847"}
{"arxiv_id": "2510.12771v1", "title": "Trajectory-Protected Quantum Computing", "summary": "We introduce a novel method that simultaneously isolates a quantum computer from decoherence and enables the controlled implementation of computational gates. We demonstrate a quantum computing model that utilizes a qubit's motion to protect it from decoherence. We model a qubit interacting with a quantum field via the standard light-matter interaction model: an Unruh-DeWitt detector, i.e., the qubit, follows a prescribed classical trajectory while interacting with a scalar quantum field. We switch off the rotating-wave terms, i.e., the resonant transitions, using the technique of acceleration-induced transparency which eliminates the dominant decoherence channels by controlling the qubit's trajectory. We are able to perform one-qubit gates by stimulating the counter-rotating wave terms (i.e., the non-resonant transitions) and two-qubit gates by extracting the entanglement from the quantum field prepared in a squeezed state. Finally, we discuss the fundamental limits on quantum error protection: on the trade-off between isolating a quantum computer from decoherence, and the speed with which entangling gates may be applied, comparable to the Eastin-Knill theorem for quantum error correction.", "published": "2025-10-14T17:51:03Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.197000"}
{"arxiv_id": "2510.12667v1", "title": "The anisotropic Heisenberg model close to the Ising limit: triangular   lattice vs. effective models", "summary": "Stimulated by recent experiments on materials representing the realization of the anisotropic Heisenberg spin-$1/2$ model on the triangular lattice, we explore further properties of such a model in the easy-axis regime $\\alpha = J_\\perp/J_z &lt; 1$, as well as effective models that also capture such physics. We show that anisotropic Heisenberg models on the honeycomb lattice and even on the square lattice reveal similarities to the full triangular lattice in the magnetization curve as well as in the transverse magnetization (superfluid) order parameter $m_\\perp$ at finite fields. Still, at $\\alpha \\ll 1$, results reveal gapless excitations and small but finite $m_\\perp &gt;0 $ at effective fields corresponding to the triangular case without the field. In contrast, several additional numerical studies of the full model on the triangular lattice confirm the existence of the gap at $\\alpha \\ll 1$. In particular, the magnetization curve $m(h)$ as well as the spin stiffness $\\rho_s$ indicate (at zero field) a transition/crossover from gapped to gapless regime at $\\alpha \\sim \\alpha^*$ with $\\alpha^* \\lesssim 0.5$. We also show that deviations from the linear spin-wave theory and the emergence of the gap can be traced back to the strong effective repulsion between magnon excitations, having similarity to strongly correlated systems.", "published": "2025-10-14T16:01:33Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.197163"}
{"arxiv_id": "2510.11965v1", "title": "Ultrafast optical gating in a nonlinear lithium niobate microcavity", "summary": "Recent advances in optical simulation and computational techniques have renewed interest in high-finesse optical cavities for applications such as enhancing light-matter interactions, engineering complex photonic band structures, and storing quantum information. However, the extended interaction times enabled by these cavities often come at the cost of slow optical read-out protocols and limited control over system transients. To address this challenge, we demonstrate an ultrafast intra-cavity optical gating scheme in a high-finesse, second-order nonlinear microcavity incorporating a thin-film of lithium niobate. A femtosecond optical gate pulse -- tuned to the transparency region of the cavity's dielectric mirrors -- achieves instantaneous up-conversion of the intra-cavity field via sum-frequency generation. The resulting upconverted signal exits the cavity as a short pulse, providing space- and time-resolved, on-demand access to the intra-cavity state. We validate this approach by tracking the dynamics of multiple resonant modes excited in a plano-concave distributed Bragg reflector microcavity, showing close agreement with analytical models. Additionally, we demonstrate that stimulated intra-cavity difference-frequency generation can efficiently instantiate cavity modes on femtosecond timescales. This gating scheme is fully compatible with low-temperature microcavity experiments, paving the way for advanced quantum state storage, retrieval, and real-time control of light-matter interactions.", "published": "2025-10-13T21:57:43Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.197288"}
{"arxiv_id": "2510.11906v1", "title": "Modelling of magnetic vortex microdisc dynamics under varying magnetic   field in biological viscoelastic environments", "summary": "Magnetically driven microparticles provide a versatile platform for probing and manipulating biological systems, yet the physical framework governing their actuation in complex environments remains only partially explored. Within the field of cellular magneto-mechanical stimulation, vortex microdiscs have emerged as particularly promising candidates for developing novel therapeutic approaches. Here, we introduce a simplified two-dimensional model describing the magneto-mechanical response of such particles embedded in viscoelastic media under varying magnetic fields. Using a Maxwell description of the medium combined with simplified elasticity assumptions, we derive analytical expressions and support them with numerical simulations of particle motion under both oscillating and rotating magnetic fields. Our results show that rotating fields typically induce oscillatory dynamics and that the transition to asynchronous motion occurs at a critical frequency determined by viscosity and stiffness. The amplitude and phase of this motion is governed by the competition between magnetic and viscoelastic contributions, with particle motion being strongly impaired when the latter dominate. Energy-based considerations further demonstrate that, within the frequency range explored of few tens of Hertz, no heat is generated -- distinguishing this approach from magnetic hyperthermia -- while the elastic energy transferred to the surrounding medium is, in principle, sufficient to perturb major cellular processes. This work provides a simple framework to anticipate the first-order influence of rheological properties on magnetically driven microdisc dynamics, thereby enabling a better understanding of their impact in cells or extracellular materials and bridging the gap between experimental observations and theoretical modelling.", "published": "2025-10-13T20:15:17Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:25.197462"}
{"arxiv_id": "2510.11460v2", "title": "Exponential Suppression of the Unruh Effect and Geometric Enhancement in   a Fermionic Cavity QED Setup", "summary": "The Unruh effect--the prediction that an accelerated observer perceives the vacuum as a thermal bath--remains one of the most profound yet experimentally unverified consequences of quantum field theory. This work analyzes a model for the decay of an excited state within a uniformly accelerated cavity to address the historical null results and to identify an alternative, non-thermal signature. In our framework, a massless Dirac field confined to a cavity is coupled to an external massive Dirac field of mass $M$. Our analysis reveals that for fundamental fermions (such as the electron), the condition $Mc^2 \\gg \\hbar a/c$ is satisfied at all achievable accelerations, placing the system in a regime of exponential suppression, $\\Gamma_{\\text{acc}}/\\Gamma_{\\text{in}} \\sim \\exp(-2 M c^2 / (\\hbar a/c))$ (with $\\Gamma_{\\text{in}}$ the inertial decay rate). This suppression holds universally across all cavity sizes and experimental designs, providing a potential explanation within this model for the non-observation of Unruh effects. Furthermore, for intermediate-sized cavities ($a l \\sim c^2$) with light external fields ($Mc^2 \\ll \\hbar a/c$), the model predicts a geometric enhancement of the decay rate, scaling as $\\Gamma_{\\text{acc}}/\\Gamma_{\\text{in}} \\sim \\frac{a l/c^2}{\\ln(1 + a l/c^2)}$, which arises from kinematic constraints rather than thermal stimulation. This enhancement, reaching up to 26% for realistic parameters ($a\\sim 10^{20}$ m/s$^2$, $l\\sim 500~\\mu$m), is presented as a measurable signature accessible through quantum simulation platforms. Our results propose a unified framework that explains past experimental challenges and suggests a viable path forward for detecting non-inertial quantum effects.", "published": "2025-10-13T14:31:49Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:25.197630"}
{"arxiv_id": "2510.10487v1", "title": "Towards Self-Refinement of Vision-Language Models with Triangular   Consistency", "summary": "Vision-Language Models (VLMs) integrate visual knowledge with the analytical capabilities of Large Language Models (LLMs) through supervised visual instruction tuning, using image-question-answer triplets. However, the potential of VLMs trained without supervised instruction remains largely unexplored. This study validates that VLMs possess inherent self-refinement capabilities, enabling them to generate high-quality supervised data without external inputs and thereby learn autonomously. Specifically, to stimulate the self-refinement ability of VLMs, we propose a self-refinement framework based on a Triangular Consistency principle: within the image-query-answer triangle, any masked elements should be consistently and accurately reconstructed. The framework involves three steps: (1) We enable the instruction generation ability of VLMs by adding multi-task instruction tuning like image$\\rightarrow$question-answer or image-answer$\\rightarrow$question. (2) We generate image-query-answer triplets from unlabeled images and use the Triangular Consistency principle for filtering. (3) The model is further updated using the filtered synthetic data. To investigate the underlying mechanisms behind this self-refinement capability, we conduct a theoretical analysis from a causal perspective. Using the widely recognized LLaVA-1.5 as our baseline, our experiments reveal that the model can autonomously achieve consistent, though deliberately modest, improvements across multiple benchmarks without any external supervision, such as human annotations or environmental feedback. We expect that the insights of this study on the self-refinement ability of VLMs can inspire future research on the learning mechanism of VLMs. Code is available at https://github.com/dengyl20/SRF-LLaVA-1.5.", "published": "2025-10-12T07:37:47Z", "query": "transcranial stimulation", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.197761"}
{"arxiv_id": "2510.10289v1", "title": "Optimal monophasic, asymmetric electric field pulses for selective   transcranial magnetic stimulation (TMS) with minimised power and coil heating", "summary": "Transcranial magnetic stimulation (TMS) with asymmetric electric field pulses, such as monophasic, offers directional selectivity for neural activation but requires excessive energy. Previous pulse shape optimisation has been limited to symmetric pulses or heavily constrained variations of conventional waveforms without achieving general optimality in energy efficiency or neural selectivity. We implemented an optimisation framework that incorporates neuron model activation constraints and flexible control of pulse asymmetry. The optimised electric field waveforms achieved up to 92 % and 88 % reduction in energy loss and thus coil heating respectively compared to conventional monophasic pulses and previously improved monophasic-equivalent pulses. In the human experiments, OUR pulses showed similar motor thresholds to monophasic pulses in both AP and PA directions with significantly lower energy loss, particularly in the AP direction. Moreover, there was a significant MEP latency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR pulses, which suggests directional selectivity. Our framework successfully identified highly energy-efficient asymmetric pulses for directionally-selective neural engagement. These pulses can enable selective rapid-rate repetitive TMS protocols with reduced power consumption and coil heating, with potential benefits for precision and potency of neuro-modulation.", "published": "2025-10-11T17:08:15Z", "query": "transcranial stimulation", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:25.197896"}
{"arxiv_id": "2510.10217v1", "title": "UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven   Foresight Prediction", "summary": "Training robots to operate effectively in environments with uncertain states, such as ambiguous object properties or unpredictable interactions, remains a longstanding challenge in robotics. Imitation learning methods typically rely on successful examples and often neglect failure scenarios where uncertainty is most pronounced. To address this limitation, we propose the Uncertainty-driven Foresight Recurrent Neural Network (UF-RNN), a model that combines standard time-series prediction with an active \"Foresight\" module. This module performs internal simulations of multiple future trajectories and refines the hidden state to minimize predicted variance, enabling the model to selectively explore actions under high uncertainty. We evaluate UF-RNN on a door-opening task in both simulation and a real-robot setting, demonstrating that, despite the absence of explicit failure demonstrations, the model exhibits robust adaptation by leveraging self-induced chaotic dynamics in its latent space. When guided by the Foresight module, these chaotic properties stimulate exploratory behaviors precisely when the environment is ambiguous, yielding improved success rates compared to conventional stochastic RNN baselines. These findings suggest that integrating uncertainty-driven foresight into imitation learning pipelines can significantly enhance a robot's ability to handle unpredictable real-world conditions.", "published": "2025-10-11T13:44:20Z", "query": "transcranial stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.198017"}
{"arxiv_id": "2510.10169v2", "title": "BrainForm: a Serious Game for BCI Training and Data Collection", "summary": "$\\textit{BrainForm}$ is a gamified Brain-Computer Interface (BCI) training system designed for scalable data collection using consumer hardware and a minimal setup. We investigated (1) how users develop BCI control skills across repeated sessions and (2) perceptual and performance effects of two visual stimulation textures. Game Experience Questionnaire (GEQ) scores for Flow, Positive Affect, Competence and Challenge were strongly positive, indicating sustained engagement. A within-subject study with multiple runs, two task complexities, and post-session questionnaires revealed no significant performance differences between textures but increased ocular irritation over time. Online metrics$\\unicode{x2013}$Task Accuracy, Task Time, and Information Transfer Rate$\\unicode{x2013}$improved across sessions, confirming learning effects for symbol spelling, even under pressure conditions. Our results highlight the potential of $\\textit{BrainForm}$ as a scalable, user-friendly BCI research tool and offer guidance for sustained engagement and reduced training fatigue.", "published": "2025-10-11T11:17:04Z", "query": "transcranial stimulation", "relevance": 0.35, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.198116"}
{"arxiv_id": "2510.09758v1", "title": "Stochastic numerical head phantoms to enable virtual imaging studies of   transcranial photoacoustic computed tomography", "summary": "Transcranial photoacoustic computed tomography (PACT) is an emerging neuroimaging modality, but skull-induced aberrations can result in severe image artifacts if not compensated for during image reconstruction. The development of advanced image reconstruction methods for transcranial PACT is hindered by the lack of well-characterized, clinically relevant evaluation frameworks. Virtual imaging studies offer a solution, but require realistic numerical phantoms. To address this need, this study introduces a framework for generating ensembles of realistic 3D numerical head phantoms for virtual imaging studies. The framework uses adjunct CT data to create anatomical phantoms, which are then enhanced with stochastically synthesized vasculature and assigned realistic optical and acoustic-elastic properties. The utility of the framework is demonstrated through a case study on the impact of skull modeling errors on transcranial PACT image quality. By allowing researchers to assess and refine reconstruction methods meaningfully, the presented framework is expected to accelerate the development of transcranial PACT.", "published": "2025-10-10T18:05:15Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.198221"}
{"arxiv_id": "2510.09248v2", "title": "Quantum-Limited Acoustoelectric Amplification in a Piezoelectric-2DEG   Heterostructure", "summary": "We provide a quantum mechanical description of phonon amplification in a heterostructure consisting of a two-dimensional electron gas (2DEG) stacked on top of a piezoelectric material. An applied drift voltage effectively creates a population inversion in the momentum states of the 2DEG electrons, giving rise to spontaneous emission of phonons. Once an acoustic wave is launched, the pumped electrons release phonons via stimulated emission, returning to depleted ground states before being pumped back to the excited states. We show that whereas efficient amplification using a 1D electron gas requires the acoustic wavelength to roughly equal the average electron-electron spacing, a 2DEG enables efficient amplification for any wavelength greater than the average electron-electron spacing. We derive the imaginary and real parts of the 2DEG first-order acoustic susceptibility as functions of electronic drift velocity in specific limits and derive the gain per unit length for the signal and the quantum noise, with the gain matching the classical result in the short-electronic-lifetime (low-mobility) regime. Moreover, we analyze the gain clamping due to pump depletion and calculate the maximum achievable intensity. Our results provide a framework for designing novel acoustic devices including a quantum phononic laser and phase-insensitive quantum phononic amplifiers.", "published": "2025-10-10T10:36:52Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.198384"}
{"arxiv_id": "2510.08930v1", "title": "Co-Authoring the Self: A Human-AI Interface for Interest Reflection in   Recommenders", "summary": "Natural language-based user profiles in recommender systems have been explored for their interpretability and potential to help users scrutinize and refine their interests, thereby improving recommendation quality. Building on this foundation, we introduce a human-AI collaborative profile for a movie recommender system that presents editable personalized interest summaries of a user's movie history. Unlike static profiles, this design invites users to directly inspect, modify, and reflect on the system's inferences. In an eight-week online field deployment with 1775 active movie recommender users, we find persistent gaps between user-perceived and system-inferred interests, show how the profile encourages engagement and reflection, and identify design directions for leveraging imperfect AI-powered user profiles to stimulate more user intervention and build more transparent and trustworthy recommender experiences.", "published": "2025-10-10T02:20:13Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:25.198516"}
{"arxiv_id": "2510.08407v1", "title": "Biology-driven assessment of deep learning super-resolution imaging of   the porosity network in dentin", "summary": "The mechanosensory system of teeth is currently believed to partly rely on Odontoblast cells stimulation by fluid flow through a porosity network extending through dentin. Visualizing the smallest sub-microscopic porosity vessels therefore requires the highest achievable resolution from confocal fluorescence microscopy, the current gold standard. This considerably limits the extent of the field of view to very small sample regions. To overcome this limitation, we tested different deep learning (DL) super-resolution (SR) models to allow faster experimental acquisitions of lower resolution images and restore optimal image quality by post-processing. Three supervised 2D SR models (RCAN, pix2pix, FSRCNN) and one unsupervised (CycleGAN) were applied to a unique set of experimentally paired high- and low-resolution confocal images acquired with different sampling schemes, resulting in a pixel size increase of x2, x4, x8. Model performance was quantified using a broad set of similarity and distribution-based image quality assessment (IQA) metrics, which yielded inconsistent results that mostly contradicted our visual perception. This raises the question of the relevance of such generic metrics to efficiently target the specific structure of dental porosity. To resolve this conflicting information, the generated SR images were segmented taking into account the specific scales and morphology of the porosity network and analysed by comparing connected components. Additionally, the capacity of the SR models to preserve 3D porosity connectivity throughout the confocal image stacks was evaluated using graph analysis. This biology-driven assessment allowed a far better mechanistic interpretation of SR performance, highlighting differences in model sensitivity to weak intensity features and the impact of non-linearity in image generation, which explains the failure of standard IQA metrics.", "published": "2025-10-09T16:26:38Z", "query": "transcranial stimulation", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:25.198647"}
{"arxiv_id": "2510.08189v2", "title": "R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth   and Depth?", "summary": "Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSeek-R1) have led to remarkable improvements through long Chain-of-Thought (CoT). However, existing benchmarks mainly focus on immediate, single-horizon tasks, failing to adequately evaluate models' ability to understand and respond to complex, long-horizon scenarios. To address this incomplete evaluation of Large Reasoning Models (LRMs), we propose R-HORIZON, a method designed to stimulate long-horizon reasoning behaviors in LRMs through query composition. Based on R-HORIZON, we construct a long-horizon reasoning benchmark, comprising complex multi-step reasoning tasks with interdependent problems that span long reasoning horizons. Through comprehensive evaluation of LRMs using the R-HORIZON benchmark, we find that even the most advanced LRMs suffer significant performance degradation. Our analysis reveals that LRMs exhibit limited effective reasoning length and struggle to allocate thinking budget across multiple problems appropriately. Recognizing these limitations, we use R-HORIZON to construct long-horizon reasoning data for reinforcement learning with verified rewards (RLVR). Compared to training with single-horizon data, RLVR with R-HORIZON not only substantially improves performance on the multi-horizon reasoning tasks, but also promotes accuracy on standard reasoning tasks, with an increase of 7.5 on AIME2024. These results position R-HORIZON as a scalable, controllable, and low-cost paradigm for enhancing and evaluating the long-horizon reasoning capabilities of LRMs.", "published": "2025-10-09T13:16:22Z", "query": "transcranial stimulation", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:25.198810"}
{"arxiv_id": "2510.07956v1", "title": "State-dependent brain responsiveness, from local circuits to the whole   brain", "summary": "The objective of this paper is to review physiological and computational aspects of the responsiveness of the cerebral cortex to stimulation, and how responsiveness depends on the state of the system. This correspondence between brain state and brain responsiveness (state-dependent responses) is outlined at different scales from the cellular and circuit level, to the mesoscale and macroscale level. At each scale, we review how quantitative methods can be used to characterize network states based on brain responses, such as the Perturbational Complexity Index (PCI). This description will compare data and models, systematically and at multiple scales, with a focus on the mechanisms that explain how brain responses depend on brain states.", "published": "2025-10-09T08:52:14Z", "query": "transcranial stimulation", "relevance": 0.05, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:25.198918"}
{"arxiv_id": "2510.20819v1", "title": "Towards General Modality Translation with Contrastive and Predictive   Latent Diffusion Bridge", "summary": "Recent advances in generative modeling have positioned diffusion models as state-of-the-art tools for sampling from complex data distributions. While these models have shown remarkable success across single-modality domains such as images and audio, extending their capabilities to Modality Translation (MT), translating information across different sensory modalities, remains an open challenge. Existing approaches often rely on restrictive assumptions, including shared dimensionality, Gaussian source priors, and modality-specific architectures, which limit their generality and theoretical grounding. In this work, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a general-purpose framework for modality translation based on a latent-variable extension of Denoising Diffusion Bridge Models. By operating in a shared latent space, our method learns a bridge between arbitrary modalities without requiring aligned dimensions. We introduce a contrastive alignment loss to enforce semantic consistency between paired samples and design a domain-agnostic encoder-decoder architecture tailored for noise prediction in latent space. Additionally, we propose a predictive loss to guide training toward accurate cross-domain translation and explore several training strategies to improve stability. Our approach supports arbitrary modality pairs and performs strongly on diverse MT tasks, including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis. Comprehensive experiments and ablations validate the effectiveness of our framework, establishing a new strong baseline in general modality translation. For more information, see our project page: https://sites.google.com/view/lddbm/home.", "published": "2025-10-23T17:59:54Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:28.696082"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "sensory cortex stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.696588"}
{"arxiv_id": "2510.20480v1", "title": "Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization   Leveraging LiDAR-Based Robot Detections", "summary": "Accurate long-term localization using onboard sensors is crucial for robots operating in Global Navigation Satellite System (GNSS)-denied environments. While complementary sensors mitigate individual degradations, carrying all the available sensor types on a single robot significantly increases the size, weight, and power demands. Distributing sensors across multiple robots enhances the deployability but introduces challenges in fusing asynchronous, multi-modal data from independently moving platforms. We propose a novel adaptive multi-modal multi-robot cooperative localization approach using a factor-graph formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial Odometry (LIO), and 3D inter-robot detections from distinct robots in a loosely-coupled fashion. The approach adapts to changing conditions, leveraging reliable data to assist robots affected by sensory degradations. A novel interpolation-based factor enables fusion of the unsynchronized measurements. LIO degradations are evaluated based on the approximate scan-matching Hessian. A novel approach of weighting odometry data proportionally to the Wasserstein distance between the consecutive VIO outputs is proposed. A theoretical analysis is provided, investigating the cooperative localization problem under various conditions, mainly in the presence of sensory degradations. The proposed method has been extensively evaluated on real-world data gathered with heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial Vehicles (UAVs), showing that the approach provides significant improvements in localization accuracy in the presence of various sensory degradations.", "published": "2025-10-23T12:20:09Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.696934"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "sensory cortex stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:28.697164"}
{"arxiv_id": "2510.19636v1", "title": "Multilayer Perceptron Neural Network Model: A Novel Approach for LFP   Contrast Sensitivity Tuning", "summary": "Local field potentials (LFPs) have been demonstrated to be an important measurement to study the activity of a local population of neurons. The response tunings of LFPs have been mostly reported as weaker and broader than spike tunings. Therefore, selecting optimized tuning methods is essential for appropriately evaluating the LFP responses and comparing them with neighboring spiking activity. In this paper, new models for tuning of the contrast response functions (CRFs) are proposed. To this end, luminance contrast-evoked LFP responses recorded in primate primary visual cortex (V1) are first analyzed. Then, supersaturating CRFs are distinguished from linear and saturating CRFs by using monotonicity index (MI). The supersaturated recording data are then identified through static identification methods including multilayer perceptron (MLP) neural network, radial basis function (RBF) neural network, fuzzy model, neuro-fuzzy model, and the local linear model tree (LOLIMOT) algorithm. Our results demonstrate that the MLP neural network, compared to traditional and modified hyperbolic Naka-Rushton functions, exhibits superior performance in tuning the local field potential responses to luminance contrast stimuli, resulting in successful tuning of a significantly higher number of neural recordings of all three types. These results suggest that the MLP neural network model can be used as a novel approach to measure a better fitted contrast sensitivity tuning curve of a population of neurons than other currently used models.", "published": "2025-10-22T14:34:09Z", "query": "sensory cortex stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.697332"}
{"arxiv_id": "2510.19373v1", "title": "Using Temperature Sampling to Effectively Train Robot Learning Policies   on Imbalanced Datasets", "summary": "Increasingly large datasets of robot actions and sensory observations are being collected to train ever-larger neural networks. These datasets are collected based on tasks and while these tasks may be distinct in their descriptions, many involve very similar physical action sequences (e.g., 'pick up an apple' versus 'pick up an orange'). As a result, many datasets of robotic tasks are substantially imbalanced in terms of the physical robotic actions they represent. In this work, we propose a simple sampling strategy for policy training that mitigates this imbalance. Our method requires only a few lines of code to integrate into existing codebases and improves generalization. We evaluate our method in both pre-training small models and fine-tuning large foundational models. Our results show substantial improvements on low-resource tasks compared to prior state-of-the-art methods, without degrading performance on high-resource tasks. This enables more effective use of model capacity for multi-task policies. We also further validate our approach in a real-world setup on a Franka Panda robot arm across a diverse set of tasks.", "published": "2025-10-22T08:48:55Z", "query": "sensory cortex stimulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.697505"}
{"arxiv_id": "2510.19360v1", "title": "Multi-code rate Task-Oriented Communication for Multi-Edge Cooperative   Inference", "summary": "The integration of artificial intelligence (AI) with the internet of things (IoT) enables task-oriented communication for multi-edge cooperative inference system, where edge devices transmit extracted features of local sensory data to an edge server to perform AI-driven tasks. However, the privacy concerns and limited communication bandwidth pose fundamental challenges, since simultaneous transmission of extracted features with a single fixed compression ratio from all devices leads to severe inefficiency in communication resource utilization. To address this challenge, we propose a framework that dynamically adjusts the code rate in feature extraction based on its importance to the downstream inference task by adopting a rate-adaptive quantization (RAQ) scheme. Furthermore, to select the code rate for each edge device under limited bandwidth constraint, a dynamic programming (DP) approach is leveraged to allocate the code rate across discrete code rate options. Experiments on multi-view datasets demonstrate that the proposed frameworks significantly outperform the frameworks using fixed-rate quantization, achieving a favorable balance between communication efficiency and inference performance under limited bandwidth conditions.", "published": "2025-10-22T08:32:50Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:28.697698"}
{"arxiv_id": "2510.18866v1", "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation", "summary": "Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. Experiments on LongMemEval with GPT and Qwen backbones show that LightMem outperforms strong baselines in accuracy (up to 10.9% gains) while reducing token usage by up to 117x, API calls by up to 159x, and runtime by over 12x. The code is available at https://github.com/zjunlp/LightMem.", "published": "2025-10-21T17:58:17Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:28.697939"}
{"arxiv_id": "2510.18640v1", "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "summary": "Performance regressions in large-scale software systems can lead to substantial resource inefficiencies, making their early detection critical. Frequent benchmarking is essential for identifying these regressions and maintaining service-level agreements (SLAs). Performance benchmarks, however, are resource-intensive and time-consuming, which is a major challenge for integration into Continuous Integration / Continuous Deployment (CI/CD) pipelines. Although numerous benchmark optimization techniques have been proposed to accelerate benchmark execution, there is currently no practical system that integrates these optimizations seamlessly into real-world CI/CD pipelines. In this vision paper, we argue that the field of benchmark optimization remains under-explored in key areas that hinder its broader adoption. We identify three central challenges to enabling frequent and efficient benchmarking: (a) the composability of benchmark optimization strategies, (b) automated evaluation of benchmarking results, and (c) the usability and complexity of applying these strategies as part of CI/CD systems in practice. We also introduce a conceptual cloud-based benchmarking framework handling these challenges transparently. By presenting these open problems, we aim to stimulate research toward making performance regression detection in CI/CD systems more practical and effective.", "published": "2025-10-21T13:43:20Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.698208"}
{"arxiv_id": "2510.18570v1", "title": "Electromagnetic Field Exposure Assessment and Mitigation Strategies for   Wireless Power Transfer Systems: A Review and Future Perspectives", "summary": "Wireless power transfer (WPT) technologies are increasingly being applied in fields ranging from consumer electronics and electric vehicles to space-based energy systems and medical implants. While WPT offers contactless power delivery, it introduces electromagnetic field (EMF) emissions, necessitating careful assessment to address safety and public health concerns. Exposure guidelines developed by ICNIRP and IEEE define frequency-dependent limits based on internal quantities, such as electric field strength and specific absorption rate, intended to prevent tissue nerve stimulation &lt; 100 kHz and heating &gt; 100 kHz, respectively. Complementing these guidelines, assessment standards including the International Electrotechnical Commission (IEC)/IEEE 63184 and IEC Technical Report 63377, provide practical procedures for evaluating the EMF exposure in WPT systems. This review offers a comparative overview of major WPT modalities, with a focus on recent developments in computational dosimetry and standardized assessment techniques for the complex, non-uniform fields typical of WPT environments. It also discusses electromagnetic interference with medical devices and exposure scenarios involving partial body proximity and various postures. A notable observation across modalities is the considerable variability, often spanning an order of magnitude, in the allowable transfer power, depending on the field distribution and assessment approach. Remaining challenges include the lack of harmonized guidance for intermediate frequencies and localized exposure, underscoring the importance of further coordination in international standardization efforts. Addressing these issues is essential for the safe and widespread deployment of WPT technologies.", "published": "2025-10-21T12:25:44Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:28.698453"}
{"arxiv_id": "2510.18492v1", "title": "Electromagnetic characteristics as probes into the inner structures of   the predicted $\u039e_c^{(',*)}D^{(*)}_s$ molecular states", "summary": "In this work, we conduct a systematic investigation of the electromagnetic properties, specifically the magnetic moments and the M1 radiative decay behavior, of the predicted $\\Xi_c^{(',*)}D^{(*)}_s$-type double-charm hidden-strangeness molecular pentaquarks. The study is carried out within the framework of the constituent quark model to evaluate these electromagnetic observables, and our analysis incorporates three distinct scenarios: single-channel analysis, $S$-$D$ wave mixing analysis, and coupled-channel analysis. The calculated magnetic moments reveal characteristic patterns that reflect their underlying constituent configurations and provide sensitive probes for their quantum number assignments. Furthermore, we identify several M1 radiative decay channels with sizable widths that may offer promising signatures for future experimental detection. These M1 transitions also act as sensitive probes into their inner structures, displaying distinctive features that help differentiate between their constituent configurations and quantum number assignments. We anticipate that this study will stimulate experimental interest in exploring the electromagnetic properties of the $\\Xi_c^{(',*)}D^{(*)}_s$ molecular states, thereby advancing our structural understanding of these exotic hadronic states.", "published": "2025-10-21T10:30:12Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.698680"}
{"arxiv_id": "2510.18303v1", "title": "Proactive Reasoning-with-Retrieval Framework for Medical Multimodal   Large Language Models", "summary": "Incentivizing the reasoning ability of Multimodal Large Language Models (MLLMs) is essential for medical applications to transparently analyze medical scans and provide reliable diagnosis. However, existing medical MLLMs rely solely on internal knowledge during reasoning, leading to hallucinated reasoning and factual inaccuracies when encountering cases beyond their training scope. Although recent Agentic Retrieval-Augmented Generation (RAG) methods elicit the medical model's proactive retrieval ability during reasoning, they are confined to unimodal LLMs, neglecting the crucial visual information during reasoning and retrieval. Consequently, we propose the first Multimodal Medical Reasoning-with-Retrieval framework, Med-RwR, which actively retrieves external knowledge by querying observed symptoms or domain-specific medical concepts during reasoning. Specifically, we design a two-stage reinforcement learning strategy with tailored rewards that stimulate the model to leverage both visual diagnostic findings and textual clinical information for effective retrieval. Building on this foundation, we further propose a Confidence-Driven Image Re-retrieval (CDIR) method for test-time scaling when low prediction confidence is detected. Evaluation on various public medical benchmarks demonstrates Med-RwR's significant improvements over baseline models, proving the effectiveness of enhancing reasoning capabilities with external knowledge integration. Furthermore, Med-RwR demonstrates remarkable generalizability to unfamiliar domains, evidenced by 8.8% performance gain on our proposed EchoCardiography Benchmark (ECBench), despite the scarcity of echocardiography data in the training corpus. Our data, model, and codes will be made publicly available at https://github.com/xmed-lab/Med-RwR.", "published": "2025-10-21T05:18:18Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.698847"}
{"arxiv_id": "2510.18178v1", "title": "MACE Foundation Models for Lattice Dynamics: A Benchmark Study on Double   Halide Perovskites", "summary": "Recent developments in materials informatics and artificial intelligence has led to the emergence of foundational energy models for material chemistry, as represented by the suite of MACE-based foundation models, bringing a significant breakthrough in universal potentials for inorganic solids. As to all method developments in computational materials science, performance benchmarking against existing high-level data with focusing on specific applications, is critically needed to understand the limitations in the models, thus facilitating the ongoing improvements in the model development process, and occasionally, leading to significant conceptual leaps in materials theory. Here, using our own published DFT (Density Functional Theory) database of room-temperature dynamic stability and vibrational anharmonicity for $\\sim2000$ cubic halide double perovskites, we benchmarked the performances of four different variants of the MACE foundation models for screening the dynamic stabilities of inorganic solids. Our analysis shows that, as anticipated, the model accuracy improves with more training data. The dynamic stabilities of weakly anharmonic materials (as predicted by DFT) are more accurately reproduced by the foundation model, than those highly anharmonic and dynamically unstable ones. The predominant source of error in predicting the dynamic stability arises predominantly from the amplification of errors in atomic forces when predicting the harmonic phonon properties through the computation of the Hessian matrix, less so is the contribution from possible differences in the range of the configurational spaces that are sampled by DFT and the foundation model in molecular dynamics. We hope that our present findings will stimulate future works towards more physics-inspired approaches in assessing the accuracy of foundation models for atomistic modelling.", "published": "2025-10-21T00:05:41Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.699068"}
{"arxiv_id": "2510.18037v2", "title": "Benchmarking Probabilistic Time Series Forecasting Models on Neural   Activity", "summary": "Neural activity forecasting is central to understanding neural systems and enabling closed-loop control. While deep learning has recently advanced the state-of-the-art in the time series forecasting literature, its application to neural activity forecasting remains limited. To bridge this gap, we systematically evaluated eight probabilistic deep learning models, including two foundation models, that have demonstrated strong performance on general forecasting benchmarks. We compared them against four classical statistical models and two baseline methods on spontaneous neural activity recorded from mouse cortex via widefield imaging. Across prediction horizons, several deep learning models consistently outperformed classical approaches, with the best model producing informative forecasts up to 1.5 seconds into the future. Our findings point toward future control applications and open new avenues for probing the intrinsic temporal structure of neural activity.", "published": "2025-10-20T19:19:29Z", "query": "sensory cortex stimulation", "relevance": 0.39999999999999997, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:28.699225"}
{"arxiv_id": "2510.17745v1", "title": "A Multi-Threading Kernel for Enabling Neuromorphic Edge Applications", "summary": "Spiking Neural Networks (SNNs) have sparse, event driven processing that can leverage neuromorphic applications. In this work, we introduce a multi-threading kernel that enables neuromorphic applications running at the edge, meaning they process sensory input directly and without any up-link to or dependency on a cloud service. The kernel shows speed-up gains over single thread processing by a factor of four on moderately sized SNNs and 1.7X on a Synfire network. Furthermore, it load-balances all cores available on multi-core processors, such as ARM, which run today's mobile devices and is up to 70% more energy efficient compared to statical core assignment. The present work can enable the development of edge applications that have low Size, Weight, and Power (SWaP), and can prototype the integration of neuromorphic chips.", "published": "2025-10-20T17:01:18Z", "query": "sensory cortex stimulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.699389"}
{"arxiv_id": "2510.17442v1", "title": "Modulation of Memristive Characteristics by Dynamic Nanoprecipitation   inside Conical Nanopores", "summary": "Nanofluidic memristors have demonstrated great potential for neuromorphic system applications with the advantages of low energy consumption and excellent biocompatibility. Here, an effective way is developed to regulate the memristive behavior of conical nanopores by leveraging the reversible formation and dissolution of nanoprecipitates induced by ion enrichment and depletion in nanopores under opposite voltages. Through the interplay between precipitation dynamics at the pore tip and the ion enrichment/depletion inside the nanopore, conical nanopores exhibit pronounced current hysteresis loops in the presence of CaHPO4, a slightly soluble inorganic salt. The memristive characteristics are found to be strongly dependent on the concentration of CaHPO4, besides the applied voltage amplitude and scan rate. Under the stimulation of pulse voltages, ionic current demonstrates stable learning and forgetting processes with robust switching stability and effective reset capability, which is similar to the short-term plasticity characteristics of biological synapses. Our research may provide a straightforward and tunable approach for the design of nanofluidic memristors.", "published": "2025-10-20T11:31:00Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:28.699540"}
{"arxiv_id": "2510.17365v1", "title": "Kinetic and Thermodynamic Descriptions of Open Systems of Complex   Chemical Reactions with Multiple Scales", "summary": "The general theory of a complex system of nonlinear chemical reactions is a primary language of chemistry that includes chemical engineering and cellular biochemistry. Its significance as an analytical framework, however, has not been fully appreciated outside the community of physical chemists. In this review, we discuss the latest advances in the kinetics and Gibbsian thermodynamics of chemical reactions in a spatially homogeneous aqueous solution with a multiscale perspective on complex systems. From the microscopic level of single reaction events which are purely stochastic in continuous time, one at a time among a set of molecules, to the macroscopic chemical reaction systems in bulk in terms of deterministic rate equations, the mathematical descriptions of kinetic models for chemical reactions at different levels are presented in detail, with rigorous mathematical justifications presented. In parallel with the kinetics of chemical reactions, the irreversible thermodynamics of open systems and the stochastic thermodynamics along reactions trajectories are reviewed thoroughly. As a novel feature, the mathematical theory of large deviations is shown to play a pivotal role in the thermodynamics of chemical reactions in equilibrium and in irreversible processes. This review is expected to stimulate interests in and help defining multiscale phenomena and nonequilibrium thermodynamics in many research fields on population dynamics of interacting species using chemical reactions as an analytic paradigm.", "published": "2025-10-20T10:04:52Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.699721"}
{"arxiv_id": "2510.17145v1", "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted   Feature Fusion", "summary": "Accurate assessment of fish freshness remains a major challenge in the food industry, with direct consequences for product quality, market value, and consumer health. Conventional sensory evaluation is inherently subjective, inconsistent, and difficult to standardize across contexts, often limited by subtle, species-dependent spoilage cues. To address these limitations, we propose a handcrafted feature-based approach that systematically extracts and incrementally fuses complementary descriptors, including color statistics, histograms across multiple color spaces, and texture features such as Local Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish eye images. Our method captures global chromatic variations from full images and localized degradations from ROI segments, fusing each independently to evaluate their effectiveness in assessing freshness. Experiments on the Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's effectiveness: in a standard train-test setting, a LightGBM classifier achieved 77.56% accuracy, a 14.35% improvement over the previous deep learning baseline of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached 97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results demonstrate that carefully engineered, handcrafted features, when strategically processed, yield a robust, interpretable, and reliable solution for automated fish freshness assessment, providing valuable insights for practical applications in food quality monitoring.", "published": "2025-10-20T04:36:34Z", "query": "sensory cortex stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.699867"}
{"arxiv_id": "2510.17129v1", "title": "Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied   Agents", "summary": "Recent advancements in Large Language Models (LLMs) have greatly enhanced natural language understanding and content generation. However, these models primarily operate in disembodied digital environments and lack interaction with the physical world. To address this limitation, Embodied Artificial Intelligence (EAI) has emerged, focusing on agents that can perceive and interact with their surroundings. Despite progress, current embodied agents face challenges in unstructured real-world environments due to insufficient semantic intelligence, which is critical for understanding and reasoning about complex tasks. This paper introduces the Semantic Intelligence-Driven Embodied (SIDE) agent framework, which integrates a hierarchical semantic cognition architecture with a semantic-driven decision-making process. This enables agents to reason about and interact with the physical world in a contextually adaptive manner. The framework is inspired by biological cognitive mechanisms and utilizes bio-inspired principles to design a semantic cognitive architecture that mimics how humans and animals integrate and process sensory information. We present this framework as a step toward developing more intelligent and versatile embodied agents.", "published": "2025-10-20T03:50:09Z", "query": "sensory cortex stimulation", "relevance": 0.1, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:28.700023"}
{"arxiv_id": "2510.17083v2", "title": "Toward a Cognitive-Affective-Systemic Framework for Art and   Sustainability", "summary": "This paper proposes a cognitive-Affective-Systemic (CAS) framework that integrates cognition, emotion, and systemic understanding to cultivate sustainability awareness through art. Drawing from eco-aesthetics, affect theory, complexity science, and posthuman ethics, the framework defines artistic practice as both epistemic and performative--a way of knowing through making and feeling. Central to this is logomotion, an aesthetic mode where comprehension and emotion move together as a unified experience. Two artworks, SPill, visualizing antimicrobial resistance through avalanche dynamics, and Echoes of the Land, modeling anthropogenic seismicity, demonstrate how systemic modeling and sensory immersion transform complex science into embodied ecological understanding. The framework offers a methodological foundation for artists, theorists, and activists to translate awareness into engagement, advancing collective creativity toward sustainable futures.", "published": "2025-10-20T01:27:43Z", "query": "sensory cortex stimulation", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.700138"}
{"arxiv_id": "2510.16924v1", "title": "Does Visual Grounding Enhance the Understanding of Embodied Knowledge in   Large Language Models?", "summary": "Despite significant progress in multimodal language models (LMs), it remains unclear whether visual grounding enhances their understanding of embodied knowledge compared to text-only models. To address this question, we propose a novel embodied knowledge understanding benchmark based on the perceptual theory from psychology, encompassing visual, auditory, tactile, gustatory, olfactory external senses, and interoception. The benchmark assesses the models' perceptual abilities across different sensory modalities through vector comparison and question-answering tasks with over 1,700 questions. By comparing 30 state-of-the-art LMs, we surprisingly find that vision-language models (VLMs) do not outperform text-only models in either task. Moreover, the models perform significantly worse in the visual dimension compared to other sensory dimensions. Further analysis reveals that the vector representations are easily influenced by word form and frequency, and the models struggle to answer questions involving spatial perception and reasoning. Our findings underscore the need for more effective integration of embodied knowledge in LMs to enhance their understanding of the physical world.", "published": "2025-10-19T16:43:04Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.700262"}
{"arxiv_id": "2510.16767v1", "title": "T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning   with Temporal Logic", "summary": "Translating natural language instructions into executable motion plans is a fundamental challenge in robotics. Traditional approaches are typically constrained by their reliance on domain-specific expertise to customize planners, and often struggle with spatio-temporal couplings that usually lead to infeasible motions or discrepancies between task planning and motion execution. Despite the proficiency of Large Language Models (LLMs) in high-level semantic reasoning, hallucination could result in infeasible motion plans. In this paper, we introduce the T3 Planner, an LLM-enabled robotic motion planning framework that self-corrects it output with formal methods. The framework decomposes spatio-temporal task constraints via three cascaded modules, each of which stimulates an LLM to generate candidate trajectory sequences and examines their feasibility via a Signal Temporal Logic (STL) verifier until one that satisfies complex spatial, temporal, and logical constraints is found.Experiments across different scenarios show that T3 Planner significantly outperforms the baselines. The required reasoning can be distilled into a lightweight Qwen3-4B model that enables efficient deployment. All supplementary materials are accessible at https://github.com/leeejia/T3_Planner.", "published": "2025-10-19T09:12:53Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:28.700442"}
{"arxiv_id": "2510.16685v1", "title": "Temporal Understanding under Deictic Frame of Reference", "summary": "Understanding time is fundamental to human cognition, where temporal experience is often conceptualized through spatial metaphors grounded in sensory-motor experience. For example, \"summer is approaching\" parallels \"We are approaching the summer\". In such expressions, humans rely on a frame of reference (FoR) to interpret meaning relative to a particular viewpoint. Extending this concept to time, a temporal frame of reference (t-FoR) defines how temporal relations are perceived relative to an experiencer's moment of \"now\". While Large Language Models (LLMs) have shown remarkable advances in natural language understanding, their ability to interpret and reason about time remains limited. In this work, we introduce TUuD (Temporal Understanding under Deictic t-FoR), a framework that evaluates how LLMs interpret time-event and event-event relations when the reference point of \"now\" dynamically shifts along a timeline. Following recent work on temporal cognition \\cite{li2025other}, LLMs are prompted to rate the similarity between the current moment and a target event from 0.00 (completely dissimilar) to 1.00 (highly similar), where similarity quantifies perceived temporal alignment between the two points. Our results show that four evaluated LLMs exhibit measurable adaptation to a deictic t-FoR, with similarity ratings peaking around the present and decreasing toward past and future events. The adaptation, however, weakens beyond near-term contexts, suggesting that while LLMs display partial human-like temporal cognition, their temporal reasoning remains sensitive to reference-frame shifts and temporal distance.", "published": "2025-10-19T02:08:35Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:28.700592"}
{"arxiv_id": "2510.16280v1", "title": "Towards Smart Manufacturing Metaverse via Digital Twinning in Extended   Reality", "summary": "The rapid evolution of modern manufacturing systems is driven by the integration of emerging metaverse technologies such as artificial intelligence (AI), digital twin (DT) with different forms of extended reality (XR) like virtual reality (VR), augmented reality (AR), and mixed reality (MR). These advances confront manufacturing workers with complex and evolving environments that demand digital literacy for problem solving in the future workplace. However, manufacturing industry faces a critical shortage of skilled workforce with digital literacy in the world. Further, global pandemic has significantly changed how people work and collaborate digitally and remotely. There is an urgent need to rethink digital platformization and leverage emerging technologies to propel industrial evolution toward human-centered manufacturing metaverse (MfgVerse). This paper presents a forward-looking perspective on the development of smart MfgVerse, highlighting current efforts in learning factory, cognitive digital twinning, and the new sharing economy of manufacturing-as-a-service (MaaS). MfgVerse is converging into multiplex networks, including a social network of human stakeholders, an interconnected network of manufacturing things or agents (e.g., machines, robots, facilities, material handling systems), a network of digital twins of physical things, as well as auxiliary networks of sales, supply chain, logistics, and remanufacturing systems. We also showcase the design and development of a learning factory for workforce training in extended reality. Finally, future directions, challenges, and opportunities are discussed for human-centered manufacturing metaverse. We hope this work helps stimulate more comprehensive studies and in-depth research efforts to advance MfgVerse technologies.", "published": "2025-10-18T00:37:40Z", "query": "sensory cortex stimulation", "relevance": 0.2, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:28.700770"}
{"arxiv_id": "2510.16216v1", "title": "Topological decoding of grid cell activity via path lifting to covering   spaces", "summary": "High-dimensional neural activity often reside in a low-dimensional subspace, referred to as neural manifolds. Grid cells in the medial entorhinal cortex provide a periodic spatial code that are organized near a toroidal manifold, independent of the spatial environment. Due to the periodic nature of its code, it is unclear how the brain utilizes the toroidal manifold to understand its state in a spatial environment. We introduce a novel framework that decodes spatial information from grid cell activity using topology. Our approach uses topological data analysis to extract toroidal coordinates from grid cell population activity and employs path-lifting to reconstruct trajectories in physical space. The reconstructed paths differ from the original by an affine transformation. We validated the method on both continuous attractor network simulations and experimental recordings of grid cells, demonstrating that local trajectories can be reliably reconstructed from a single grid cell module without external position information or training data. These results suggest that co-modular grid cells contain sufficient information for path integration and suggest a potential computational mechanism for spatial navigation.", "published": "2025-10-17T21:02:28Z", "query": "sensory cortex stimulation", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:28.700910"}
{"arxiv_id": "2510.15180v1", "title": "Game mechanics for cyber-harm awareness in the metaverse", "summary": "Educating children and young people to be safe online is essential, especially as the metaverse, a next-generation internet blending immersive technologies, promises to reshape their interactions and amplify their experiences. While virtual reality offers fully immersive, highly interactive, and multi-sensory engagement, it also heightens cyber harm risks for young or vulnerable users. To address this, the CyberNinjas VR experience was developed to educate children aged 8 to 16 on safe metaverse behaviours, providing clear referral steps for harmful interactions. Understanding user engagement in metaverse gaming will aid the design of future VR environments which prioritize safety and inclusivity. This project analyses CyberNinjas to understand how game mechanics can foster cyber-safe behaviours.", "published": "2025-10-16T22:53:04Z", "query": "sensory cortex stimulation", "relevance": 0.35, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:28.701034"}
{"arxiv_id": "2510.14647v1", "title": "Spatially anchored Tactile Awareness for Robust Dexterous Manipulation", "summary": "Dexterous manipulation requires precise geometric reasoning, yet existing visuo-tactile learning methods struggle with sub-millimeter precision tasks that are routine for traditional model-based approaches. We identify a key limitation: while tactile sensors provide rich contact information, current learning frameworks fail to effectively leverage both the perceptual richness of tactile signals and their spatial relationship with hand kinematics. We believe an ideal tactile representation should explicitly ground contact measurements in a stable reference frame while preserving detailed sensory information, enabling policies to not only detect contact occurrence but also precisely infer object geometry in the hand's coordinate system. We introduce SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an end-to-end policy framework that explicitly anchors tactile features to the hand's kinematic frame through forward kinematics, enabling accurate geometric reasoning without requiring object models or explicit pose estimation. Our key insight is that spatially grounded tactile representations allow policies to not only detect contact occurrence but also precisely infer object geometry in the hand's coordinate system. We validate SaTA on challenging dexterous manipulation tasks, including bimanual USB-C mating in free space, a task demanding sub-millimeter alignment precision, as well as light bulb installation requiring precise thread engagement and rotational control, and card sliding that demands delicate force modulation and angular precision. These tasks represent significant challenges for learning-based methods due to their stringent precision requirements. Across multiple benchmarks, SaTA significantly outperforms strong visuo-tactile baselines, improving success rates by up to 30 percentage while reducing task completion times by 27 percentage.", "published": "2025-10-16T12:59:34Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.701188"}
{"arxiv_id": "2510.14618v1", "title": "Reconfigurable on-chip vortex beam generation via Brillouin nonlinear   optical radiation", "summary": "The integrated devices that generate structural optical fields with non-trivial orbital angular momentums (OAMs) hold great potential for advanced optical applications, but are restricted to complex nanostructures and static functionalities. Here, we demonstrate a reconfigurable OAM beam generator from a simple microring resonator without requiring grating-like nanostructures. Our approach harnesses Brillouin interaction between confined phonon and optical modes, where the acoustic field is excited through microwave input. The phonon stimulate the conversion from a guided optical mode into a free-space vortex beam. Under the selection rule of radiation, the OAM order of the emitted light is determined by the acousto-optic phase matching and is rapidly reconfigurable by simply tuning the microwave frequency. Furthermore, this all-microwave control scheme allows for the synthesis of arbitrary high-dimensional OAM superposition states by programming the amplitudes and phases of the driving fields. Analytical and numerical models predict a radiation efficiency over 25\\% for experimentally feasible on-chip microcavities. This work introduces a novel paradigm for chip-to-free-space interfaces, replacing fixed nanophotonic structures with programmable acousto-optic interactions for versatile structured light generation.", "published": "2025-10-16T12:24:54Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.701320"}
{"arxiv_id": "2510.16036v1", "title": "IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model   for Industrial Anomaly Detection", "summary": "The robust causal capability of Multimodal Large Language Models (MLLMs) hold the potential of detecting defective objects in Industrial Anomaly Detection (IAD). However, most traditional IAD methods lack the ability to provide multi-turn human-machine dialogues and detailed descriptions, such as the color of objects, the shape of an anomaly, or specific types of anomalies. At the same time, methods based on large pre-trained models have not fully stimulated the ability of large models in anomaly detection tasks. In this paper, we explore the combination of rich text semantics with both image-level and pixel-level information from images and propose IAD-GPT, a novel paradigm based on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate detailed anomaly prompts for specific objects. These specific prompts from the large language model (LLM) are used to activate the detection and segmentation functions of the pre-trained visual-language model (i.e., CLIP). To enhance the visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein image features interact with normal and abnormal text prompts to dynamically select enhancement pathways, which enables language models to focus on specific aspects of visual data, enhancing their ability to accurately interpret and respond to anomalies within images. Moreover, we design a Multi-Mask Fusion module to incorporate mask as expert knowledge, which enhances the LLM's perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA datasets demonstrate our state-of-the-art performance on self-supervised and few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA datasets. The codes are available at \\href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.", "published": "2025-10-16T02:48:05Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:28.701464"}
{"arxiv_id": "2510.14126v1", "title": "Cortex: Workflow-Aware Resource Pooling and Scheduling for Agentic   Serving", "summary": "We introduce Cortex, a prototype workflow-aware serving platform designed for agentic workloads. The core principle of Cortex is stage isolation: it provisions dedicated resource pools for each distinct stage of an agentic workflow. This simple yet powerful strategy mitigates inter-stage interference in compute and memory, leading to better KV cache utilization, higher throughput, and more predictable performance. By customizing resource allocation and scheduling within each distinct stage of agentic workflows, Cortex lays the groundwork for more advanced, agent-native serving paradigms, including malleable resource management, speculative execution of workflow branches, and a shared, multi-tiered cache for \"agentic state.\"", "published": "2025-10-15T21:49:38Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:28.701590"}
{"arxiv_id": "2510.20820v1", "title": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered   Canvas", "summary": "Despite their impressive visual fidelity, existing personalized generative models lack interactive control over spatial composition and scale poorly to multiple subjects. To address these limitations, we present LayerComposer, an interactive framework for personalized, multi-subject text-to-image generation. Our approach introduces two main contributions: (1) a layered canvas, a novel representation in which each subject is placed on a distinct layer, enabling occlusion-free composition; and (2) a locking mechanism that preserves selected layers with high fidelity while allowing the remaining layers to adapt flexibly to the surrounding context. Similar to professional image-editing software, the proposed layered canvas allows users to place, resize, or lock input subjects through intuitive layer manipulation. Our versatile locking mechanism requires no architectural changes, relying instead on inherent positional embeddings combined with a new complementary data sampling strategy. Extensive experiments demonstrate that LayerComposer achieves superior spatial control and identity preservation compared to the state-of-the-art methods in multi-subject personalized image generation.", "published": "2025-10-23T17:59:55Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.179863"}
{"arxiv_id": "2510.20813v1", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic   Manipulation", "summary": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.", "published": "2025-10-23T17:59:26Z", "query": "visual cortex prosthesis", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.180391"}
{"arxiv_id": "2510.20812v1", "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via   Speculation", "summary": "Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict", "published": "2025-10-23T17:59:21Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.180673"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.180888"}
{"arxiv_id": "2510.20803v1", "title": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model", "summary": "We propose a novel AutoRegressive Generation-based paradigm for image Segmentation (ARGenSeg), achieving multimodal understanding and pixel-level perception within a unified framework. Prior works integrating image segmentation into multimodal large language models (MLLMs) typically employ either boundary points representation or dedicated segmentation heads. These methods rely on discrete representations or semantic prompts fed into task-specific decoders, which limits the ability of the MLLM to capture fine-grained visual details. To address these challenges, we introduce a segmentation framework for MLLM based on image generation, which naturally produces dense masks for target objects. We leverage MLLM to output visual tokens and detokenize them into images using an universal VQ-VAE, making the segmentation fully dependent on the pixel-level understanding of the MLLM. To reduce inference latency, we employ a next-scale-prediction strategy to generate required visual tokens in parallel. Extensive experiments demonstrate that our method surpasses prior state-of-the-art approaches on multiple segmentation datasets with a remarkable boost in inference speed, while maintaining strong understanding capabilities.", "published": "2025-10-23T17:58:26Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.181054"}
{"arxiv_id": "2510.20776v1", "title": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "summary": "This work proposes a new generation-based 3D reconstruction method, named Cupid, that accurately infers the camera pose, 3D shape, and texture of an object from a single 2D image. Cupid casts 3D reconstruction as a conditional sampling process from a learned distribution of 3D objects, and it jointly generates voxels and pixel-voxel correspondences, enabling robust pose and shape estimation under a unified generative framework. By representing both input camera poses and 3D shape as a distribution in a shared 3D latent space, Cupid adopts a two-stage flow matching pipeline: (1) a coarse stage that produces initial 3D geometry with associated 2D projections for pose recovery; and (2) a refinement stage that integrates pose-aligned image features to enhance structural fidelity and appearance details. Extensive experiments demonstrate Cupid outperforms leading 3D reconstruction methods with an over 3 dB PSNR gain and an over 10% Chamfer Distance reduction, while matching monocular estimators on pose accuracy and delivering superior visual fidelity over baseline 3D generative models. For an immersive view of the 3D results generated by Cupid, please visit cupid3d.github.io.", "published": "2025-10-23T17:47:38Z", "query": "visual cortex prosthesis", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.181211"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "visual cortex prosthesis", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.181385"}
{"arxiv_id": "2510.20738v1", "title": "Optimizing Feature Ordering in Radar Charts for Multi-Profile Comparison", "summary": "Radar charts are widely used to visualize multivariate data and compare multiple profiles across features. However, the visual clarity of radar charts can be severely compromised when feature values alternate drastically in magnitude around the circle, causing areas to collapse, which misrepresents relative differences. In the present work we introduce a permutation optimization strategy that reorders features to minimize polygon ``spikiness'' across multiple profiles simultaneously. The method is combinatorial (exhaustive search) for moderate numbers of features and uses a lexicographic minimax criterion that first considers overall smoothness (mean jump) and then the largest single jump as a tie-breaker. This preserves more global information and produces visually balanced arrangements. We discuss complexity, practical bounds, and relations to existing approaches that either change the visualization (e.g., OrigamiPlot) or learn orderings (e.g., Versatile Ordering Network). An example with two profiles and $p=6$ features (before/after ordering) illustrates the qualitative improvement.   Keywords: data visualization, radar charts, combinatorial optimization, minimax optimization, feature ordering", "published": "2025-10-23T16:56:32Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.181542"}
{"arxiv_id": "2510.20696v1", "title": "Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward", "summary": "Multimodal large language models (MLLMs) that integrate visual and textual reasoning leverage chain-of-thought (CoT) prompting to tackle complex visual tasks, yet continue to exhibit visual hallucinations and an over-reliance on textual priors. We present a systematic diagnosis of state-of-the-art vision-language models using a three-stage evaluation framework, uncovering key failure modes. To address these, we propose an agent-based architecture that combines LLM reasoning with lightweight visual modules, enabling fine-grained analysis and iterative refinement of reasoning chains. Our results highlight future visual reasoning models should focus on integrating a broader set of specialized tools for analyzing visual content. Our system achieves significant gains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or surpassing much larger models. We will release our framework and evaluation suite to facilitate future research.", "published": "2025-10-23T16:10:03Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.181685"}
{"arxiv_id": "2510.20685v1", "title": "C-NAV: Towards Self-Evolving Continual Object Navigation in Open World", "summary": "Embodied agents are expected to perform object navigation in dynamic, open-world environments. However, existing approaches typically rely on static trajectories and a fixed set of object categories during training, overlooking the real-world requirement for continual adaptation to evolving scenarios. To facilitate related studies, we introduce the continual object navigation benchmark, which requires agents to acquire navigation skills for new object categories while avoiding catastrophic forgetting of previously learned knowledge. To tackle this challenge, we propose C-Nav, a continual visual navigation framework that integrates two key innovations: (1) A dual-path anti-forgetting mechanism, which comprises feature distillation that aligns multi-modal inputs into a consistent representation space to ensure representation consistency, and feature replay that retains temporal features within the action decoder to ensure policy consistency. (2) An adaptive sampling strategy that selects diverse and informative experiences, thereby reducing redundancy and minimizing memory overhead. Extensive experiments across multiple model architectures demonstrate that C-Nav consistently outperforms existing approaches, achieving superior performance even compared to baselines with full trajectory retention, while significantly lowering memory requirements. The code will be publicly available at https://bigtree765.github.io/C-Nav-project.", "published": "2025-10-23T15:57:43Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.181851"}
{"arxiv_id": "2510.20661v1", "title": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale   High-Quality Dataset", "summary": "Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable progress. However, two key challenges remain : 1) the absence of a large-scale high-quality UHR T2I dataset, and (2) the neglect of tailored training strategies for fine-grained detail synthesis in UHR scenarios. To tackle the first challenge, we introduce \\textbf{UltraHR-100K}, a high-quality dataset of 100K UHR images with rich captions, offering diverse content and strong visual fidelity. Each image exceeds 3K resolution and is rigorously curated based on detail richness, content complexity, and aesthetic quality. To tackle the second challenge, we propose a frequency-aware post-training method that enhances fine-detail generation in T2I diffusion models. Specifically, we design (i) \\textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning on detail-critical denoising steps, and (ii) \\textit{Soft-Weighting Frequency Regularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to softly constrain frequency components, encouraging high-frequency detail preservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks demonstrate that our approach significantly improves the fine-grained detail quality and overall fidelity of UHR image generation. The code is available at \\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.", "published": "2025-10-23T15:34:53Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182037"}
{"arxiv_id": "2510.20622v1", "title": "SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video   Understanding", "summary": "Long video understanding remains challenging due to its complex, diverse, and temporally scattered content. Although video large language models (Video-LLMs) can process videos lasting tens of minutes, applying them to truly long sequences is computationally prohibitive and often leads to unfocused or inconsistent reasoning. A promising solution is to select only the most informative frames, yet existing approaches typically ignore temporal dependencies or rely on unimodal evidence, limiting their ability to provide complete and query-relevant context. We propose a Semantic-Visual Consensus Evidence Selection (SeViCES) framework for effective and reliable long video understanding. SeViCES is training-free and model-agnostic, and introduces two key components. The Semantic-Visual Consensus Frame Selection (SVCFS) module selects frames through (1) a temporal-aware semantic branch that leverages LLM reasoning over captions, and (2) a cluster-guided visual branch that aligns embeddings with semantic scores via mutual information. The Answer Consensus Refinement (ACR) module further resolves inconsistencies between semantic- and visual-based predictions by fusing evidence and constraining the answer space. Extensive experiments on long video understanding benchmarks show that SeViCES consistently outperforms state-of-the-art methods in both accuracy and robustness, demonstrating the importance of consensus-driven evidence selection for Video-LLMs.", "published": "2025-10-23T14:55:28Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182220"}
{"arxiv_id": "2510.20614v1", "title": "Performance of an open-source image-based history matching framework for   CO$_2$ storage", "summary": "We present a history matching (HM) workflow applied to the International FluidFlower benchmark study dataset, which features high-resolution images of CO$_2$ storage in a meter-scale, geologically complex reservoir. The dataset provides dense spatial and temporal observations of fluid displacement, offering a rare opportunity to validate and enhance HM techniques for geological carbon storage (GCS). The combination of detailed experimental data and direct visual observation of flow behavior at this scale is novel and valuable. This study explores the potential and limitations of using experimental data to calibrate standard models for GCS simulation. By leveraging high-resolution images and resulting interpretations of fluid phase distributions, we adjust uncertain parameters and reduce the mismatch between simulation results and observed data. Simulations are performed using the open-source OPM Flow simulator, while the open-source Everest decision-making tool is employed to conduct the HM. After the HM process, the final simulation results show good agreement with the experimental CO$_2$ storage data. This suggests that the system can be effectively described using standard flow equations, conventional saturation functions, and typical PVT properties for CO$_2$-brine mixtures. Our results demonstrate that the Wasserstein distance is a particularly effective metric for matching multi-phase, multi-component flow data. The entire workflow is implemented in a Python package named pofff (Python OPM Flow FluidFlower), which organizes all functionality through a single input file. This design ensures reproducibility and facilitates future extensions of the study.", "published": "2025-10-23T14:45:07Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182387"}
{"arxiv_id": "2510.20586v1", "title": "GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation   Models", "summary": "Recent years have seen impressive advances in text-to-image generation, with image generative or unified models producing high-quality images from text. Yet these models still struggle with fine-grained color controllability, often failing to accurately match colors specified in text prompts. While existing benchmarks evaluate compositional reasoning and prompt adherence, none systematically assess color precision. Color is fundamental to human visual perception and communication, critical for applications from art to design workflows requiring brand consistency. However, current benchmarks either neglect color or rely on coarse assessments, missing key capabilities such as interpreting RGB values or aligning with human expectations. To this end, we propose GenColorBench, the first comprehensive benchmark for text-to-image color generation, grounded in color systems like ISCC-NBS and CSS3/X11, including numerical colors which are absent elsewhere. With 44K color-focused prompts covering 400+ colors, it reveals models' true capabilities via perceptual and automated assessments. Evaluations of popular text-to-image models using GenColorBench show performance variations, highlighting which color conventions models understand best and identifying failure modes. Our GenColorBench assessments will guide improvements in precise color generation. The benchmark will be made public upon acceptance.", "published": "2025-10-23T14:12:55Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182519"}
{"arxiv_id": "2510.20579v1", "title": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal   Evidence", "summary": "Most video reasoning models only generate textual reasoning traces without indicating when and where key evidence appears. Recent models such as OpenAI-o3 have sparked wide interest in evidence-centered reasoning for images, yet extending this ability to videos is more challenging, as it requires joint temporal tracking and spatial localization across dynamic scenes. We introduce Open-o3 Video, a non-agent framework that integrates explicit spatio-temporal evidence into video reasoning, and carefully collect training data and design training strategies to address the aforementioned challenges. The model highlights key timestamps, objects, and bounding boxes alongside its answers, allowing reasoning to be grounded in concrete visual observations. To enable this functionality, we first curate and build two high-quality datasets, STGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed temporal and spatial annotations, since most existing datasets offer either temporal spans for videos or spatial boxes on images, lacking unified spatio-temporal supervision and reasoning traces. Then, we adopt a cold-start reinforcement learning strategy with multiple specially designed rewards that jointly encourage answer accuracy, temporal alignment, and spatial precision. On V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance, raising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent improvements are also observed on a broad range of video understanding benchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond accuracy, the reasoning traces produced by Open-o3 Video also provide valuable signals for test-time scaling, enabling confidence-aware verification and improving answer reliability.", "published": "2025-10-23T14:05:56Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182655"}
{"arxiv_id": "2510.20558v1", "title": "From Far and Near: Perceptual Evaluation of Crowd Representations Across   Levels of Detail", "summary": "In this paper, we investigate how users perceive the visual quality of crowd character representations at different levels of detail (LoD) and viewing distances. Each representation: geometric meshes, image-based impostors, Neural Radiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between visual fidelity and computational performance. Our qualitative and quantitative results provide insights to guide the design of perceptually optimized LoD strategies for crowd rendering.", "published": "2025-10-23T13:39:18Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182749"}
{"arxiv_id": "2510.20549v1", "title": "Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired   Navigation", "summary": "Despite advancements in SLAM technologies, robust operation under challenging conditions such as low-texture, motion-blur, or challenging lighting remains an open challenge. Such conditions are common in applications such as assistive navigation for the visually impaired. These challenges undermine localization accuracy and tracking stability, reducing navigation reliability and safety. To overcome these limitations, we present SELM-SLAM3, a deep learning-enhanced visual SLAM framework that integrates SuperPoint and LightGlue for robust feature extraction and matching. We evaluated our framework using TUM RGB-D, ICL-NUIM, and TartanAir datasets, which feature diverse and challenging scenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of 87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework demonstrates enhanced performance under challenging conditions, such as low-texture scenes and fast motion, providing a reliable platform for developing navigation aids for the visually impaired.", "published": "2025-10-23T13:35:12Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.182871"}
{"arxiv_id": "2510.20531v1", "title": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis", "summary": "The advancement of Multimodal Large Language Models (MLLMs) has bridged the gap between vision and language tasks, enabling the implementation of Explainable DeepFake Analysis (XDFA). However, current methods suffer from a lack of fine-grained awareness: the description of artifacts in data annotation is unreliable and coarse-grained, and the models fail to support the output of connections between textual forgery explanations and the visual evidence of artifacts, as well as the input of queries for arbitrary facial regions. As a result, their responses are not sufficiently grounded in Face Visual Context (Facext). To address this limitation, we propose the Fake-in-Facext (FiFa) framework, with contributions focusing on data annotation and model construction. We first define a Facial Image Concept Tree (FICT) to divide facial images into fine-grained regional concepts, thereby obtaining a more reliable data annotation pipeline, FiFa-Annotator, for forgery explanation. Based on this dedicated data annotation, we introduce a novel Artifact-Grounding Explanation (AGE) task, which generates textual forgery explanations interleaved with segmentation masks of manipulated artifacts. We propose a unified multi-task learning architecture, FiFa-MLLM, to simultaneously support abundant multimodal inputs and outputs for fine-grained Explainable DeepFake Analysis. With multiple auxiliary supervision tasks, FiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA performance on existing XDFA datasets. The code and data will be made open-source at https://github.com/lxq1000/Fake-in-Facext.", "published": "2025-10-23T13:16:12Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183007"}
{"arxiv_id": "2510.20529v1", "title": "RubbleSim: A Photorealistic Structural Collapse Simulator for Confined   Space Mapping", "summary": "Despite well-reported instances of robots being used in disaster response, there is scant published data on the internal composition of the void spaces within structural collapse incidents. Data collected during these incidents is mired in legal constraints, as ownership is often tied to the responding agencies, with little hope of public release for research. While engineered rubble piles are used for training, these sites are also reluctant to release information about their proprietary training grounds. To overcome this access challenge, we present RubbleSim -- an open-source, reconfigurable simulator for photorealistic void space exploration. The design of the simulation assets is directly informed by visits to numerous training rubble sites at differing levels of complexity. The simulator is implemented in Unity with multi-operating system support. The simulation uses a physics-based approach to build stochastic rubble piles, allowing for rapid iteration between simulation worlds while retaining absolute knowledge of the ground truth. Using RubbleSim, we apply a state-of-the-art structure-from-motion algorithm to illustrate how perception performance degrades under challenging visual conditions inside the emulated void spaces. Pre-built binaries and source code to implement are available online: https://github.com/mit-ll/rubble_pile_simulator.", "published": "2025-10-23T13:14:12Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183133"}
{"arxiv_id": "2510.20498v1", "title": "Robust Preference Alignment via Directional Neighborhood Consensus", "summary": "Aligning large language models with human preferences is critical for creating reliable and controllable AI systems. A human preference can be visualized as a high-dimensional vector where different directions represent trade-offs between desired attributes (e.g., helpfulness vs. verbosity). Yet, because the training data often reflects dominant, average preferences, LLMs tend to perform well on common requests but fall short in specific, individual needs. This mismatch creates a preference coverage gap. Existing methods often address this through costly retraining, which may not be generalized to the full spectrum of diverse preferences. This brittleness means that when a user's request reflects a nuanced preference deviating from the training data's central tendency, model performance can degrade unpredictably. To address this challenge, we introduce Robust Preference Selection (RPS), a post-hoc, training-free method by leveraging directional neighborhood consensus. Instead of forcing a model to generate a response from a single, highly specific preference, RPS samples multiple responses from a local neighborhood of related preferences to create a superior candidate pool. It then selects the response that best aligns with the user's original intent. We provide a theoretical framework showing our neighborhood generation strategy is provably superior to a strong baseline that also samples multiple candidates. Comprehensive experiments across three distinct alignment paradigms (DPA, DPO, and SFT) demonstrate that RPS consistently improves robustness against this baseline, achieving win rates of up to 69% on challenging preferences from under-represented regions of the space without any model retraining. Our work presents a practical, theoretically-grounded solution for enhancing the reliability of preference-aligned models.", "published": "2025-10-23T12:39:20Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183273"}
{"arxiv_id": "2510.20480v1", "title": "Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization   Leveraging LiDAR-Based Robot Detections", "summary": "Accurate long-term localization using onboard sensors is crucial for robots operating in Global Navigation Satellite System (GNSS)-denied environments. While complementary sensors mitigate individual degradations, carrying all the available sensor types on a single robot significantly increases the size, weight, and power demands. Distributing sensors across multiple robots enhances the deployability but introduces challenges in fusing asynchronous, multi-modal data from independently moving platforms. We propose a novel adaptive multi-modal multi-robot cooperative localization approach using a factor-graph formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial Odometry (LIO), and 3D inter-robot detections from distinct robots in a loosely-coupled fashion. The approach adapts to changing conditions, leveraging reliable data to assist robots affected by sensory degradations. A novel interpolation-based factor enables fusion of the unsynchronized measurements. LIO degradations are evaluated based on the approximate scan-matching Hessian. A novel approach of weighting odometry data proportionally to the Wasserstein distance between the consecutive VIO outputs is proposed. A theoretical analysis is provided, investigating the cooperative localization problem under various conditions, mainly in the presence of sensory degradations. The proposed method has been extensively evaluated on real-world data gathered with heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial Vehicles (UAVs), showing that the approach provides significant improvements in localization accuracy in the presence of various sensory degradations.", "published": "2025-10-23T12:20:09Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183412"}
{"arxiv_id": "2510.20470v1", "title": "Conan: Progressive Learning to Reason Like a Detective over Multi-Scale   Visual Evidence", "summary": "Video reasoning, which requires multi-step deduction across frames, remains a major challenge for multimodal large language models (MLLMs). While reinforcement learning (RL)-based methods enhance reasoning capabilities, they often rely on text-only chains that yield ungrounded or hallucinated conclusions. Conversely, frame-retrieval approaches introduce visual grounding but still struggle with inaccurate evidence localization. To address these challenges, we present Conan, a framework for evidence-grounded multi-step video reasoning. Conan identifies contextual and evidence frames, reasons over cross-frame clues, and adaptively decides when to conclude or explore further. To achieve this, we (1) construct Conan-91K, a large-scale dataset of automatically generated reasoning traces that includes frame identification, evidence reasoning, and action decision, and (2) design a multi-stage progressive cold-start strategy combined with an Identification-Reasoning-Action (AIR) RLVR training framework to jointly enhance multi-step visual reasoning. Extensive experiments on six multi-step reasoning benchmarks demonstrate that Conan surpasses the baseline Qwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving state-of-the-art performance. Furthermore, Conan generalizes effectively to long-video understanding tasks, validating its strong scalability and robustness.", "published": "2025-10-23T12:11:46Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183538"}
{"arxiv_id": "2510.20407v1", "title": "MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System   with Reaction Torque Indicator via Bilateral Control", "summary": "We present a mixed reality-based underwater robot arm teleoperation system with a reaction torque indicator via bilateral control (MR-UBi). The reaction torque indicator (RTI) overlays a color and length-coded torque bar in the MR-HMD, enabling seamless integration of visual and haptic feedback during underwater robot arm teleoperation. User studies with sixteen participants compared MR-UBi against a bilateral-control baseline. MR-UBi significantly improved grasping-torque control accuracy, increasing the time within the optimal torque range and reducing both low and high grasping torque range during lift and pick-and-place tasks with objects of different stiffness. Subjective evaluations further showed higher usability (SUS) and lower workload (NASA--TLX). Overall, the results confirm that \\textit{MR-UBi} enables more stable, accurate, and user-friendly underwater robot-arm teleoperation through the integration of visual and haptic feedback. For additional material, please check: https://mertcookimg.github.io/mr-ubi", "published": "2025-10-23T10:21:53Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183687"}
{"arxiv_id": "2510.20393v1", "title": "Mitigating Cross-modal Representation Bias for Multicultural   Image-to-Recipe Retrieval", "summary": "Existing approaches for image-to-recipe retrieval have the implicit assumption that a food image can fully capture the details textually documented in its recipe. However, a food image only reflects the visual outcome of a cooked dish and not the underlying cooking process. Consequently, learning cross-modal representations to bridge the modality gap between images and recipes tends to ignore subtle, recipe-specific details that are not visually apparent but are crucial for recipe retrieval. Specifically, the representations are biased to capture the dominant visual elements, resulting in difficulty in ranking similar recipes with subtle differences in use of ingredients and cooking methods. The bias in representation learning is expected to be more severe when the training data is mixed of images and recipes sourced from different cuisines. This paper proposes a novel causal approach that predicts the culinary elements potentially overlooked in images, while explicitly injecting these elements into cross-modal representation learning to mitigate biases. Experiments are conducted on the standard monolingual Recipe1M dataset and a newly curated multilingual multicultural cuisine dataset. The results indicate that the proposed causal representation learning is capable of uncovering subtle ingredients and cooking actions and achieves impressive retrieval performance on both monolingual and multilingual multicultural datasets.", "published": "2025-10-23T09:43:43Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183854"}
{"arxiv_id": "2510.20385v1", "title": "Positional Encoding Field", "summary": "Diffusion Transformers (DiTs) have emerged as the dominant architecture for visual generation, powering state-of-the-art image and video models. By representing images as patch tokens with positional encodings (PEs), DiTs combine Transformer scalability with spatial and temporal inductive biases. In this work, we revisit how DiTs organize visual content and discover that patch tokens exhibit a surprising degree of independence: even when PEs are perturbed, DiTs still produce globally coherent outputs, indicating that spatial coherence is primarily governed by PEs. Motivated by this finding, we introduce the Positional Encoding Field (PE-Field), which extends positional encodings from the 2D plane to a structured 3D field. PE-Field incorporates depth-aware encodings for volumetric reasoning and hierarchical encodings for fine-grained sub-patch control, enabling DiTs to model geometry directly in 3D space. Our PE-Field-augmented DiT achieves state-of-the-art performance on single-image novel view synthesis and generalizes to controllable spatial image editing.", "published": "2025-10-23T09:32:37Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.183996"}
{"arxiv_id": "2510.20350v1", "title": "What do AI-Generated Images Want?", "summary": "W.J.T. Mitchell's influential essay 'What do pictures want?' shifts the theoretical focus away from the interpretative act of understanding pictures and from the motivations of the humans who create them to the possibility that the picture itself is an entity with agency and wants. In this article, I reframe Mitchell's question in light of contemporary AI image generation tools to ask: what do AI-generated images want? Drawing from art historical discourse on the nature of abstraction, I argue that AI-generated images want specificity and concreteness because they are fundamentally abstract. Multimodal text-to-image models, which are the primary subject of this article, are based on the premise that text and image are interchangeable or exchangeable tokens and that there is a commensurability between them, at least as represented mathematically in data. The user pipeline that sees textual input become visual output, however, obscures this representational regress and makes it seem like one form transforms into the other -- as if by magic.", "published": "2025-10-23T08:48:47Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.184146"}
{"arxiv_id": "2510.20335v1", "title": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous   Parking", "summary": "Parking is a critical pillar of driving safety. While recent end-to-end (E2E) approaches have achieved promising in-domain results, robustness under domain shifts (e.g., weather and lighting changes) remains a key challenge. Rather than relying on additional data, in this paper, we propose Dino-Diffusion Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates visual foundation models with diffusion-based planning to enable generalized perception and robust motion planning under distribution shifts. We train our pipeline in CARLA at regular setting and transfer it to more adversarial settings in a zero-shot fashion. Our model consistently achieves a parking success rate above 90% across all tested out-of-distribution (OOD) scenarios, with ablation studies confirming that both the network architecture and algorithmic design significantly enhance cross-domain performance over existing baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment reconstructed from a real-world parking lot demonstrates promising sim-to-real transfer.", "published": "2025-10-23T08:35:50Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.184287"}
{"arxiv_id": "2510.20333v1", "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in   Dynamic On-Device Environments?", "summary": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.", "published": "2025-10-23T08:33:24Z", "query": "visual cortex prosthesis", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.184471"}
{"arxiv_id": "2510.20322v1", "title": "HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large   Language Models", "summary": "Multi-modal large language models (MLLMs) have emerged as a transformative approach for aligning visual and textual understanding. They typically require extremely high computational resources (e.g., thousands of GPUs) for training to achieve cross-modal alignment at multi-granularity levels. We argue that a key source of this inefficiency lies in the vision encoders they widely equip with, e.g., CLIP and SAM, which lack the alignment with language at multi-granularity levels. To address this issue, in this paper, we leverage hyperbolic space, which inherently models hierarchical levels and thus provides a principled framework for bridging the granularity gap between visual and textual modalities at an arbitrary granularity level. Concretely, we propose an efficient training paradigm for MLLMs, dubbed as HyperET, which can optimize visual representations to align with their textual counterparts at an arbitrary granularity level through dynamic hyperbolic radius adjustment in hyperbolic space. HyperET employs learnable matrices with M\\\"{o}bius multiplication operations, implemented via three effective configurations: diagonal scaling matrices, block-diagonal matrices, and banded matrices, providing a flexible yet efficient parametrization strategy. Comprehensive experiments across multiple MLLM benchmarks demonstrate that HyperET consistently improves both existing pre-training and fine-tuning MLLMs clearly with less than 1\\% additional parameters.", "published": "2025-10-23T08:16:44Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.184641"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "visual cortex prosthesis", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:32.184810"}
{"arxiv_id": "2510.20792v1", "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for   Text-Guided Graph Generation", "summary": "The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method targeting latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.", "published": "2025-10-23T17:54:17Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.640817"}
{"arxiv_id": "2510.20602v1", "title": "Resounding Acoustic Fields with Reciprocity", "summary": "Achieving immersive auditory experiences in virtual environments requires flexible sound modeling that supports dynamic source positions. In this paper, we introduce a task called resounding, which aims to estimate room impulse responses at arbitrary emitter location from a sparse set of measured emitter positions, analogous to the relighting problem in vision. We leverage the reciprocity property and introduce Versa, a physics-inspired approach to facilitating acoustic field learning. Our method creates physically valid samples with dense virtual emitter positions by exchanging emitter and listener poses. We also identify challenges in deploying reciprocity due to emitter/listener gain patterns and propose a self-supervised learning approach to address them. Results show that Versa substantially improve the performance of acoustic field learning on both simulated and real-world datasets across different metrics. Perceptual user studies show that Versa can greatly improve the immersive spatial sound experience. Code, dataset and demo videos are available on the project website: https://waves.seas.upenn.edu/projects/versa.", "published": "2025-10-23T14:30:09Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.641346"}
{"arxiv_id": "2510.19354v1", "title": "An Efficient Neural Network for Modeling Human Auditory Neurograms for   Speech", "summary": "Classical auditory-periphery models, exemplified by Bruce et al., 2018, provide high-fidelity simulations but are stochastic and computationally demanding, limiting large-scale experimentation and low-latency use. Prior neural encoders approximate aspects of the periphery; however, few are explicitly trained to reproduce the deterministic, rate-domain neurogram , hindering like-for-like evaluation. We present a compact convolutional encoder that approximates the Bruce mean-rate pathway and maps audio to a multi-frequency neurogram. We deliberately omit stochastic spiking effects and focus on a deterministic mapping (identical outputs for identical inputs). Using a computationally efficient design, the encoder achieves close correspondence to the reference while significantly reducing computation, enabling efficient modeling and front-end processing for auditory neuroscience and audio signal processing applications.", "published": "2025-10-22T08:26:26Z", "query": "auditory brainstem implant", "relevance": 0.15000000000000002, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.641631"}
{"arxiv_id": "2510.19300v1", "title": "An Adaptive Intelligent Thermal-Aware Routing Protocol for Wireless Body   Area Networks", "summary": "Wireless Body Area Networks (WBANs) have gained significant attention due to their applications in healthcare monitoring, sports, military communication, and remote patient care. These networks consist of wearable or implanted sensors that continuously collect and transmit physiological data, requiring efficient and reliable communication. However, WBANs face challenges such as limited energy, dynamic topology, and sensitivity to node temperature, which demand specialized routing strategies. Traditional shortest-path routing often causes congestion and overheating in specific nodes, leading to early failures. To address these problems, this paper proposes an intelligent temperature-aware and reliability-based routing approach that enhances WBAN performance. The proposed method works in two phases: (1) network setup and intelligent path selection, and (2) dynamic traffic management and hotspot avoidance. In the first phase, nodes share information such as residual energy, temperature, link reliability, and delay to build an optimized topology using a multi-criteria decision algorithm. The second phase continuously monitors real-time conditions and reroutes traffic away from overheated or depleted nodes. Simulation results show that the proposed approach improves throughput by 13 percent, reduces end-to-end delay by 10 percent, decreases energy consumption by 25 percent, and lowers routing load by 30 percent compared to existing methods.", "published": "2025-10-22T07:02:32Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:35.641917"}
{"arxiv_id": "2510.19228v1", "title": "Laser fabrication of Ti stent and facile MEMS flow sensor integration   for implantable respiration monitoring", "summary": "Animal experiments play a vital role in drug discovery and development by providing essential data on a drug's efficacy, safety, and physiological effects before advancing to human clinical trials. In this study, we propose a stent-based flow sensor designed to measure airflow in the airways of laboratory animals. The stent was fabricated from biocompatible Ti using a combination of fiber laser digital processing and an origami-inspired folding technique. The sensing structure was developed through standard micro-electromechanical systems (MEMS) microfabrication technology. To integrate the sensing structure with the metallic stent, a facile insertion process was employed, where the sensor film was positioned at the stent's center using its natural buckling mechanism. Once fabricated, the stent implant was expanded and installed within an airway-mimicking tube to validate its functionality. A proof-of-concept trial using an artificial ventilator successfully demonstrated real-time respiration monitoring, confirming the feasibility of the proposed system for airflow measurement in preclinical studies. This stent-based sensor offers a promising approach for enhancing respiratory assessments in laboratory animals, potentially improving the accuracy of drug evaluations and respiratory disease research.", "published": "2025-10-22T04:27:42Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.642163"}
{"arxiv_id": "2510.19189v1", "title": "Calculating the Luttinger liquid parameter for an interacting Kitaev   chain quantum simulator", "summary": "In this work, we introduce a solid-state platform for building quantum simulators using implanted spin centers in solid-state materials. We build upon the proposal for an $S=1$ chain of spin centers coupled through the magnetic dipole-dipole interaction and subjected to an external magnetic field as a quantum simulator for critical floating phases. We introduce another magnetic field and map the system to the interacting Kitaev chain. This setup, tunable through the applied fields and the orientation of the spin centers within the crystal, exhibits a variety of rich quantum behavior which notably includes floating phases, a $Z_2$ symmetry-breaking phase, and lines of both Berezinskii-Kosterlitz-Thouless (BKT) and Pokrovsky-Talapov transitions. Furthermore, we employ several novel methods to calculate the Luttinger liquid parameter in our model with incommensurate correlations. We find that these methods provide a route to identify BKT transitions with less computational resources than utilizing entanglement entropy and central charge.", "published": "2025-10-22T02:50:22Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.642360"}
{"arxiv_id": "2510.19174v1", "title": "Auditory Attention Decoding from Ear-EEG Signals: A Dataset with Dynamic   Attention Switching and Rigorous Cross-Validation", "summary": "Recent promising results in auditory attention decoding (AAD) using scalp electroencephalography (EEG) have motivated the exploration of cEEGrid, a flexible and portable ear-EEG system. While prior cEEGrid-based studies have confirmed the feasibility of AAD, they often neglect the dynamic nature of attentional states in real-world contexts. To address this gap, a novel cEEGrid dataset featuring three concurrent speakers distributed across three of five distinct spatial locations is introduced. The novel dataset is designed to probe attentional tracking and switching in realistic scenarios. Nested leave-one-out validation-an approach more rigorous than conventional single-loop leave-one-out validation-is employed to reduce biases stemming from EEG's intricate temporal dynamics. Four rule-based models are evaluated: Wiener filter (WF), canonical component analysis (CCA), common spatial pattern (CSP) and Riemannian Geometry-based classifier (RGC). With a 30-second decision window, WF and CCA models achieve decoding accuracies of 41.5% and 41.4%, respectively, while CSP and RGC models yield 37.8% and 37.6% accuracies using a 10-second window. Notably, both WF and CCA successfully track attentional state switches across all experimental tasks. Additionally, higher decoding accuracies are observed for electrodes positioned at the upper cEEGrid layout and near the listener's right ear. These findings underscore the utility of dynamic, ecologically valid paradigms and rigorous validation in advancing AAD research with cEEGrid.", "published": "2025-10-22T02:20:08Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.642548"}
{"arxiv_id": "2510.19055v1", "title": "The MUSE Benchmark: Probing Music Perception and Auditory Relational   Reasoning in Audio LLMS", "summary": "Multimodal Large Language Models (MLLMs) have demonstrated capabilities in audio understanding, but current evaluations may obscure fundamental weaknesses in relational reasoning. We introduce the Music Understanding and Structural Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to probe fundamental music perception skills. We evaluate four SOTA models (Gemini Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a persistent gap with human experts. While Gemini Pro succeeds on basic perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT) prompting provides inconsistent, often detrimental results. Our work provides a critical tool for evaluating invariant musical representations and driving development of more robust AI systems.", "published": "2025-10-21T20:14:36Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.642709"}
{"arxiv_id": "2510.18842v1", "title": "Vector spin polarization evolution determined in an entangled   muon-fluorine system under pulsed excitation", "summary": "A spin-polarized muon implanted into a fluoride forms a coupled F--$\\mu$--F complex in which the muon spin and neighbouring fluorine nuclear spins become entangled. Here we apply radio-frequency (RF) excitation to this coupled system and use the three-dimensional distribution of emitted positrons to reconstruct the time-dependent evolution of the muon spin polarization. This three-dimensional readout, using single spin detection, is not possible in a single NMR experiment and demonstrates significant advantages that are achieved by using RF muon techniques. We demonstrate the application of this vector-readout method to the experimental observation of a muon spin echo signal that is controlled by the dipolar coupling to fluorine, as well as to a double resonance experiment, in which we use pulses tuned to separate frequencies to address both the muon and fluorine spins. This targeted approach, in which selective RF pulses can control the muon spin and other spins to which it is coupled, provides a novel route for probing systems of entangled spins.", "published": "2025-10-21T17:35:27Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.642896"}
{"arxiv_id": "2510.18570v1", "title": "Electromagnetic Field Exposure Assessment and Mitigation Strategies for   Wireless Power Transfer Systems: A Review and Future Perspectives", "summary": "Wireless power transfer (WPT) technologies are increasingly being applied in fields ranging from consumer electronics and electric vehicles to space-based energy systems and medical implants. While WPT offers contactless power delivery, it introduces electromagnetic field (EMF) emissions, necessitating careful assessment to address safety and public health concerns. Exposure guidelines developed by ICNIRP and IEEE define frequency-dependent limits based on internal quantities, such as electric field strength and specific absorption rate, intended to prevent tissue nerve stimulation &lt; 100 kHz and heating &gt; 100 kHz, respectively. Complementing these guidelines, assessment standards including the International Electrotechnical Commission (IEC)/IEEE 63184 and IEC Technical Report 63377, provide practical procedures for evaluating the EMF exposure in WPT systems. This review offers a comparative overview of major WPT modalities, with a focus on recent developments in computational dosimetry and standardized assessment techniques for the complex, non-uniform fields typical of WPT environments. It also discusses electromagnetic interference with medical devices and exposure scenarios involving partial body proximity and various postures. A notable observation across modalities is the considerable variability, often spanning an order of magnitude, in the allowable transfer power, depending on the field distribution and assessment approach. Remaining challenges include the lack of harmonized guidance for intermediate frequencies and localized exposure, underscoring the importance of further coordination in international standardization efforts. Addressing these issues is essential for the safe and widespread deployment of WPT technologies.", "published": "2025-10-21T12:25:44Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:35.643120"}
{"arxiv_id": "2510.18384v1", "title": "Diagnostics of a Multicusp-Assisted Inductively-Coupled Radio-Frequency   Plasma Source for Plasma Immersion Ion Implantation", "summary": "In this article, we present a detailed characterisation of a multicusp-assisted inductively coupled RF plasma source for plasma immersion ion implantation (PIII). Using laser-induced fluorescence (LIF) and RF-compensated Langmuir probe diagnostics, we measured ion temperature T i and drift velocity v z in argon plasmas near an immersed electrode. The multicusp configuration enhances plasma density at low pressure, enabling stable operation down to 0.8 mTorr. Timeaveraged measurements show no detectable perturbation near the pulsed electrode, indicating full plasma recovery between high-voltage pulses. LIF-derived potential profiles match Riemann's presheath theory, and ion velocity distributions reveal acceleration consistent with sheath dynamics. These results support the use of LIF for steady-state characterisation of the bulk and presheath regions in PIII systems.", "published": "2025-10-21T08:03:30Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.643306"}
{"arxiv_id": "2510.18346v1", "title": "AV-Master: Dual-Path Comprehensive Perception Makes Better Audio-Visual   Question Answering", "summary": "Audio-Visual Question Answering (AVQA) requires models to effectively utilize both visual and auditory modalities to answer complex and diverse questions about audio-visual scenes. However, existing methods lack sufficient flexibility and dynamic adaptability in temporal sampling and modality preference awareness, making it difficult to focus on key information based on the question. This limits their reasoning capability in complex scenarios. To address these challenges, we propose a novel framework named AV-Master. It enhances the model's ability to extract key information from complex audio-visual scenes with substantial redundant content by dynamically modeling both temporal and modality dimensions. In the temporal dimension, we introduce a dynamic adaptive focus sampling mechanism that progressively focuses on audio-visual segments most relevant to the question, effectively mitigating redundancy and segment fragmentation in traditional sampling methods. In the modality dimension, we propose a preference-aware strategy that models each modality's contribution independently, enabling selective activation of critical features. Furthermore, we introduce a dual-path contrastive loss to reinforce consistency and complementarity across temporal and modality dimensions, guiding the model to learn question-specific cross-modal collaborative representations. Experiments on four large-scale benchmarks show that AV-Master significantly outperforms existing methods, especially in complex reasoning tasks.", "published": "2025-10-21T06:58:34Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.643474"}
{"arxiv_id": "2510.17779v1", "title": "Quench rate dependence of center formation in Er implanted Si", "summary": "Er implanted Si (Er:Si) is a promising candidate for scalable planar quantum memory (QM) applications. Er has a preference to coordinate with O impurities, and multiple types of Er center are typically formed after a post implant anneal. Float zone Si was implanted with 1018 cm-3 Er and separate samples were annealed using a rapid quench annealing technique at 950 degC for 10 min with quench rates of 5, 23, 46, 93, 185 and 400 degC/s. The evolution of photoluminescence (PL) peaks and their associated Er centers was tracked as a function of quench rate. Across all samples, five distinct Er centers were identified. Two centers, one with mixed Si and O coordination and one with Si-only coordination, exhibited fully resolved crystal-field splitting of the 4I15/2 ground state together with 2 to 3 hot lines from the 4I13/2 excited state; fitting of crystal-field parameters for both was consistent with C2v symmetry. The mixed Si and O coordinated center was suppressed at quench rates above 185 degC/s, while the Si-only coordinated center was progressively enhanced with increasing quench rate up to the maximum of 400 degC/s. These results demonstrate that rapid quench annealing has the potential to selectively stabilize a single, Si-coordinated Er center in Er:Si, which is required for QM applications.", "published": "2025-10-20T17:36:31Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:35.643672"}
{"arxiv_id": "2510.17941v1", "title": "Believe It or Not: How Deeply do LLMs Believe Implanted Facts?", "summary": "Knowledge editing techniques promise to implant new factual knowledge into large language models (LLMs). But do LLMs really believe these facts? We develop a framework to measure belief depth and use it to evaluate the success of knowledge editing techniques. We operationalize belief depth as the extent to which implanted knowledge 1) generalizes to related contexts (e.g. Fermi estimates several logical steps removed), 2) is robust to self-scrutiny and direct challenge, and 3) is represented similarly to genuine knowledge (as measured by linear probes). Our evaluations show that simple prompting and mechanistic editing techniques fail to implant knowledge deeply. In contrast, Synthetic Document Finetuning (SDF) - where models are trained on LLM-generated documents consistent with a fact - often succeeds at implanting beliefs that behave similarly to genuine knowledge. However, SDF's success is not universal, as implanted beliefs that contradict basic world knowledge are brittle and representationally distinct from genuine knowledge. Overall, our work introduces measurable criteria for belief depth and enables the rigorous evaluation necessary for deploying knowledge editing in real-world applications.", "published": "2025-10-20T16:58:54Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.643895"}
{"arxiv_id": "2510.17378v1", "title": "Model Metamers Reveal Invariances in Graph Neural Networks", "summary": "In recent years, deep neural networks have been extensively employed in perceptual systems to learn representations endowed with invariances, aiming to emulate the invariance mechanisms observed in the human brain. However, studies in the visual and auditory domains have confirmed that significant gaps remain between the invariance properties of artificial neural networks and those of humans. To investigate the invariance behavior within graph neural networks (GNNs), we introduce a model ``metamers'' generation technique. By optimizing input graphs such that their internal node activations match those of a reference graph, we obtain graphs that are equivalent in the model's representation space, yet differ significantly in both structure and node features. Our theoretical analysis focuses on two aspects: the local metamer dimension for a single node and the activation-induced volume change of the metamer manifold. Utilizing this approach, we uncover extreme levels of representational invariance across several classic GNN architectures. Although targeted modifications to model architecture and training strategies can partially mitigate this excessive invariance, they fail to fundamentally bridge the gap to human-like invariance. Finally, we quantify the deviation between metamer graphs and their original counterparts, revealing unique failure modes of current GNNs and providing a complementary benchmark for model evaluation.", "published": "2025-10-20T10:13:55Z", "query": "auditory brainstem implant", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.644167"}
{"arxiv_id": "2510.16924v1", "title": "Does Visual Grounding Enhance the Understanding of Embodied Knowledge in   Large Language Models?", "summary": "Despite significant progress in multimodal language models (LMs), it remains unclear whether visual grounding enhances their understanding of embodied knowledge compared to text-only models. To address this question, we propose a novel embodied knowledge understanding benchmark based on the perceptual theory from psychology, encompassing visual, auditory, tactile, gustatory, olfactory external senses, and interoception. The benchmark assesses the models' perceptual abilities across different sensory modalities through vector comparison and question-answering tasks with over 1,700 questions. By comparing 30 state-of-the-art LMs, we surprisingly find that vision-language models (VLMs) do not outperform text-only models in either task. Moreover, the models perform significantly worse in the visual dimension compared to other sensory dimensions. Further analysis reveals that the vector representations are easily influenced by word form and frequency, and the models struggle to answer questions involving spatial perception and reasoning. Our findings underscore the need for more effective integration of embodied knowledge in LMs to enhance their understanding of the physical world.", "published": "2025-10-19T16:43:04Z", "query": "auditory brainstem implant", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.644310"}
{"arxiv_id": "2510.16917v1", "title": "SAKE: Towards Editing Auditory Attribute Knowledge of Large   Audio-Language Models", "summary": "Knowledge editing offers an efficient way to update model knowledge without full retraining, but prior work has concentrated almost exclusively on textual or visual modalities. We introduce SAKE, the first benchmark specifically designed for editing auditory attribute knowledge in Large Audio-Language Models (LALMs). Unlike factual updates, SAKE targets several abstract auditory attributes, capturing knowledge types that go beyond conventional textual and visual domains. We benchmark seven editing methods on two LALMs along four dimensions: reliability, generality, audio/text locality, and portability. Results highlight challenges such as preserving intra-attribute knowledge unrelated to the edit, generalizing edits to multimodal reasoning, and maintaining edits under sequential updates. SAKE provides a principled framework to study how knowledge editing extends to the auditory modalities, opening new directions for maintaining and adapting LALMs in more diverse real-world scenarios.", "published": "2025-10-19T16:22:09Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.644432"}
{"arxiv_id": "2510.16893v1", "title": "Investigating Safety Vulnerabilities of Large Audio-Language Models   Under Speaker Emotional Variations", "summary": "Large audio-language models (LALMs) extend text-based LLMs with auditory understanding, offering new opportunities for multimodal applications. While their perception, reasoning, and task performance have been widely studied, their safety alignment under paralinguistic variation remains underexplored. This work systematically investigates the role of speaker emotion. We construct a dataset of malicious speech instructions expressed across multiple emotions and intensities, and evaluate several state-of-the-art LALMs. Our results reveal substantial safety inconsistencies: different emotions elicit varying levels of unsafe responses, and the effect of intensity is non-monotonic, with medium expressions often posing the greatest risk. These findings highlight an overlooked vulnerability in LALMs and call for alignment strategies explicitly designed to ensure robustness under emotional variation, a prerequisite for trustworthy deployment in real-world settings.", "published": "2025-10-19T15:41:25Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.644554"}
{"arxiv_id": "2510.16192v2", "title": "VoiceMorph: How AI Voice Morphing Reveals the Boundaries of Auditory   Self-Recognition", "summary": "This study investigated auditory self-recognition boundaries using AI voice morphing technology, examining when individuals cease recognizing their own voice. Through controlled morphing between participants' voices and demographically matched targets at 1% increments using a mixed-methods design, we measured self-identification ratings and response times among 21 participants aged 18-64.   Results revealed a critical recognition threshold at 35.2% morphing (95% CI [31.4, 38.1]). Older participants tolerated significantly higher morphing levels before losing self-recognition ($\\beta$ = 0.617, p = 0.048), suggesting age-related vulnerabilities. Greater acoustic embedding distances predicted slower decision-making ($r \\approx 0.5-0.53, p &lt; 0.05$), with the longest response times for cloned versions of participants' own voices.   Qualitative analysis revealed prosodic-based recognition strategies, universal voice manipulation discomfort, and awareness of applications spanning assistive technology to security risks. These findings establish foundational evidence for individual differences in voice morphing detection, with implications for AI ethics and vulnerable population protection as voice synthesis becomes accessible.", "published": "2025-10-17T20:02:18Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.644689"}
{"arxiv_id": "2510.14921v1", "title": "Sound Masking Strategies for Interference with Mosquito Hearing", "summary": "The use of auditory masking has long been of interest in psychoacoustics and for engineering purposes, in order to cover sounds that are disruptive to humans or to species whose habitats overlap with ours. In most cases, we seek to minimize the disturbances to the communication of wildlife. However, in the case of pathogen-carrying insects, we may want to maximize these disturbances as a way to control populations. In the current work, we explore candidate masking strategies for a generic model of active auditory systems and a model of the mosquito auditory system. For both models, we find that masks with all acoustic power focused into just one or a few frequencies perform best. We propose that masks based on rapid frequency modulation are most effective for maximal disruption of information transfer and minimizing intelligibility. We hope that these results will serve to guide the avoidance or selection of possible acoustic signals for, respectively, maximizing or minimizing communication.", "published": "2025-10-16T17:38:29Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.644834"}
{"arxiv_id": "2510.14531v1", "title": "Design and simulation of a 4H-SiC low gain avalanche diode with   trench-isolation", "summary": "We present the design and simulation of a 30 $\\mathrm{\\mu m}$ thick 4H-SiC Low Gain Avalanche Diode (LGAD) optimized for high-voltage operation. A 2.4 $\\mathrm{\\mu m}$ thick epitaxially grown gain layer enables controlled internal amplification up to 1 kV reverse bias, while maintaining full depletion below 500 V. Electrical characteristics, including I-V, C-V, and gain behavior, were simulated in Synopsys Sentaurus Technology Computer-Aided Design (TCAD) using a quasi-1D geometry and verified across process-related variations in gain layer parameters. To ensure high-voltage stability and proper edge termination, a guard structure combining deep etched trenches and deep $p^+$ junction termination extension (JTE) implants was designed. TCAD simulations varying the guard structure dimensions yielded an optimized design with a breakdown voltage above 2.4 kV. A corresponding wafer run is currently processed at IMB-CNM, Barcelona.", "published": "2025-10-16T10:21:35Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.645012"}
{"arxiv_id": "2510.14495v1", "title": "Enhanced Secondary Electron Detection of Single Ion Implants in Silicon   Through Thin SiO2 Layers", "summary": "Deterministic placement of single dopants is essential for scalable quantum devices based on group-V donors in silicon. We demonstrate a non-destructive, high-efficiency method for detecting individual ion implantation events using secondary electrons (SEs) in a focused ion beam (FIB) system. Using low-energy Sb ions implanted into undoped silicon, we achieve up to 98% single-ion detection efficiency, verified by calibrated ion-current measurements before and after implantation. The technique attains ~30 nm spatial resolution without requiring electrical contacts or device fabrication, in contrast to ion-beam-induced-current (IBIC) methods. We find that introducing a controlled SiO2 capping layer significantly enhances SE yield, consistent with an increased electron mean free path in the oxide, while maintaining high probability of successful ion deposition in the underlying substrate. The yield appears to scale with ion velocity, so higher projectile mass (e.g. Yb, Bi etc) requires increased energy to maintain detection efficiency. Our approach provides a robust and scalable route to precise donor placement and extends deterministic implantation strategies to a broad range of material systems and quantum device architectures.", "published": "2025-10-16T09:39:39Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:35.645217"}
{"arxiv_id": "2510.14267v2", "title": "TapNav: Adaptive Spatiotactile Screen Readers for Tactually Guided   Touchscreen Interactions for Blind and Low Vision People", "summary": "Screen readers are audio-based software that Blind and Low Vision (BLV) people use to interact with computing devices, such as tablets and smartphones. Although this technology has significantly improved the accessibility of touchscreen devices, the sequential nature of audio limits the bandwidth of information users can receive and process. We introduce TapNav, an adaptive spatiotactile screen reader prototype developed to interact with touchscreen interfaces spatially. TapNav's screen reader provides adaptive auditory feedback that, in combination with a tactile overlay, conveys spatial information and location of interface elements on-screen. We evaluated TapNav with 12 BLV users who interacted with TapNav to explore a data visualization and interact with a bank transactions application. Our qualitative findings show that touch points and spatially constrained navigation helped users anticipate outcomes for faster exploration, and offload cognitive load to touch. We provide design guidelines for creating tactile overlays for adaptive spatiotactile screen readers and discuss their generalizability beyond our exploratory data analysis and everyday application navigation scenarios.", "published": "2025-10-16T03:36:35Z", "query": "auditory brainstem implant", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.645370"}
{"arxiv_id": "2510.14249v1", "title": "Do Joint Language-Audio Embeddings Encode Perceptual Timbre Semantics?", "summary": "Understanding and modeling the relationship between language and sound is critical for applications such as music information retrieval,text-guided music generation, and audio captioning. Central to these tasks is the use of joint language-audio embedding spaces, which map textual descriptions and auditory content into a shared embedding space. While multimodal embedding models such as MS-CLAP, LAION-CLAP, and MuQ-MuLan have shown strong performance in aligning language and audio, their correspondence to human perception of timbre, a multifaceted attribute encompassing qualities such as brightness, roughness, and warmth, remains underexplored. In this paper, we evaluate the above three joint language-audio embedding models on their ability to capture perceptual dimensions of timbre. Our findings show that LAION-CLAP consistently provides the most reliable alignment with human-perceived timbre semantics across both instrumental sounds and audio effects.", "published": "2025-10-16T03:01:41Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.645512"}
{"arxiv_id": "2510.14159v1", "title": "Musical consonance: a review of theory and evidence on perception and   preference of auditory roughness in humans and other animals", "summary": "The origins of consonance in human music has long been contested, and today there are three primary hypotheses: aversion to roughness, preference for harmonicity, and learned preferences from cultural exposure. While the evidence is currently insufficient to disentangle the contributions of these hypotheses, I propose several reasons why roughness is an especially promising area for future study. The aim of this review is to summarize and critically evaluate roughness theory and models, experimental data, to highlight areas that deserve further research. I identify 2 key areas: There are fundamental issues with the definition and interpretation of results due to tautology in the definition of roughness, and the lack of independence in empirical measurements. Despite extensive model development, there are many duplications and models have issues with data quality and overfitting. Future theory development should aim for model simplicity, and extra assumptions, features and parameters should be evaluated systematically. Model evaluation should aim to maximise the breadth of stimuli that are predicted.", "published": "2025-10-15T23:07:52Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.645660"}
{"arxiv_id": "2510.13991v1", "title": "Impact of irradiation conditions on the magnetic field sensitivity of   spin defects in hBN nano flakes", "summary": "We study $V_{\\mathrm{B}}^-$ centres generated by helium focused ion beam (FIB) irradiation in thin ($\\sim$70 nm) hBN nanoflakes, in order to investigate the effect of implantation conditions on the key parameters that influence the magnetic field sensitivity of $V_{\\mathrm{B}}^-$ quantum sensors. Using a combination of photoluminescence, optically detected magnetic resonance, and Raman spectroscopy, we examine the competing factors of maximising signal intensity through larger $V_{\\mathrm{B}}^-$ concentration against the degradation in spin coherence and lattice quality observed at high ion fluences. Our results indicate that both the $V_{\\mathrm{B}}^-$ spin properties and hBN lattice parameters are largely preserved up to an ion fluence of $10^{14}$ ions/cm$^2$, and beyond this significant degradation occurs in both. At the optimal implantation dose, an AC magnetic sensitivity of $\\sim 1\\,\\mu\\mathrm{T}/\\sqrt{\\mathrm{Hz}}$ is achieved. Using the patterned implantation enabled by the FIB, we find that $V_{\\mathrm{B}}^-$ centres and the associated lattice damage are well localised to the implanted regions. This work demonstrates how careful selection of fabrication parameters can be used to optimise the properties of $V_{\\mathrm{B}}^-$ centres in hBN, supporting their application as quantum sensors based on 2D materials.", "published": "2025-10-15T18:14:55Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.645816"}
{"arxiv_id": "2510.13344v1", "title": "UniMoE-Audio: Unified Speech and Music Generation with Dynamic-Capacity   MoE", "summary": "Recent advances in unified multimodal models indicate a clear trend towards comprehensive content generation. However, the auditory domain remains a significant challenge, with music and speech often developed in isolation, hindering progress towards universal audio synthesis. This separation stems from inherent task conflicts and severe data imbalances, which impede the development of a truly unified audio generation model. To address this challenge, we propose UniMoE-Audio, a unified speech and music generation model within a novel Dynamic-Capacity Mixture-of-Experts (MoE) framework. Architecturally, UniMoE-Audio introduces a Top-P routing strategy for dynamic expert number allocation, and a hybrid expert design comprising routed experts for domain-specific knowledge, shared experts for domain-agnostic features, and null experts for adaptive computation skipping. To tackle data imbalance, we introduce a three-stage training curriculum: 1) Independent Specialist Training leverages original datasets to instill domain-specific knowledge into each \"proto-expert\" without interference; 2) MoE Integration and Warmup incorporates these specialists into the UniMoE-Audio architecture, warming up the gate module and shared expert using a subset of balanced dataset; and 3) Synergistic Joint Training trains the entire model end-to-end on the fully balanced dataset, fostering enhanced cross-domain synergy. Extensive experiments show that UniMoE-Audio not only achieves state-of-the-art performance on major speech and music generation benchmarks, but also demonstrates superior synergistic learning, mitigating the performance degradation typically seen in naive joint training. Our findings highlight the substantial potential of specialized MoE architecture and curated training strategies in advancing the field of universal audio generation. Homepage: https://mukioxun.github.io/Uni-MoE-site/home.html", "published": "2025-10-15T09:30:25Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.646007"}
{"arxiv_id": "2510.13244v1", "title": "MotionBeat: Motion-Aligned Music Representation via Embodied Contrastive   Learning and Bar-Equivariant Contact-Aware Encoding", "summary": "Music is both an auditory and an embodied phenomenon, closely linked to human motion and naturally expressed through dance. However, most existing audio representations neglect this embodied dimension, limiting their ability to capture rhythmic and structural cues that drive movement. We propose MotionBeat, a framework for motion-aligned music representation learning. MotionBeat is trained with two newly proposed objectives: the Embodied Contrastive Loss (ECL), an enhanced InfoNCE formulation with tempo-aware and beat-jitter negatives to achieve fine-grained rhythmic discrimination, and the Structural Rhythm Alignment Loss (SRAL), which ensures rhythm consistency by aligning music accents with corresponding motion events. Architecturally, MotionBeat introduces bar-equivariant phase rotations to capture cyclic rhythmic patterns and contact-guided attention to emphasize motion events synchronized with musical accents. Experiments show that MotionBeat outperforms state-of-the-art audio encoders in music-to-dance generation and transfers effectively to beat tracking, music tagging, genre and instrument classification, emotion recognition, and audio-visual retrieval. Our project demo page: https://motionbeat2025.github.io/.", "published": "2025-10-15T07:44:32Z", "query": "auditory brainstem implant", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.646161"}
{"arxiv_id": "2510.13899v1", "title": "Post-surgical Endometriosis Segmentation in Laparoscopic Videos", "summary": "Endometriosis is a common women's condition exhibiting a manifold visual appearance in various body-internal locations. Having such properties makes its identification very difficult and error-prone, at least for laymen and non-specialized medical practitioners. In an attempt to provide assistance to gynecologic physicians treating endometriosis, this demo paper describes a system that is trained to segment one frequently occurring visual appearance of endometriosis, namely dark endometrial implants. The system is capable of analyzing laparoscopic surgery videos, annotating identified implant regions with multi-colored overlays and displaying a detection summary for improved video browsing.", "published": "2025-10-14T18:54:28Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:35.646284"}
{"arxiv_id": "2510.12275v1", "title": "TFGA-Net: Temporal-Frequency Graph Attention Network for   Brain-Controlled Speaker Extraction", "summary": "The rapid development of auditory attention decoding (AAD) based on electroencephalography (EEG) signals offers the possibility EEG-driven target speaker extraction. However, how to effectively utilize the target-speaker common information between EEG and speech remains an unresolved problem. In this paper, we propose a model for brain-controlled speaker extraction, which utilizes the EEG recorded from the listener to extract the target speech. In order to effectively extract information from EEG signals, we derive multi-scale time--frequency features and further incorporate cortical topological structures that are selectively engaged during the task. Moreover, to effectively exploit the non-Euclidean structure of EEG signals and capture their global features, the graph convolutional networks and self-attention mechanism are used in the EEG encoder. In addition, to make full use of the fused EEG and speech feature and preserve global context and capture speech rhythm and prosody, we introduce MossFormer2 which combines MossFormer and RNN-Free Recurrent as separator. Experimental results on both the public Cocktail Party and KUL dataset in this paper show that our TFGA-Net model significantly outper-forms the state-of-the-art method in certain objective evaluation metrics. The source code is available at: https://github.com/LaoDa-X/TFGA-NET.", "published": "2025-10-14T08:26:50Z", "query": "auditory brainstem implant", "relevance": 0.2, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:35.646427"}
{"arxiv_id": "2510.14414v1", "title": "RoboANKLE: Design, Development, and Functional Evaluation of a Robotic   Ankle with a Motorized Compliant Unit", "summary": "This study presents a powered transtibial prosthesis with complete push-off assistance, RoboANKLE. The design aims to fulfill specific requirements, such as a sufficient range of motion (RoM) while providing the necessary torque for achieving natural ankle motion in daily activities. Addressing the challenges faced in designing active transtibial prostheses, such as maintaining energetic autonomy and minimizing weight, is vital for the study. With this aim, we try to imitate the human ankle by providing extensive push-off assistance to achieve a natural-like torque profile. Thus, Energy Store and Extended Release mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism. Kinematic and kinetic analyses are carried out to determine the design parameters and assess the design performance. Subsequently, a Computer-Aided Design (CAD) model is built and used in comprehensive dynamic and structural analyses. These analyses are used for the design performance evaluation and determine the forces and torques applied to the prosthesis, which aids in optimizing the design for minimal weight via structural analysis and topology optimization. The design of the prototype is then finalized and manufactured for experimental evaluation to validate the design and functionality. The prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm. The Functional evaluations of the RoboANKLE revealed that it is capable of achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also, Thanks to the implemented mechanisms, the results show that RoboANKLE can generate 57% higher than the required torque for natural walking. The result of the power generation capacity of the RoboANKLE is 10% more than the natural power during the gait cycle.", "published": "2025-10-16T08:18:51Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.184782"}
{"arxiv_id": "2510.09209v1", "title": "PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling   Precision-Lateral Dexterous Manipulation", "summary": "Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and have motors inside to protect them from damage and dirt. In addition to the ability to perform daily activities, these features are essential for everyday use of the hand. In-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting cards before slot insertion and operating tools such as screwdrivers. However, currently used electric prosthetic hands only achieve static grasp postures, and existing manipulation approaches require either many motors, which makes the prosthesis heavy for daily use in the hand, or complex mechanisms that demand a large internal space and force external motor placement, complicating attachment and exposing the components to damage. Alternatively, we combine a single-axis thumb and optimized thumb positioning to achieve basic posture and in-hand manipulation, that is, the reorientation between precision and lateral grasps, using only four motors in a lightweight (311 g) prosthetic hand. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success rates of 90-100% for reorientation tasks. The hand performed seal stamping and USB device insertion, as well as rotation to operate a screwdriver.", "published": "2025-10-10T09:44:53Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.185059"}
{"arxiv_id": "2510.06091v1", "title": "Learning Mixtures of Linear Dynamical Systems (MoLDS) via Hybrid   Tensor-EM Method", "summary": "Mixtures of linear dynamical systems (MoLDS) provide a path to model time-series data that exhibit diverse temporal dynamics across trajectories. However, its application remains challenging in complex and noisy settings, limiting its effectiveness for neural data analysis. Tensor-based moment methods can provide global identifiability guarantees for MoLDS, but their performance degrades under noise and complexity. Commonly used expectation-maximization (EM) methods offer flexibility in fitting latent models but are highly sensitive to initialization and prone to poor local minima. Here, we propose a tensor-based method that provides identifiability guarantees for learning MoLDS, which is followed by EM updates to combine the strengths of both approaches. The novelty in our approach lies in the construction of moment tensors using the input-output data to recover globally consistent estimates of mixture weights and system parameters. These estimates can then be refined through a Kalman EM algorithm, with closed-form updates for all LDS parameters. We validate our framework on synthetic benchmarks and real-world datasets. On synthetic data, the proposed Tensor-EM method achieves more reliable recovery and improved robustness compared to either pure tensor or randomly initialized EM methods. We then analyze neural recordings from the primate somatosensory cortex while a non-human primate performs reaches in different directions. Our method successfully models and clusters different conditions as separate subsystems, consistent with supervised single-LDS fits for each condition. Finally, we apply this approach to another neural dataset where monkeys perform a sequential reaching task. These results demonstrate that MoLDS provides an effective framework for modeling complex neural data, and that Tensor-EM is a reliable approach to MoLDS learning for these applications.", "published": "2025-10-07T16:17:52Z", "query": "somatosensory prosthesis", "relevance": 0.25, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.185252"}
{"arxiv_id": "2509.20523v1", "title": "A Compound Classification System Based on Fuzzy Relations Applied to the   Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition", "summary": "Modern anthropomorphic upper limb bioprostheses are typically controlled by electromyographic (EMG) biosignals using a pattern recognition scheme. Unfortunately, there are many factors originating from the human source of objects to be classified and from the human-prosthesis interface that make it difficult to obtain an acceptable classification quality. One of these factors is the high susceptibility of biosignals to contamination, which can considerably reduce the quality of classification of a recognition system.   In the paper, the authors propose a new recognition system intended for EMG based control of the hand prosthesis with detection of contaminated biosignals in order to mitigate the adverse effect of contaminations. The system consists of two ensembles: the set of one-class classifiers (OCC) to assess the degree of contamination of individual channels and the ensemble of K-nearest neighbours (KNN) classifier to recognise the patient's intent. For all recognition systems, an original, coherent fuzzy model was developed, which allows the use of a uniform soft (fuzzy) decision scheme throughout the recognition process. The experimental evaluation was conducted using real biosignals from a public repository. The goal was to provide an experimental comparative analysis of the parameters and procedures of the developed method on which the quality of the recognition system depends. The proposed fuzzy recognition system was also compared with similar systems described in the literature.", "published": "2025-09-24T19:48:21Z", "query": "somatosensory prosthesis", "relevance": 0.2, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.185417"}
{"arxiv_id": "2509.02275v1", "title": "Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object   and Pose Recognition Using Multimodal Signals", "summary": "The human somatosensory system integrates multimodal sensory feedback, including tactile, proprioceptive, and thermal signals, to enable comprehensive perception and effective interaction with the environment. Inspired by the biological mechanism, we present a sensorized soft anthropomorphic hand equipped with diverse sensors designed to emulate the sensory modalities of the human hand. This system incorporates biologically inspired encoding schemes that convert multimodal sensory data into spike trains, enabling highly-efficient processing through Spiking Neural Networks (SNNs). By utilizing these neuromorphic signals, the proposed framework achieves 97.14% accuracy in object recognition across varying poses, significantly outperforming previous studies on soft hands. Additionally, we introduce a novel differentiator neuron model to enhance material classification by capturing dynamic thermal responses. Our results demonstrate the benefits of multimodal sensory fusion and highlight the potential of neuromorphic approaches for achieving efficient, robust, and human-like perception in robotic systems.", "published": "2025-09-02T12:52:53Z", "query": "somatosensory prosthesis", "relevance": 0.3, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.185546"}
{"arxiv_id": "2509.00787v3", "title": "Image-to-Brain Signal Generation for Visual Prosthesis with CLIP Guided   Multimodal Diffusion Models", "summary": "Visual prostheses hold great promise for restoring vision in blind individuals. While researchers have successfully utilized M/EEG signals to evoke visual perceptions during the brain decoding stage of visual prostheses, the complementary process of converting images into M/EEG signals in the brain encoding stage remains largely unexplored, hindering the formation of a complete functional pipeline. In this work, we present, to our knowledge, the first image-to-brain signal framework that generates M/EEG from images by leveraging denoising diffusion probabilistic models enhanced with cross-attention mechanisms. Specifically, the proposed framework comprises two key components: a pretrained CLIP visual encoder that extracts rich semantic representations from input images, and a cross-attention enhanced U-Net diffusion model that reconstructs brain signals through iterative denoising. Unlike conventional generative models that rely on simple concatenation for conditioning, our cross-attention modules capture the complex interplay between visual features and brain signal representations, enabling fine-grained alignment during generation. We evaluate the framework on two multimodal benchmark datasets and demonstrate that it generates biologically plausible brain signals. We also present visualizations of M/EEG topographies across all subjects in both datasets, providing intuitive demonstrations of intra-subject and inter-subject variations in brain signals.", "published": "2025-08-31T10:29:58Z", "query": "somatosensory prosthesis", "relevance": 0.65, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.185665"}
{"arxiv_id": "2508.01808v1", "title": "Learning to Perform Low-Contact Autonomous Nasotracheal Intubation by   Recurrent Action-Confidence Chunking with Transformer", "summary": "Nasotracheal intubation (NTI) is critical for establishing artificial airways in clinical anesthesia and critical care. Current manual methods face significant challenges, including cross-infection, especially during respiratory infection care, and insufficient control of endoluminal contact forces, increasing the risk of mucosal injuries. While existing studies have focused on automated endoscopic insertion, the automation of NTI remains unexplored despite its unique challenges: Nasotracheal tubes exhibit greater diameter and rigidity than standard endoscopes, substantially increasing insertion complexity and patient risks. We propose a novel autonomous NTI system with two key components to address these challenges. First, an autonomous NTI system is developed, incorporating a prosthesis embedded with force sensors, allowing for safety assessment and data filtering. Then, the Recurrent Action-Confidence Chunking with Transformer (RACCT) model is developed to handle complex tube-tissue interactions and partial visual observations. Experimental results demonstrate that the RACCT model outperforms the ACT model in all aspects and achieves a 66% reduction in average peak insertion force compared to manual operations while maintaining equivalent success rates. This validates the system's potential for reducing infection risks and improving procedural safety.", "published": "2025-08-03T15:43:58Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.185788"}
{"arxiv_id": "2508.00491v1", "title": "HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation   Learning", "summary": "Recent advancements in control of prosthetic hands have focused on increasing autonomy through the use of cameras and other sensory inputs. These systems aim to reduce the cognitive load on the user by automatically controlling certain degrees of freedom. In robotics, imitation learning has emerged as a promising approach for learning grasping and complex manipulation tasks while simplifying data collection. Its application to the control of prosthetic hands remains, however, largely unexplored. Bridging this gap could enhance dexterity restoration and enable prosthetic devices to operate in more unconstrained scenarios, where tasks are learned from demonstrations rather than relying on manually annotated sequences. To this end, we present HannesImitationPolicy, an imitation learning-based method to control the Hannes prosthetic hand, enabling object grasping in unstructured environments. Moreover, we introduce the HannesImitationDataset comprising grasping demonstrations in table, shelf, and human-to-prosthesis handover scenarios. We leverage such data to train a single diffusion policy and deploy it on the prosthetic hand to predict the wrist orientation and hand closure for grasping. Experimental evaluation demonstrates successful grasps across diverse objects and conditions. Finally, we show that the policy outperforms a segmentation-based visual servo controller in unstructured scenarios. Additional material is provided on our project page: https://hsp-iit.github.io/HannesImitation", "published": "2025-08-01T10:09:38Z", "query": "somatosensory prosthesis", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.185912"}
{"arxiv_id": "2507.23450v1", "title": "The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG   Source Localization", "summary": "EEG Source localization is a critical tool in neuroscience, with applications ranging from epilepsy diagnosis to cognitive research. It involves solving an ill-posed inverse problem that lacks a unique solution unless constrained by prior knowledge. The Bayesian framework enables the incorporation of such knowledge, typically encoded through prior models. Various algorithms have been proposed for source localization, and they differ significantly in how prior knowledge is incorporated. Some approaches rely on anatomical or functional constraints, while others use statistical distributions or sampling-based techniques. In this landscape, the Standardized Kalman Filter (SKF) represents a dynamic Bayesian approach that integrates temporal modeling with a Gaussian prior structure. It addresses the depth bias, a common limitation in source localization, through a post-hoc standardization step that equalizes sensitivity across cortical depths and makes deep activity detection feasible.   This study focuses on the development and optimization of Gaussian prior models within the SKF framework for simultaneous cortical and sub-cortical activity detection. Synthetic data similar to the P20 / N20 component of the somatosensory evoked potentials (SEP) was used to identify effective prior parameter configurations for reconstructing both deep and superficial sources under different noise levels. We also investigated the role of RTS smoothing in enhancing source separability. Our results indicate that raising the standardization exponent to 1.25, along with smoothing, significantly improves depth localization accuracy at low noise levels.", "published": "2025-07-31T11:27:02Z", "query": "somatosensory prosthesis", "relevance": 0.44999999999999996, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.186057"}
{"arxiv_id": "2508.00928v1", "title": "Modeling Head-Neck Dynamics under Lateral Perturbations Using MPC to   Mimic CNS postural stabilization strategy", "summary": "Automated vehicles will allow occupants to engage in non-driving tasks, but limited visual cues will make them vulnerable to unexpected movements. These unpredictable perturbations create a \"surprise factor,\" forcing the central nervous system to rely on compensatory postural adjustments, which are less effective, and are more likely to trigger sensory conflicts. Since the head is a key reference for sensory input (vestibular and vision), models accurately capturing head-neck postural stabilization are essential for assessing AV comfort. This study extends an existing model predictive control-based framework to simulate head-neck postural control under lateral perturbations. Experimental validation against human data demonstrates that the model can accurately reproduce dynamic responses during lateral trunk perturbations. The results show that muscle effort combined with partial somatosensory feedback provides the best overall dynamic fit without requiring corrective relative and global head orientation integrators for posture.", "published": "2025-07-30T13:19:40Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.186163"}
{"arxiv_id": "2507.21384v1", "title": "Projecting the New Body: How Body Image Evolves During Learning to Walk   with a Wearable Robot", "summary": "Advances in wearable robotics challenge the traditional definition of human motor systems, as wearable robots redefine body structure, movement capability, and perception of their own bodies. We measured gait performance and perceived body images via Selected Coefficient of Perceived Motion, SCoMo, after each training session. Based on human motor learning theory extended to wearer-robot systems, we hypothesized that learning the perceived body image when walking with a robotic leg co-evolves with the actual gait improvement and becomes more certain and more accurate to the actual motion. Our result confirmed that motor learning improved both physical and perceived gait pattern towards normal, indicating that via practice the wearers incorporated the robotic leg into their sensorimotor systems to enable wearer-robot movement coordination. However, a persistent discrepancy between perceived and actual motion remained, likely due to the absence of direct sensation and control of the prosthesis from wearers. Additionally, the perceptual overestimation at the later training sessions might limit further motor improvement. These findings suggest that enhancing the human sense of wearable robots and frequent calibrating perception of body image are essential for effective training with lower limb wearable robots and for developing more embodied assistive technologies.", "published": "2025-07-28T23:34:57Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.186292"}
{"arxiv_id": "2507.20049v1", "title": "A real-time full-chain wearable sensor-based musculoskeletal simulation:   an OpenSim-ROS Integration", "summary": "Musculoskeletal modeling and simulations enable the accurate description and analysis of the movement of biological systems with applications such as rehabilitation assessment, prosthesis, and exoskeleton design. However, the widespread usage of these techniques is limited by costly sensors, laboratory-based setups, computationally demanding processes, and the use of diverse software tools that often lack seamless integration. In this work, we address these limitations by proposing an integrated, real-time framework for musculoskeletal modeling and simulations that leverages OpenSimRT, the robotics operating system (ROS), and wearable sensors. As a proof-of-concept, we demonstrate that this framework can reasonably well describe inverse kinematics of both lower and upper body using either inertial measurement units or fiducial markers. Additionally, we show that it can effectively estimate inverse dynamics of the ankle joint and muscle activations of major lower limb muscles during daily activities, including walking, squatting and sit to stand, stand to sit when combined with pressure insoles. We believe this work lays the groundwork for further studies with more complex real-time and wearable sensor-based human movement analysis systems and holds potential to advance technologies in rehabilitation, robotics and exoskeleton designs.", "published": "2025-07-26T20:04:26Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.186420"}
{"arxiv_id": "2507.17649v1", "title": "Event Detection for Active Lower Limb Prosthesis", "summary": "Accurate event detection is key to the successful design of semi-passive and powered prosthetics. Kinematically, the natural knee is complex, with translation and rotation components that have a substantial impact on gait characteristics. When simplified to a pin joint, some of this behaviour is lost. This study investigates the role of cruciate ligament stretch in event detection. A bicondylar knee design was used, constrained by analogues of the anterior and posterior cruciate ligaments. This offers the ability to characterize knee kinematics by the stretch of the ligaments. The ligament stretch was recorded using LVDTs parallel to the ligaments of the Russell knee on a bent knee crutch. Which was used to capture data on a treadmill at 3 speeds. This study finds speed dependence within the stretch of the cruciate ligaments, prominently around 5\\% and 80\\% of the gait cycle for the posterior and anterior. The cycle profile remains consistent with speed; therefore, other static events such as the turning point feature at around 90\\% and 95\\% of the cycle, for the posterior and anterior, respectively, could be used as a predictive precursor for initial contact. Likewise at 90\\% and 95\\%, another pair of turning points that in this case could be used to predict foot flat. This concludes that the use of a bicondylar knee design could improve the detection of events during the gait cycle, and therefore could increase the accuracy of subsequent controllers for powered prosthetics.", "published": "2025-07-23T16:14:08Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.186555"}
{"arxiv_id": "2507.10223v1", "title": "ProGait: A Multi-Purpose Video Dataset and Benchmark for Transfemoral   Prosthesis Users", "summary": "Prosthetic legs play a pivotal role in clinical rehabilitation, allowing individuals with lower-limb amputations the ability to regain mobility and improve their quality of life. Gait analysis is fundamental for optimizing prosthesis design and alignment, directly impacting the mobility and life quality of individuals with lower-limb amputations. Vision-based machine learning (ML) methods offer a scalable and non-invasive solution to gait analysis, but face challenges in correctly detecting and analyzing prosthesis, due to their unique appearances and new movement patterns. In this paper, we aim to bridge this gap by introducing a multi-purpose dataset, namely ProGait, to support multiple vision tasks including Video Object Segmentation, 2D Human Pose Estimation, and Gait Analysis (GA). ProGait provides 412 video clips from four above-knee amputees when testing multiple newly-fitted prosthetic legs through walking trials, and depicts the presence, contours, poses, and gait patterns of human subjects with transfemoral prosthetic legs. Alongside the dataset itself, we also present benchmark tasks and fine-tuned baseline models to illustrate the practical application and performance of the ProGait dataset. We compared our baseline models against pre-trained vision models, demonstrating improved generalizability when applying the ProGait dataset for prosthesis-specific tasks. Our code is available at https://github.com/pittisl/ProGait and dataset at https://huggingface.co/datasets/ericyxy98/ProGait.", "published": "2025-07-14T12:40:57Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.186691"}
{"arxiv_id": "2507.08268v1", "title": "Portable Biomechanics Laboratory: Clinically Accessible Movement   Analysis from a Handheld Smartphone", "summary": "The way a person moves is a direct reflection of their neurological and musculoskeletal health, yet it remains one of the most underutilized vital signs in clinical practice. Although clinicians visually observe movement impairments, they lack accessible and validated methods to objectively measure movement in routine care. This gap prevents wider use of biomechanical measurements in practice, which could enable more sensitive outcome measures or earlier identification of impairment. We present our Portable Biomechanics Laboratory (PBL), which includes a secure, cloud-enabled smartphone app for data collection and a novel algorithm for fitting biomechanical models to this data. We extensively validated PBL's biomechanical measures using a large, clinically representative dataset. Next, we tested the usability and utility of our system in neurosurgery and sports medicine clinics. We found joint angle errors within 3 degrees across participants with neurological injury, lower-limb prosthesis users, pediatric inpatients, and controls. In addition to being easy to use, gait metrics computed from the PBL showed high reliability and were sensitive to clinical differences. For example, in individuals undergoing decompression surgery for cervical myelopathy, the mJOA score is a common patient-reported outcome measure; we found that PBL gait metrics correlated with mJOA scores and demonstrated greater responsiveness to surgical intervention than the patient-reported outcomes. These findings support the use of handheld smartphone video as a scalable, low-burden tool for capturing clinically meaningful biomechanical data, offering a promising path toward accessible monitoring of mobility impairments. We release the first clinically validated method for measuring whole-body kinematics from handheld smartphone video at https://intelligentsensingandrehabilitation.github.io/MonocularBiomechanics/ .", "published": "2025-07-11T02:29:26Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.186829"}
{"arxiv_id": "2506.14563v1", "title": "Single-Example Learning in a Mixture of GPDMs with Latent Geometries", "summary": "We present the Gaussian process dynamical mixture model (GPDMM) and show its utility in single-example learning of human motion data. The Gaussian process dynamical model (GPDM) is a form of the Gaussian process latent variable model (GPLVM), but optimized with a hidden Markov model dynamical prior. The GPDMM combines multiple GPDMs in a probabilistic mixture-of-experts framework, utilizing embedded geometric features to allow for diverse sequences to be encoded in a single latent space, enabling the categorization and generation of each sequence class. GPDMs and our mixture model are particularly advantageous in addressing the challenges of modeling human movement in scenarios where data is limited and model interpretability is vital, such as in patient-specific medical applications like prosthesis control. We score the GPDMM on classification accuracy and generative ability in single-example learning, showcase model variations, and benchmark it against LSTMs, VAEs, and transformers.", "published": "2025-06-17T14:22:07Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.186941"}
{"arxiv_id": "2506.03423v1", "title": "Sub-Scalp EEG for Sensorimotor Brain-Computer Interface", "summary": "Objective: To establish sub-scalp electroencephalography (EEG) as a viable option for brain-computer interface (BCI) applications, particularly for chronic use, by demonstrating its effectiveness in recording and classifying sensorimotor neural activity. Approach: Two experiments were conducted in this study. The first aim was to demonstrate the high spatial resolution of sub-scalp EEG through analysis of somatosensory evoked potentials in sheep models. The second focused on the practical application of sub-scalp EEG, classifying motor execution using data collected during a sheep behavioural experiment. Main Results: We successfully demonstrated the recording of sensorimotor rhythms using sub-scalp EEG in sheep models. Important spatial, temporal, and spectral features of these signals were identified, and we were able to classify motor execution with above-chance performance. These results are comparable to previous work that investigated signal quality and motor execution classification using ECoG and endovascular arrays in sheep models. Significance: These results suggest that sub-scalp EEG may provide signal quality that approaches that of more invasive neural recording methods such as ECoG and endovascular arrays, and support the use of sub-scalp EEG for chronic BCI applications.", "published": "2025-06-03T22:03:58Z", "query": "somatosensory prosthesis", "relevance": 0.9500000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.187057"}
{"arxiv_id": "2505.18361v4", "title": "Task-Optimized Convolutional Recurrent Networks Align with Tactile   Processing in the Rodent Brain", "summary": "Tactile sensing remains far less understood in neuroscience and less effective in artificial systems compared to more mature modalities such as vision and language. We bridge these gaps by introducing a novel Encoder-Attender-Decoder (EAD) framework to systematically explore the space of task-optimized temporal neural networks trained on realistic tactile input sequences from a customized rodent whisker-array simulator. We identify convolutional recurrent neural networks (ConvRNNs) as superior encoders to purely feedforward and state-space architectures for tactile categorization. Crucially, these ConvRNN-encoder-based EAD models achieve neural representations closely matching rodent somatosensory cortex, saturating the explainable neural variability and revealing a clear linear relationship between supervised categorization performance and neural alignment. Furthermore, contrastive self-supervised ConvRNN-encoder-based EADs, trained with tactile-specific augmentations, match supervised neural fits, serving as an ethologically-relevant, label-free proxy.   For neuroscience, our findings highlight nonlinear recurrent processing as important for general-purpose tactile representations in somatosensory cortex, providing the first quantitative characterization of the underlying inductive biases in this system. For embodied AI, our results emphasize the importance of recurrent EAD architectures to handle realistic tactile inputs, along with tailored self-supervised learning methods for achieving robust tactile perception with the same type of sensors animals use to sense in unstructured environments.", "published": "2025-05-23T20:40:28Z", "query": "somatosensory prosthesis", "relevance": 0.2, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.187209"}
{"arxiv_id": "2505.09819v2", "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding   Performance of Upper Limb Prostheses", "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern recognition (PR) control systems that translate electromyography (EMG) signals into desired movements. As prosthesis movement complexity increases, users often struggle to produce sufficiently distinct EMG patterns for reliable classification. Existing training typically involves heuristic, trial-and-error user adjustments to static decoder boundaries. Goal: We introduce the Reviewer, a 3D visual interface projecting EMG signals directly into the decoder's classification space, providing intuitive, real-time insight into PR algorithm behavior. This structured feedback reduces cognitive load and fosters mutual, data-driven adaptation between user-generated EMG patterns and decoder boundaries. Methods: A 10-session study with 12 able-bodied participants compared PR performance after motor-based training and updating using the Reviewer versus conventional virtual arm visualization. Performance was assessed using a Fitts law task that involved the aperture of the cursor and the control of orientation. Results: Participants trained with the Reviewer achieved higher completion rates, reduced overshoot, and improved path efficiency and throughput compared to the standard visualization group. Significance: The Reviewer introduces decoder-informed motor training, facilitating immediate and consistent PR-based myoelectric control improvements. By iteratively refining control through real-time feedback, this approach reduces reliance on trial-and-error recalibration, enabling a more adaptive, self-correcting training framework. Conclusion: The 3D visual feedback significantly improves PR control in novice operators through structured training, enabling feedback-driven adaptation and reducing reliance on extensive heuristic adjustments.", "published": "2025-05-14T21:47:28Z", "query": "somatosensory prosthesis", "relevance": 0.25, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.187340"}
{"arxiv_id": "2505.09366v1", "title": "Personalized Control for Lower Limb Prosthesis Using Kolmogorov-Arnold   Networks", "summary": "Objective: This paper investigates the potential of learnable activation functions in Kolmogorov-Arnold Networks (KANs) for personalized control in a lower-limb prosthesis. In addition, user-specific vs. pooled training data is evaluated to improve machine learning (ML) and Deep Learning (DL) performance for turn intent prediction.   Method: Inertial measurement unit (IMU) data from the shank were collected from five individuals with lower-limb amputation performing turning tasks in a laboratory setting. Ability to classify an upcoming turn was evaluated for Multilayer Perceptron (MLP), Kolmogorov-Arnold Network (KAN), convolutional neural network (CNN), and fractional Kolmogorov-Arnold Networks (FKAN). The comparison of MLP and KAN (for ML models) and FKAN and CNN (for DL models) assessed the effectiveness of learnable activation functions. Models were trained separately on user-specific and pooled data to evaluate the impact of training data on their performance.   Results: Learnable activation functions in KAN and FKAN did not yield significant improvement compared to MLP and CNN, respectively. Training on user-specific data yielded superior results compared to pooled data for ML models ($p &lt; 0.05$). In contrast, no significant difference was observed between user-specific and pooled training for DL models.   Significance: These findings suggest that learnable activation functions may demonstrate distinct advantages in datasets involving more complex tasks and larger volumes. In addition, pooled training showed comparable performance to user-specific training in DL models, indicating that model training for prosthesis control can utilize data from multiple participants.", "published": "2025-05-14T13:18:57Z", "query": "somatosensory prosthesis", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.187488"}
{"arxiv_id": "2505.03458v2", "title": "The classification of Alzheimer's disease and mild cognitive impairment   improved by dynamic functional network analysis", "summary": "Brain network analysis using functional MRI has advanced our understanding of cortical activity and its changes in neurodegenerative disorders that cause dementia. Recently, research in brain connectivity has focused on dynamic (time-varying) brain networks that capture both spatial and temporal information on cortical, regional co-activity patterns. However, this approach has been largely unexplored within the Alzheimer's spectrum. We analysed age- and sex-matched static and dynamic fMRI brain networks from 315 individuals with Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI), and cognitively-normal Healthy Elderly (HE), using data from the ADNI-3 protocol. We examined both similarities and differences between these groups, employing the Juelich brain atlas for network nodes, sliding-window correlations for time-varying network links, and non-parametric statistics to assess between-group differences at the link or the node centrality level. While the HE and MCI groups show similar static and dynamic networks at the link level, significant differences emerge compared to AD participants. We found stable (stationary) differences in patterns of functional connections between the white matter regions and the parietal lobe's, and somatosensory cortices, while metastable (temporal) networks' differences were consistently found between the amygdala and hippocampal formation. In addition, our node centrality analysis showed that the white matter connectivity patterns are local in nature. Our results highlight shared and unique functional connectivity patterns in both stationary and dynamic functional networks, emphasising the need to include dynamic information in brain network analysis in studies of Alzheimer's spectrum.", "published": "2025-05-06T11:57:06Z", "query": "somatosensory prosthesis", "relevance": 0.35, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.187639"}
{"arxiv_id": "2505.02574v1", "title": "Learning and Online Replication of Grasp Forces from Electromyography   Signals for Prosthetic Finger Control", "summary": "Partial hand amputations significantly affect the physical and psychosocial well-being of individuals, yet intuitive control of externally powered prostheses remains an open challenge. To address this gap, we developed a force-controlled prosthetic finger activated by electromyography (EMG) signals. The prototype, constructed around a wrist brace, functions as a supernumerary finger placed near the index, allowing for early-stage evaluation on unimpaired subjects. A neural network-based model was then implemented to estimate fingertip forces from EMG inputs, allowing for online adjustment of the prosthetic finger grip strength. The force estimation model was validated through experiments with ten participants, demonstrating its effectiveness in predicting forces. Additionally, online trials with four users wearing the prosthesis exhibited precise control over the device. Our findings highlight the potential of using EMG-based force estimation to enhance the functionality of prosthetic fingers.", "published": "2025-05-05T11:23:51Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:39.187781"}
{"arxiv_id": "2505.01718v1", "title": "Mitigating Compensatory Movements in Prosthesis Users via Adaptive   Collaborative Robotics", "summary": "Prosthesis users can regain partial limb functionality, however, full natural limb mobility is rarely restored, often resulting in compensatory movements that lead to discomfort, inefficiency, and long-term physical strain. To address this issue, we propose a novel human-robot collaboration framework to mitigate compensatory mechanisms in upper-limb prosthesis users by exploiting their residual motion capabilities while respecting task requirements. Our approach introduces a personalised mobility model that quantifies joint-specific functional limitations and the cost of compensatory movements. This model is integrated into a constrained optimisation framework that computes optimal user postures for task performance, balancing functionality and comfort. The solution guides a collaborative robot to reconfigure the task environment, promoting effective interaction. We validated the framework using a new body-powered prosthetic device for single-finger amputation, which enhances grasping capabilities through synergistic closure with the hand but imposes wrist constraints. Initial experiments with healthy subjects wearing the prosthesis as a supernumerary finger demonstrated that a robotic assistant embedding the user-specific mobility model outperformed human partners in handover tasks, improving both the efficiency of the prosthesis user's grasp and reducing compensatory movements in functioning joints. These results highlight the potential of collaborative robots as effective workplace and caregiving assistants, promoting inclusion and better integration of prosthetic devices into daily tasks.", "published": "2025-05-03T07:05:19Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.187919"}
{"arxiv_id": "2505.00196v1", "title": "Mapping minds not averages: a scalable subject-specific manifold   learning framework for neuroimaging data", "summary": "Mental and cognitive representations are believed to reside on low-dimensional, non-linear manifolds embedded within high-dimensional brain activity. Uncovering these manifolds is key to understanding individual differences in brain function, yet most existing machine learning methods either rely on population-level spatial alignment or assume data that is temporally structured, either because data is aligned among subjects or because event timings are known. We introduce a manifold learning framework that can capture subject-specific spatial variations across both structured and temporally unstructured neuroimaging data. On simulated data and two naturalistic fMRI datasets (Sherlock and Forrest Gump), our framework outperforms group-based baselines by recovering more accurate and individualized representations. We further show that the framework scales efficiently to large datasets and generalizes well to new subjects. To test this, we apply the framework to temporally unstructured resting-state fMRI data from individuals with schizophrenia and healthy controls. We further apply our method to a large resting-state fMRI dataset comprising individuals with schizophrenia and controls. In this setting, we demonstrate that the framework scales efficiently to large populations and generalizes robustly to unseen subjects. The learned subject-specific spatial maps our model finds reveal clinically relevant patterns, including increased activation in the basal ganglia, visual, auditory, and somatosensory regions, and decreased activation in the insula, inferior frontal gyrus, and angular gyrus. These findings suggest that our framework can uncover clinically relevant subject-specific brain activity patterns. Our approach thus provides a scalable and individualized framework for modeling brain activity, with applications in computational neuroscience and clinical research.", "published": "2025-04-30T21:40:54Z", "query": "somatosensory prosthesis", "relevance": 0.25, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.188050"}
{"arxiv_id": "2504.15654v2", "title": "A Vision-Enabled Prosthetic Hand for Children with Upper Limb   Disabilities", "summary": "This paper introduces a novel AI vision-enabled pediatric prosthetic hand designed to assist children aged 10-12 with upper limb disabilities. The prosthesis features an anthropomorphic appearance, multi-articulating functionality, and a lightweight design that mimics a natural hand, making it both accessible and affordable for low-income families. Using 3D printing technology and integrating advanced machine vision, sensing, and embedded computing, the prosthetic hand offers a low-cost, customizable solution that addresses the limitations of current myoelectric prostheses. A micro camera is interfaced with a low-power FPGA for real-time object detection and assists with precise grasping. The onboard DL-based object detection and grasp classification models achieved accuracies of 96% and 100% respectively. In the force prediction, the mean absolute error was found to be 0.018. The features of the proposed prosthetic hand can thus be summarized as: a) a wrist-mounted micro camera for artificial sensing, enabling a wide range of hand-based tasks; b) real-time object detection and distance estimation for precise grasping; and c) ultra-low-power operation that delivers high performance within constrained power and resource limits.", "published": "2025-04-22T07:23:51Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.188202"}
{"arxiv_id": "2503.23808v1", "title": "Why does tinnitus vary with naps? A polysomnographic prospective study   exploring the somatosensory hypothesis", "summary": "Background: Tinnitus, defined as the conscious awareness of a noise without any identifiable corresponding external acoustic source, can be modulated by various factors. Among these factors, tinnitus patients commonly report drastic increases of tinnitus loudness following nap sleep. Previous studies have suggested that this clinical pattern could be attributed to a somatosensory modulation of tinnitus. To our knowledge, no polysomnographic study has been carried out to assess this hypothesis. Methods: For this observational prospective study, 37 participants reporting frequent increases of tinnitus following naps were recruited. They participated to six full-polysomnography nap attempts over two days. Audiological and kinesiologic tests were conducted before and after each nap attempt. Results: 197 naps were collected. Each nap at each time of day elicited an overall significant increase in tinnitus minimum masking level (MML). Each inter nap period elicited an overall significant decrease. Tinnitus modulations were found significantly correlated with nap sleep duration (Visual numeric scale on tinnitus loudness, VNS-L, p &lt; 0.05), with snoring duration (MML, p &lt; 0.001), with snoring average sound level (VNS on tinnitus intrusiveness, VNS-I, p &lt; 0.05) and with sleep apnea count (VNS-I, p &lt; 0.001). Conclusions: This study confirms objectively that tinnitus may increase following naps. No association was found between these modulations and somatosensory modulations involving the temporomandibular joint and cervical areas. However, it may be possible that nap-induced tinnitus modulations are a hidden form of somatosensory modulation as snoring and sleep apnea events are often related to tensor veli palatini muscle dysfunction.", "published": "2025-03-31T07:42:33Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:39.188465"}
{"arxiv_id": "2503.23394v2", "title": "Spatiotemporal Learning of Brain Dynamics from fMRI Using   Frequency-Specific Multi-Band Attention for Cognitive and Psychiatric   Applications", "summary": "Understanding how the brain's complex nonlinear dynamics give rise to cognitive function remains a central challenge in neuroscience. While brain functional dynamics exhibits scale-free and multifractal properties across temporal scales, conventional neuroimaging analytics assume linearity and stationarity, failing to capture frequency-specific neural computations. Here, we introduce Multi-Band Brain Net (MBBN), the first transformer-based framework to explicitly model frequency-specific spatiotemporal brain dynamics from fMRI. MBBN integrates biologically-grounded frequency decomposition with multi-band self-attention mechanisms, enabling discovery of previously undetectable frequency-dependent network interactions. Trained on 49,673 individuals across three large-scale cohorts (UK Biobank, ABCD, ABIDE), MBBN sets a new state-of-the-art in predicting psychiatric and cognitive outcomes (depression, ADHD, ASD), showing particular strength in classification tasks with up to 52.5\\% higher AUROC and provides a novel framework for predicting cognitive intelligence scores. Frequency-resolved analyses uncover disorder-specific signatures: in ADHD, high-frequency fronto-sensorimotor connectivity is attenuated and opercular somatosensory nodes emerge as dynamic hubs; in ASD, orbitofrontal-somatosensory circuits show focal high-frequency disruption together with enhanced ultra-low-frequency coupling between the temporo-parietal junction and prefrontal cortex. By integrating scale-aware neural dynamics with deep learning, MBBN delivers more accurate and interpretable biomarkers, opening avenues for precision psychiatry and developmental neuroscience.", "published": "2025-03-30T10:56:50Z", "query": "somatosensory prosthesis", "relevance": 0.35, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.188643"}
{"arxiv_id": "2503.15663v1", "title": "Implantable CMOS probes for high resolution Electrical Imaging of Local   Field Potentials Across the Rat Barrel Cortex in vivo", "summary": "High-resolution recordings of extracellular potentials are fundamental for the study of neuronal networks, the basis of neuronal coding and transmission. Here we present an innovative method for an in vivo electrical imaging of Local Field Potentials using novel implantable neural interfaces with a high-density array of 256 recording sites and a spatial resolution of 15 {\\mu}m. Thanks to this technology, we analyze the propagation of whisker-evoked activity in a single barrel-column of the rat somatosensory cortex.", "published": "2025-03-19T19:28:37Z", "query": "somatosensory prosthesis", "relevance": 0.39999999999999997, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.188761"}
{"arxiv_id": "2503.13490v1", "title": "Cascade of one-class classifier ensemble and dynamic naive Bayes   classifier applied to the myoelectric-based upper limb prosthesis control   with contaminated channels detection", "summary": "Modern upper limb bioprostheses are typically controlled by sEMG signals using a pattern recognition scheme in the control process. Unfortunately, the sEMG signal is very susceptible to contamination that deteriorates the quality of the control system and reduces the usefulness of the prosthesis in the patient's everyday life. In the paper, the authors propose a new recognition system intended for sEMG-based control of the hand prosthesis with detection of contaminated sEMG signals. The originality of the proposed solution lies in the co-operation of two recognition systems working in a cascade structure: (1) an ensemble of one-class classifiers used to recognise contaminated signals and (2) a naive Bayes classifier (NBC) which recognises the patient's intentions using the information about contaminations produced by the ensemble. Although in the proposed approach, the NBC model is changed dynamically, due to the multiplicative form of the classification functions, training can be performed in a one-shot procedure. Experimental studies were conducted using real sEMG signals. The results obtained confirm the hypothesis that the use of the one-class classifier ensemble and the dynamic NBC model leads to improved classification quality.", "published": "2025-03-10T11:39:36Z", "query": "somatosensory prosthesis", "relevance": 0.2, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:39.188936"}
{"arxiv_id": "2503.01058v3", "title": "Training Tactile Sensors to Learn Force Sensing from Each Other", "summary": "Humans achieve stable and dexterous object manipulation by coordinating grasp forces across multiple fingers and palms, facilitated by a unified tactile memory system in the somatosensory cortex. This system encodes and stores tactile experiences across skin regions, enabling the flexible reuse and transfer of touch information. Inspired by this biological capability, we present GenForce, the first framework that enables transferable force sensing across tactile sensors in robotic hands. GenForce unifies tactile signals into shared marker representations, analogous to cortical sensory encoding, allowing force prediction models trained on one sensor to be transferred to others without the need for exhaustive force data collection. We demonstrate that GenForce generalizes across both homogeneous sensors with varying configurations and heterogeneous sensors with distinct sensing modalities and material properties. This transferable force sensing is also demonstrated with high performance in robot force control including daily object grasping, slip detection and avoidance. Our results highlight a scalable paradigm for cross-sensor robotic tactile learning, offering new pathways toward adaptable and tactile memory-driven manipulation in unstructured environments.", "published": "2025-03-02T23:36:21Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-25T15:16:39.189117"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.647711"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "closed-loop brain stimulation", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:42.648225"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.648457"}
{"arxiv_id": "2510.20196v1", "title": "A Structured Review and Quantitative Profiling of Public Brain MRI   Datasets for Foundation Model Development", "summary": "The development of foundation models for brain MRI depends critically on the scale, diversity, and consistency of available data, yet systematic assessments of these factors remain scarce. In this study, we analyze 54 publicly accessible brain MRI datasets encompassing over 538,031 to provide a structured, multi-level overview tailored to foundation model development. At the dataset level, we characterize modality composition, disease coverage, and dataset scale, revealing strong imbalances between large healthy cohorts and smaller clinical populations. At the image level, we quantify voxel spacing, orientation, and intensity distributions across 15 representative datasets, demonstrating substantial heterogeneity that can influence representation learning. We then perform a quantitative evaluation of preprocessing variability, examining how intensity normalization, bias field correction, skull stripping, spatial registration, and interpolation alter voxel statistics and geometry. While these steps improve within-dataset consistency, residual differences persist between datasets. Finally, feature-space case study using a 3D DenseNet121 shows measurable residual covariate shift after standardized preprocessing, confirming that harmonization alone cannot eliminate inter-dataset bias. Together, these analyses provide a unified characterization of variability in public brain MRI resources and emphasize the need for preprocessing-aware and domain-adaptive strategies in the design of generalizable brain MRI foundation models.", "published": "2025-10-23T04:31:09Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:42.648665"}
{"arxiv_id": "2510.20148v1", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity   in Tau Propagation Through Multi-Layer Modeling", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.", "published": "2025-10-23T02:52:42Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:42.648876"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:42.649074"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "closed-loop brain stimulation", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:42.649300"}
{"arxiv_id": "2510.19996v1", "title": "A Fundamental Algorithm for Dependency Parsing (With Corrections)", "summary": "This paper presents a fundamental algorithm for parsing natural language sentences into dependency trees. Unlike phrase-structure (constituency) parsers, this algorithm operates one word at a time, attaching each word as soon as it can be attached, corresponding to properties claimed for the parser in the human brain. Like phrase-structure parsing, its worst-case complexity is $O(n^3)$, but in human language, the worst case occurs only for small $n$.", "published": "2025-10-22T19:48:38Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.649477"}
{"arxiv_id": "2510.19764v1", "title": "A flexible framework for structural plasticity in GPU-accelerated sparse   spiking neural networks", "summary": "The majority of research in both training Artificial Neural Networks (ANNs) and modeling learning in biological brains focuses on synaptic plasticity, where learning equates to changing the strength of existing connections. However, in biological brains, structural plasticity - where new connections are created and others removed - is also vital, not only for effective learning but also for recovery from damage and optimal resource usage. Inspired by structural plasticity, pruning is often used in machine learning to remove weak connections from trained models to reduce the computational requirements of inference. However, the machine learning frameworks typically used for backpropagation-based training of both ANNs and Spiking Neural Networks (SNNs) are optimized for dense connectivity, meaning that pruning does not help reduce the training costs of ever-larger models. The GeNN simulator already supports efficient GPU-accelerated simulation of sparse SNNs for computational neuroscience and machine learning. Here, we present a new flexible framework for implementing GPU-accelerated structural plasticity rules and demonstrate this first using the e-prop supervised learning rule and DEEP R to train efficient, sparse SNN classifiers and then, in an unsupervised learning context, to learn topographic maps. Compared to baseline dense models, our sparse classifiers reduce training time by up to 10x while the DEEP R rewiring enables them to perform as well as the original models. We demonstrate topographic map formation in faster-than-realtime simulations, provide insights into the connectivity evolution, and measure simulation speed versus network size. The proposed framework will enable further research into achieving and maintaining sparsity in network structure and neural communication, as well as exploring the computational benefits of sparsity in a range of neuromorphic applications.", "published": "2025-10-22T16:50:00Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.649709"}
{"arxiv_id": "2510.19747v1", "title": "Review of Tools for Zero-Code LLM Based Application Development", "summary": "Large Language Models (LLMs) are transforming software creation by enabling zero code development platforms. Our survey reviews recent platforms that let users build applications without writing code, by leveraging LLMs as the brains of the development process. We adopt a broad survey methodology, categorizing platforms based on key dimensions such as interface style, backend integration, output type, and extensibility. We analyze both dedicated LLM based app builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and general no code platforms (e.g., Bubble, Glide) that integrate LLM capabilities. We present a taxonomy categorizing these platforms by their interface (conversational, visual, etc.), supported LLM backends, output type (chatbot, full application, workflow), and degree of extensibility. Core features such as autonomous agents, memory management, workflow orchestration, and API integrations are in scope of the survey. We provide a detailed comparison, highlighting each platform's strengths and limitations. Trade offs (customizability, scalability, vendor lock-in) are discussed in comparison with traditional and low code development approaches. Finally, we outline future directions, including multimodal interfaces, on device LLMs, and improved orchestration for democratizing app creation with AI. Our findings indicate that while zero code LLM platforms greatly reduce the barrier to creating AI powered applications, they still face challenges in flexibility and reliability. Overall, the landscape is rapidly evolving, offering exciting opportunities to empower non programmers to create sophisticated software.", "published": "2025-10-22T16:41:16Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.649918"}
{"arxiv_id": "2510.19702v1", "title": "Dictionary learning methods for brain activity mapping with MEG data", "summary": "A central goal in many brain studies is the identification of those brain regions that are activated during an observation window that may correspond to a motor task, a stimulus, or simply a resting state. While functional MRI is currently the most commonly employed modality for such task, methods based on the electromagnetic activity of the brain are valuable alternatives because of their excellent time resolution and of the fact that the measured signals are directly related to brain activation and not to a secondary effect such as the hemodynamic response. In this work we focus on the MEG modality, investigating the performance of a recently proposed Bayesian dictionary learning (BDL) algorithm for brain region identification. The partitioning of the source space into the 148 regions of interest (ROI) corresponding to parcellation of the Destrieux atlas provides a natural determination of the subdictionaries necessary for the BDL algorithm. We design a simulation protocol where a small randomly selected patch in each ROI is activated, the MEG signal is computed and the inverse problem of active brain region identification is solved using the BDL algorithm. The BDL algorithm consists of two phases, the first one comprising dictionary compression and Bayesian compression error analysis, and the second one performing dictionary coding with a deflated dictionary built on the output of the first phase, both steps relying on Bayesian sparsity promoting computations. For assessing the performance, we give a probabilistic interpretation of the confusion matrix, and consider different impurity measures for a multi-class classifier.", "published": "2025-10-22T15:53:22Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:42.650139"}
{"arxiv_id": "2510.19680v1", "title": "T2 mapping at 0.55 T using Ultra-Fast Spin Echo MRI", "summary": "Low-field T2 mapping MRI can democratize neuropediatric imaging by improving accessibility and providing quantitative biomarkers of brain development. \\textbf{Purpose:} To evaluate the feasibility of high-resolution T2 mapping using a single-shot fast spin-echo (SS-FSE) sequence at 0.55~T in a healthy control cohort. \\textbf{Study Type:} Prospective single-center study. \\textbf{Population:} In vivo: ten healthy adults (18--43~years, 5 females/5 males). In vitro: NIST Phantom. \\textbf{Field strength/sequence:} Multi-echo ultra-fast spin-echo at 0.55~T and 1.5~T. \\textbf{Assessment:} Feasibility was first assessed in vitro using the NIST Phantom, comparing T2 relaxation times to spectrometer references at 0.55~T. Acquisition and T2-fitting parameters optimized in vitro were applied in vivo. Repeatability was evaluated by atlas-based analysis of white matter (WM) and cortical grey matter (GM) regions. Coefficients of variation (CoV) were computed across runs, sessions, and subjects. \\textbf{Statistical Tests:} Wilcoxon signed-rank test with Bonferroni correction ($\\alpha = 0.05/n_{ROI}$) assessed CoV differences. Pearson correlation coefficients quantified T2 associations. \\textbf{Results:} In vitro, mono-exponential fitting under Gaussian--Rician noise yielded deviations $&lt;12\\%$ from reference values. In vivo, inter-subject CoV was 5.2\\% (WM) and 17.7\\% (GM), comparable to 1.5~T. Mean T2 times were 118~ms (WM) and 188~ms (GM) at 0.55~T, with a 16.5-minute acquisition. \\textbf{Conclusion:} A rapid, robust high-resolution T2 mapping protocol at 0.55~T for HASTE MRI is presented, employing Gaussian noise-based fitting. We report the first normative T2 values for healthy adult brains at 0.55~T, demonstrating technical feasibility and reliability.", "published": "2025-10-22T15:25:11Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.650414"}
{"arxiv_id": "2510.19537v1", "title": "Privacy-Preserving Spiking Neural Networks: A Deep Dive into Encryption   Parameter Optimisation", "summary": "Deep learning is widely applied to modern problems through neural networks, but the growing computational and energy demands of these models have driven interest in more efficient approaches. Spiking Neural Networks (SNNs), the third generation of neural networks, mimic the brain's event-driven behaviour, offering improved performance and reduced power use. At the same time, concerns about data privacy during cloud-based model execution have led to the adoption of cryptographic methods. This article introduces BioEncryptSNN, a spiking neural network based encryption-decryption framework for secure and noise-resilient data protection. Unlike conventional algorithms, BioEncryptSNN converts ciphertext into spike trains and exploits temporal neural dynamics to model encryption and decryption, optimising parameters such as key length, spike timing, and synaptic connectivity. Benchmarked against AES-128, RSA-2048, and DES, BioEncryptSNN preserved data integrity while achieving up to 4.1x faster encryption and decryption than PyCryptodome's AES implementation. The framework demonstrates scalability and adaptability across symmetric and asymmetric ciphers, positioning SNNs as a promising direction for secure, energy-efficient computing.", "published": "2025-10-22T12:43:46Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.650647"}
{"arxiv_id": "2510.19498v1", "title": "Energy-Efficient and Dequantization-Free Q-LLMs: A Spiking Neural   Network Approach to Salient Value Mitigation", "summary": "In the era of large language models (LLMs), weight-activation quantization helps fit models on edge device by reducing memory and compute bit-widths. However, three challenges persist for energy constrained hardware: (1) even after quantization, multiply-accumulate (MAC) operations remain unavoidable and continue to dominate energy consumption; (2) dequantization (or per-tensor/channel rescaling) introduces extra arithmetic and data movement, increasing latency and energy; (3) uniform parameters bit widths clip salient values-while intra-channel mixed precision is generally impractical on current matrix hardware and memory. In contrast, brain-inspired Spiking Neural Networks (SNNs), owing to their binary spike-based information representation and the Integrate-and-Fire (IF) paradigm, naturally support mixed-precision storage and energy-efficient computation by replacing complex MACs with temporal Accumulate (ACCs). Motivated by this property, we propose SpikeQuant, which selectively applies mixed-precision quantization to activations with salient values and re-encodes them into binary spike counts, thereby enabling dynamic mixed storage of different bitwidths. Furthermore, by embedding the quantization scale into the threshold of the IF mechanism, our approach performs energy-efficient linear transformations on weights and activations while avoiding explicit dequantization. Experimental results demonstrate that SpikeQuant consistently achieves near-FP16 perplexity under W4A4 quantization while reducing energy cost by up to 4.6 times compared to existing methods, highlighting its effectiveness for accurate and energy-efficient LLM deployment.", "published": "2025-10-22T11:50:00Z", "query": "closed-loop brain stimulation", "relevance": 0.1, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:42.650846"}
{"arxiv_id": "2510.19332v1", "title": "BrainMCLIP: Brain Image Decoding with Multi-Layer feature Fusion of CLIP", "summary": "Decoding images from fMRI often involves mapping brain activity to CLIP's final semantic layer. To capture finer visual details, many approaches add a parameter-intensive VAE-based pipeline. However, these approaches overlook rich object information within CLIP's intermediate layers and contradicts the brain's functionally hierarchical. We introduce BrainMCLIP, which pioneers a parameter-efficient, multi-layer fusion approach guided by human visual system's functional hierarchy, eliminating the need for such a separate VAE pathway. BrainMCLIP aligns fMRI signals from functionally distinct visual areas (low-/high-level) to corresponding intermediate and final CLIP layers, respecting functional hierarchy. We further introduce a Cross-Reconstruction strategy and a novel multi-granularity loss. Results show BrainMCLIP achieves highly competitive performance, particularly excelling on high-level semantic metrics where it matches or surpasses SOTA(state-of-the-art) methods, including those using VAE pipelines. Crucially, it achieves this with substantially fewer parameters, demonstrating a reduction of 71.7\\%(Table.\\ref{tab:compare_clip_vae}) compared to top VAE-based SOTA methods, by avoiding the VAE pathway. By leveraging intermediate CLIP features, it effectively captures visual details often missed by CLIP-only approaches, striking a compelling balance between semantic accuracy and detail fidelity without requiring a separate VAE pipeline.", "published": "2025-10-22T07:51:52Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.651010"}
{"arxiv_id": "2510.19282v1", "title": "Enhancing Early Alzheimer Disease Detection through Big Data and   Ensemble Few-Shot Learning", "summary": "Alzheimer disease is a severe brain disorder that causes harm in various brain areas and leads to memory damage. The limited availability of labeled medical data poses a significant challenge for accurate Alzheimer disease detection. There is a critical need for effective methods to improve the accuracy of Alzheimer disease detection, considering the scarcity of labeled data, the complexity of the disease, and the constraints related to data privacy. To address this challenge, our study leverages the power of big data in the form of pre-trained Convolutional Neural Networks (CNNs) within the framework of Few-Shot Learning (FSL) and ensemble learning. We propose an ensemble approach based on a Prototypical Network (ProtoNet), a powerful method in FSL, integrating various pre-trained CNNs as encoders. This integration enhances the richness of features extracted from medical images. Our approach also includes a combination of class-aware loss and entropy loss to ensure a more precise classification of Alzheimer disease progression levels. The effectiveness of our method was evaluated using two datasets, the Kaggle Alzheimer dataset and the ADNI dataset, achieving an accuracy of 99.72% and 99.86%, respectively. The comparison of our results with relevant state-of-the-art studies demonstrated that our approach achieved superior accuracy and highlighted its validity and potential for real-world applications in early Alzheimer disease detection.", "published": "2025-10-22T06:35:03Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:42.651203"}
{"arxiv_id": "2510.19229v1", "title": "Brain-Inspired Perspective on Configurations: Unsupervised Similarity   and Early Cognition", "summary": "Infants discover categories, detect novelty, and adapt to new contexts without supervision -- a challenge for current machine learning. We present a brain-inspired perspective on configurations, a finite-resolution clustering framework that uses a single resolution parameter and attraction-repulsion dynamics to yield hierarchical organization, novelty sensitivity, and flexible adaptation. To evaluate these properties, we introduce mheatmap, which provides proportional heatmaps and a reassignment algorithm to fairly assess multi-resolution and dynamic behavior. Across datasets, configurations are competitive on standard clustering metrics, achieve 87% AUC in novelty detection, and show 35% better stability during dynamic category evolution. These results position configurations as a principled computational model of early cognitive categorization and a step toward brain-inspired AI.", "published": "2025-10-22T04:28:23Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:42.651386"}
{"arxiv_id": "2510.19212v1", "title": "No Intelligence Without Statistics: The Invisible Backbone of Artificial   Intelligence", "summary": "The rapid ascent of artificial intelligence (AI) is often portrayed as a revolution born from computer science and engineering. This narrative, however, obscures a fundamental truth: the theoretical and methodological core of AI is, and has always been, statistical. This paper systematically argues that the field of statistics provides the indispensable foundation for machine learning and modern AI. We deconstruct AI into nine foundational pillars-Inference, Density Estimation, Sequential Learning, Generalization, Representation Learning, Interpretability, Causality, Optimization, and Unification-demonstrating that each is built upon century-old statistical principles. From the inferential frameworks of hypothesis testing and estimation that underpin model evaluation, to the density estimation roots of clustering and generative AI; from the time-series analysis inspiring recurrent networks to the causal models that promise true understanding, we trace an unbroken statistical lineage. While celebrating the computational engines that power modern AI, we contend that statistics provides the brain-the theoretical frameworks, uncertainty quantification, and inferential goals-while computer science provides the brawn-the scalable algorithms and hardware. Recognizing this statistical backbone is not merely an academic exercise, but a necessary step for developing more robust, interpretable, and trustworthy intelligent systems. We issue a call to action for education, research, and practice to re-embrace this statistical foundation. Ignoring these roots risks building a fragile future; embracing them is the path to truly intelligent machines. There is no machine learning without statistical learning; no artificial intelligence without statistical thought.", "published": "2025-10-22T03:47:30Z", "query": "closed-loop brain stimulation", "relevance": 0.25, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.651635"}
{"arxiv_id": "2510.19109v1", "title": "Advancing Brain Tumor Segmentation via Attention-based 3D U-Net   Architecture and Digital Image Processing", "summary": "In the realm of medical diagnostics, rapid advancements in Artificial Intelligence (AI) have significantly yielded remarkable improvements in brain tumor segmentation. Encoder-Decoder architectures, such as U-Net, have played a transformative role by effectively extracting meaningful representations in 3D brain tumor segmentation from Magnetic resonance imaging (MRI) scans. However, standard U-Net models encounter challenges in accurately delineating tumor regions, especially when dealing with irregular shapes and ambiguous boundaries. Additionally, training robust segmentation models on high-resolution MRI data, such as the BraTS datasets, necessitates high computational resources and often faces challenges associated with class imbalance. This study proposes the integration of the attention mechanism into the 3D U-Net model, enabling the model to capture intricate details and prioritize informative regions during the segmentation process. Additionally, a tumor detection algorithm based on digital image processing techniques is utilized to address the issue of imbalanced training data and mitigate bias. This study aims to enhance the performance of brain tumor segmentation, ultimately improving the reliability of diagnosis. The proposed model is thoroughly evaluated and assessed on the BraTS 2020 dataset using various performance metrics to accomplish this goal. The obtained results indicate that the model outperformed related studies, exhibiting dice of 0.975, specificity of 0.988, and sensitivity of 0.995, indicating the efficacy of the proposed model in improving brain tumor segmentation, offering valuable insights for reliable diagnosis in clinical settings.", "published": "2025-10-21T22:11:19Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.651838"}
{"arxiv_id": "2510.19057v1", "title": "Macroscopic EEG Reveals Discriminative Low-Frequency Oscillations in   Plan-to-Grasp Visuomotor Tasks", "summary": "The vision-based grasping brain network integrates visual perception with cognitive and motor processes for visuomotor tasks. While invasive recordings have successfully decoded localized neural activity related to grasp type planning and execution, macroscopic neural activation patterns captured by noninvasive electroencephalography (EEG) remain far less understood. We introduce a novel vision-based grasping platform to investigate grasp-type-specific (precision, power, no-grasp) neural activity across large-scale brain networks using EEG neuroimaging. The platform isolates grasp-specific planning from its associated execution phases in naturalistic visuomotor tasks, where the Filter-Bank Common Spatial Pattern (FBCSP) technique was designed to extract discriminative frequency-specific features within each phase. Support vector machine (SVM) classification discriminated binary (precision vs. power, grasp vs. no-grasp) and multiclass (precision vs. power vs. no-grasp) scenarios for each phase, and were compared against traditional Movement-Related Cortical Potential (MRCP) methods. Low-frequency oscillations (0.5-8 Hz) carry grasp-related information established during planning and maintained throughout execution, with consistent classification performance across both phases (75.3-77.8\\%) for precision vs. power discrimination, compared to 61.1\\% using MRCP. Higher-frequency activity (12-40 Hz) showed phase-dependent results with 93.3\\% accuracy for grasp vs. no-grasp classification but 61.2\\% for precision vs. power discrimination. Feature importance using SVM coefficients identified discriminative features within frontoparietal networks during planning and motor networks during execution. This work demonstrated the role of low-frequency oscillations in decoding grasp type during planning using noninvasive EEG.", "published": "2025-10-21T20:17:33Z", "query": "closed-loop brain stimulation", "relevance": 0.35, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.652069"}
{"arxiv_id": "2510.18812v1", "title": "A Unified Perspective on Optimization in Machine Learning and   Neuroscience: From Gradient Descent to Neural Adaptation", "summary": "Iterative optimization is central to modern artificial intelligence (AI) and provides a crucial framework for understanding adaptive systems. This review provides a unified perspective on this subject, bridging classic theory with neural network training and biological learning. Although gradient-based methods, powered by the efficient but biologically implausible backpropagation (BP), dominate machine learning, their computational demands can hinder scalability in high-dimensional settings. In contrast, derivative-free or zeroth-order (ZO) optimization feature computationally lighter approaches that rely only on function evaluations and randomness. While generally less sample efficient, recent breakthroughs demonstrate that modern ZO methods can effectively approximate gradients and achieve performance competitive with BP in neural network models. This ZO paradigm is also particularly relevant for biology. Its core principles of random exploration (probing) and feedback-guided adaptation (reinforcing) parallel key mechanisms of biological learning, offering a mathematically principled perspective on how the brain learns. In this review, we begin by categorizing optimization approaches based on the order of derivative information they utilize, ranging from first-, second-, and higher-order gradient-based to ZO methods. We then explore how these methods are adapted to the unique challenges of neural network training and the resulting learning dynamics. Finally, we build upon these insights to view biological learning through an optimization lens, arguing that a ZO paradigm leverages the brain's intrinsic noise as a computational resource. This framework not only illuminates our understanding of natural intelligence but also holds vast implications for neuromorphic hardware, helping us design fast and energy-efficient AI systems that exploit intrinsic hardware noise.", "published": "2025-10-21T17:10:15Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.652405"}
{"arxiv_id": "2510.18745v1", "title": "Topoformer: brain-like topographic organization in Transformer language   models through spatial querying and reweighting", "summary": "Spatial functional organization is a hallmark of biological brains: neurons are arranged topographically according to their response properties, at multiple scales. In contrast, representations within most machine learning models lack spatial biases, instead manifesting as disorganized vector spaces that are difficult to visualize and interpret. Here, we propose a novel form of self-attention that turns Transformers into \"Topoformers\" with topographic organization. We introduce spatial querying - where keys and queries are arranged on 2D grids, and local pools of queries are associated with a given key - and spatial reweighting, where we convert the standard fully connected layer of self-attention into a locally connected layer. We first demonstrate the feasibility of our approach by training a 1-layer Topoformer on a sentiment classification task. Training with spatial querying encourages topographic organization in the queries and keys, and spatial reweighting separately encourages topographic organization in the values and self-attention outputs. We then apply the Topoformer motifs at scale, training a BERT architecture with a masked language modeling objective. We find that the topographic variant performs on par with a non-topographic control model on NLP benchmarks, yet produces interpretable topographic organization as evaluated via eight linguistic test suites. Finally, analyzing an fMRI dataset of human brain responses to a large set of naturalistic sentences, we demonstrate alignment between low-dimensional topographic variability in the Topoformer model and human brain language network. Scaling up Topoformers further holds promise for greater interpretability in NLP research, and for more accurate models of the organization of linguistic information in the human brain.", "published": "2025-10-21T15:54:57Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.652670"}
{"arxiv_id": "2510.18640v1", "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "summary": "Performance regressions in large-scale software systems can lead to substantial resource inefficiencies, making their early detection critical. Frequent benchmarking is essential for identifying these regressions and maintaining service-level agreements (SLAs). Performance benchmarks, however, are resource-intensive and time-consuming, which is a major challenge for integration into Continuous Integration / Continuous Deployment (CI/CD) pipelines. Although numerous benchmark optimization techniques have been proposed to accelerate benchmark execution, there is currently no practical system that integrates these optimizations seamlessly into real-world CI/CD pipelines. In this vision paper, we argue that the field of benchmark optimization remains under-explored in key areas that hinder its broader adoption. We identify three central challenges to enabling frequent and efficient benchmarking: (a) the composability of benchmark optimization strategies, (b) automated evaluation of benchmarking results, and (c) the usability and complexity of applying these strategies as part of CI/CD systems in practice. We also introduce a conceptual cloud-based benchmarking framework handling these challenges transparently. By presenting these open problems, we aim to stimulate research toward making performance regression detection in CI/CD systems more practical and effective.", "published": "2025-10-21T13:43:20Z", "query": "closed-loop brain stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.652920"}
{"arxiv_id": "2510.18570v1", "title": "Electromagnetic Field Exposure Assessment and Mitigation Strategies for   Wireless Power Transfer Systems: A Review and Future Perspectives", "summary": "Wireless power transfer (WPT) technologies are increasingly being applied in fields ranging from consumer electronics and electric vehicles to space-based energy systems and medical implants. While WPT offers contactless power delivery, it introduces electromagnetic field (EMF) emissions, necessitating careful assessment to address safety and public health concerns. Exposure guidelines developed by ICNIRP and IEEE define frequency-dependent limits based on internal quantities, such as electric field strength and specific absorption rate, intended to prevent tissue nerve stimulation &lt; 100 kHz and heating &gt; 100 kHz, respectively. Complementing these guidelines, assessment standards including the International Electrotechnical Commission (IEC)/IEEE 63184 and IEC Technical Report 63377, provide practical procedures for evaluating the EMF exposure in WPT systems. This review offers a comparative overview of major WPT modalities, with a focus on recent developments in computational dosimetry and standardized assessment techniques for the complex, non-uniform fields typical of WPT environments. It also discusses electromagnetic interference with medical devices and exposure scenarios involving partial body proximity and various postures. A notable observation across modalities is the considerable variability, often spanning an order of magnitude, in the allowable transfer power, depending on the field distribution and assessment approach. Remaining challenges include the lack of harmonized guidance for intermediate frequencies and localized exposure, underscoring the importance of further coordination in international standardization efforts. Addressing these issues is essential for the safe and widespread deployment of WPT technologies.", "published": "2025-10-21T12:25:44Z", "query": "closed-loop brain stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:42.653156"}
{"arxiv_id": "2510.18516v1", "title": "Decoding Dynamic Visual Experience from Calcium Imaging via   Cell-Pattern-Aware SSL", "summary": "Self-supervised learning (SSL) holds a great deal of promise for applications in neuroscience, due to the lack of large-scale, consistently labeled neural datasets. However, most neural datasets contain heterogeneous populations that mix stable, predictable cells with highly stochastic, stimulus-contingent ones, which has made it hard to identify consistent activity patterns during SSL. As a result, self-supervised pretraining has yet to show clear signs of benefits from scale on neural data. Here, we present a novel approach to self-supervised pretraining, POYO-SSL that exploits the heterogeneity of neural data to improve pre-training and achieve benefits of scale. Specifically, in POYO-SSL we pretrain only on predictable (statistically regular) neurons-identified on the pretraining split via simple higher-order statistics (skewness and kurtosis)-then we fine-tune on the unpredictable population for downstream tasks. On the Allen Brain Observatory dataset, this strategy yields approximately 12-13% relative gains over from-scratch training and exhibits smooth, monotonic scaling with model size. In contrast, existing state-of-the-art baselines plateau or destabilize as model size increases. By making predictability an explicit metric for crafting the data diet, POYO-SSL turns heterogeneity from a liability into an asset, providing a robust, biologically grounded recipe for scalable neural decoding and a path toward foundation models of neural dynamics.", "published": "2025-10-21T10:57:52Z", "query": "closed-loop brain stimulation", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.653341"}
{"arxiv_id": "2510.18492v1", "title": "Electromagnetic characteristics as probes into the inner structures of   the predicted $\u039e_c^{(',*)}D^{(*)}_s$ molecular states", "summary": "In this work, we conduct a systematic investigation of the electromagnetic properties, specifically the magnetic moments and the M1 radiative decay behavior, of the predicted $\\Xi_c^{(',*)}D^{(*)}_s$-type double-charm hidden-strangeness molecular pentaquarks. The study is carried out within the framework of the constituent quark model to evaluate these electromagnetic observables, and our analysis incorporates three distinct scenarios: single-channel analysis, $S$-$D$ wave mixing analysis, and coupled-channel analysis. The calculated magnetic moments reveal characteristic patterns that reflect their underlying constituent configurations and provide sensitive probes for their quantum number assignments. Furthermore, we identify several M1 radiative decay channels with sizable widths that may offer promising signatures for future experimental detection. These M1 transitions also act as sensitive probes into their inner structures, displaying distinctive features that help differentiate between their constituent configurations and quantum number assignments. We anticipate that this study will stimulate experimental interest in exploring the electromagnetic properties of the $\\Xi_c^{(',*)}D^{(*)}_s$ molecular states, thereby advancing our structural understanding of these exotic hadronic states.", "published": "2025-10-21T10:30:12Z", "query": "closed-loop brain stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.653588"}
{"arxiv_id": "2510.18396v1", "title": "Entropy-Enhanced Conformal Features from Ricci Flow for Robust   Alzheimer's Disease Classification", "summary": "Background and Objective: In brain imaging, geometric surface models are essential for analyzing the 3D shapes of anatomical structures. Alzheimer's disease (AD) is associated with significant cortical atrophy, making such shape analysis a valuable diagnostic tool. The objective of this study is to introduce and validate a novel local surface representation method for the automated and accurate diagnosis of AD. Methods: The study utilizes T1-weighted MRI scans from 160 participants (80 AD patients and 80 healthy controls) from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Cortical surface models were reconstructed from the MRI data using Freesurfer. Key geometric attributes were computed from the 3D meshes. Area distortion and conformal factor were derived using Ricci flow for conformal parameterization, while Gaussian curvature was calculated directly from the mesh geometry. Shannon entropy was applied to these three features to create compact and informative feature vectors. The feature vectors were used to train and evaluate a suite of classifiers (e.g. XGBoost, MLP, Logistic Regression, etc.). Results: Statistical significance of performance differences between classifiers was evaluated using paired Welch's t-test. The method proved highly effective in distinguishing AD patients from healthy controls. The Multi-Layer Perceptron (MLP) and Logistic Regression classifiers outperformed all others, achieving an accuracy and F$_1$ Score of 98.62%. Conclusions: This study confirms that the entropy of conformally-derived geometric features provides a powerful and robust metric for cortical morphometry. The high classification accuracy underscores the method's potential to enhance the study and diagnosis of Alzheimer's disease, offering a straightforward yet powerful tool for clinical research applications.", "published": "2025-10-21T08:16:45Z", "query": "closed-loop brain stimulation", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:42.653812"}
{"arxiv_id": "2510.18387v1", "title": "Quantification of dual-state 5-ALA-induced PpIX fluorescence:   Methodology and validation in tissue-mimicking phantoms", "summary": "Quantification of protoporphyrin IX (PpIX) fluorescence in human brain tumours has the potential to significantly improve patient outcomes in neuro-oncology, but represents a formidable imaging challenge. Protoporphyrin is a biological molecule which interacts with the tissue micro-environment to form two photochemical states in glioma. Each exhibits markedly different quantum efficiencies, with distinct but overlapping emission spectra that also overlap with tissue autofluorescence. Fluorescence emission is known to be distorted by the intrinsic optical properties of tissue, coupled with marked intra-tumoural heterogeneity as a hallmark of glioma tumours. Existing quantitative fluorescence systems are developed and validated using simplified phantoms that do not simultaneously mimic the complex interactions between fluorophores and tissue optical properties or micro-environment. Consequently, existing systems risk introducing systematic errors into PpIX quantification when used in tissue. In this work, we introduce a novel pipeline for quantification of PpIX in glioma, which robustly differentiates both emission states from background autofluorescence without reliance on a priori spectral information, and accounts for variations in their quantum efficiency. Unmixed PpIX emission forms are then corrected for wavelength-dependent optical distortions and weighted for accurate quantification. Significantly, this pipeline is developed and validated using novel tissue-mimicking phantoms replicating the optical properties of glioma tissues and photochemical variability of PpIX fluorescence in glioma. Our workflow achieves strong correlation with ground-truth PpIX concentrations (R2 = 0.918+-0.002), demonstrating its potential for robust, quantitative PpIX fluorescence imaging in clinical settings.", "published": "2025-10-21T08:07:14Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.654008"}
{"arxiv_id": "2510.18303v1", "title": "Proactive Reasoning-with-Retrieval Framework for Medical Multimodal   Large Language Models", "summary": "Incentivizing the reasoning ability of Multimodal Large Language Models (MLLMs) is essential for medical applications to transparently analyze medical scans and provide reliable diagnosis. However, existing medical MLLMs rely solely on internal knowledge during reasoning, leading to hallucinated reasoning and factual inaccuracies when encountering cases beyond their training scope. Although recent Agentic Retrieval-Augmented Generation (RAG) methods elicit the medical model's proactive retrieval ability during reasoning, they are confined to unimodal LLMs, neglecting the crucial visual information during reasoning and retrieval. Consequently, we propose the first Multimodal Medical Reasoning-with-Retrieval framework, Med-RwR, which actively retrieves external knowledge by querying observed symptoms or domain-specific medical concepts during reasoning. Specifically, we design a two-stage reinforcement learning strategy with tailored rewards that stimulate the model to leverage both visual diagnostic findings and textual clinical information for effective retrieval. Building on this foundation, we further propose a Confidence-Driven Image Re-retrieval (CDIR) method for test-time scaling when low prediction confidence is detected. Evaluation on various public medical benchmarks demonstrates Med-RwR's significant improvements over baseline models, proving the effectiveness of enhancing reasoning capabilities with external knowledge integration. Furthermore, Med-RwR demonstrates remarkable generalizability to unfamiliar domains, evidenced by 8.8% performance gain on our proposed EchoCardiography Benchmark (ECBench), despite the scarcity of echocardiography data in the training corpus. Our data, model, and codes will be made publicly available at https://github.com/xmed-lab/Med-RwR.", "published": "2025-10-21T05:18:18Z", "query": "closed-loop brain stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:42.654199"}
{"arxiv_id": "2510.18910v1", "title": "Large Connectome Model: An fMRI Foundation Model of Brain Connectomes   Empowered by Brain-Environment Interaction in Multitask Learning Landscape", "summary": "A reliable foundation model of functional neuroimages is critical to promote clinical applications where the performance of current AI models is significantly impeded by a limited sample size. To that end, tremendous efforts have been made to pretraining large models on extensive unlabeled fMRI data using scalable self-supervised learning. Since self-supervision is not necessarily aligned with the brain-to-outcome relationship, most foundation models are suboptimal to the downstream task, such as predicting disease outcomes. By capitalizing on rich environmental variables and demographic data along with an unprecedented amount of functional neuroimages, we form the brain modeling as a multitask learning and present a scalable model architecture for (i) multitask pretraining by tokenizing multiple brain-environment interactions (BEI) and (ii) semi-supervised finetuning by assigning pseudo-labels of pretrained BEI. We have evaluated our foundation model on a variety of applications, including sex prediction, human behavior recognition, and disease early diagnosis of Autism, Parkinson's disease, Alzheimer's disease, and {Schizophrenia}, where promising results indicate the great potential to facilitate current neuroimaging applications in clinical routines.", "published": "2025-10-21T03:50:51Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:42.654407"}
{"arxiv_id": "2510.20820v1", "title": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered   Canvas", "summary": "Despite their impressive visual fidelity, existing personalized generative models lack interactive control over spatial composition and scale poorly to multiple subjects. To address these limitations, we present LayerComposer, an interactive framework for personalized, multi-subject text-to-image generation. Our approach introduces two main contributions: (1) a layered canvas, a novel representation in which each subject is placed on a distinct layer, enabling occlusion-free composition; and (2) a locking mechanism that preserves selected layers with high fidelity while allowing the remaining layers to adapt flexibly to the surrounding context. Similar to professional image-editing software, the proposed layered canvas allows users to place, resize, or lock input subjects through intuitive layer manipulation. Our versatile locking mechanism requires no architectural changes, relying instead on inherent positional embeddings combined with a new complementary data sampling strategy. Extensive experiments demonstrate that LayerComposer achieves superior spatial control and identity preservation compared to the state-of-the-art methods in multi-subject personalized image generation.", "published": "2025-10-23T17:59:55Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:46.090228"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.091171"}
{"arxiv_id": "2510.20815v1", "title": "Generative Reasoning Recommendation via LLMs", "summary": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.", "published": "2025-10-23T17:59:31Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.091528"}
{"arxiv_id": "2510.20813v1", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic   Manipulation", "summary": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics manipulation that combines 3D Gaussian Splatting with physics engines. Our framework advocates \"closing the loop\" of developing manipulation policies with reproducible evaluation of policies learned from real-robot data and sim2real policy training without using real robots. To enable photo-realistic rendering of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian Scene Description File), that infuses Gaussian-on-Mesh representation with robot URDF and other objects. With a streamlined reconstruction pipeline, we curate a database of GSDF that contains 3 robot embodiments for single-arm and bimanual manipulation, as well as more than 40 objects. Combining GSDF with physics engines, we demonstrate several immediate interesting applications: (1) learning zero-shot sim2real pixel-to-action manipulation policy with photo-realistic rendering, (2) automated high-quality DAgger data collection for adapting policies to deployment environments, (3) reproducible benchmarking of real-robot manipulation policies in simulation, (4) simulation data collection by virtual teleoperation, and (5) zero-shot sim2real visual reinforcement learning. Website: https://3dgsworld.github.io/.", "published": "2025-10-23T17:59:26Z", "query": "adaptive neural interface", "relevance": 0.3, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:46.091696"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:46.091838"}
{"arxiv_id": "2510.20800v1", "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient   Step on 100 Samples", "summary": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank reduction (LASER) which demonstrated that pruning high-order components of carefully chosen LLM's weight matrices can boost downstream accuracy -- without any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each requiring full-dataset forward passes) makes it impractical for rapid deployment. We demonstrate that this overhead can be removed and find that: (i) Only a small, carefully chosen subset of matrices needs to be inspected -- eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's singular values pinpoints which matrices merit reduction, (iii) Increasing the factorization search space by allowing matrices rows to cluster around multiple subspaces and then decomposing each cluster separately further reduces overfitting on the original training data and further lifts accuracy by up to 24.6 percentage points, and finally, (iv) we discover that evaluating on just 100 samples rather than the full training data -- both for computing the indicative gradients and for measuring the final accuracy -- suffices to further reduce the search time; we explain that as adaptation to downstream tasks is dominated by prompting style, not dataset size. As a result, we show that combining these findings yields a fast and robust adaptation algorithm for downstream tasks. Overall, with a single gradient step on 100 examples and a quick scan of the top candidate layers and factorization techniques, we can adapt LLMs to new datasets -- entirely without fine-tuning.", "published": "2025-10-23T17:58:01Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.092105"}
{"arxiv_id": "2510.20798v1", "title": "Analog Quantum Feature Selection with Neutral-Atom Quantum Processors", "summary": "We present a quantum-native approach to quantum feature selection (QFS) based on analog quantum simulation with neutral atom arrays, adaptable to a variety of academic and industrial applications. In our method, feature relevance-measured via mutual information with the target-is encoded as local detuning amplitudes, while feature redundancy is embedded through distance-dependent van der Waals interactions, constrained by the Rydberg blockade radius. The system is evolved adiabatically toward low-energy configurations, and the resulting measurement bitstrings are used to extract physically consistent subsets of features. The protocol is evaluated through simulations on three benchmark binary classification datasets: Adult Income, Bank Marketing, and Telco Churn. Compared to classical methods such as mutual information ranking and Boruta, combined with XGBoost and Random Forest classifiers, our quantum-computing approach achieves competitive or superior performance. In particular, for compact subsets of 2-5 features, analog QFS improves mean AUC scores by 1.5-2.3% while reducing the number of features by 75-84%, offering interpretable, low-redundancy solutions. These results demonstrate that programmable Rydberg arrays offer a viable platform for intelligent feature selection with practical relevance in machine learning pipelines, capable of transforming computational quantum advantage into industrial quantum usefulness.", "published": "2025-10-23T17:57:34Z", "query": "adaptive neural interface", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:46.092441"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:46.092725"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "adaptive neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.093011"}
{"arxiv_id": "2510.20788v1", "title": "Predicting Protein-Nucleic Acid Flexibility Using Persistent Sheaf   Laplacians", "summary": "Understanding the flexibility of protein-nucleic acid complexes, often characterized by atomic B-factors, is essential for elucidating their structure, dynamics, and functions, such as reactivity and allosteric pathways. Traditional models such as Gaussian Network Models (GNM) and Elastic Network Models (ENM) often fall short in capturing multiscale interactions, especially in large or complex biomolecular systems. In this work, we apply the Persistent Sheaf Laplacian (PSL) framework for the B-factor prediction of protein-nucleic acid complexes. The PSL model integrates multiscale analysis, algebraic topology, combinatoric Laplacians, and sheaf theory for data representation. It reveals topological invariants in its harmonic spectra and captures the homotopic shape evolution of data with its non-harmonic spectra. Its localization enables accurate B-factor predictions. We benchmark our method on three diverse datasets, including protein-RNA and nucleic-acid-only structures, and demonstrate that PSL consistently outperforms existing models such as GNM and multiscale FRI (mFRI), achieving up to a 21% improvement in Pearson correlation coefficient for B-factor prediction. These results highlight the robustness and adaptability of PSL in modeling complex biomolecular interactions and suggest its potential utility in broader applications such as mutation impact analysis and drug design.", "published": "2025-10-23T17:53:33Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.093244"}
{"arxiv_id": "2510.20787v1", "title": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention   and Contextualized Learnable Token Eviction", "summary": "Linear-attention models that compress the entire input sequence into a fixed-size recurrent state offer an efficient alternative to Transformers, but their finite memory induces forgetfulness that harms retrieval-intensive tasks. To mitigate the issue, we explore a series of hybrid models that restore direct access to past tokens. We interleave token mixers with intermediate time and space complexity between linear and full attention, including sparse attention with token eviction, and the query-aware native sparse attention. Particularly, we propose a novel learnable token eviction approach. Combined with sliding-window attention, an end-to-end trainable lightweight CNN aggregates information from both past and future adjacent tokens to adaptively retain a limited set of critical KV-pairs per head, maintaining linear attention's constant time and space complexity. Efficient Triton kernels for the sparse attention mechanisms are provided. Empirical evaluations on retrieval-intensive benchmarks support the effectiveness of our approaches.", "published": "2025-10-23T17:53:03Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:46.093438"}
{"arxiv_id": "2510.20783v1", "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "summary": "Chess is a canonical example of a task that requires rigorous reasoning and long-term planning. Modern decision Transformers - trained similarly to LLMs - are able to learn competent gameplay, but it is unclear to what extent they truly capture the rules of chess. To investigate this, we train a 270M parameter chess Transformer and test it on out-of-distribution scenarios, designed to reveal failures of systematic generalization. Our analysis shows that Transformers exhibit compositional generalization, as evidenced by strong rule extrapolation: they adhere to fundamental syntactic rules of the game by consistently choosing valid moves even in situations very different from the training data. Moreover, they also generate high-quality moves for OOD puzzles. In a more challenging test, we evaluate the models on variants including Chess960 (Fischer Random Chess) - a variant of chess where starting positions of pieces are randomized. We found that while the model exhibits basic strategy adaptation, they are inferior to symbolic AI algorithms that perform explicit search, but gap is smaller when playing against users on Lichess. Moreover, the training dynamics revealed that the model initially learns to move only its own pieces, suggesting an emergent compositional understanding of the game.", "published": "2025-10-23T17:51:28Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.093650"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.093871"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "adaptive neural interface", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:46.094044"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.094301"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "adaptive neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.094479"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.094657"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.094871"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "adaptive neural interface", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.095065"}
{"arxiv_id": "2510.20742v1", "title": "Bayesian Prediction under Moment Conditioning", "summary": "Prediction is a central task of statistics and machine learning, yet many inferential settings provide only partial information, typically in the form of moment constraints or estimating equations. We develop a finite, fully Bayesian framework for propagating such partial information through predictive distributions. Building on de Finetti's representation theorem, we construct a curvature-adaptive version of exchangeable updating that operates directly under finite constraints, yielding an explicit discrete-Gaussian mixture that quantifies predictive uncertainty. The resulting finite-sample bounds depend on the smallest eigenvalue of the information-geometric Hessian, which measures the curvature and identification strength of the constraint manifold. This approach unifies empirical likelihood, Bayesian empirical likelihood, and generalized method-of-moments estimation within a common predictive geometry. On the operational side, it provides computable curvature-sensitive uncertainty bounds for constrained prediction; on the theoretical side, it recovers de Finetti's coherence, Doob's martingale convergence and local asymptotic normality as limiting cases of the same finite mechanism. Our framework thus offers a constructive bridge between partial information and full Bayesian prediction.", "published": "2025-10-23T17:03:17Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.095265"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "adaptive neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.095465"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.095669"}
{"arxiv_id": "2510.20713v1", "title": "Experimental differentiation and extremization with analog quantum   circuits", "summary": "Solving and optimizing differential equations (DEs) is ubiquitous in both engineering and fundamental science. The promise of quantum architectures to accelerate scientific computing thus naturally involved interest towards how efficiently quantum algorithms can solve DEs. Differentiable quantum circuits (DQC) offer a viable route to compute DE solutions using a variational approach amenable to existing quantum computers, by producing a machine-learnable surrogate of the solution. Quantum extremal learning (QEL) complements such approach by finding extreme points in the output of learnable models of unknown (implicit) functions, offering a powerful tool to bypass a full DE solution, in cases where the crux consists in retrieving solution extrema. In this work, we provide the results from the first experimental demonstration of both DQC and QEL, displaying their performance on a synthetic usecase. Whilst both DQC and QEL are expected to require digital quantum hardware, we successfully challenge this assumption by running a closed-loop instance on a commercial analog quantum computer, based upon neutral atom technology.", "published": "2025-10-23T16:29:28Z", "query": "adaptive neural interface", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.095818"}
{"arxiv_id": "2510.20709v1", "title": "Separating the what and how of compositional computation to enable reuse   and continual learning", "summary": "The ability to continually learn, retain and deploy skills to accomplish goals is a key feature of intelligent and efficient behavior. However, the neural mechanisms facilitating the continual learning and flexible (re-)composition of skills remain elusive. Here, we study continual learning and the compositional reuse of learned computations in recurrent neural network (RNN) models using a novel two-system approach: one system that infers what computation to perform, and one that implements how to perform it. We focus on a set of compositional cognitive tasks commonly studied in neuroscience. To construct the what system, we first show that a large family of tasks can be systematically described by a probabilistic generative model, where compositionality stems from a shared underlying vocabulary of discrete task epochs. The shared epoch structure makes these tasks inherently compositional. We first show that this compositionality can be systematically described by a probabilistic generative model. Furthermore, We develop an unsupervised online learning approach that can learn this model on a single-trial basis, building its vocabulary incrementally as it is exposed to new tasks, and inferring the latent epoch structure as a time-varying computational context within a trial. We implement the how system as an RNN whose low-rank components are composed according to the context inferred by the what system. Contextual inference facilitates the creation, learning, and reuse of low-rank RNN components as new tasks are introduced sequentially, enabling continual learning without catastrophic forgetting. Using an example task set, we demonstrate the efficacy and competitive performance of this two-system learning framework, its potential for forward and backward transfer, as well as fast compositional generalization to unseen tasks.", "published": "2025-10-23T16:24:40Z", "query": "adaptive neural interface", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:46.096003"}
{"arxiv_id": "2510.20707v1", "title": "Mixing Importance with Diversity: Joint Optimization for KV Cache   Compression in Large Vision-Language Models", "summary": "Recent large vision-language models (LVLMs) demonstrate remarkable capabilities in processing extended multi-modal sequences, yet the resulting key-value (KV) cache expansion creates a critical memory bottleneck that fundamentally limits deployment scalability. While existing KV cache compression methods focus on retaining high-importance KV pairs to minimize storage, they often overlook the modality-specific semantic redundancy patterns that emerge distinctively in multi-modal KV caches. In this work, we first analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying levels of redundancy across attention heads. We show that relying solely on importance can only cover a subset of the full KV cache information distribution, leading to potential loss of semantic coverage. To address this, we propose \\texttt{MixKV}, a novel method that mixes importance with diversity for optimized KV cache compression in LVLMs. \\texttt{MixKV} adapts to head-wise semantic redundancy, selectively balancing diversity and importance when compressing KV pairs. Extensive experiments demonstrate that \\texttt{MixKV} consistently enhances existing methods across multiple LVLMs. Under extreme compression (budget=64), \\texttt{MixKV} improves baseline methods by an average of \\textbf{5.1\\%} across five multi-modal understanding benchmarks and achieves remarkable gains of \\textbf{8.0\\%} and \\textbf{9.0\\%} for SnapKV and AdaKV on GUI grounding tasks, all while maintaining comparable inference efficiency. Furthermore, \\texttt{MixKV} extends seamlessly to LLMs with comparable performance gains. Our code is available at \\href{https://github.com/xuyang-liu16/MixKV}{\\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.", "published": "2025-10-23T16:17:47Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:46.096208"}
{"arxiv_id": "2510.20706v1", "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control   and Reinforcement Learning", "summary": "Model-free reinforcement learning (RL) has enabled adaptable and agile quadruped locomotion; however, policies often converge to a single gait, leading to suboptimal performance. Traditionally, Model Predictive Control (MPC) has been extensively used to obtain task-specific optimal policies but lacks the ability to adapt to varying environments. To address these limitations, we propose an optimization framework for real-time gait adaptation in a continuous gait space, combining the Model Predictive Path Integral (MPPI) algorithm with a Dreamer module to produce adaptive and optimal policies for quadruped locomotion. At each time step, MPPI jointly optimizes the actions and gait variables using a learned Dreamer reward that promotes velocity tracking, energy efficiency, stability, and smooth transitions, while penalizing abrupt gait changes. A learned value function is incorporated as terminal reward, extending the formulation to an infinite-horizon planner. We evaluate our framework in simulation on the Unitree Go1, demonstrating an average reduction of up to 36.48\\% in energy consumption across varying target speeds, while maintaining accurate tracking and adaptive, task-appropriate gaits.", "published": "2025-10-23T16:17:45Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.096431"}
{"arxiv_id": "2510.20700v1", "title": "Structure-Conditional Minimum Bayes Risk Decoding", "summary": "Minimum Bayes Risk (MBR) decoding has seen renewed interest as an alternative to traditional generation strategies. While MBR has proven effective in machine translation, where the variability of a language model's outcome space is naturally constrained, it may face challenges in more open-ended tasks such as dialogue or instruction-following. We hypothesise that in such settings, applying MBR with standard similarity-based utility functions may result in selecting responses that are broadly representative of the model's distribution, yet sub-optimal with respect to any particular grouping of generations that share an underlying latent structure. In this work, we introduce three lightweight adaptations to the utility function, designed to make MBR more sensitive to structural variability in the outcome space. To test our hypothesis, we curate a dataset capturing three representative types of latent structure: dialogue act, emotion, and response structure (e.g., a sentence, a paragraph, or a list). We further propose two metrics to evaluate the structural optimality of MBR. Our analysis demonstrates that common similarity-based utility functions fall short by these metrics. In contrast, our proposed adaptations considerably improve structural optimality. Finally, we evaluate our approaches on real-world instruction-following benchmarks, AlpacaEval and MT-Bench, and show that increased structural sensitivity improves generation quality by up to 13.7 percentage points in win rate.", "published": "2025-10-23T16:13:49Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:46.096671"}
{"arxiv_id": "2510.20699v1", "title": "Fusing Narrative Semantics for Financial Volatility Forecasting", "summary": "We introduce M2VN: Multi-Modal Volatility Network, a novel deep learning-based framework for financial volatility forecasting that unifies time series features with unstructured news data. M2VN leverages the representational power of deep neural networks to address two key challenges in this domain: (i) aligning and fusing heterogeneous data modalities, numerical financial data and textual information, and (ii) mitigating look-ahead bias that can undermine the validity of financial models. To achieve this, M2VN combines open-source market features with news embeddings generated by Time Machine GPT, a recently introduced point-in-time LLM, ensuring temporal integrity. An auxiliary alignment loss is introduced to enhance the integration of structured and unstructured data within the deep learning architecture. Extensive experiments demonstrate that M2VN consistently outperforms existing baselines, underscoring its practical value for risk management and financial decision-making in dynamic markets.", "published": "2025-10-23T16:13:46Z", "query": "adaptive neural interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:46.096864"}
{"arxiv_id": "2510.20697v1", "title": "Observationally derived change in star-formation rate as mergers   progress", "summary": "Galaxy mergers can change the rate at which stars are formed. We can trace when these changes occur in simulations of galaxy mergers. However, for observed galaxies we do not know how the star-formation rate (SFR) evolves along the merger sequence as it is difficult to probe the time before or after coalescence. We aim to derive how SFR changes in observed mergers throughout the merger sequence, from a statistical perspective. Merger times were estimated for observed galaxy mergers in the Kilo Degree Survey (KiDS) using a convolutional neural network (CNN). The CNN was trained on mock KiDS images created using IllustrisTNG data. The SFRs were derived from spectral energy density fitting to KiDS and VIKINGs data. To determine the change in SFR for the merging galaxies, each merging galaxy was matched and compared to ten comparable non-merging galaxies; matching redshift, stellar mass, and local density. Mergers see an increase in SFR for galaxies from 300~Myr before the merger until coalescence, continuing until at least 200~Myr after the merger event. After this, there is a possibility that SFR activity in the mergers begins to decrease, but we need more data to better constrain our merger times and SFRs to confirm this. We find that more galaxies with larger stellar mass (M$_{\\star}$) have greater SFR enhancement as they merge compared to lower M$_{\\star}$ galaxies. There is no clear trend of changing SFR enhancement as local density changes, but the least dense environments have the least SFR enhancement. The increasing SFR enhancement is likely due to closer proximity of galaxies and the presence of more close passes as the time before merger approaches 0~Myr, with SFR slowing 200~Myr after the merger event.", "published": "2025-10-23T16:10:32Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:46.097284"}
{"arxiv_id": "2510.20691v1", "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over   Knowledge Graphs", "summary": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.", "published": "2025-10-23T16:04:13Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:46.098072"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.556675"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "bidirectional brain interface", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.557179"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:49.557490"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "bidirectional brain interface", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.557714"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "bidirectional brain interface", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:49.557896"}
{"arxiv_id": "2510.20560v1", "title": "Super-robust telecommunications enabled by topological half-supermodes", "summary": "Topological photonics offers transformative potential for robust integrated waveguide devices due to their backscattering-immune properties. However, their integration faces two fundamental challenges: mode symmetry mismatch with conventional waveguides and prohibitive dimensions. We successfully overcome these two critical challenges by introducing a novel valley-ridge gap waveguide based on topological half-supermode engineering. By strategically hybridizing ridge waveguide modes and valley kink states, we create an exotic odd-symmetric supermode enabling robust propagation and ultra-compact operation. The further implementation of a perfect electric conductor boundary halves lateral dimensions while eliminating radiation loss. Crucially, our proposed valley-ridge interface achieves direct transverse electric mode matching with standard waveguides without transition structures, enabling seamless integration. Experimental results demonstrate reflection losses lower than -15 dB in realistic telecommunication scenarios with super-robust signal propagation through sharp bends. This work innovatively conceptualizes topological half-supermodes and pioneers their practical applications for integrated waveguide devices, establishing a completely new waveguide class that uniquely combines robust backscattering immunity with deep subwavelength compactness.", "published": "2025-10-23T13:41:49Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.558070"}
{"arxiv_id": "2510.20559v1", "title": "High-Resolution Echelle Spectroscopy for Solar System Planets: A   Planet-as-Point-Source Analogy", "summary": "Transmission spectroscopy has proven to be an effective technique for characterizing exoplanet atmospheres. However, transmission spectroscopy requires planetary transits, which occur for only a small fraction of planetary systems due to geometric alignment constraints; hence, characterizing exoplanets through their reflected spectrum of host stars will be helpful for a large number of exoplanets. The upcoming extremely large telescopes (ELTs) will be able to study the reflected spectra of exoplanets. Here, we present a preliminary optical design and a detailed throughput analysis of the instrumentation that interfaces the 2.34 m Vainu Bappu Telescope prime focus to an existing high-resolution echelle spectrograph with disk-integrated light from solar system objects. One of the primary objectives is to obtain high-resolution, high signal-to-noise reflected spectra from the solar system objects.", "published": "2025-10-23T13:40:33Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.558184"}
{"arxiv_id": "2510.20512v1", "title": "EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion   Personalization", "summary": "Recent advances in accelerating text-to-image (T2I) diffusion models have enabled the synthesis of high-fidelity images even in a single step. However, personalizing these models to incorporate novel concepts remains a challenge due to the limited capacity of one-step models to capture new concept distributions effectively. We propose a bidirectional concept distillation framework, EchoDistill, to enable one-step diffusion personalization (1-SDP). Our approach involves an end-to-end training process where a multi-step diffusion model (teacher) and a one-step diffusion model (student) are trained simultaneously. The concept is first distilled from the teacher model to the student, and then echoed back from the student to the teacher. During the EchoDistill, we share the text encoder between the two models to ensure consistent semantic understanding. Following this, the student model is optimized with adversarial losses to align with the real image distribution and with alignment losses to maintain consistency with the teacher's output. Furthermore, we introduce the bidirectional echoing refinement strategy, wherein the student model leverages its faster generation capability to feedback to the teacher model. This bidirectional concept distillation mechanism not only enhances the student ability to personalize novel concepts but also improves the generative quality of the teacher model. Our experiments demonstrate that this collaborative framework significantly outperforms existing personalization methods over the 1-SDP setup, establishing a novel paradigm for rapid and effective personalization in T2I diffusion models.", "published": "2025-10-23T12:56:33Z", "query": "bidirectional brain interface", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:49.558357"}
{"arxiv_id": "2510.20463v1", "title": "Suspension-Free Integrated Cavity Brillouin Optomechanics on a Chip", "summary": "Cavity optomechanical systems enable coherent photon-phonon interactions essential for quantum technologies, yet high-performance devices have been limited to suspended structures. Here, we overcome this limitation by demonstrating cavity Brillouin optomechanics in a suspension-free racetrack microring resonator on a lithium-niobate-on-sapphire chip, a platform that merits high stability and scalability. We demonstrate coherent coupling between telecom-band optical modes and a 9.6-GHz phonon mode, achieving a maximum cooperativity of $0.41$ and a phonon quality-factor-frequency product of $10^{13}\\,\\mathrm{Hz}$. The momentum-matching condition inherent to traveling-wave Brillouin interactions establishes a one-to-one mapping between optical wavelength and phonon frequency, enabling multi-channel parallel operations across nearly $300\\,\\mathrm{MHz}$ in phonon frequency and $40\\,\\mathrm{nm}$ in optical wavelength. Our suspension-free architecture provides a coherent photon-phonon interface compatible with wafer-scale integration, opening pathways toward hybrid quantum circuits that unite photonic, phononic, and superconducting components on a single chip.", "published": "2025-10-23T11:59:39Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.558474"}
{"arxiv_id": "2510.20416v1", "title": "Learning Coupled Earth System Dynamics with GraphDOP", "summary": "Interactions between different components of the Earth System (e.g. ocean, atmosphere, land and cryosphere) are a crucial driver of global weather patterns. Modern Numerical Weather Prediction (NWP) systems typically run separate models of the different components, explicitly coupled across their interfaces to additionally model exchanges between the different components. Accurately representing these coupled interactions remains a major scientific and technical challenge of weather forecasting. GraphDOP is a graph-based machine learning model that learns to forecast weather directly from raw satellite and in-situ observations, without reliance on reanalysis products or traditional physics-based NWP models. GraphDOP simultaneously embeds information from diverse observation sources spanning the full Earth system into a shared latent space. This enables predictions that implicitly capture cross-domain interactions in a single model without the need for any explicit coupling. Here we present a selection of case studies which illustrate the capability of GraphDOP to forecast events where coupled processes play a particularly key role. These include rapid sea-ice freezing in the Arctic, mixing-induced ocean surface cooling during Hurricane Ian and the severe European heat wave of 2022. The results suggest that learning directly from Earth System observations can successfully characterise and propagate cross-component interactions, offering a promising path towards physically consistent end-to-end data-driven Earth System prediction with a single model.", "published": "2025-10-23T10:36:20Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.558670"}
{"arxiv_id": "2510.20389v1", "title": "Symmetry in Software Platforms as an Architectural Principle", "summary": "Software platforms often act as structure preserving systems. They provide consistent interfaces and behaviors that remain stable under specific transformations that we denote as symmetries. This paper explores the idea that architectural robustness emerges from enforcing such structural regularities", "published": "2025-10-23T09:38:32Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.558792"}
{"arxiv_id": "2510.20338v1", "title": "Comparative Analysis of Thermal Models for Test Masses in   Next-Generation Gravitational Wave Interferometers", "summary": "Accurate thermal modeling of Terminal Test Masses (TTMs) is crucial for optimizing the sensitivity of gravitational wave interferometers like Virgo. In fact, in such gravitational wave detectors even minimal laser power absorption can induce performance-limiting thermal effects. This paper presents a detailed investigation into the steady-state thermal behavior of TTMs. In particular, future scenarios of increased intracavity laser beam power and optical coating absorption are considered. We develop and compare two numerical models: a comprehensive model incorporating volumetric heat absorption in both the multilayer coating and the bulk substrate, and a simplified reduced model where the coating's thermal impact is represented as an effective surface boundary condition on the substrate. Our simulations were focused on a ternary coating design, which is a candidate for use in next-generation detectors. Results reveal that higher coating absorption localizes peak temperatures near the coating--vacuum interface. Importantly, the comparative analysis demonstrates that temperature predictions from the reduced model differ from the detailed model by only milli-Kelvins, a discrepancy often within the experimental uncertainties of the system's thermo-physical parameters. This finding suggests that computationally efficient reduced models can provide sufficiently accurate results for thermal management and first-order distortion analyses. Moreover, the critical role of accurately characterizing the total power absorbed by the coating is emphasized.", "published": "2025-10-23T08:37:47Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.558925"}
{"arxiv_id": "2510.20333v1", "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in   Dynamic On-Device Environments?", "summary": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.", "published": "2025-10-23T08:33:24Z", "query": "bidirectional brain interface", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.559067"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "bidirectional brain interface", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.559197"}
{"arxiv_id": "2510.20277v1", "title": "A Location-Aware Hybrid Deep Learning Framework for Dynamic Near-Far   Field Channel Estimation in Low-Altitude UAV Communications", "summary": "In low altitude UAV communications, accurate channel estimation remains challenging due to the dynamic nature of air to ground links, exacerbated by high node mobility and the use of large scale antenna arrays, which introduce hybrid near and far field propagation conditions. While conventional estimation methods rely on far field assumptions, they fail to capture the intricate channel variations in near-field scenarios and overlook valuable geometric priors such as real-time transceiver positions. To overcome these limitations, this paper introduces a unified channel estimation framework based on a location aware hybrid deep learning architecture. The proposed model synergistically combines convolutional neural networks (CNNs) for spatial feature extraction, bidirectional long short term memory (BiLSTM) networks for modeling temporal evolution, and a multihead self attention mechanism to enhance focus on discriminative channel components. Furthermore, real-time transmitter and receiver locations are embedded as geometric priors, improving sensitivity to distance under near field spherical wavefronts and boosting model generalization. Extensive simulations validate the effectiveness of the proposed approach, showing that it outperforms existing benchmarks by a significant margin, achieving at least a 30.25% reduction in normalized mean square error (NMSE) on average.", "published": "2025-10-23T07:04:12Z", "query": "bidirectional brain interface", "relevance": 0.39999999999999997, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:49.559359"}
{"arxiv_id": "2510.20211v1", "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a \"source-of-truth\" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors.   We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$ improvement).", "published": "2025-10-23T04:57:00Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.559507"}
{"arxiv_id": "2510.20196v1", "title": "A Structured Review and Quantitative Profiling of Public Brain MRI   Datasets for Foundation Model Development", "summary": "The development of foundation models for brain MRI depends critically on the scale, diversity, and consistency of available data, yet systematic assessments of these factors remain scarce. In this study, we analyze 54 publicly accessible brain MRI datasets encompassing over 538,031 to provide a structured, multi-level overview tailored to foundation model development. At the dataset level, we characterize modality composition, disease coverage, and dataset scale, revealing strong imbalances between large healthy cohorts and smaller clinical populations. At the image level, we quantify voxel spacing, orientation, and intensity distributions across 15 representative datasets, demonstrating substantial heterogeneity that can influence representation learning. We then perform a quantitative evaluation of preprocessing variability, examining how intensity normalization, bias field correction, skull stripping, spatial registration, and interpolation alter voxel statistics and geometry. While these steps improve within-dataset consistency, residual differences persist between datasets. Finally, feature-space case study using a 3D DenseNet121 shows measurable residual covariate shift after standardized preprocessing, confirming that harmonization alone cannot eliminate inter-dataset bias. Together, these analyses provide a unified characterization of variability in public brain MRI resources and emphasize the need for preprocessing-aware and domain-adaptive strategies in the design of generalizable brain MRI foundation models.", "published": "2025-10-23T04:31:09Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:49.559683"}
{"arxiv_id": "2510.20184v1", "title": "A Unified and Scalable Method for Optimization over Graphs of Convex   Sets", "summary": "A Graph of Convex Sets (GCS) is a graph in which vertices are associated with convex programs and edges couple pairs of programs through additional convex costs and constraints. Any optimization problem over an ordinary weighted graph (e.g., the shortest-path, the traveling-salesman, and the minimum-spanning-tree problems) can be naturally generalized to a GCS, yielding a new class of problems at the interface of combinatorial and convex optimization with numerous applications. In this paper, we introduce a unified method for solving any such problem. Starting from an integer linear program that models an optimization problem over a weighted graph, our method automatically produces an efficient mixed-integer convex formulation of the corresponding GCS problem. This formulation is based on homogenization (perspective) transformations, and the resulting program is solved to global optimality using off-the-shelf branch-and-bound solvers. We implement this framework in GCSOPT, an open-source and easy-to-use Python library designed for fast prototyping. We illustrate the versatility and scalability of our approach through multiple numerical examples and comparisons.", "published": "2025-10-23T04:08:39Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.559857"}
{"arxiv_id": "2510.20148v1", "title": "Understanding Mechanistic Role of Structural and Functional Connectivity   in Tau Propagation Through Multi-Layer Modeling", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up along specific brain networks, suggesting that large-scale network architecture plays a key role in the progression of Alzheimer's disease (AD). However, how structural connectivity (SC) and functional connectivity (FC) interact to influence tau propagation remains unclear. Leveraging an unprecedented volume of longitudinal neuroimaging data, we examine SC-FC interactions through a multi-layer graph diffusion model. Beyond showing that connectome architecture constrains tau spread, our model reveals a regionally asymmetric contribution of SC and FC. Specifically, FC predominantly drives tau spread in subcortical areas, the insula, frontal and temporal cortices, whereas SC plays a larger role in occipital, parietal, and limbic regions. The relative dominance of SC versus FC shifts over the course of disease, with FC generally prevailing in early AD and SC becoming primary in later stages. Spatial patterns of SC- and FC-dominant regions strongly align with the regional expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In parallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and biological mechanisms (e.g., amyloid deposition) selectively reshape tau propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings are validated in an independent AD cohort.", "published": "2025-10-23T02:52:42Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:49.560049"}
{"arxiv_id": "2510.20128v1", "title": "A Full Stack Framework for High Performance Quantum-Classical Computing", "summary": "To address the growing needs for scalable High Performance Computing (HPC) and Quantum Computing (QC) integration, we present our HPC-QC full stack framework and its hybrid workload development capability with modular hardware/device-agnostic software integration approach. The latest development in extensible interfaces for quantum programming, dispatching, and compilation within existing mature HPC programming environment are demonstrated. Our HPC-QC full stack enables high-level, portable invocation of quantum kernels from commercial quantum SDKs within HPC meta-program in compiled languages (C/C++ and Fortran) as well as Python through a quantum programming interface library extension. An adaptive circuit knitting hypervisor is being developed to partition large quantum circuits into sub-circuits that fit on smaller noisy quantum devices and classical simulators. At the lower-level, we leverage Cray LLVM-based compilation framework to transform and consume LLVM IR and Quantum IR (QIR) from commercial quantum software frontends in a retargetable fashion to different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU and GPU workloads (including solving linear system of equations, quantum optimization, and simulating quantum phase transitions) have been demonstrated on HPE EX supercomputers to illustrate functionality and execution viability for all three components developed so far. This work provides the framework for a unified quantum-classical programming environment built upon classical HPC software stack (compilers, libraries, parallel runtime and process scheduling).", "published": "2025-10-23T02:07:29Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:49.560274"}
{"arxiv_id": "2510.20114v1", "title": "Fabrication and Structural Analysis of Trilayers for Tantalum Josephson   Junctions with Ta$_2$O$_5$ Barriers", "summary": "Tantalum (Ta) has recently emerged as a promising low-loss material, enabling record coherence times in superconducting qubits. This enhanced performance is largely attributed to its stable native oxide, which is believed to host fewer two-level system (TLS) defects key $-$ contributors to decoherence in superconducting circuits. Nevertheless, aluminum oxide (AlO$_x$) remains the predominant choice for Josephson junction barriers in most qubit architectures. In this study, we systematically investigate various techniques for forming high-quality oxide layers on $\\alpha$-phase tantalum ($\\alpha$-Ta) thin films, aiming to develop effective Josephson junction barriers. We explore thermal oxidation in a tube furnace, rapid thermal annealing, as well as plasma oxidation of both room-temperature and heated Ta films, and propose a mechanistic picture of the underlying oxidation mechanisms. All methods yield Ta$_2$O$_5$, the same compound as tantalum's native oxide. Among these, plasma oxidation produces the smoothest and highest-quality oxide layers, making it particularly well-suited for Josephson junction fabrication. Furthermore, we demonstrate the successful epitaxial growth of $\\alpha$-Ta atop oxidized $\\alpha$-Ta films, paving the way for the realization of trilayer Ta/Ta-O/Ta Josephson junctions with clean, low-loss interfaces.", "published": "2025-10-23T01:35:14Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.560476"}
{"arxiv_id": "2510.20088v1", "title": "RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling", "summary": "Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves to desired directions to enhance signal coverage and/or improve signal-to-noise ratio (SNR) at the user equipment (UE). We present the design, implementation, and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2 millimeter wave (mmWave) frequency band. We first introduce the design of 1,024 element (32 $\\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2 interface can be leveraged to dynamically control RIS configurations without modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G system, we conducted extensive field trials in both indoor and outdoor environments. The results of the O-RAN link coverage trials show that the deployed RIS provides substantial received signal power gains, ranging from 9 to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively. Handling UE mobility in RIS-assisted systems is challenging due to the need for joint RIS and UE beam management. For that, we develop two UE mobility management algorithms and evaluate them in real-time operation using the RIS O-RAN testbed. These algorithms leverage the received signal power at the UE to jointly track and adapt the RIS and UE beams in real time as the UE moves. The findings draw important insights into the practical feasibility of integrating RIS into O-RAN systems to enhance coverage, mobility support, and link reliability in next-generation cellular networks.", "published": "2025-10-23T00:09:57Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:49.560654"}
{"arxiv_id": "2510.20068v1", "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural   Latent Dynamics", "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas reveal rich mixtures of activity that are shared between regions and dynamics that are unique to each region. Existing alignment or multi-view methods neglect temporal structure, whereas dynamical latent variable models capture temporal dependencies but are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals. We introduce the Coupled Transformer Autoencoder (CTAE) - a sequence model that addresses both (i) non-stationary, non-linear dynamics and (ii) separation of shared versus region-specific structure in a single framework. CTAE employs transformer encoders and decoders to capture long-range neural dynamics and explicitly partitions each region's latent space into orthogonal shared and private subspaces. We demonstrate the effectiveness of CTAE on two high-density electrophysiology datasets with simultaneous recordings from multiple regions, one from motor cortical areas and the other from sensory areas. CTAE extracts meaningful representations that better decode behavioral variables compared to existing approaches.", "published": "2025-10-22T22:47:15Z", "query": "bidirectional brain interface", "relevance": 0.15000000000000002, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:49.560832"}
{"arxiv_id": "2510.20039v1", "title": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn   Human-LLM Interactions", "summary": "Large language model (LLM)-powered chatbots are increasingly used for opinion exploration. Prior research examined how LLMs alter user views, yet little work extended beyond one-way influence to address how user input can affect LLM responses and how such bi-directional influence manifests throughout the multi-turn conversations. This study investigates this dynamic through 50 controversial-topic discussions with participants (N=266) across three conditions: static statements, standard chatbot, and personalized chatbot. Results show that human opinions barely shifted, while LLM outputs changed more substantially, narrowing the gap between human and LLM stance. Personalization amplified these shifts in both directions compared to the standard setting. Analysis of multi-turn conversations further revealed that exchanges involving participants' personal stories were most likely to trigger stance changes for both humans and LLMs. Our work highlights the risk of over-alignment in human-LLM interaction and the need for careful design of personalized chatbots to more thoughtfully and stably align with users.", "published": "2025-10-22T21:38:10Z", "query": "bidirectional brain interface", "relevance": 0.3, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:49.561023"}
{"arxiv_id": "2510.20033v1", "title": "Improving Transfer Learning for Sequence Labeling Tasks by Adapting   Pre-trained Neural Language Models", "summary": "This doctoral thesis improves the transfer learning for sequence labeling tasks by adapting pre-trained neural language models. The proposed improvements in transfer learning involve introducing a multi-task model that incorporates an additional signal, a method based on architectural modifications in autoregressive large language models, and a sequence labeling framework for autoregressive large language models utilizing supervised in-context fine-tuning combined with response-oriented adaptation strategies. The first improvement is given in the context of domain transfer for the event trigger detection task. The domain transfer of the event trigger detection task can be improved by incorporating an additional signal obtained from a domain-independent text processing system into a multi-task model. The second improvement involves modifying the model's architecture. For that purpose, a method is proposed to enable bidirectional information flow across layers of autoregressive large language models. The third improvement utilizes autoregressive large language models as text generators through a generative supervised in-context fine-tuning framework. The proposed model, method, and framework demonstrate that pre-trained neural language models achieve their best performance on sequence labeling tasks when adapted through targeted transfer learning paradigms.", "published": "2025-10-22T21:23:53Z", "query": "bidirectional brain interface", "relevance": 0.35, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:49.561227"}
{"arxiv_id": "2510.20030v1", "title": "On Encoding Matrices using Quantum Circuits", "summary": "Over a decade ago, it was demonstrated that quantum computing has the potential to revolutionize numerical linear algebra by enabling algorithms with complexity superior to what is classically achievable, e.g., the seminal HHL algorithm for solving linear systems. Efficient execution of such algorithms critically depends on representing inputs (matrices and vectors) as quantum circuits that encode or implement these inputs. For that task, two common circuit representations emerged in the literature: block encodings and state preparation circuits. In this paper, we systematically study encodings matrices in the form of block encodings and state preparation circuits. We examine methods for constructing these representations from matrices given in classical form, as well as quantum two-way conversions between circuit representations. Two key results we establish (among others) are: (a) a general method for efficiently constructing a block encoding of an arbitrary matrix given in classical form (entries stored in classical random access memory); and (b) low-overhead, bidirectional conversion algorithms between block encodings and state preparation circuits, showing that these models are essentially equivalent. From a technical perspective, two central components of our constructions are: (i) a special constant-depth multiplexer that simultaneously multiplexes all higher-order Pauli matrices of a given size, and (ii) an algorithm for performing a quantum conversion between a matrix's expansion in the standard basis and its expansion in the basis of higher-order Pauli matrices.", "published": "2025-10-22T21:20:08Z", "query": "bidirectional brain interface", "relevance": 0.3, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-25T15:16:49.561421"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "bidirectional brain interface", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-25T15:16:49.561605"}
{"arxiv_id": "2510.19996v1", "title": "A Fundamental Algorithm for Dependency Parsing (With Corrections)", "summary": "This paper presents a fundamental algorithm for parsing natural language sentences into dependency trees. Unlike phrase-structure (constituency) parsers, this algorithm operates one word at a time, attaching each word as soon as it can be attached, corresponding to properties claimed for the parser in the human brain. Like phrase-structure parsing, its worst-case complexity is $O(n^3)$, but in human language, the worst case occurs only for small $n$.", "published": "2025-10-22T19:48:38Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.561739"}
{"arxiv_id": "2510.19983v1", "title": "A transmon qubit realized by exploiting the superconductor-insulator   transition", "summary": "Superconducting qubits are among the most promising platforms for realizing practical quantum computers. One requirement to create a quantum processor is nonlinearity, which in superconducting circuits is typically achieved by sandwiching a layer of aluminum oxide between two aluminum electrodes to form a Josephson junction. These junctions, however, face several limitations that hinder their scalability: the small superconducting gap of aluminum necessitates millikelvin operating temperatures, the material interfaces lead to dissipation, and the sandwich geometry adds unwelcome capacitance for high-frequency applications. In this work, we address all three limitations using a novel superconducting weak link based on the superconductor-insulator transition. By locally thinning a single film of niobium nitride, we exploit its thickness-driven superconductor-insulator transition to form a weak link employing only atomic layer deposition and atomic layer etching. We utilize our weak links to produce a transmon qubit, '$planaron$', with a measured anharmonicity of $\\alpha/2\\pi = 235$ MHz; at present, the linewidth is $\\kappa/2\\pi = 15 \\mathrm{\\: MHz}$. The high superconducting gap of niobium nitride can enable operation at elevated temperatures in future devices, and the fully planar geometry of the weak link eliminates superfluous material interfaces and capacitances. The investigation of small patches of material near the SIT can shed new light on the nature of the transition, including the role of dissipation and finite-size effects.", "published": "2025-10-22T19:29:01Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.561948"}
{"arxiv_id": "2510.19968v1", "title": "Q-RAN: Quantum-Resilient O-RAN Architecture", "summary": "The telecommunications industry faces a dual transformation: the architectural shift toward Open Radio Access Networks (O-RAN) and the emerging threat from quantum computing. O-RAN disaggregated, multi-vendor architecture creates a larger attack surface vulnerable to crypt-analytically relevant quantum computers(CRQCs) that will break current public key cryptography. The Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate, as adversaries can intercept encrypted data today for future decryption. This paper presents Q-RAN, a comprehensive quantum-resistant security framework for O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204), integrated with Quantum Random Number Generators (QRNG) for cryptographic entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate Authority (PQ-CA) within the SMO framework. This work provides a complete roadmap for securing disaggregated O-RAN ecosystems against quantum adversaries.", "published": "2025-10-22T18:57:44Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:49.562124"}
{"arxiv_id": "2510.20822v1", "title": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video   Narratives", "summary": "State-of-the-art text-to-video models excel at generating isolated clips but fall short of creating the coherent, multi-shot narratives, which are the essence of storytelling. We bridge this \"narrative gap\" with HoloCine, a model that generates entire scenes holistically to ensure global consistency from the first shot to the last. Our architecture achieves precise directorial control through a Window Cross-Attention mechanism that localizes text prompts to specific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within shots but sparse between them) ensures the efficiency required for minute-scale generation. Beyond setting a new state-of-the-art in narrative coherence, HoloCine develops remarkable emergent abilities: a persistent memory for characters and scenes, and an intuitive grasp of cinematic techniques. Our work marks a pivotal shift from clip synthesis towards automated filmmaking, making end-to-end cinematic creation a tangible future. Our code is available at: https://holo-cine.github.io/.", "published": "2025-10-23T17:59:59Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:53.069195"}
{"arxiv_id": "2510.20820v1", "title": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered   Canvas", "summary": "Despite their impressive visual fidelity, existing personalized generative models lack interactive control over spatial composition and scale poorly to multiple subjects. To address these limitations, we present LayerComposer, an interactive framework for personalized, multi-subject text-to-image generation. Our approach introduces two main contributions: (1) a layered canvas, a novel representation in which each subject is placed on a distinct layer, enabling occlusion-free composition; and (2) a locking mechanism that preserves selected layers with high fidelity while allowing the remaining layers to adapt flexibly to the surrounding context. Similar to professional image-editing software, the proposed layered canvas allows users to place, resize, or lock input subjects through intuitive layer manipulation. Our versatile locking mechanism requires no architectural changes, relying instead on inherent positional embeddings combined with a new complementary data sampling strategy. Extensive experiments demonstrate that LayerComposer achieves superior spatial control and identity preservation compared to the state-of-the-art methods in multi-subject personalized image generation.", "published": "2025-10-23T17:59:55Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:53.069518"}
{"arxiv_id": "2510.20815v1", "title": "Generative Reasoning Recommendation via LLMs", "summary": "Despite their remarkable reasoning capabilities across diverse domains, large language models (LLMs) face fundamental challenges in natively functioning as generative reasoning recommendation models (GRRMs), where the intrinsic modeling gap between textual semantics and collaborative filtering signals, combined with the sparsity and stochasticity of user feedback, presents significant obstacles. This work explores how to build GRRMs by adapting pre-trained LLMs, which achieves a unified understanding-reasoning-prediction manner for recommendation tasks. We propose GREAM, an end-to-end framework that integrates three components: (i) Collaborative-Semantic Alignment, which fuses heterogeneous textual evidence to construct semantically consistent, discrete item indices and auxiliary alignment tasks that ground linguistic representations in interaction semantics; (ii) Reasoning Curriculum Activation, which builds a synthetic dataset with explicit Chain-of-Thought supervision and a curriculum that progresses through behavioral evidence extraction, latent preference modeling, intent inference, recommendation formulation, and denoised sequence rewriting; and (iii) Sparse-Regularized Group Policy Optimization (SRPO), which stabilizes post-training via Residual-Sensitive Verifiable Reward and Bonus-Calibrated Group Advantage Estimation, enabling end-to-end optimization under verifiable signals despite sparse successes. GREAM natively supports two complementary inference modes: Direct Sequence Recommendation for high-throughput, low-latency deployment, and Sequential Reasoning Recommendation that first emits an interpretable reasoning chain for causal transparency. Experiments on three datasets demonstrate consistent gains over strong baselines, providing a practical path toward verifiable-RL-driven LLM recommenders.", "published": "2025-10-23T17:59:31Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:53.069854"}
{"arxiv_id": "2510.20808v1", "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "summary": "Machine learning has facilitated significant advancements across various robotics domains, including navigation, locomotion, and manipulation. Many such achievements have been driven by the extensive use of simulation as a critical tool for training and testing robotic systems prior to their deployment in real-world environments. However, simulations consist of abstractions and approximations that inevitably introduce discrepancies between simulated and real environments, known as the reality gap. These discrepancies significantly hinder the successful transfer of systems from simulation to the real world. Closing this gap remains one of the most pressing challenges in robotics. Recent advances in sim-to-real transfer have demonstrated promising results across various platforms, including locomotion, navigation, and manipulation. By leveraging techniques such as domain randomization, real-to-sim transfer, state and action abstractions, and sim-real co-training, many works have overcome the reality gap. However, challenges persist, and a deeper understanding of the reality gap's root causes and solutions is necessary. In this survey, we present a comprehensive overview of the sim-to-real landscape, highlighting the causes, solutions, and evaluation metrics for the reality gap and sim-to-real transfer.", "published": "2025-10-23T17:58:53Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.070032"}
{"arxiv_id": "2510.20807v1", "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space   Spatiotemporal Transformers", "summary": "Inspired by the performance and scalability of autoregressive large language models (LLMs), transformer-based models have seen recent success in the visual domain. This study investigates a transformer adaptation for video prediction with a simple end-to-end approach, comparing various spatiotemporal self-attention layouts. Focusing on causal modeling of physical simulations over time; a common shortcoming of existing video-generative approaches, we attempt to isolate spatiotemporal reasoning via physical object tracking metrics and unsupervised training on physical simulation datasets. We introduce a simple yet effective pure transformer model for autoregressive video prediction, utilizing continuous pixel-space representations for video prediction. Without the need for complex training strategies or latent feature-learning components, our approach significantly extends the time horizon for physically accurate predictions by up to 50% when compared with existing latent-space approaches, while maintaining comparable performance on common video quality metrics. In addition, we conduct interpretability experiments to identify network regions that encode information useful to perform accurate estimations of PDE simulation parameters via probing models, and find that this generalizes to the estimation of out-of-distribution simulation parameters. This work serves as a platform for further attention-based spatiotemporal modeling of videos via a simple, parameter efficient, and interpretable approach.", "published": "2025-10-23T17:58:45Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:53.070164"}
{"arxiv_id": "2510.20805v1", "title": "Bilevel Analysis of Cost and Emissions Externalities from Data Center   Load Shifting", "summary": "Data centers are emerging as large, flexible electricity consumers capable of shifting computational workloads across locations in response to economic and environmental signals. While this flexibility has potential for emissions reduction, its impact on power system operations depends critically on how such behavior interacts with network constraints and market signals. We develop a bilevel optimization framework in which a data center minimizes a weighted combination of electricity cost and marginal emissions intensity (LME), while the system operator clears economic dispatch under transmission and generation constraints. Focusing on a stylized three-bus power system, we derive closed-form, piecewise-linear expressions for both the data center and system-wide objectives as functions of the data centers' load shift. These expressions capture threshold-driven regime changes due to congestion and renewable saturation. We identify sufficient conditions under which the data center's decentralized decisions align with or diverge from socially optimal behavior and characterize the resulting externalities. Our results reveal how system topology and generator asymmetry affect incentive alignment and provide insight into when marginal price or emissions signals may fail to guide flexible loads toward socially beneficial outcomes. Our results offer a tractable starting point for analyzing decentralized flexibility under carbon-aware incentives and suggest directions for improving coordination between flexible loads and system operations.", "published": "2025-10-23T17:58:31Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:53.070299"}
{"arxiv_id": "2510.20796v1", "title": "AI-Enabled Digital Twins for Next-Generation Networks: Forecasting   Traffic and Resource Management in 5G/6G", "summary": "As 5G and future 6G mobile networks become increasingly more sophisticated, the requirements for agility, scalability, resilience, and precision in real-time service provisioning cannot be met using traditional and heuristic-based resource management techniques, just like any advancing technology. With the aim of overcoming such limitations, network operators are foreseeing Digital Twins (DTs) as key enablers, which are designed as dynamic and virtual replicas of network infrastructure, allowing operators to model, analyze, and optimize various operations without any risk of affecting the live network. However, for Digital Twin Networks (DTNs) to meet the challenges faced by operators especially in line with resource management, a driving engine is needed. In this paper, an AI (Artificial Intelligence)-driven approach is presented by integrating a Long Short-Term Memory (LSTM) neural network into the DT framework, aimed at forecasting network traffic patterns and proactively managing resource allocation. Through analytical experiments, the AI-Enabled DT framework demonstrates superior performance benchmarked against baseline methods. Our study concludes that embedding AI capabilities within DTs paves the way for fully autonomous, adaptive, and high-performance network management in future mobile networks.", "published": "2025-10-23T17:56:35Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-25T15:16:53.070459"}
{"arxiv_id": "2510.20795v1", "title": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with   Spherical Graph Neural Networks", "summary": "Deep learning has emerged as a transformative methodology in modern cosmology, providing powerful tools to extract meaningful physical information from complex astronomical datasets. This paper implements a novel Bayesian graph deep learning framework for estimating key cosmological parameters in a primordial magnetic field (PMF) cosmology directly from simulated Cosmic Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a spherical convolutional neural network architecture specifically designed to respect the spherical geometry of CMB data through HEALPix pixelization. To advance beyond deterministic point estimates and enable robust uncertainty quantification, we integrate Bayesian Neural Networks (BNNs) into the framework, capturing aleatoric and epistemic uncertainties that reflect the model confidence in its predictions. The proposed approach demonstrates exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the magnetic parameter estimation. We further obtain well-calibrated uncertainty estimates through post-hoc training techniques including Variance Scaling and GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate parameter estimation from CMB maps with PMF contributions but also provides reliable uncertainty quantification, providing the necessary tools for robust cosmological inference in the era of precision cosmology.", "published": "2025-10-23T17:56:04Z", "query": "neural feedback control", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.070631"}
{"arxiv_id": "2510.20794v1", "title": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common   Feature", "summary": "This paper presents a Multi-Object Tracking (MOT) framework that fuses radar and camera data to enhance tracking efficiency while minimizing manual interventions. Contrary to many studies that underutilize radar and assign it a supplementary role--despite its capability to provide accurate range/depth information of targets in a world 3D coordinate system--our approach positions radar in a crucial role. Meanwhile, this paper utilizes common features to enable online calibration to autonomously associate detections from radar and camera. The main contributions of this work include: (1) the development of a radar-camera fusion MOT framework that exploits online radar-camera calibration to simplify the integration of detection results from these two sensors, (2) the utilization of common features between radar and camera data to accurately derive real-world positions of detected objects, and (3) the adoption of feature matching and category-consistency checking to surpass the limitations of mere position matching in enhancing sensor association accuracy. To the best of our knowledge, we are the first to investigate the integration of radar-camera common features and their use in online calibration for achieving MOT. The efficacy of our framework is demonstrated by its ability to streamline the radar-camera mapping process and improve tracking precision, as evidenced by real-world experiments conducted in both controlled environments and actual traffic scenarios. Code is available at https://github.com/radar-lab/Radar_Camera_MOT", "published": "2025-10-23T17:54:57Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.070810"}
{"arxiv_id": "2510.20790v1", "title": "Trapping, manipulating and probing ultracold atoms: a quantum   technologies tutorial", "summary": "Engineered ultracold atomic systems are a valuable platform for fundamental quantum mechanics studies and the development of quantum technologies. At near zero absolute temperature, atoms exhibit macroscopic phase coherence and collective quantum behavior, enabling their use in precision metrology, quantum simulation, and even information processing. This review provides an introductory overview of the key techniques used to trap, manipulate, and detect ultracold atoms, while highlighting the main applications of each method. We outline the principles of laser cooling, magnetic and optical trapping, and the most widely used techniques, including optical lattices and tweezers. Next, we discuss the manipulation methods of atomic internal and external degrees of freedom, and we present atom interferometry techniques and how to leverage and control interatomic interactions. Next, we review common ensemble detection strategies, including absorption and fluorescence imaging, state-selective readout, correlation and quantum non-demolition measurements and conclude with high-resolution approaches. This review aims to provide newcomers to the field with a broad understanding of the experimental toolkit that underpins research in ultracold atom physics and its applications across quantum science and technology.", "published": "2025-10-23T17:54:06Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:53.070929"}
{"arxiv_id": "2510.20786v1", "title": "Balancing Gradient and Hessian Queries in Non-Convex Optimization", "summary": "We develop optimization methods which offer new trade-offs between the number of gradient and Hessian computations needed to compute the critical point of a non-convex function. We provide a method that for any twice-differentiable $f\\colon \\mathbb R^d \\rightarrow \\mathbb R$ with $L_2$-Lipschitz Hessian, input initial point with $\\Delta$-bounded sub-optimality, and sufficiently small $\\epsilon &gt; 0$, outputs an $\\epsilon$-critical point, i.e., a point $x$ such that $\\|\\nabla f(x)\\| \\leq \\epsilon$, using $\\tilde{O}(L_2^{1/4} n_H^{-1/2}\\Delta\\epsilon^{-9/4})$ queries to a gradient oracle and $n_H$ queries to a Hessian oracle for any positive integer $n_H$. As a consequence, we obtain an improved gradient query complexity of $\\tilde{O}(d^{1/3}L_2^{1/2}\\Delta\\epsilon^{-3/2})$ in the case of bounded dimension and of $\\tilde{O}(L_2^{3/4}\\Delta^{3/2}\\epsilon^{-9/4})$ in the case where we are allowed only a \\emph{single} Hessian query. We obtain these results through a more general algorithm which can handle approximate Hessian computations and recovers the state-of-the-art bound of computing an $\\epsilon$-critical point with $O(L_1^{1/2}L_2^{1/4}\\Delta\\epsilon^{-7/4})$   gradient queries provided that $f$ also has an $L_1$-Lipschitz gradient.", "published": "2025-10-23T17:53:01Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.071081"}
{"arxiv_id": "2510.20778v1", "title": "Lens Model Accuracy in the Expected LSST Lensed AGN Sample", "summary": "Strong gravitational lensing of active galactic nuclei (AGN) enables measurements of cosmological parameters through time-delay cosmography (TDC). With data from the upcoming LSST survey, we anticipate using a sample of O(1000) lensed AGN for TDC. To prepare for this dataset and enable this measurement, we construct and analyze a realistic mock sample of 1300 systems drawn from the OM10 (Oguri &amp; Marshall 2010) catalog of simulated lenses with AGN sources at $z&lt;3.1$ in order to test a key aspect of the analysis pipeline, that of the lens modeling. We realize the lenses as power law elliptical mass distributions and simulate 5-year LSST i-band coadd images. From every image, we infer the lens mass model parameters using neural posterior estimation (NPE). Focusing on the key model parameters, $\\theta_E$ (the Einstein Radius) and $\\gamma_{lens}$ (the projected mass density profile slope), with consistent mass-light ellipticity correlations in test and training data, we recover $\\theta_E$ with less than 1% bias per lens, 6.5% precision per lens and $\\gamma_{lens}$ with less than 3% bias per lens, 8% precision per lens. We find that lens light subtraction prior to modeling is only useful when applied to data sampled from the training prior. If emulated deconvolution is applied to the data prior to modeling, precision improves across all parameters by a factor of 2. Finally, we combine the inferred lens mass models using Bayesian Hierarchical Inference to recover the global properties of the lens sample with less than 1% bias.", "published": "2025-10-23T17:48:11Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.071254"}
{"arxiv_id": "2510.20777v1", "title": "Learning Optimal Power Flow with Pointwise Constraints", "summary": "Training learning parameterizations to solve optimal power flow (OPF) with pointwise constraints is proposed. In this novel training approach, a learning parameterization is substituted directly into an OPF problem with constraints required to hold over all problem instances. This is different from existing supervised learning methods in which constraints are required to hold across the average of problem instances. Training with pointwise constraints is undertaken in the dual domain with the use of augmented Lagrangian and dual gradient ascent algorithm. Numerical experiments demonstrate that training with pointwise constraints produces solutions with smaller constraint violations. Experiments further demonstrated that pointwise constraints are most effective at reducing constraint violations in corner cases - defined as those realizations in which constraints are most difficult to satisfy. Gains are most pronounced in power systems with large numbers of buses.", "published": "2025-10-23T17:48:10Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-25T15:16:53.071383"}
{"arxiv_id": "2510.20770v1", "title": "A Tverberg-type problem of Kalai: Two negative answers to questions of   Alon and Smorodinsky, and the power of disjointness", "summary": "Let $f_r(d,s_1,\\ldots,s_r)$ denote the least integer $n$ such that every $n$-point set $P\\subseteq\\mathbb{R}^d$ admits a partition $P=P_1\\cup\\cdots\\cup P_r$ with the property that for any choice of $s_i$-convex sets $C_i\\supseteq P_i$ $(i\\in[r])$ one necessarily has $\\bigcap_{i=1}^r C_i\\neq\\emptyset$, where an $s_i$-convex set means a union of $s_i$ convex sets. A recent breakthrough by Alon and Smorodinsky establishes a general upper bound $f_r(d,s_1,\\dots,s_r) = O(dr^2\\log r \\prod_{i=1}^r s_i\\cdot \\log(\\prod_{i=1}^r s_i).$ Specializing to $r=2$ resolves the problem of Kalai from the 1970s. They further singled out two particularly intriguing questions: whether $f_{2}(2,s,s)$ can be improved from $O(s^2\\log s)$ to $O(s)$, and whether $f_r(d,s,\\ldots,s)\\le Poly(r,d,s)$. We answer both in the negative by showing the exponential lower bound $f_{r}(d,s,\\ldots,s)&gt; s^{r}$ for any $r\\ge 2$, $s\\ge 1$ and $d\\ge 2r-2$, which matches the upper bound up to a multiplicative $\\log{s}$ factor for sufficiently large $s$. Our construction combines a scalloped planar configuration with a direct product of regular $s$-gon on the high-dimensional torus $(\\mathbb{S}^1)^{r-2}$. Perhaps surprisingly, if we additionally require that within each block the $s_i$ convex sets are pairwise disjoint, the picture changes markedly. Let $F_r(d,s_1,\\ldots,s_r)$ denote this disjoint-union variant of the extremal function. We show: (1) $F_{2}(2,s,s)=O(s\\log s)$ by performing controlled planar geometric transformations and constructing an auxiliary graph whose planarity yields the upper bound; (2) when $s$ is large, $F_r(d,s,\\ldots,s)$ can be bounded by $O_{r,d}(s^{(1-\\frac{1}{2^{d}(d+1)})r+1})$ and $O_{d}(r^{3}\\log r\\cdot s^{2d+3})$, respectively. This builds on a novel connection between the geometric obstruction and hypergraph Tur\\'{a}n numbers, in particular, a variant of the Erd\\H{o}s box problem.", "published": "2025-10-23T17:44:34Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.071574"}
{"arxiv_id": "2510.20763v1", "title": "Consumption-Investment Problem in Rank-Based Models", "summary": "We study a consumption-investment problem in a multi-asset market where the returns follow a generic rank-based model. Our main result derives an HJB equation with Neumann boundary conditions for the value function and proves a corresponding verification theorem. The control problem is nonstandard due to the discontinuous nature of the coefficients in rank-based models, requiring a bespoke approach of independent mathematical interest. The special case of first-order models, prescribing constant drift and diffusion coefficients for the ranked returns, admits explicit solutions when the investor is either (a) unconstrained, (b) abides by open market constraints or (c) is fully invested in the market. The explicit optimal strategies in all cases are related to the celebrated solution to Merton's problem, despite the intractability of constraint (b) in that setting.", "published": "2025-10-23T17:35:44Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.071704"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "neural feedback control", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:53.071836"}
{"arxiv_id": "2510.20759v1", "title": "Controllable Embedding Transformation for Mood-Guided Music Retrieval", "summary": "Music representations are the backbone of modern recommendation systems, powering playlist generation, similarity search, and personalized discovery. Yet most embeddings offer little control for adjusting a single musical attribute, e.g., changing only the mood of a track while preserving its genre or instrumentation. In this work, we address the problem of controllable music retrieval through embedding-based transformation, where the objective is to retrieve songs that remain similar to a seed track but are modified along one chosen dimension. We propose a novel framework for mood-guided music embedding transformation, which learns a mapping from a seed audio embedding to a target embedding guided by mood labels, while preserving other musical attributes. Because mood cannot be directly altered in the seed audio, we introduce a sampling mechanism that retrieves proxy targets to balance diversity with similarity to the seed. We train a lightweight translation model using this sampling strategy and introduce a novel joint objective that encourages transformation and information preservation. Extensive experiments on two datasets show strong mood transformation performance while retaining genre and instrumentation far better than training-free baselines, establishing controllable embedding transformation as a promising paradigm for personalized music retrieval.", "published": "2025-10-23T17:29:13Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.071998"}
{"arxiv_id": "2510.20758v1", "title": "Theta-term in Russian Doll Model: phase structure, quantum metric and   BPS multifractality", "summary": "We investigate the phase structure of the deterministic and disordered versions of the Russian Doll Model (RDM), which is a generalization of Richardson model of superconductivity in a finite system with time-reversal symmetry breaking parameter $\\theta$. It is one of the simplest examples of the cyclic RG where $\\log N$ plays the role of the RG time. The deterministic model is integrable and shares the same Bethe Ansatz (BA) equations with the inhomogeneous twisted XXX spin chain. We analyze the quantum metric, the Berry curvature, and the fractal dimension in the sector with a single Cooper pair. A rich phase structure in the $(\\theta,\\gamma)$ parameter plane is found, where $\\gamma \\log N$ quantifies the hopping term.   For the deterministic RDM we clearly identify the extended domain of non-ergodic multifractal phase on the $(\\theta,\\gamma)$ parameter plane supporting the reentrance transitions between the localized, ergodic, and multifractal phases. We find the pattern of phase transitions in the global charge $Q(\\theta,\\gamma)$, which arises from the BA equation. In particular, in the multifractal phase in the deterministic model $Q(\\gamma)$ exhibits the analogue of \"charge concentration\" and fortuity phenomena discussed in the context of black hole microstates at finite $N$. The BA equations in RDM exactly coincide with the equations defining the ground states in the theory on the worldvolume of the vortex strings in $N_F=2N_C$ ${\\cal N}=2$ SQCD at a strong coupling point $\\frac{1}{g_{YM}^2}=0$ with identification $\\theta_{RDM}= \\theta_{4D}-\\pi$. We conjecture that the Hamiltonian of the RDM model describes the mixing in particular 2d-4d BPS sector of the Hilbert space. Our findings provide an example of the BPS multifractality regime for the probe operator in the sector of Hilbert space, and we comment on the possible application to dense QCD with $\\theta$ term.", "published": "2025-10-23T17:25:01Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.072193"}
{"arxiv_id": "2510.20755v1", "title": "Incomplete U-Statistics of Equireplicate Designs: Berry-Esseen Bound and   Efficient Construction", "summary": "U-statistics are a fundamental class of estimators that generalize the sample mean and underpin much of nonparametric statistics. Although extensively studied in both statistics and probability, key challenges remain: their high computational cost - addressed partly through incomplete U-statistics - and their non-standard asymptotic behavior in the degenerate case, which typically requires resampling methods for hypothesis testing. This paper presents a novel perspective on U-statistics, grounded in hypergraph theory and combinatorial designs. Our approach bypasses the traditional Hoeffding decomposition, the main analytical tool in this literature but one highly sensitive to degeneracy. By characterizing the dependence structure of a U-statistic, we derive a Berry-Esseen bound that applies to all incomplete U-statistics of deterministic designs, yielding conditions under which Gaussian limiting distributions can be established even in the degenerate case and when the order diverges. We also introduce efficient algorithms to construct incomplete U-statistics of equireplicate designs, a subclass of deterministic designs that, in certain cases, achieve minimum variance. Finally, we apply our framework to kernel-based tests that use Maximum Mean Discrepancy (MMD) and Hilbert-Schmidt Independence Criterion. In a real data example with CIFAR-10, our permutation-free MMD test delivers substantial computational gains while retaining power and type I error control.", "published": "2025-10-23T17:21:54Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.072368"}
{"arxiv_id": "2510.20754v1", "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for   Tissue Segmentation in Histopathology", "summary": "Automated histopathological image analysis plays a vital role in computer-aided diagnosis of various diseases. Among developed algorithms, deep learning-based approaches have demonstrated excellent performance in multiple tasks, including semantic tissue segmentation in histological images. In this study, we propose a novel approach based on attention-driven feature fusion of convolutional neural networks (CNNs) and vision transformers (ViTs) within a unified dual-encoder model to improve semantic segmentation performance. Evaluation on two publicly available datasets showed that our model achieved {\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and 64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline benchmarks. The implementation of our method is publicly available in a GitHub repository: https://github.com/NimaTorbati/ACS-SegNet", "published": "2025-10-23T17:21:06Z", "query": "neural feedback control", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.072497"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:53.072634"}
{"arxiv_id": "2510.20748v1", "title": "Reinforcement Learning and Consumption-Savings Behavior", "summary": "This paper demonstrates how reinforcement learning can explain two puzzling empirical patterns in household consumption behavior during economic downturns. I develop a model where agents use Q-learning with neural network approximation to make consumption-savings decisions under income uncertainty, departing from standard rational expectations assumptions. The model replicates two key findings from recent literature: (1) unemployed households with previously low liquid assets exhibit substantially higher marginal propensities to consume (MPCs) out of stimulus transfers compared to high-asset households (0.50 vs 0.34), even when neither group faces borrowing constraints, consistent with Ganong et al. (2024); and (2) households with more past unemployment experiences maintain persistently lower consumption levels after controlling for current economic conditions, a \"scarring\" effect documented by Malmendier and Shen (2024). Unlike existing explanations based on belief updating about income risk or ex-ante heterogeneity, the reinforcement learning mechanism generates both higher MPCs and lower consumption levels simultaneously through value function approximation errors that evolve with experience. Simulation results closely match the empirical estimates, suggesting that adaptive learning through reinforcement learning provides a unifying framework for understanding how past experiences shape current consumption behavior beyond what current economic conditions would predict.", "published": "2025-10-23T17:14:49Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:53.072802"}
{"arxiv_id": "2510.20746v1", "title": "Berry Curvature Dipole-induced Non-linear Hall Effect in Oxide   Heterostructures", "summary": "The observation of non-linear Hall effects in time-reversal invariant systems has established the intriguing role of band topology beyond Berry curvature in determining transport phenomena. Many of these non-linear responses owe their origin to the Berry curvature dipole (BCD), which, like the Berry curvature (monopole), is also an electronic band structure effect, but is routinely strongly constrained by crystalline symmetries. Here, we propose non-centrosymmetric transition metal oxide heterostructures as promising platforms for realizing and tuning BCD-induced non-linear Hall effects. Specifically, we investigate superlattices of the form $(\\mathrm{Ba(Os,Ir)}\\mathrm{O}_3)_n/(\\mathrm{BaTiO}_3)_4$ ($n{=}1, 2$), comprising metallic perovskite layers ($\\mathrm{BaOsO_3}$ or $\\mathrm{BaIrO_3}$) sandwiched between insulating ferroelectric $\\mathrm{BaTiO_3}$ (BTO). The ferroelectric distortion in BTO breaks inversion symmetry of the superlattice, giving rise to a finite BCD with two symmetry-allowed components of equal magnitude and opposite sign. Our first-principles calculations demonstrate that the magnitude of the BCD -- and consequently the nonlinear Hall response -- can be effectively tuned by varying the number of metallic layers or the choice of the B-site cation in these $\\mathrm{ABO_3}$ perovskites. Since Rashba splitting and ferroelectric distortion in these systems are readily controllable via an external electric field or strain, the non-linear Hall response in these materials can be directly engineered. Our findings establish non-centrosymmetric oxide perovskite heterostructures as a versatile platform for exploring and manipulating BCD-driven non-linear transport phenomena.", "published": "2025-10-23T17:09:58Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.072993"}
{"arxiv_id": "2510.20745v1", "title": "Isotropic Noise in Stochastic and Quantum Convex Optimization", "summary": "We consider the problem of minimizing a $d$-dimensional Lipschitz convex function using a stochastic gradient oracle. We introduce and motivate a setting where the noise of the stochastic gradient is isotropic in that it is bounded in every direction with high probability. We then develop an algorithm for this setting which improves upon prior results by a factor of $d$ in certain regimes, and as a corollary, achieves a new state-of-the-art complexity for sub-exponential noise. We give matching lower bounds (up to polylogarithmic factors) for both results. Additionally, we develop an efficient quantum isotropifier, a quantum algorithm which converts a variance-bounded quantum sampling oracle into one that outputs an unbiased estimate with isotropic error. Combining our results, we obtain improved dimension-dependent rates for quantum stochastic convex optimization.", "published": "2025-10-23T17:09:41Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.073128"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "neural feedback control", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.073275"}
{"arxiv_id": "2510.20739v1", "title": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in   Node.js Packages", "summary": "Program analysis tools often produce large volumes of candidate vulnerability reports that require costly manual review, creating a practical challenge: how can security analysts prioritize the reports most likely to be true vulnerabilities?   This paper investigates whether machine learning can be applied to prioritizing vulnerabilities reported by program analysis tools. We focus on Node.js packages and collect a benchmark of 1,883 Node.js packages, each containing one reported ACE or ACI vulnerability. We evaluate a variety of machine learning approaches, including classical models, graph neural networks (GNNs), large language models (LLMs), and hybrid models that combine GNN and LLMs, trained on data based on a dynamic program analysis tool's output. The top LLM achieves $F_{1} {=} 0.915$, while the best GNN and classical ML models reaching $F_{1} {=} 0.904$. At a less than 7% false-negative rate, the leading model eliminates 66.9% of benign packages from manual review, taking around 60 ms per package. If the best model is tuned to operate at a precision level of 0.8 (i.e., allowing 20% false positives amongst all warnings), our approach can detect 99.2% of exploitable taint flows while missing only 0.8%, demonstrating strong potential for real-world vulnerability triage.", "published": "2025-10-23T16:58:02Z", "query": "neural feedback control", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.073427"}
{"arxiv_id": "2510.20738v1", "title": "Optimizing Feature Ordering in Radar Charts for Multi-Profile Comparison", "summary": "Radar charts are widely used to visualize multivariate data and compare multiple profiles across features. However, the visual clarity of radar charts can be severely compromised when feature values alternate drastically in magnitude around the circle, causing areas to collapse, which misrepresents relative differences. In the present work we introduce a permutation optimization strategy that reorders features to minimize polygon ``spikiness'' across multiple profiles simultaneously. The method is combinatorial (exhaustive search) for moderate numbers of features and uses a lexicographic minimax criterion that first considers overall smoothness (mean jump) and then the largest single jump as a tie-breaker. This preserves more global information and produces visually balanced arrangements. We discuss complexity, practical bounds, and relations to existing approaches that either change the visualization (e.g., OrigamiPlot) or learn orderings (e.g., Versatile Ordering Network). An example with two profiles and $p=6$ features (before/after ordering) illustrates the qualitative improvement.   Keywords: data visualization, radar charts, combinatorial optimization, minimax optimization, feature ordering", "published": "2025-10-23T16:56:32Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:53.073532"}
{"arxiv_id": "2510.20735v1", "title": "Magnetic tunnel junction as a real-time entropy source:   Field-Programmable Gate Array based random bit generation without   post-processing", "summary": "We demonstrate a method to generate application-ready truly random bits from a magnetic tunnel junction driven by a Field-Programmable Gate Array (FPGA). We implement a real-time feedback loop that stabilizes the switching probability near 50\\% and apply an XOR operation, both on the FPGA, to suppress short-term correlations, together mitigating long-term drift and bias in the bitstream. This combined approach enables NIST-compliant random bit generation at 5~Mb/s without post-processing, providing a practical hardware solution for fast and reliable true random number generation. Beyond cryptographic applications, these capabilities open opportunities for stochastic hardware accelerators, probabilistic computing, and large-scale modeling where real-time access to unbiased randomness is essential.", "published": "2025-10-23T16:50:51Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:53.073655"}
{"arxiv_id": "2510.20728v1", "title": "Co-Designing Quantum Codes with Transversal Diagonal Gates via   Multi-Agent Systems", "summary": "We present a multi-agent, human-in-the-loop workflow that co-designs quantum codes with prescribed transversal diagonal gates. It builds on the Subset-Sum Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL) equalities via small LPs. The workflow is powered by GPT-5 and implemented within TeXRA (https://texra.ai)-a multi-agent research assistant platform that supports an iterative tool-use loop agent and a derivation-then-edit workflow reasoning agent. We work in a LaTeX-Python environment where agents reason, edit documents, execute code, and synchronize their work to Git/Overleaf. Within this workspace, three roles collaborate: a Synthesis Agent formulates the problem; a Search Agent sweeps/screens candidates and exactifies numerics into rationals; and an Audit Agent independently checks all KL equalities and the induced logical action. As a first step we focus on distance $d=2$ with nondegenerate residues. For code dimension $K\\in\\{2,3,4\\}$ and $n\\le6$ qubits, systematic sweeps yield certificate-backed tables cataloging attainable cyclic logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$ at $n=6$. From verified instances, Synthesis Agent abstracts recurring structures into closed-form families and proves they satisfy the KL equalities for all parameters. It further demonstrates that SSLP accommodates residue degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts diagonal-transversal feasibility as an analytical pipeline executed at scale, combining systematic enumeration with exact analytical reconstruction. It yields reproducible code constructions, supports targeted extensions to larger $K$ and higher distances, and leads toward data-driven classification.", "published": "2025-10-23T16:45:39Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-25T15:16:53.073822"}
{"arxiv_id": "2510.20718v1", "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in   Multi-variate Semiconductor Process Time Series", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven process, characterized by thousands of interdependent parameters collected across diverse tools and process steps. Multi-variate time-series analysis has emerged as a critical field for real-time monitoring and fault detection in such environments. However, anomaly prediction in semiconductor fabrication presents several critical challenges, including high dimensionality of sensor data and severe class imbalance due to the rarity of true faults. Furthermore, the complex interdependencies between variables complicate both anomaly prediction and root-cause-analysis. This paper proposes two novel approaches to advance the field from anomaly detection to anomaly prediction, an essential step toward enabling real-time process correction and proactive fault prevention. The proposed anomaly prediction framework contains two main stages: (a) training a forecasting model on a dataset assumed to contain no anomalies, and (b) performing forecast on unseen time series data. The forecast is compared with the forecast of the trained signal. Deviations beyond a predefined threshold are flagged as anomalies. The two approaches differ in the forecasting model employed. The first assumes independence between variables by utilizing the N-BEATS model for univariate time series forecasting. The second lifts this assumption by utilizing a Graph Neural Network (GNN) to capture inter-variable relationships. Both models demonstrate strong forecasting performance up to a horizon of 20 time points and maintain stable anomaly prediction up to 50 time points. The GNN consistently outperforms the N-BEATS model while requiring significantly fewer trainable parameters and lower computational cost. These results position the GNN as promising solution for online anomaly forecasting to be deployed in manufacturing environments.", "published": "2025-10-23T16:33:52Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:53.074023"}
{"arxiv_id": "2510.20818v1", "title": "VAMOS: A Hierarchical Vision-Language-Action Model for   Capability-Modulated and Steerable Navigation", "summary": "A fundamental challenge in robot navigation lies in learning policies that generalize across diverse environments while conforming to the unique physical constraints and capabilities of a specific embodiment (e.g., quadrupeds can walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that decouples semantic planning from embodiment grounding: a generalist planner learns from diverse, open-world data, while a specialist affordance model learns the robot's physical constraints and capabilities in safe, low-cost simulation. We enabled this separation by carefully designing an interface that lets a high-level planner propose candidate paths directly in image space that the affordance model then evaluates and re-ranks. Our real-world experiments show that VAMOS achieves higher success rates in both indoor and complex outdoor navigation than state-of-the-art model-based and end-to-end learning methods. We also show that our hierarchical design enables cross-embodied navigation across legged and wheeled robots and is easily steerable using natural language. Real-world ablations confirm that the specialist model is key to embodiment grounding, enabling a single high-level planner to be deployed across physically distinct wheeled and legged robots. Finally, this model significantly enhances single-robot reliability, achieving 3X higher success rates by rejecting physically infeasible plans. Website: https://vamos-vla.github.io/", "published": "2025-10-23T17:59:45Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.551768"}
{"arxiv_id": "2510.20762v1", "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging   Most Exciting Inputs", "summary": "Decoding visual stimuli from neural population activity is crucial for understanding the brain and for applications in brain-machine interfaces. However, such biological data is often scarce, particularly in primates or humans, where high-throughput recording techniques, such as two-photon imaging, remain challenging or impossible to apply. This, in turn, poses a challenge for deep learning decoding techniques. To overcome this, we introduce MEIcoder, a biologically informed decoding method that leverages neuron-specific most exciting inputs (MEIs), a structural similarity index measure loss, and adversarial training. MEIcoder achieves state-of-the-art performance in reconstructing visual stimuli from single-cell activity in primary visual cortex (V1), especially excelling on small datasets with fewer recorded neurons. Using ablation studies, we demonstrate that MEIs are the main drivers of the performance, and in scaling experiments, we show that MEIcoder can reconstruct high-fidelity natural-looking images from as few as 1,000-2,500 neurons and less than 1,000 training data points. We also propose a unified benchmark with over 160,000 samples to foster future research. Our results demonstrate the feasibility of reliable decoding in early visual system and provide practical insights for neuroscience and neuroengineering applications.", "published": "2025-10-23T17:35:34Z", "query": "brain-to-brain interface", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.552359"}
{"arxiv_id": "2510.20753v1", "title": "Building Network Digital Twins Part II: Real-Time Adaptive PID for   Enhanced State Synchronization", "summary": "As we evolve towards more heterogeneous and cutting-edge mobile networks, Network Digital Twins (NDTs) are proving to be a promising paradigm in solving challenges faced by network operators, as they give a possibility of replicating the physical network operations and testing scenarios separately without interfering with the live network. However, with mobile networks becoming increasingly dynamic and heterogeneous due to massive device connectivity, replicating traffic and having NDTs synchronized in real-time with the physical network remains a challenge, thus necessitating the need to develop real-time adaptive mechanisms to bridge this gap. In this part II of our work, we implement a novel framework that integrates an adaptive Proportional-Integral-Derivative (PID) controller to dynamically improve synchronization. Additionally, through an interactive user interface, results of our enhanced approach demonstrate an improvement in real-time traffic synchronization.", "published": "2025-10-23T17:20:02Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:56.552675"}
{"arxiv_id": "2510.20743v1", "title": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM   Conversations", "summary": "We present Empathic Prompting, a novel framework for multimodal human-AI interaction that enriches Large Language Model (LLM) conversations with implicit non-verbal context. The system integrates a commercial facial expression recognition service to capture users' emotional cues and embeds them as contextual signals during prompting. Unlike traditional multimodal interfaces, empathic prompting requires no explicit user control; instead, it unobtrusively augments textual input with affective information for conversational and smoothness alignment. The architecture is modular and scalable, allowing integration of additional non-verbal modules. We describe the system design, implemented through a locally deployed DeepSeek instance, and report a preliminary service and usability evaluation (N=5). Results show consistent integration of non-verbal input into coherent LLM outputs, with participants highlighting conversational fluidity. Beyond this proof of concept, empathic prompting points to applications in chatbot-mediated communication, particularly in domains like healthcare or education, where users' emotional signals are critical yet often opaque in verbal exchanges.", "published": "2025-10-23T17:08:03Z", "query": "brain-to-brain interface", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.552908"}
{"arxiv_id": "2510.20683v1", "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding   with Spiking Neural Networks", "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as speech and prosthetic control, for individuals with neuromotor impairments. Central to their success are neural decoders, models that map neural activity to intended behavior. Current learning-based decoding approaches fall into two classes: simple, causal models that lack generalization, or complex, non-causal models that generalize and scale offline but struggle in real-time settings. Both face a common challenge, their reliance on power-hungry artificial neural network backbones, which makes integration into real-world, resource-limited systems difficult. Spiking neural networks (SNNs) offer a promising alternative. Because they operate causally these models are suitable for real-time use, and their low energy demands make them ideal for battery-constrained environments. To this end, we introduce Spikachu: a scalable, causal, and energy-efficient neural decoding framework based on SNNs. Our approach processes binned spikes directly by projecting them into a shared latent space, where spiking modules, adapted to the timing of the input, extract relevant features; these latent representations are then integrated and decoded to generate behavioral predictions. We evaluate our approach on 113 recording sessions from 6 non-human primates, totaling 43 hours of recordings. Our method outperforms causal baselines when trained on single sessions using between 2.26 and 418.81 times less energy. Furthermore, we demonstrate that scaling up training to multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks. Overall, Spikachu introduces a scalable, online-compatible neural decoding framework based on SNNs, whose performance is competitive relative to state-of-the-art models while consuming orders of magnitude less energy.", "published": "2025-10-23T15:55:45Z", "query": "brain-to-brain interface", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-25T15:16:56.553114"}
{"arxiv_id": "2510.20560v1", "title": "Super-robust telecommunications enabled by topological half-supermodes", "summary": "Topological photonics offers transformative potential for robust integrated waveguide devices due to their backscattering-immune properties. However, their integration faces two fundamental challenges: mode symmetry mismatch with conventional waveguides and prohibitive dimensions. We successfully overcome these two critical challenges by introducing a novel valley-ridge gap waveguide based on topological half-supermode engineering. By strategically hybridizing ridge waveguide modes and valley kink states, we create an exotic odd-symmetric supermode enabling robust propagation and ultra-compact operation. The further implementation of a perfect electric conductor boundary halves lateral dimensions while eliminating radiation loss. Crucially, our proposed valley-ridge interface achieves direct transverse electric mode matching with standard waveguides without transition structures, enabling seamless integration. Experimental results demonstrate reflection losses lower than -15 dB in realistic telecommunication scenarios with super-robust signal propagation through sharp bends. This work innovatively conceptualizes topological half-supermodes and pioneers their practical applications for integrated waveguide devices, establishing a completely new waveguide class that uniquely combines robust backscattering immunity with deep subwavelength compactness.", "published": "2025-10-23T13:41:49Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.553338"}
{"arxiv_id": "2510.20559v1", "title": "High-Resolution Echelle Spectroscopy for Solar System Planets: A   Planet-as-Point-Source Analogy", "summary": "Transmission spectroscopy has proven to be an effective technique for characterizing exoplanet atmospheres. However, transmission spectroscopy requires planetary transits, which occur for only a small fraction of planetary systems due to geometric alignment constraints; hence, characterizing exoplanets through their reflected spectrum of host stars will be helpful for a large number of exoplanets. The upcoming extremely large telescopes (ELTs) will be able to study the reflected spectra of exoplanets. Here, we present a preliminary optical design and a detailed throughput analysis of the instrumentation that interfaces the 2.34 m Vainu Bappu Telescope prime focus to an existing high-resolution echelle spectrograph with disk-integrated light from solar system objects. One of the primary objectives is to obtain high-resolution, high signal-to-noise reflected spectra from the solar system objects.", "published": "2025-10-23T13:40:33Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.553486"}
{"arxiv_id": "2510.20463v1", "title": "Suspension-Free Integrated Cavity Brillouin Optomechanics on a Chip", "summary": "Cavity optomechanical systems enable coherent photon-phonon interactions essential for quantum technologies, yet high-performance devices have been limited to suspended structures. Here, we overcome this limitation by demonstrating cavity Brillouin optomechanics in a suspension-free racetrack microring resonator on a lithium-niobate-on-sapphire chip, a platform that merits high stability and scalability. We demonstrate coherent coupling between telecom-band optical modes and a 9.6-GHz phonon mode, achieving a maximum cooperativity of $0.41$ and a phonon quality-factor-frequency product of $10^{13}\\,\\mathrm{Hz}$. The momentum-matching condition inherent to traveling-wave Brillouin interactions establishes a one-to-one mapping between optical wavelength and phonon frequency, enabling multi-channel parallel operations across nearly $300\\,\\mathrm{MHz}$ in phonon frequency and $40\\,\\mathrm{nm}$ in optical wavelength. Our suspension-free architecture provides a coherent photon-phonon interface compatible with wafer-scale integration, opening pathways toward hybrid quantum circuits that unite photonic, phononic, and superconducting components on a single chip.", "published": "2025-10-23T11:59:39Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.553655"}
{"arxiv_id": "2510.20416v1", "title": "Learning Coupled Earth System Dynamics with GraphDOP", "summary": "Interactions between different components of the Earth System (e.g. ocean, atmosphere, land and cryosphere) are a crucial driver of global weather patterns. Modern Numerical Weather Prediction (NWP) systems typically run separate models of the different components, explicitly coupled across their interfaces to additionally model exchanges between the different components. Accurately representing these coupled interactions remains a major scientific and technical challenge of weather forecasting. GraphDOP is a graph-based machine learning model that learns to forecast weather directly from raw satellite and in-situ observations, without reliance on reanalysis products or traditional physics-based NWP models. GraphDOP simultaneously embeds information from diverse observation sources spanning the full Earth system into a shared latent space. This enables predictions that implicitly capture cross-domain interactions in a single model without the need for any explicit coupling. Here we present a selection of case studies which illustrate the capability of GraphDOP to forecast events where coupled processes play a particularly key role. These include rapid sea-ice freezing in the Arctic, mixing-induced ocean surface cooling during Hurricane Ian and the severe European heat wave of 2022. The results suggest that learning directly from Earth System observations can successfully characterise and propagate cross-component interactions, offering a promising path towards physically consistent end-to-end data-driven Earth System prediction with a single model.", "published": "2025-10-23T10:36:20Z", "query": "brain-to-brain interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.553897"}
{"arxiv_id": "2510.20389v1", "title": "Symmetry in Software Platforms as an Architectural Principle", "summary": "Software platforms often act as structure preserving systems. They provide consistent interfaces and behaviors that remain stable under specific transformations that we denote as symmetries. This paper explores the idea that architectural robustness emerges from enforcing such structural regularities", "published": "2025-10-23T09:38:32Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.554030"}
{"arxiv_id": "2510.20338v1", "title": "Comparative Analysis of Thermal Models for Test Masses in   Next-Generation Gravitational Wave Interferometers", "summary": "Accurate thermal modeling of Terminal Test Masses (TTMs) is crucial for optimizing the sensitivity of gravitational wave interferometers like Virgo. In fact, in such gravitational wave detectors even minimal laser power absorption can induce performance-limiting thermal effects. This paper presents a detailed investigation into the steady-state thermal behavior of TTMs. In particular, future scenarios of increased intracavity laser beam power and optical coating absorption are considered. We develop and compare two numerical models: a comprehensive model incorporating volumetric heat absorption in both the multilayer coating and the bulk substrate, and a simplified reduced model where the coating's thermal impact is represented as an effective surface boundary condition on the substrate. Our simulations were focused on a ternary coating design, which is a candidate for use in next-generation detectors. Results reveal that higher coating absorption localizes peak temperatures near the coating--vacuum interface. Importantly, the comparative analysis demonstrates that temperature predictions from the reduced model differ from the detailed model by only milli-Kelvins, a discrepancy often within the experimental uncertainties of the system's thermo-physical parameters. This finding suggests that computationally efficient reduced models can provide sufficiently accurate results for thermal management and first-order distortion analyses. Moreover, the critical role of accurately characterizing the total power absorbed by the coating is emphasized.", "published": "2025-10-23T08:37:47Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.554223"}
{"arxiv_id": "2510.20333v1", "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in   Dynamic On-Device Environments?", "summary": "Vision-Language Models (VLMs) are increasingly deployed as autonomous agents to navigate mobile graphical user interfaces (GUIs). Operating in dynamic on-device ecosystems, which include notifications, pop-ups, and inter-app interactions, exposes them to a unique and underexplored threat vector: environmental injection. Unlike prompt-based attacks that manipulate textual instructions, environmental injection corrupts an agent's visual perception by inserting adversarial UI elements (for example, deceptive overlays or spoofed notifications) directly into the GUI. This bypasses textual safeguards and can derail execution, causing privacy leakage, financial loss, or irreversible device compromise. To systematically evaluate this threat, we introduce GhostEI-Bench, the first benchmark for assessing mobile agents under environmental injection attacks within dynamic, executable environments. Moving beyond static image-based assessments, GhostEI-Bench injects adversarial events into realistic application workflows inside fully operational Android emulators and evaluates performance across critical risk scenarios. We further propose a judge-LLM protocol that conducts fine-grained failure analysis by reviewing the agent's action trajectory alongside the corresponding screenshot sequence, pinpointing failure in perception, recognition, or reasoning. Comprehensive experiments on state-of-the-art agents reveal pronounced vulnerability to deceptive environmental cues: current models systematically fail to perceive and reason about manipulated UIs. GhostEI-Bench provides a framework for quantifying and mitigating this emerging threat, paving the way toward more robust and secure embodied agents.", "published": "2025-10-23T08:33:24Z", "query": "brain-to-brain interface", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.554426"}
{"arxiv_id": "2510.20299v1", "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for   Multi-Class Classification with Grad-CAM Interpretability", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and precise diagnosis is important for successful treatment. Deep learning-based brain tumor classification methods often rely on heavy data augmentation which can limit generalization and trust in clinical applications. In this paper, we propose a double-backbone network integrating VGG16 and Xception with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Unlike previous studies, our model achieves state-of-the-art performance without augmentation which demonstrates robustness to variably sized and distributed datasets. For further transparency, Grad-CAM is integrated to visualize the tumor regions based on which the model is giving prediction, bridging the gap between model prediction and clinical interpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS dataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class and 2-class settings, respectively. On the independent 3K-DS dataset, the model generalizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art methods. To further support clinical usability, we developed a graphical user interface (GUI) that provides real-time classification and Grad-CAM-based tumor localization. These findings suggest that augmentation-free, interpretable, and deployable deep learning models such as DB-FGA-Net hold strong potential for reliable clinical translation in brain tumor diagnosis.", "published": "2025-10-23T07:39:00Z", "query": "brain-to-brain interface", "relevance": 0.15000000000000002, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.554599"}
{"arxiv_id": "2510.20211v1", "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a \"source-of-truth\" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors.   We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$ improvement).", "published": "2025-10-23T04:57:00Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.554806"}
{"arxiv_id": "2510.20184v1", "title": "A Unified and Scalable Method for Optimization over Graphs of Convex   Sets", "summary": "A Graph of Convex Sets (GCS) is a graph in which vertices are associated with convex programs and edges couple pairs of programs through additional convex costs and constraints. Any optimization problem over an ordinary weighted graph (e.g., the shortest-path, the traveling-salesman, and the minimum-spanning-tree problems) can be naturally generalized to a GCS, yielding a new class of problems at the interface of combinatorial and convex optimization with numerous applications. In this paper, we introduce a unified method for solving any such problem. Starting from an integer linear program that models an optimization problem over a weighted graph, our method automatically produces an efficient mixed-integer convex formulation of the corresponding GCS problem. This formulation is based on homogenization (perspective) transformations, and the resulting program is solved to global optimality using off-the-shelf branch-and-bound solvers. We implement this framework in GCSOPT, an open-source and easy-to-use Python library designed for fast prototyping. We illustrate the versatility and scalability of our approach through multiple numerical examples and comparisons.", "published": "2025-10-23T04:08:39Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.555000"}
{"arxiv_id": "2510.20128v1", "title": "A Full Stack Framework for High Performance Quantum-Classical Computing", "summary": "To address the growing needs for scalable High Performance Computing (HPC) and Quantum Computing (QC) integration, we present our HPC-QC full stack framework and its hybrid workload development capability with modular hardware/device-agnostic software integration approach. The latest development in extensible interfaces for quantum programming, dispatching, and compilation within existing mature HPC programming environment are demonstrated. Our HPC-QC full stack enables high-level, portable invocation of quantum kernels from commercial quantum SDKs within HPC meta-program in compiled languages (C/C++ and Fortran) as well as Python through a quantum programming interface library extension. An adaptive circuit knitting hypervisor is being developed to partition large quantum circuits into sub-circuits that fit on smaller noisy quantum devices and classical simulators. At the lower-level, we leverage Cray LLVM-based compilation framework to transform and consume LLVM IR and Quantum IR (QIR) from commercial quantum software frontends in a retargetable fashion to different hardware architectures. Several hybrid HPC-QC multi-node multi-CPU and GPU workloads (including solving linear system of equations, quantum optimization, and simulating quantum phase transitions) have been demonstrated on HPE EX supercomputers to illustrate functionality and execution viability for all three components developed so far. This work provides the framework for a unified quantum-classical programming environment built upon classical HPC software stack (compilers, libraries, parallel runtime and process scheduling).", "published": "2025-10-23T02:07:29Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-25T15:16:56.555231"}
{"arxiv_id": "2510.20114v1", "title": "Fabrication and Structural Analysis of Trilayers for Tantalum Josephson   Junctions with Ta$_2$O$_5$ Barriers", "summary": "Tantalum (Ta) has recently emerged as a promising low-loss material, enabling record coherence times in superconducting qubits. This enhanced performance is largely attributed to its stable native oxide, which is believed to host fewer two-level system (TLS) defects key $-$ contributors to decoherence in superconducting circuits. Nevertheless, aluminum oxide (AlO$_x$) remains the predominant choice for Josephson junction barriers in most qubit architectures. In this study, we systematically investigate various techniques for forming high-quality oxide layers on $\\alpha$-phase tantalum ($\\alpha$-Ta) thin films, aiming to develop effective Josephson junction barriers. We explore thermal oxidation in a tube furnace, rapid thermal annealing, as well as plasma oxidation of both room-temperature and heated Ta films, and propose a mechanistic picture of the underlying oxidation mechanisms. All methods yield Ta$_2$O$_5$, the same compound as tantalum's native oxide. Among these, plasma oxidation produces the smoothest and highest-quality oxide layers, making it particularly well-suited for Josephson junction fabrication. Furthermore, we demonstrate the successful epitaxial growth of $\\alpha$-Ta atop oxidized $\\alpha$-Ta films, paving the way for the realization of trilayer Ta/Ta-O/Ta Josephson junctions with clean, low-loss interfaces.", "published": "2025-10-23T01:35:14Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.555440"}
{"arxiv_id": "2510.20088v1", "title": "RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling", "summary": "Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves to desired directions to enhance signal coverage and/or improve signal-to-noise ratio (SNR) at the user equipment (UE). We present the design, implementation, and evaluation of an RIS-assisted O-RAN 5G system operating in the FR2 millimeter wave (mmWave) frequency band. We first introduce the design of 1,024 element (32 $\\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a modular and scalable tiled architecture. Then we demonstrate how the O-RAN E2 interface can be leveraged to dynamically control RIS configurations without modifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G system, we conducted extensive field trials in both indoor and outdoor environments. The results of the O-RAN link coverage trials show that the deployed RIS provides substantial received signal power gains, ranging from 9 to 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively. Handling UE mobility in RIS-assisted systems is challenging due to the need for joint RIS and UE beam management. For that, we develop two UE mobility management algorithms and evaluate them in real-time operation using the RIS O-RAN testbed. These algorithms leverage the received signal power at the UE to jointly track and adapt the RIS and UE beams in real time as the UE moves. The findings draw important insights into the practical feasibility of integrating RIS into O-RAN systems to enhance coverage, mobility support, and link reliability in next-generation cellular networks.", "published": "2025-10-23T00:09:57Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.555623"}
{"arxiv_id": "2510.19983v1", "title": "A transmon qubit realized by exploiting the superconductor-insulator   transition", "summary": "Superconducting qubits are among the most promising platforms for realizing practical quantum computers. One requirement to create a quantum processor is nonlinearity, which in superconducting circuits is typically achieved by sandwiching a layer of aluminum oxide between two aluminum electrodes to form a Josephson junction. These junctions, however, face several limitations that hinder their scalability: the small superconducting gap of aluminum necessitates millikelvin operating temperatures, the material interfaces lead to dissipation, and the sandwich geometry adds unwelcome capacitance for high-frequency applications. In this work, we address all three limitations using a novel superconducting weak link based on the superconductor-insulator transition. By locally thinning a single film of niobium nitride, we exploit its thickness-driven superconductor-insulator transition to form a weak link employing only atomic layer deposition and atomic layer etching. We utilize our weak links to produce a transmon qubit, '$planaron$', with a measured anharmonicity of $\\alpha/2\\pi = 235$ MHz; at present, the linewidth is $\\kappa/2\\pi = 15 \\mathrm{\\: MHz}$. The high superconducting gap of niobium nitride can enable operation at elevated temperatures in future devices, and the fully planar geometry of the weak link eliminates superfluous material interfaces and capacitances. The investigation of small patches of material near the SIT can shed new light on the nature of the transition, including the role of dissipation and finite-size effects.", "published": "2025-10-22T19:29:01Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.555869"}
{"arxiv_id": "2510.19968v1", "title": "Q-RAN: Quantum-Resilient O-RAN Architecture", "summary": "The telecommunications industry faces a dual transformation: the architectural shift toward Open Radio Access Networks (O-RAN) and the emerging threat from quantum computing. O-RAN disaggregated, multi-vendor architecture creates a larger attack surface vulnerable to crypt-analytically relevant quantum computers(CRQCs) that will break current public key cryptography. The Harvest Now, Decrypt Later (HNDL) attack strategy makes this threat immediate, as adversaries can intercept encrypted data today for future decryption. This paper presents Q-RAN, a comprehensive quantum-resistant security framework for O-RAN networks using NIST-standardized Post-Quantum Cryptography (PQC). We detail the implementation of ML-KEM (FIPS 203) and ML-DSA (FIPS 204), integrated with Quantum Random Number Generators (QRNG) for cryptographic entropy. The solution deploys PQ-IPsec, PQ-DTLS, and PQ-mTLS protocols across all O-RAN interfaces, anchored by a centralized Post-Quantum Certificate Authority (PQ-CA) within the SMO framework. This work provides a complete roadmap for securing disaggregated O-RAN ecosystems against quantum adversaries.", "published": "2025-10-22T18:57:44Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.556218"}
{"arxiv_id": "2510.19949v1", "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "summary": "Building agents that generalize across web, desktop, and mobile environments remains an open challenge, as prior systems rely on environment-specific interfaces that limit cross-platform deployment. We introduce Surfer 2, a unified architecture operating purely from visual observations that achieves state-of-the-art performance across all three environments. Surfer 2 integrates hierarchical context management, decoupled planning and execution, and self-verification with adaptive recovery, enabling reliable operation over long task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior systems without task-specific fine-tuning. With multiple attempts, Surfer 2 exceeds human performance on all benchmarks. These results demonstrate that systematic orchestration amplifies foundation model capabilities and enables general-purpose computer control through visual interaction alone, while calling for a next-generation vision language model to achieve Pareto-optimal cost-efficiency.", "published": "2025-10-22T18:21:52Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.556633"}
{"arxiv_id": "2510.19923v1", "title": "Novel Defect Universality Classes from Interacting RG Interfaces", "summary": "We search for new defect universality classes by considering localised interactions placed on an RG interface separating two interacting multiscalar CFTs in $4-\\varepsilon$ dimensions. Studying interactions spread throughout the entire interface as well as defects restricted to lines and surfaces within the interface, we find that this setup leads to a great number of additional physical fixed points in the space of conformal defects. At one loop it is possible to interpret these fixed points as coming from defects placed within a single bulk whose interaction is an average of the two sides. This averaging means that it is possible to identify conformal defects with considerably less global symmetry than was possible beforehand. We finally compute conformal data for this setup, and find the free energy associated with these RG interfaces.", "published": "2025-10-22T18:00:04Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.556852"}
{"arxiv_id": "2510.19747v1", "title": "Review of Tools for Zero-Code LLM Based Application Development", "summary": "Large Language Models (LLMs) are transforming software creation by enabling zero code development platforms. Our survey reviews recent platforms that let users build applications without writing code, by leveraging LLMs as the brains of the development process. We adopt a broad survey methodology, categorizing platforms based on key dimensions such as interface style, backend integration, output type, and extensibility. We analyze both dedicated LLM based app builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and general no code platforms (e.g., Bubble, Glide) that integrate LLM capabilities. We present a taxonomy categorizing these platforms by their interface (conversational, visual, etc.), supported LLM backends, output type (chatbot, full application, workflow), and degree of extensibility. Core features such as autonomous agents, memory management, workflow orchestration, and API integrations are in scope of the survey. We provide a detailed comparison, highlighting each platform's strengths and limitations. Trade offs (customizability, scalability, vendor lock-in) are discussed in comparison with traditional and low code development approaches. Finally, we outline future directions, including multimodal interfaces, on device LLMs, and improved orchestration for democratizing app creation with AI. Our findings indicate that while zero code LLM platforms greatly reduce the barrier to creating AI powered applications, they still face challenges in flexibility and reliability. Overall, the landscape is rapidly evolving, offering exciting opportunities to empower non programmers to create sophisticated software.", "published": "2025-10-22T16:41:16Z", "query": "brain-to-brain interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.557039"}
{"arxiv_id": "2510.19721v1", "title": "An active-flux-type scheme for ideal MHD with provable positivity and   discrete divergence-free property", "summary": "We develop a positivity-preserving (PP) PAMPA (Point-Average-Moment PolynomiAl-interpreted) scheme that enforces a discrete divergence-free (DDF) magnetic field for ideal MHD on Cartesian grids. Extending our 1D invariant-domain-preserving (IDP) PAMPA framework (Abgrall, Jiao, Liu, Wu, SIAM J. Sci. Comput., to appear) to multidimensional, multiwave MHD, the method combines a limiter-free PP update of interface point values via a new nonconservative reformulation with a local DDF projection. Cell averages are provably PP under a mild a~priori positivity condition on one cell-centered state, using: (i) DDF-constrained interface values, (ii) a PP limiter only at the cell center, (iii) a PP flux with appropriate wave-speed bounds, and (iv) a suitable discretization of the Godunov--Powell source term. The PP proof employs geometric quasi-linearization (GQL; Wu &amp; Shu, SIAM Review, 2023), which linearizes the pressure constraint. The scheme avoids explicit polynomial reconstructions, is compatible with arbitrarily high-order strong-stability-preserving (SSP) time integration, and is simple to implement. Robustness and resolution are enhanced by a problem-independent Lax-type entropy troubled-cell indicator using only two characteristic speeds and a convex oscillation elimination (COE) mechanism with a new intercell-difference norm. Tests -- including a blast wave with plasma $\\beta \\approx 2.51\\times 10^{-6}$ and jets up to Mach $10^{4}$ -- show high-order accuracy, sharp MHD-structure resolution, and strong-shock robustness. To our knowledge, this is the first active-flux-type ideal-MHD method rigorously PP for both cell averages and interface point values while maintaining DDF throughout.", "published": "2025-10-22T16:07:03Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.557282"}
{"arxiv_id": "2510.19682v1", "title": "M5 branes on ADE singularities: BPS spectrum and partition functions", "summary": "The dynamics of a stack of M5 branes probing a transverse multi-centered Taub-NUT space are described by a class of 6d $\\mathcal{N}=(1,0)$ superconformal field theories known as the M-string orbifold SCFTs. We determine the equivariant partition functions for this class of theories on a geometric background of type $T^2\\times\\mathbb{C}^2/\\Gamma$, where $\\Gamma \\in\\{\\mathcal{C}_N,\\mathcal{Q}_N, \\mathcal{T},\\mathcal{O},\\mathcal{I}\\}$ is an arbitrary finite subgroup of $SU(2)$. The partition functions are built out of contributions from BPS strings as well as BPS particles that arise upon putting the 6d theory on a circle. We find that BPS particle contributions can be expressed in terms of $\\Gamma$-covariant Hilbert series which count holomorphic sections of vector bundles on the orbifold singularity with monodromy specified by an irreducible representation of $\\Gamma$. The BPS string contributions, on the other hand, are given by the elliptic genera of 2d $\\mathcal{N}=(0,4)$ $\\Gamma$-dressed quiver gauge theories, obtained by stacking Kronheimer-Nakajima quivers of type $\\Gamma$ between interfaces that support current algebras for the McKay dual affine Lie algebra $\\widehat{\\mathfrak{g}}$. We obtain explicit expressions for the elliptic genera of arbitrary BPS string configurations corresponding to fractional instanton strings on $\\mathbb{C}^2/\\Gamma$, and for the case of star-shaped quivers of type $\\Gamma\\in\\{\\mathcal{Q}_4,\\mathcal{T},\\mathcal{O},\\mathcal{I}\\}$ we give a prescription to compute the elliptic genera by gluing 2d analogues of Gaiotto and Witten's $T[SU(N)]$ theories.", "published": "2025-10-22T15:27:43Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.557512"}
{"arxiv_id": "2510.19582v1", "title": "From Interface Dynamics to Darcy Scale Description of Multiphase Flow in   Porous Media", "summary": "An outstanding characteristic of porous media, desired in many applications, is the large surface area, which facilitates solid-fluid interactions, making porous media an extreme case in colloid and interface science. In two-fluid systems, wetting and the balance of capillary and viscous forces control fluid displacement processes, leading to a wide range of complex flow regimes with rich spatio-temporal dynamics. Macroscopic two-phase flow is historically described through the phenomenological extensions of Darcy's law. Besides many other shortcomings and inconsistencies, it covers only connected pathway flow in the capillary-dominated flow regime in a rigorous manner while other flow regimes with moving interfaces and associated topological changes are entirely implicit. Given the lack of adequate descriptions, upscaling multiphase flow from pore to Darcy scale represents a long-standing challenge paving into the fields of thermodynamics, statistical mechanics and integral geometry. In this review, we compare novel concepts which have been largely motivated by experimental insights, enabled by significant advances in pore-scale imaging and modeling over the last decade.", "published": "2025-10-22T13:34:16Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.557659"}
{"arxiv_id": "2510.19554v1", "title": "Observation of counterion binding in the inner Helmholtz layer at the   ionic surfactant-water interface", "summary": "Understanding specific ion adsorption within the inner Helmholtz layer remains central to electrochemistry yet experimentally elusive. Here we directly quantify counterion adsorption and extract the associated thermodynamic parameters within the inner Helmholtz layer using phase-sensitive sum-frequency vibrational spectroscopy (PS-SFVS). Using sodium dodecyl sulfate (SDS) as a model ionic surfactant, we determine the Na+ and DS- surface densities by simultaneously analyzing interfacial free OH response and the diffuse-layer SF signal, from which the adsorption thermodynamic parameters are derived. We then construct an adsorption phase diagram that maps the evolution of Na+ and DS- species in the compact layer as functions of bulk NaCl and SDS concentrations, revealing a continuous increase in surface ion pairing. The DS-: Na+ pairing ratio gradually decreases with increasing NaCl and approaches 2.8 at the supersaturation state prior to surface nucleation. These results establish PS-SFVS as a quantitative probe of ion-headgroup correlations in charged interfaces and reveal the thermodynamic mechanism underlying counterion-mediated interfacial ordering, with broad implications for electrolyte design, biomembrane stability, and soft-matter assembly.", "published": "2025-10-22T13:07:52Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.557819"}
{"arxiv_id": "2510.19551v1", "title": "4d Maxwell on the Edge: Global Aspects of Boundary Conditions and   Duality", "summary": "We revisit Maxwell theory in 4d with a boundary, with particular attention to the global properties of the boundary conditions, both in the free (topological) and interacting (conformal) cases. We analyze the fate of Wilson-'t Hooft lines, identifying the subset that is trivialized on the boundary and the ones that become topological, thus generating a boundary 1-form symmetry. We further study how the boundary conditions are mapped to each other by 3d topological interfaces implementing bulk dualities and rescalings of the coupling. Together, these interfaces generate an $SL(2,\\mathbb{Q})$ action on the bulk complexified coupling $\\tau$, and they generalize the usual $SL(2,\\mathbb{Z})$ action on 3d CFTs by including both topological and non-topological manipulations within a unified framework. We then show how to recover our results in a streamlined way from a SymTFT picture in 5d with corners. Finally, we comment on the possible inclusion of non-compact 3d edge modes.", "published": "2025-10-22T13:04:03Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-25T15:16:56.557960"}
{"arxiv_id": "2510.19514v1", "title": "From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals   for Multivariate Time-Series Multi-class Classification", "summary": "In eXplainable Artificial Intelligence (XAI), instance-based explanations for time series have gained increasing attention due to their potential for actionable and interpretable insights in domains such as healthcare. Addressing the challenges of explainability of state-of-the-art models, we propose a prototype-driven framework for generating sparse counterfactual explanations tailored to 12-lead ECG classification models. Our method employs SHAP-based thresholds to identify critical signal segments and convert them into interval rules, uses Dynamic Time Warping (DTW) and medoid clustering to extract representative prototypes, and aligns these prototypes to query R-peaks for coherence with the sample being explained. The framework generates counterfactuals that modify only 78% of the original signal while maintaining 81.3% validity across all classes and achieving 43% improvement in temporal stability. We evaluate three variants of our approach, Original, Sparse, and Aligned Sparse, with class-specific performance ranging from 98.9% validity for myocardial infarction (MI) to challenges with hypertrophy (HYP) detection (13.2%). This approach supports near realtime generation (&lt; 1 second) of clinically valid counterfactuals and provides a foundation for interactive explanation platforms. Our findings establish design principles for physiologically-aware counterfactual explanations in AI-based diagnosis systems and outline pathways toward user-controlled explanation interfaces for clinical deployment.", "published": "2025-10-22T12:09:50Z", "query": "brain-to-brain interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.558098"}
{"arxiv_id": "2510.19512v1", "title": "Design Considerations for Human Oversight of AI: Insights from Co-Design   Workshops and Work Design Theory", "summary": "As AI systems become increasingly capable and autonomous, domain experts' roles are shifting from performing tasks themselves to overseeing AI-generated outputs. Such oversight is critical, as undetected errors can have serious consequences or undermine the benefits of AI. Effective oversight, however, depends not only on detecting and correcting AI errors but also on the motivation and engagement of the oversight personnel and the meaningfulness they see in their work. Yet little is known about how domain experts approach and experience the oversight task and what should be considered to design effective and motivational interfaces that support human oversight. To address these questions, we conducted four co-design workshops with domain experts from psychology and computer science. We asked them to first oversee an AI-based grading system, and then discuss their experiences and needs during oversight. Finally, they collaboratively prototyped interfaces that could support them in their oversight task. Our thematic analysis revealed four key user requirements: understanding tasks and responsibilities, gaining insight into the AI's decision-making, contributing meaningfully to the process, and collaborating with peers and the AI. We integrated these empirical insights with the SMART model of work design to develop a generalizable framework of twelve design considerations. Our framework links interface characteristics and user requirements to the psychological processes underlying effective and satisfying work. Being grounded in work design theory, we expect these considerations to be applicable across domains and discuss how they extend existing guidelines for human-AI interaction and theoretical frameworks for effective human oversight by providing concrete guidance on the design of engaging and meaningful interfaces that support human oversight of AI systems.", "published": "2025-10-22T12:05:51Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-25T15:16:56.558247"}
{"arxiv_id": "2510.24718v1", "title": "Generative View Stitching", "summary": "Autoregressive video diffusion models are capable of long rollouts that are stable and consistent with history, but they are unable to guide the current generation with conditioning from the future. In camera-guided video generation with a predefined camera trajectory, this limitation leads to collisions with the generated scene, after which autoregression quickly collapses. To address this, we propose Generative View Stitching (GVS), which samples the entire sequence in parallel such that the generated scene is faithful to every part of the predefined camera trajectory. Our main contribution is a sampling algorithm that extends prior work on diffusion stitching for robot planning to video generation. While such stitching methods usually require a specially trained model, GVS is compatible with any off-the-shelf video model trained with Diffusion Forcing, a prevalent sequence diffusion framework that we show already provides the affordances necessary for stitching. We then introduce Omni Guidance, a technique that enhances the temporal consistency in stitching by conditioning on both the past and future, and that enables our proposed loop-closing mechanism for delivering long-range coherence. Overall, GVS achieves camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and closes loops for a variety of predefined camera paths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best viewed as videos at https://andrewsonga.github.io/gvs.", "published": "2025-10-28T17:59:58Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:53.997776"}
{"arxiv_id": "2510.24717v1", "title": "Uniform Discrete Diffusion with Metric Path for Video Generation", "summary": "Continuous-space video generation has advanced rapidly, while discrete approaches lag behind due to error accumulation and long-context inconsistency. In this work, we revisit discrete generative modeling and present Uniform discRete diffuSion with metric pAth (URSA), a simple yet powerful framework that bridges the gap with continuous approaches for the scalable video generation. At its core, URSA formulates the video generation task as an iterative global refinement of discrete spatiotemporal tokens. It integrates two key designs: a Linearized Metric Path and a Resolution-dependent Timestep Shifting mechanism. These designs enable URSA to scale efficiently to high-resolution image synthesis and long-duration video generation, while requiring significantly fewer inference steps. Additionally, we introduce an asynchronous temporal fine-tuning strategy that unifies versatile tasks within a single model, including interpolation and image-to-video generation. Extensive experiments on challenging video and image generation benchmarks demonstrate that URSA consistently outperforms existing discrete methods and achieves performance comparable to state-of-the-art continuous diffusion methods. Code and models are available at https://github.com/baaivision/URSA", "published": "2025-10-28T17:59:57Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:53.998524"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "brain computer interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:16:53.999043"}
{"arxiv_id": "2510.24711v1", "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit   Routing Guidance", "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity while preserving computational efficiency. Despite its notable success in large language models (LLMs), existing attempts to apply MoE to Diffusion Transformers (DiTs) have yielded limited gains. We attribute this gap to fundamental differences between language and visual tokens. Language tokens are semantically dense with pronounced inter-token variation, while visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization in vision MoE. To this end, we present ProMoE, an MoE framework featuring a two-step router with explicit routing guidance that promotes expert specialization. Specifically, this guidance encourages the router to partition image tokens into conditional and unconditional sets via conditional routing according to their functional roles, and refine the assignments of conditional image tokens through prototypical routing with learnable prototypes based on semantic content. Moreover, the similarity-based expert allocation in latent space enabled by prototypical routing offers a natural mechanism for incorporating explicit semantic guidance, and we validate that such guidance is crucial for vision MoE. Building on this, we propose a routing contrastive loss that explicitly enhances the prototypical routing process, promoting intra-expert coherence and inter-expert diversity. Extensive experiments on ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives. Code and models will be made publicly available.", "published": "2025-10-28T17:59:02Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:16:53.999475"}
{"arxiv_id": "2510.24710v1", "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel   Optimization", "summary": "We study bilevel optimization problems where the lower-level problems are strongly convex and have coupled linear constraints. To overcome the potential non-smoothness of the hyper-objective and the computational challenges associated with the Hessian matrix, we utilize penalty and augmented Lagrangian methods to reformulate the original problem as a single-level one. Especially, we establish a strong theoretical connection between the reformulated function and the original hyper-objective by characterizing the closeness of their values and derivatives. Based on this reformulation, we propose a single-loop, first-order algorithm for linearly constrained bilevel optimization (SFLCB). We provide rigorous analyses of its non-asymptotic convergence rates, showing an improvement over prior double-loop algorithms -- form $O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments corroborate our theoretical findings and demonstrate the practical efficiency of the proposed SFLCB algorithm. Simulation code is provided at https://github.com/ShenGroup/SFLCB.", "published": "2025-10-28T17:58:17Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:16:53.999835"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "brain computer interface", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:16:54.000053"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:16:54.000245"}
{"arxiv_id": "2510.24706v1", "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?", "summary": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.", "published": "2025-10-28T17:55:42Z", "query": "brain computer interface", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:16:54.000438"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "brain computer interface", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:16:54.000732"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "brain computer interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:54.001304"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:16:59.161017"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:59.161652"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:16:59.162091"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:59.162535"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:16:59.162958"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:59.163292"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "BCI neural interface", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:16:59.163591"}
{"arxiv_id": "2510.24645v1", "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in   Multi-Turn Function Calling", "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.", "published": "2025-10-28T17:15:26Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:16:59.164007"}
{"arxiv_id": "2510.24641v1", "title": "Density-driven scattering and valley splitting in undoped Si/SiGe   two-dimensional electron system", "summary": "Undoped Si-SiGe two-dimensional electron gas (2DEG) provide an ideal platform for hosting quantum-dot spin-qubits owing enhanced spin dephasing times and compatibility with standard CMOS technology. The strained Si quantum well reduces the valley degeneracy into two closely spaced ones. The existence of a near-degenerate valley state act as a leakage channel and compromises gate fidelity. A robust and uniform valley splitting across the entire chip is crucial for achieving scalability in the architecture and reliability in operation. Imperfections such as broadened interfaces, alloy disorders and atomic steps significantly compromise the valley splitting. The associated scattering mechanisms play detrimental roles in the performance of the qubits. In this manuscript, exploiting low-temperature magnetotransport measurements, we investigate the scattering mechanisms and valley splitting in a high-mobility undoped Si-SiGe 2DEG. At lower carrier densities, transport is limited by remote impurity scattering, whereas at higher densities, background impurity scattering near the quantum well dominates. Both the transport and quantum lifetimes of the charge carriers increase with carrier concentration, due to the enhancement in the impurity screening. Magnetic-field-induced confinement effect also is found to improve the valley splitting. Current-biasing measurements reveals the role of carrier heating in the visibility of valley splitting and reveal a temperature limited valley splitting of approximately 100 micro-eV. These results provide critical insight into scattering-dominated regimes and valley splitting in undoped Si-SiGe, advancing its potential for silicon-based quantum devices.", "published": "2025-10-28T17:07:26Z", "query": "BCI neural interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:16:59.164460"}
{"arxiv_id": "2510.24640v1", "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "summary": "The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques, ranging from face swapping and attribute editing to powerful diffusion-based image synthesis, are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function, FSC Loss, that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.", "published": "2025-10-28T17:06:40Z", "query": "BCI neural interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:16:59.164976"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:02.589681"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural prosthetics", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:02.590287"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:02.590651"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:17:02.590858"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:02.591091"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:02.591252"}
{"arxiv_id": "2510.24640v1", "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "summary": "The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques, ranging from face swapping and attribute editing to powerful diffusion-based image synthesis, are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function, FSC Loss, that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.", "published": "2025-10-28T17:06:40Z", "query": "neural prosthetics", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:02.591416"}
{"arxiv_id": "2510.24637v1", "title": "All in one timestep: Enhancing Sparsity and Energy efficiency in   Multi-level Spiking Neural Networks", "summary": "Spiking Neural Networks (SNNs) are one of the most promising bio-inspired neural networks models and have drawn increasing attention in recent years. The event-driven communication mechanism of SNNs allows for sparse and theoretically low-power operations on dedicated neuromorphic hardware. However, the binary nature of instantaneous spikes also leads to considerable information loss in SNNs, resulting in accuracy degradation. To address this issue, we propose a multi-level spiking neuron model able to provide both low-quantization error and minimal inference latency while approaching the performance of full precision Artificial Neural Networks (ANNs). Experimental results with popular network architectures and datasets, show that multi-level spiking neurons provide better information compression, allowing therefore a reduction in latency without performance loss. When compared to binary SNNs on image classification scenarios, multi-level SNNs indeed allow reducing by 2 to 3 times the energy consumption depending on the number of quantization intervals. On neuromorphic data, our approach allows us to drastically reduce the inference latency to 1 timestep, which corresponds to a compression factor of 10 compared to previously published results. At the architectural level, we propose a new residual architecture that we call Sparse-ResNet. Through a careful analysis of the spikes propagation in residual connections we highlight a spike avalanche effect, that affects most spiking residual architectures. Using our Sparse-ResNet architecture, we can provide state-of-the-art accuracy results in image classification while reducing by more than 20% the network activity compared to the previous spiking ResNets.", "published": "2025-10-28T17:03:33Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:02.591596"}
{"arxiv_id": "2510.24616v1", "title": "Statistical physics of deep learning: Optimal learning of a multi-layer   perceptron near interpolation", "summary": "For three decades statistical physics has been providing a framework to analyse neural networks. A long-standing question remained on its capacity to tackle deep learning models capturing rich feature learning effects, thus going beyond the narrow networks or kernel methods analysed until now. We positively answer through the study of the supervised learning of a multi-layer perceptron. Importantly, (i) its width scales as the input dimension, making it more prone to feature learning than ultra wide networks, and more expressive than narrow ones or with fixed embedding layers; and (ii) we focus on the challenging interpolation regime where the number of trainable parameters and data are comparable, which forces the model to adapt to the task. We consider the matched teacher-student setting. It provides the fundamental limits of learning random deep neural network targets and helps in identifying the sufficient statistics describing what is learnt by an optimally trained network as the data budget increases. A rich phenomenology emerges with various learning transitions. With enough data optimal performance is attained through model's \"specialisation\" towards the target, but it can be hard to reach for training algorithms which get attracted by sub-optimal solutions predicted by the theory. Specialisation occurs inhomogeneously across layers, propagating from shallow towards deep ones, but also across neurons in each layer. Furthermore, deeper targets are harder to learn. Despite its simplicity, the Bayesian-optimal setting provides insights on how the depth, non-linearity and finite (proportional) width influence neural networks in the feature learning regime that are potentially relevant way beyond it.", "published": "2025-10-28T16:44:34Z", "query": "neural prosthetics", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:02.591757"}
{"arxiv_id": "2510.24602v1", "title": "Learning to generalize in evolution through annealed population   heterogeneity", "summary": "Evolutionary systems must learn to generalize, often extrapolating from a limited set of selective conditions to anticipate future environmental changes. The mechanisms enabling such generalization remain poorly understood, despite their importance to predict ecological robustness, drug resistance, or design future-proof vaccination strategies. Here, we demonstrate that annealed population heterogeneity, wherein distinct individuals in the population experience different instances of a complex environment over time, can act as a form of implicit regularization and facilitate evolutionary generalization. Mathematically, annealed heterogeneity introduces a variance-weighted demographic noise term that penalizes across-environment fitness variance and effectively rescales the population size, thereby biasing evolution toward generalist solutions. This process is indeed analogous to a variant of the mini-batching strategy employed in stochastic gradient descent, where an effective multiplicative noise produces an inductive bias by triggering noise-induced transitions.   Through numerical simulations and theoretical analysis we discuss the conditions under which variation in how individuals experience environmental selection can naturally promote evolutionary strategies that generalize across environments and anticipate novel challenges.", "published": "2025-10-28T16:28:55Z", "query": "neural prosthetics", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:02.591925"}
{"arxiv_id": "2510.24718v1", "title": "Generative View Stitching", "summary": "Autoregressive video diffusion models are capable of long rollouts that are stable and consistent with history, but they are unable to guide the current generation with conditioning from the future. In camera-guided video generation with a predefined camera trajectory, this limitation leads to collisions with the generated scene, after which autoregression quickly collapses. To address this, we propose Generative View Stitching (GVS), which samples the entire sequence in parallel such that the generated scene is faithful to every part of the predefined camera trajectory. Our main contribution is a sampling algorithm that extends prior work on diffusion stitching for robot planning to video generation. While such stitching methods usually require a specially trained model, GVS is compatible with any off-the-shelf video model trained with Diffusion Forcing, a prevalent sequence diffusion framework that we show already provides the affordances necessary for stitching. We then introduce Omni Guidance, a technique that enhances the temporal consistency in stitching by conditioning on both the past and future, and that enables our proposed loop-closing mechanism for delivering long-range coherence. Overall, GVS achieves camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and closes loops for a variety of predefined camera paths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best viewed as videos at https://andrewsonga.github.io/gvs.", "published": "2025-10-28T17:59:58Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:06.196937"}
{"arxiv_id": "2510.24714v1", "title": "Machine-Learning-Assisted Comparison of Regression Functions", "summary": "We revisit the classical problem of comparing regression functions, a fundamental question in statistical inference with broad relevance to modern applications such as data integration, transfer learning, and causal inference. Existing approaches typically rely on smoothing techniques and are thus hindered by the curse of dimensionality. We propose a generalized notion of kernel-based conditional mean dependence that provides a new characterization of the null hypothesis of equal regression functions. Building on this reformulation, we develop two novel tests that leverage modern machine learning methods for flexible estimation. We establish the asymptotic properties of the test statistics, which hold under both fixed- and high-dimensional regimes. Unlike existing methods that often require restrictive distributional assumptions, our framework only imposes mild moment conditions. The efficacy of the proposed tests is demonstrated through extensive numerical studies.", "published": "2025-10-28T17:59:15Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:06.197708"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:06.198215"}
{"arxiv_id": "2510.24710v1", "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel   Optimization", "summary": "We study bilevel optimization problems where the lower-level problems are strongly convex and have coupled linear constraints. To overcome the potential non-smoothness of the hyper-objective and the computational challenges associated with the Hessian matrix, we utilize penalty and augmented Lagrangian methods to reformulate the original problem as a single-level one. Especially, we establish a strong theoretical connection between the reformulated function and the original hyper-objective by characterizing the closeness of their values and derivatives. Based on this reformulation, we propose a single-loop, first-order algorithm for linearly constrained bilevel optimization (SFLCB). We provide rigorous analyses of its non-asymptotic convergence rates, showing an improvement over prior double-loop algorithms -- form $O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments corroborate our theoretical findings and demonstrate the practical efficiency of the proposed SFLCB algorithm. Simulation code is provided at https://github.com/ShenGroup/SFLCB.", "published": "2025-10-28T17:58:17Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:17:06.198572"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "brain machine interface", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:06.198934"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "brain machine interface", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:06.199236"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:06.199537"}
{"arxiv_id": "2510.24701v1", "title": "Tongyi DeepResearch Technical Report", "summary": "We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community.", "published": "2025-10-28T17:53:02Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:06.199775"}
{"arxiv_id": "2510.24700v1", "title": "Greedy Sampling Is Provably Efficient for RLHF", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique for post-training large language models. Despite its empirical success, the theoretical understanding of RLHF is still limited, as learning the KL-regularized target with only preference feedback poses additional challenges compared with canonical RL. Existing works mostly study the reward-based Bradley-Terry (BT) preference model, and extend classical designs utilizing optimism or pessimism. This work, instead, considers the general preference model (whose practical relevance has been observed recently) and obtains performance guarantees with major, order-wise improvements over existing ones. Surprisingly, these results are derived from algorithms that directly use the empirical estimates (i.e., greedy sampling), as opposed to constructing optimistic or pessimistic estimates in previous works. This insight has a deep root in the unique structural property of the optimal policy class under the KL-regularized target, and we further specialize it to the BT model, highlighting the surprising sufficiency of greedy sampling in RLHF.", "published": "2025-10-28T17:52:08Z", "query": "brain machine interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:06.199973"}
{"arxiv_id": "2510.24699v1", "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "summary": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.", "published": "2025-10-28T17:51:50Z", "query": "brain machine interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:06.200207"}
{"arxiv_id": "2510.02979v1", "title": "Towards Electrophysiological and Histological Mapping of Upper Limb   Nerves in Pigs Using Epineural Stimulation", "summary": "Understanding the relationship between nerve anatomy and the functional outcomes of electrical stimulation is critical for optimizing neural interface design. In this study, we conducted acute experiments on four pigs in which epineural cuff electrodes with multiple contacts were placed around upper limb nerves. A subset of electrical stimulation configurations -- previously identified via computational study -- was applied, and the resulting evoked electromyographic (EMG) responses were recorded from target muscles. Muscle recruitment curves were extracted and analysed offline to quantify activation patterns. Following the electrophysiological experiments, the stimulated nerves were harvested and processed for histological analysis to visualize fascicular organization and distribution. This work presents preliminary results from the combined analysis of muscle activation profiles and fascicle anatomy in one animal. Our findings aim to inform the design of stimulation strategies by linking electrode configuration to selective muscle recruitment, ultimately contributing to more effective neuromodulation and neuroprosthetic applications.", "published": "2025-10-03T13:12:53Z", "query": "neuroprosthetics", "relevance": 0.49999999999999994, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:09.698300"}
{"arxiv_id": "2509.19957v1", "title": "Interactive Semantic Segmentation for Phosphene Vision Neuroprosthetics", "summary": "Visual impairments present significant challenges to individuals worldwide, impacting daily activities and quality of life. Visual neuroprosthetics offer a promising solution, leveraging advancements in technology to provide a simplified visual sense through devices comprising cameras, computers, and implanted electrodes. This study investigates user-centered design principles for a phosphene vision algorithm, utilizing feedback from visually impaired individuals to guide the development of a gaze-controlled semantic segmentation system. We conducted interviews revealing key design principles. These principles informed the implementation of a gaze-guided semantic segmentation algorithm using the Segment Anything Model (SAM). In a simulated phosphene vision environment, participants performed object detection tasks under SAM, edge detection, and normal vision conditions. SAM improved identification accuracy over edge detection, remained effective in complex scenes, and was particularly robust for specific object shapes. These findings demonstrate the value of user feedback and the potential of gaze-guided semantic segmentation to enhance neuroprosthetic vision.", "published": "2025-09-24T10:08:18Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:09.698638"}
{"arxiv_id": "2507.14339v1", "title": "Fiduciary AI for the Future of Brain-Technology Interactions", "summary": "Brain foundation models represent a new frontier in AI: instead of processing text or images, these models interpret real-time neural signals from EEG, fMRI, and other neurotechnologies. When integrated with brain-computer interfaces (BCIs), they may enable transformative applications-from thought controlled devices to neuroprosthetics-by interpreting and acting on brain activity in milliseconds. However, these same systems pose unprecedented risks, including the exploitation of subconscious neural signals and the erosion of cognitive liberty. Users cannot easily observe or control how their brain signals are interpreted, creating power asymmetries that are vulnerable to manipulation. This paper proposes embedding fiduciary duties-loyalty, care, and confidentiality-directly into BCI-integrated brain foundation models through technical design. Drawing on legal traditions and recent advancements in AI alignment techniques, we outline implementable architectural and governance mechanisms to ensure these systems act in users' best interests. Placing brain foundation models on a fiduciary footing is essential to realizing their potential without compromising self-determination.", "published": "2025-07-18T19:34:08Z", "query": "neuroprosthetics", "relevance": 0.9000000000000001, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:09.698912"}
{"arxiv_id": "2506.13400v1", "title": "Realtime-Capable Hybrid Spiking Neural Networks for Neural Decoding of   Cortical Activity", "summary": "Intra-cortical brain-machine interfaces (iBMIs) present a promising solution to restoring and decoding brain activity lost due to injury. However, patients with such neuroprosthetics suffer from permanent skull openings resulting from the devices' bulky wiring. This drives the development of wireless iBMIs, which demand low power consumption and small device footprint. Most recently, spiking neural networks (SNNs) have been researched as potential candidates for low-power neural decoding. In this work, we present the next step of utilizing SNNs for such tasks, building on the recently published results of the 2024 Grand Challenge on Neural Decoding Challenge for Motor Control of non-Human Primates. We optimize our model architecture to exceed the existing state of the art on the Primate Reaching dataset while maintaining similar resource demand through various compression techniques. We further focus on implementing a realtime-capable version of the model and discuss the implications of this architecture. With this, we advance one step towards latency-free decoding of cortical spike trains using neuromorphic technology, ultimately improving the lives of millions of paralyzed patients.", "published": "2025-06-16T12:08:08Z", "query": "neuroprosthetics", "relevance": 0.5499999999999999, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:17:09.699049"}
{"arxiv_id": "2504.21427v1", "title": "MPEC: Manifold-Preserved EEG Classification via an Ensemble of   Clustering-Based Classifiers", "summary": "Accurate classification of EEG signals is crucial for brain-computer interfaces (BCIs) and neuroprosthetic applications, yet many existing methods fail to account for the non-Euclidean, manifold structure of EEG data, resulting in suboptimal performance. Preserving this manifold information is essential to capture the true geometry of EEG signals, but traditional classification techniques largely overlook this need. To this end, we propose MPEC (Manifold-Preserved EEG Classification via an Ensemble of Clustering-Based Classifiers), that introduces two key innovations: (1) a feature engineering phase that combines covariance matrices and Radial Basis Function (RBF) kernels to capture both linear and non-linear relationships among EEG channels, and (2) a clustering phase that employs a modified K-means algorithm tailored for the Riemannian manifold space, ensuring local geometric sensitivity. Ensembling multiple clustering-based classifiers, MPEC achieves superior results, validated by significant improvements on the BCI Competition IV dataset 2a.", "published": "2025-04-30T08:34:15Z", "query": "neuroprosthetics", "relevance": 0.7000000000000001, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:09.699181"}
{"arxiv_id": "2504.11936v3", "title": "Mind2Matter: Creating 3D Models from EEG Signals", "summary": "The reconstruction of 3D objects from brain signals has gained significant attention in brain-computer interface (BCI) research. Current research predominantly utilizes functional magnetic resonance imaging (fMRI) for 3D reconstruction tasks due to its excellent spatial resolution. Nevertheless, the clinical utility of fMRI is limited by its prohibitive costs and inability to support real-time operations. In comparison, electroencephalography (EEG) presents distinct advantages as an affordable, non-invasive, and mobile solution for real-time brain-computer interaction systems. While recent advances in deep learning have enabled remarkable progress in image generation from neural data, decoding EEG signals into structured 3D representations remains largely unexplored. In this paper, we propose a novel framework that translates EEG recordings into 3D object reconstructions by leveraging neural decoding techniques and generative models. Our approach involves training an EEG encoder to extract spatiotemporal visual features, fine-tuning a large language model to interpret these features into descriptive multimodal outputs, and leveraging generative 3D Gaussians with layout-guided control to synthesize the final 3D structures. Experiments demonstrate that our model captures salient geometric and semantic features, paving the way for applications in brain-computer interfaces (BCIs), virtual reality, and neuroprosthetics. Our code is available in https://github.com/sddwwww/Mind2Matter.", "published": "2025-04-16T10:16:03Z", "query": "neuroprosthetics", "relevance": 1.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:09.699297"}
{"arxiv_id": "2502.06672v2", "title": "Efficient Spatial Estimation of Perceptual Thresholds for Retinal   Implants via Gaussian Process Regression", "summary": "Retinal prostheses restore vision by electrically stimulating surviving neurons, but calibrating perceptual thresholds (i.e., the minimum stimulus intensity required for perception) remains a time-intensive challenge, especially for high-electrode-count devices. Since neighboring electrodes exhibit spatial correlations, we propose a Gaussian Process Regression (GPR) framework to predict thresholds at unsampled locations while leveraging uncertainty estimates to guide adaptive sampling. Using perceptual threshold data from four Argus II users, we show that GPR with a Matern kernel provides more accurate threshold predictions than a Radial Basis Function (RBF) kernel (p &lt; .001, Wilcoxon signed-rank test). In addition, spatially optimized sampling yielded lower prediction error than uniform random sampling for Participants 1 and 3 (p &lt; .05). While adaptive sampling dynamically selects electrodes based on model uncertainty, its accuracy gains over spatial sampling were not statistically significant (p &gt; .05), though it approached significance for Participant 1 (p = .074). These findings establish GPR with spatial sampling as a scalable, efficient approach to retinal prosthesis calibration, minimizing patient burden while maintaining predictive accuracy. More broadly, this framework offers a generalizable solution for adaptive calibration in neuroprosthetic devices with spatially structured stimulation thresholds, paving the way for faster, more personalized system fitting in future high-channel-count implants. Clinical relevance: Gaussian Progress Regression offers a scalable path toward faster, more personalized calibration procedures for future high-channel-count neuroprosthetic devices.", "published": "2025-02-10T16:59:15Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:09.699431"}
{"arxiv_id": "2502.05554v1", "title": "Evaluating Cross-Subject and Cross-Device Consistency in Visual Fixation   Prediction", "summary": "Understanding cross-subject and cross-device consistency in visual fixation prediction is essential for advancing eye-tracking applications, including visual attention modeling and neuroprosthetics. This study evaluates fixation consistency using an embedded eye tracker integrated into regular-sized glasses, comparing its performance with high-end standalone eye-tracking systems. Nine participants viewed 300 images from the MIT1003 dataset in subjective experiments, allowing us to analyze cross-device and cross-subject variations in fixation patterns with various evaluation metrics. Our findings indicate that average visual fixations can be reliably transferred across devices for relatively simple stimuli. However, individual-to-average consistency remains weak, highlighting the challenges of predicting individual fixations across devices. These results provide an empirical foundation for leveraging predicted average visual fixation data to enhance neuroprosthetic applications.", "published": "2025-02-08T12:54:00Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:09.699537"}
{"arxiv_id": "2501.08025v2", "title": "Analysis of Power Losses and the Efficacy of Power Minimization   Strategies in Multichannel Electrical Stimulation Systems", "summary": "Neuroprosthetic devices require multichannel stimulator systems with an increasing number of channels. However, there are inherent power losses in typical multichannel stimulation circuits caused by a mismatch between the power supply voltage and the voltage required at each electrode to successfully stimulate tissue. This imposes a bottleneck towards high-channel-count devices, which is particularly severe in wirelessly-powered devices. Hence, advances in the power efficiency of stimulation systems are critical. To support these advances, this paper presents a methodology to identify and quantify power losses associated with different power supply scaling strategies in multichannel stimulation systems. The proposed methodology utilizes distributions of stimulation amplitudes and electrode impedances to calculate power losses in multichannel systems. Experimental data from previously published studies spanning various stimulation applications were analyzed to evaluate the performance of fixed, global, and stepped supply scaling methods, focusing on their impact on power dissipation and efficiency. Variability in output conditions results in low power efficiency in multichannel stimulation systems across all applications. Stepped voltage scaling demonstrated substantial efficiency improvements, achieving an increase of 67 % to 146 %, particularly in high-channel-count applications with significant variability in tissue impedance. Global scaling, by contrast, was more advantageous for systems with fewer channels. The findings highlight the importance of tailoring power management strategies to specific applications to optimize efficiency while minimizing system complexity. The proposed methodology offers a framework for evaluating efficiency-complexity trade-offs, advancing the design of scalable neurostimulation systems.", "published": "2025-01-14T11:28:02Z", "query": "neuroprosthetics", "relevance": 0.15, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:17:09.699714"}
{"arxiv_id": "2409.04428v2", "title": "Hybrid Spiking Neural Networks for Low-Power Intra-Cortical   Brain-Machine Interfaces", "summary": "Intra-cortical brain-machine interfaces (iBMIs) have the potential to dramatically improve the lives of people with paraplegia by restoring their ability to perform daily activities. However, current iBMIs suffer from scalability and mobility limitations due to bulky hardware and wiring. Wireless iBMIs offer a solution but are constrained by a limited data rate. To overcome this challenge, we are investigating hybrid spiking neural networks for embedded neural decoding in wireless iBMIs. The networks consist of a temporal convolution-based compression followed by recurrent processing and a final interpolation back to the original sequence length. As recurrent units, we explore gated recurrent units (GRUs), leaky integrate-and-fire (LIF) neurons, and a combination of both - spiking GRUs (sGRUs) and analyze their differences in terms of accuracy, footprint, and activation sparsity. To that end, we train decoders on the \"Nonhuman Primate Reaching with Multichannel Sensorimotor Cortex Electrophysiology\" dataset and evaluate it using the NeuroBench framework, targeting both tracks of the IEEE BioCAS Grand Challenge on Neural Decoding. Our approach achieves high accuracy in predicting velocities of primate reaching movements from multichannel primary motor cortex recordings while maintaining a low number of synaptic operations, surpassing the current baseline models in the NeuroBench framework. This work highlights the potential of hybrid neural networks to facilitate wireless iBMIs with high decoding precision and a substantial increase in the number of monitored neurons, paving the way toward more advanced neuroprosthetic technologies.", "published": "2024-09-06T17:48:44Z", "query": "neuroprosthetics", "relevance": 0.44999999999999996, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:17:09.699872"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:13.160704"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "neural signal decoding", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:13.161334"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:13.161645"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:13.161884"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural signal decoding", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:13.162090"}
{"arxiv_id": "2510.24694v1", "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision", "summary": "LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents.", "published": "2025-10-28T17:50:40Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:13.162270"}
{"arxiv_id": "2510.24684v1", "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning", "summary": "Self-improving systems require environmental interaction for continuous adaptation. We introduce SPICE (Self-Play In Corpus Environments), a reinforcement learning framework where a single model acts in two roles: a Challenger that mines documents from a large corpus to generate diverse reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics, the Challenger creates an automatic curriculum at the frontier of the Reasoner's capability, while corpus grounding provides the rich, near-inexhaustible external signal necessary for sustained improvement. Unlike existing ungrounded self-play methods that offer more limited benefits, SPICE achieves consistent gains across mathematical (+8.9%) and general reasoning (+9.8%) benchmarks on multiple model families. Our analysis reveals how document grounding is a key ingredient in SPICE to continuously generate its own increasingly challenging goals and achieve them, enabling sustained self-improvement.", "published": "2025-10-28T17:46:16Z", "query": "neural signal decoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:13.162449"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:17:13.162604"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:13.162824"}
{"arxiv_id": "2510.24662v1", "title": "Prospects for a 95 GeV Higgs Boson at Future Higgs Factories with   Transformer Networks", "summary": "Several experimental analyses have reported mild excesses near 95\\,GeV that could indicate the presence of a light Higgs-like scalar. We study the phenomenology of such a state within the flipped Next-to-Two-Higgs-Doublet Model (N2HDM-F) at the proposed Circular Electron--Positron Collider (CEPC). The light scalar $S$ is investigated through the Higgsstrahlung process $e^+e^- \\to Z(\\mu^+\\mu^-)S$ with $S\\to\\tau^+\\tau^-$ and $S\\to b \\bar{b}$ decay modes. A full Monte Carlo simulation including detector effects is performed to estimate the discovery reach and precision measurement potential. To maximize the sensitivity, we employ particle-level transformer networks (ParT and MIParT) that exploit correlations among all reconstructed objects. Compared with a cut-based baseline, improves the expected measurement precision by a factor of 2.4 in the $\\tau\\tau$ channel and 1.4 in the $b b$ channel. %of data at 240\\,GeV. For viable benchmark points in the N2HDM-F, the attainable precisions on the signal rate reach 1.0\\% and 0.63\\%, respectively. Interpreted in a model-independent framework, the CEPC can achieve a 5$\\sigma$ discovery for $\\mu_{\\tau\\tau}^{ZS}&gt;1.6\\times10^{-2}$ and $\\mu_{bb}^{ZS}&gt;4.2\\times10^{-3}$, and reach a 1\\% precision for $\\mu_{\\tau\\tau}^{ZS}&gt;0.96$ and $\\mu_{bb}^{ZS}&gt;0.13$. These results highlight the potential of particle-level machine learning techniques in extending the light-Higgs exploration program at future lepton colliders.", "published": "2025-10-28T17:26:53Z", "query": "neural signal decoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:13.163049"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "brain signal processing", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:16.686223"}
{"arxiv_id": "2510.24711v1", "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit   Routing Guidance", "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity while preserving computational efficiency. Despite its notable success in large language models (LLMs), existing attempts to apply MoE to Diffusion Transformers (DiTs) have yielded limited gains. We attribute this gap to fundamental differences between language and visual tokens. Language tokens are semantically dense with pronounced inter-token variation, while visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization in vision MoE. To this end, we present ProMoE, an MoE framework featuring a two-step router with explicit routing guidance that promotes expert specialization. Specifically, this guidance encourages the router to partition image tokens into conditional and unconditional sets via conditional routing according to their functional roles, and refine the assignments of conditional image tokens through prototypical routing with learnable prototypes based on semantic content. Moreover, the similarity-based expert allocation in latent space enabled by prototypical routing offers a natural mechanism for incorporating explicit semantic guidance, and we validate that such guidance is crucial for vision MoE. Building on this, we propose a routing contrastive loss that explicitly enhances the prototypical routing process, promoting intra-expert coherence and inter-expert diversity. Extensive experiments on ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives. Code and models will be made publicly available.", "published": "2025-10-28T17:59:02Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:16.686621"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "brain signal processing", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:16.686993"}
{"arxiv_id": "2510.24705v1", "title": "Dipole-lets: a new multiscale decomposition for MR phase and   quantitative susceptibility mapping", "summary": "Identifying and suppressing streaking artifacts is one of the most challenging problems in quantitative susceptibility mapping. The measured phase from tissue magnetization is assumed to be the convolution by the magnetic dipole kernel; direct inversion or standard regularization methods tend to create streaking artifacts in the estimated susceptibility. This is caused by extreme noise and by the presence of non-dipolar phase contributions, which are amplified by the dipole kernel following the streaking pattern. In this work, we introduce a multiscale transform, called Dipole-lets, as an optimal decomposition method for identifying dipole incompatibilities in measured field data by extracting features of different characteristic size and orientation with respect to the dipole kernel's zero-valued double-cone surface (the magic cone). We provide experiments that showcase that non-dipolar content can be extracted by Dipole-lets from phase data through artifact localization. We also present implementations of Dipole-lets as a optimization functional regularizator, through simple Tikhonov and infinity norm.", "published": "2025-10-28T17:55:40Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:16.687200"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "brain signal processing", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:16.687373"}
{"arxiv_id": "2510.24698v1", "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking", "summary": "Parallel thinking expands exploration breadth, complementing the deep exploration of information-seeking (IS) agents to further enhance problem-solving capability. However, conventional parallel thinking faces two key challenges in this setting: inefficiency from repeatedly rolling out from scratch, and difficulty in integrating long-horizon reasoning trajectories during answer generation, as limited context capacity prevents full consideration of the reasoning process. To address these issues, we propose ParallelMuse, a two-stage paradigm designed for deep IS agents. The first stage, Functionality-Specified Partial Rollout, partitions generated sequences into functional regions and performs uncertainty-guided path reuse and branching to enhance exploration efficiency. The second stage, Compressed Reasoning Aggregation, exploits reasoning redundancy to losslessly compress information relevant to answer derivation and synthesize a coherent final answer. Experiments across multiple open-source agents and benchmarks demonstrate up to 62% performance improvement with a 10--30% reduction in exploratory token consumption.", "published": "2025-10-28T17:51:50Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:16.687558"}
{"arxiv_id": "2510.24699v1", "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "summary": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.", "published": "2025-10-28T17:51:50Z", "query": "brain signal processing", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:16.687735"}
{"arxiv_id": "2510.24694v1", "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision", "summary": "LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents.", "published": "2025-10-28T17:50:40Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:16.687883"}
{"arxiv_id": "2510.24693v1", "title": "STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D   Intelligence", "summary": "Despite rapid progress in Multi-modal Large Language Models and Large Audio-Language Models, existing audio benchmarks largely test semantics that can be recovered from text captions, masking deficits in fine-grained perceptual reasoning. We formalize audio 4D intelligence that is defined as reasoning over sound dynamics in time and 3D space, and introduce STAR-Bench to measure it. STAR-Bench combines a Foundational Acoustic Perception setting (six attributes under absolute and relative regimes) with a Holistic Spatio-Temporal Reasoning setting that includes segment reordering for continuous and discrete processes and spatial tasks spanning static localization, multi-source relations, and dynamic trajectories. Our data curation pipeline uses two methods to ensure high-quality samples. For foundational tasks, we use procedurally synthesized and physics-simulated audio. For holistic data, we follow a four-stage process that includes human annotation and final selection based on human performance. Unlike prior benchmarks where caption-only answering reduces accuracy slightly, STAR-Bench induces far larger drops (-31.5\\% temporal, -35.2\\% spatial), evidencing its focus on linguistically hard-to-describe cues. Evaluating 19 models reveals substantial gaps compared with humans and a capability hierarchy: closed-source models are bottlenecked by fine-grained perception, while open-source models lag across perception, knowledge, and reasoning. Our STAR-Bench provides critical insights and a clear path forward for developing future models with a more robust understanding of the physical world.", "published": "2025-10-28T17:50:34Z", "query": "brain signal processing", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:16.688035"}
{"arxiv_id": "2510.24687v1", "title": "Fast algorithms enabling optimization and deep learning for   photoacoustic tomography in a circular detection geometry", "summary": "The inverse source problem arising in photoacoustic tomography and in several other coupled-physics modalities is frequently solved by iterative algorithms. Such algorithms are based on the minimization of a certain cost functional. In addition, novel deep learning techniques are currently being investigated to further improve such optimization approaches. All such methods require multiple applications of the operator defining the forward problem, and of its adjoint. In this paper, we present new asymptotically fast algorithms for numerical evaluation of the forward and adjoint operators, applicable in the circular acquisition geometry. For an $(n \\times n)$ image, our algorithms compute these operators in $\\mathcal{O}(n^2 \\log n)$ floating point operations. We demonstrate the performance of our algorithms in numerical simulations, where they are used as an integral part of several iterative image reconstruction techniques: classic variational methods, such as non-negative least squares and total variation regularized least squares, as well as deep learning methods, such as learned primal dual. A Python implementation of our algorithms and computational examples is available to the general public.", "published": "2025-10-28T17:49:31Z", "query": "brain signal processing", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:16.688215"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:20.199234"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "neural encoding", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:20.200100"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:20.200570"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:20.200828"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:20.201059"}
{"arxiv_id": "2510.24692v1", "title": "Embodying Physical Computing into Soft Robots", "summary": "Softening and onboarding computers and controllers is one of the final frontiers in soft robotics towards their robustness and intelligence for everyday use. In this regard, embodying soft and physical computing presents exciting potential. Physical computing seeks to encode inputs into a mechanical computing kernel and leverage the internal interactions among this kernel's constituent elements to compute the output. Moreover, such input-to-output evolution can be re-programmable. This perspective paper proposes a framework for embodying physical computing into soft robots and discusses three unique strategies in the literature: analog oscillators, physical reservoir computing, and physical algorithmic computing. These embodied computers enable the soft robot to perform complex behaviors that would otherwise require CMOS-based electronics -- including coordinated locomotion with obstacle avoidance, payload weight and orientation classification, and programmable operation based on logical rules. This paper will detail the working principles of these embodied physical computing methods, survey the current state-of-the-art, and present a perspective for future development.", "published": "2025-10-28T17:50:30Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:20.201270"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:17:20.201453"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "neural encoding", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:20.201711"}
{"arxiv_id": "2510.24657v1", "title": "Group Relative Attention Guidance for Image Editing", "summary": "Recently, image editing based on Diffusion-in-Transformer models has undergone rapid development. However, existing editing methods often lack effective control over the degree of editing, limiting their ability to achieve more customized results. To address this limitation, we investigate the MM-Attention mechanism within the DiT model and observe that the Query and Key tokens share a bias vector that is only layer-dependent. We interpret this bias as representing the model's inherent editing behavior, while the delta between each token and its corresponding bias encodes the content-specific editing signals. Based on this insight, we propose Group Relative Attention Guidance, a simple yet effective method that reweights the delta values of different tokens to modulate the focus of the model on the input image relative to the editing instruction, enabling continuous and fine-grained control over editing intensity without any tuning. Extensive experiments conducted on existing image editing frameworks demonstrate that GRAG can be integrated with as few as four lines of code, consistently enhancing editing quality. Moreover, compared to the commonly used Classifier-Free Guidance, GRAG achieves smoother and more precise control over the degree of editing. Our code will be released at https://github.com/little-misfit/GRAG-Image-Editing.", "published": "2025-10-28T17:22:44Z", "query": "neural encoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:20.201909"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "neural encoding", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:20.202109"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "cortical decoding", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.615521"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.616067"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "cortical decoding", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.616411"}
{"arxiv_id": "2510.24626v1", "title": "Relative Scaling Laws for LLMs", "summary": "Scaling laws describe how language models improve with additional data, parameters, and compute. While widely used, they are typically measured on aggregate test sets. Aggregate evaluations yield clean trends but average over heterogeneous subpopulations, obscuring performance disparities. We introduce relative scaling laws, which track how performance gaps between test distributions evolve with scale rather than focusing solely on absolute error. Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP) budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we find diverse trajectories: academic domains on MMLU converge toward parity; regional English dialects shift depending on population size; and clusters of AI risk behaviours split, with capability- and influence-related risks increasing during pretraining while adversarial risks do not. These results show that although scaling improves overall performance, it is not a universal equalizer. To support further study, we release all model checkpoints from this work to enable practitioners to measure relative alongside traditional scaling laws, in order to better prioritize robustness challenges in light of the bitter lesson.", "published": "2025-10-28T16:55:22Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.616589"}
{"arxiv_id": "2510.24619v1", "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation", "summary": "With the release of new large language models (LLMs) like Llama and Mistral, zero-shot cross-lingual transfer has become increasingly feasible due to their multilingual pretraining and strong generalization capabilities. However, adapting these decoder-only LLMs to new tasks across languages remains challenging. While parameter-efficient fine-tuning (PeFT) techniques like Low-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as soft prompt tuning, prefix tuning, and Llama Adapter are less explored, especially for zero-shot transfer in decoder-only models. We present a comprehensive study of three prefix-based methods for zero-shot cross-lingual transfer from English to 35+ high- and low-resource languages. Our analysis further explores transfer across linguistic families and scripts, as well as the impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix methods outperform LoRA-baselines by up to 6% on the Belebele benchmark. Similar improvements were observed with Mistral v0.3 7B as well. Despite using only 1.23M learning parameters with prefix tuning, we achieve consistent improvements across diverse benchmarks. These findings highlight the potential of prefix-based techniques as an effective and scalable alternative to LoRA, particularly in low-resource multilingual settings.", "published": "2025-10-28T16:48:03Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.616748"}
{"arxiv_id": "2510.24605v1", "title": "Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead   the Way", "summary": "Diffusion-based large language models (dLLMs) have exhibited substantial potential for parallel text generation, which may enable more efficient generation compared to autoregressive models. However, current dLLMs suffer from fixed generation lengths, which indicates the generation lengths of dLLMs have to be determined before decoding as a hyper-parameter, leading to issues in efficiency and flexibility. To solve these problems, in this work, we propose to train a diffusion LLM with native variable generation lengths, abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately predict the [EOS] token in the generated text, which makes a dLLM be able to natively infer in a block diffusion manner, while still maintaining the ability of global bi-directional (full) attention and high parallelism. Experiments on standard benchmarks demonstrate that our method achieves a 30.1x speedup over traditional dLLM inference paradigms and a 2.4x speedup relative to autoregressive models such as Qwen and Llama. Our method achieves higher accuracy and faster inference, elevating dLLMs beyond mere academic novelty and supporting their practical use in real-world applications. Codes and models have been released.", "published": "2025-10-28T16:32:43Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.616897"}
{"arxiv_id": "2510.24570v1", "title": "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation", "summary": "Automatic Speech Recognition (ASR) systems, despite large multilingual training, struggle in out-of-domain and low-resource scenarios where labeled data is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training and Distillation), a novel framework designed to adapt Whisper's encoder using unlabeled data. Unlike traditional self-supervised learning methods, BEARD uniquely combines a BEST-RQ objective with knowledge distillation from a frozen teacher encoder, ensuring the encoder's complementarity with the pre-trained decoder. Our experiments focus on the ATCO2 corpus from the challenging Air Traffic Control (ATC) communications domain, characterized by non-native speech, noise, and specialized phraseology. Using about 5,000 hours of untranscribed speech for BEARD and 2 hours of transcribed speech for fine-tuning, the proposed approach significantly outperforms previous baseline and fine-tuned model, achieving a relative improvement of 12% compared to the fine-tuned model. To the best of our knowledge, this is the first work to use a self-supervised learning objective for domain adaptation of Whisper.", "published": "2025-10-28T16:01:24Z", "query": "cortical decoding", "relevance": 0.15, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.617034"}
{"arxiv_id": "2510.24514v1", "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal   Reasoning in MLLMs", "summary": "While Multimodal Large Language Models (MLLMs) excel at visual understanding, they often struggle in complex scenarios that require visual planning and imagination. Inspired by how humans use sketching as a form of visual thinking to develop and communicate ideas, we introduce Latent Sketchpad, a framework that equips MLLMs with an internal visual scratchpad. The internal visual representations of MLLMs have traditionally been confined to perceptual understanding. We repurpose them to support generative visual thought without compromising reasoning ability. Building on frontier MLLMs, our approach integrates visual generation directly into their native autoregressive reasoning process. It allows the model to interleave textual reasoning with the generation of visual latents. These latents guide the internal thought process and can be translated into sketch images for interpretability. To realize this, we introduce two components: a Context-Aware Vision Head autoregressively produces visual representations, and a pretrained Sketch Decoder renders these into human-interpretable images. We evaluate the framework on our new dataset MazePlanning. Experiments across various MLLMs show that Latent Sketchpad delivers comparable or even superior reasoning performance to their backbone. It further generalizes across distinct frontier MLLMs, including Gemma3 and Qwen2.5-VL. By extending model's textual reasoning to visual thinking, our framework opens new opportunities for richer human-computer interaction and broader applications. More details and resources are available on our project page: https://latent-sketchpad.github.io/.", "published": "2025-10-28T15:26:20Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:23.617174"}
{"arxiv_id": "2510.24486v1", "title": "Fast and accurate neural reflectance transformation imaging through   knowledge distillation", "summary": "Reflectance Transformation Imaging (RTI) is very popular for its ability to visually analyze surfaces by enhancing surface details through interactive relighting, starting from only a few tens of photographs taken with a fixed camera and variable illumination. Traditional methods like Polynomial Texture Maps (PTM) and Hemispherical Harmonics (HSH) are compact and fast, but struggle to accurately capture complex reflectance fields using few per-pixel coefficients and fixed bases, leading to artifacts, especially in highly reflective or shadowed areas. The NeuralRTI approach, which exploits a neural autoencoder to learn a compact function that better approximates the local reflectance as a function of light directions, has been shown to produce superior quality at comparable storage cost. However, as it performs interactive relighting with custom decoder networks with many parameters, the rendering step is computationally expensive and not feasible at full resolution for large images on limited hardware. Earlier attempts to reduce costs by directly training smaller networks have failed to produce valid results. For this reason, we propose to reduce its computational cost through a novel solution based on Knowledge Distillation (DisK-NeuralRTI). ...", "published": "2025-10-28T15:00:07Z", "query": "cortical decoding", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:23.617314"}
{"arxiv_id": "2510.24474v1", "title": "Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated   Sampling", "summary": "Denoising generative models, such as diffusion and flow-based models, produce high-quality samples but require many denoising steps due to discretization error. Flow maps, which estimate the average velocity between timesteps, mitigate this error and enable faster sampling. However, their training typically demands architectural changes that limit compatibility with pretrained flow models. We introduce Decoupled MeanFlow, a simple decoding strategy that converts flow models into flow map models without architectural modifications. Our method conditions the final blocks of diffusion transformers on the subsequent timestep, allowing pretrained flow models to be directly repurposed as flow maps. Combined with enhanced training techniques, this design enables high-quality generation in as few as 1 to 4 steps. Notably, we find that training flow models and subsequently converting them is more efficient and effective than training flow maps from scratch. On ImageNet 256x256 and 512x512, our models attain 1-step FID of 2.16 and 2.12, respectively, surpassing prior art by a large margin. Furthermore, we achieve FID of 1.51 and 1.68 when increasing the steps to 4, which nearly matches the performance of flow models while delivering over 100x faster inference.", "published": "2025-10-28T14:43:48Z", "query": "cortical decoding", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:23.617455"}
{"arxiv_id": "2510.24718v1", "title": "Generative View Stitching", "summary": "Autoregressive video diffusion models are capable of long rollouts that are stable and consistent with history, but they are unable to guide the current generation with conditioning from the future. In camera-guided video generation with a predefined camera trajectory, this limitation leads to collisions with the generated scene, after which autoregression quickly collapses. To address this, we propose Generative View Stitching (GVS), which samples the entire sequence in parallel such that the generated scene is faithful to every part of the predefined camera trajectory. Our main contribution is a sampling algorithm that extends prior work on diffusion stitching for robot planning to video generation. While such stitching methods usually require a specially trained model, GVS is compatible with any off-the-shelf video model trained with Diffusion Forcing, a prevalent sequence diffusion framework that we show already provides the affordances necessary for stitching. We then introduce Omni Guidance, a technique that enhances the temporal consistency in stitching by conditioning on both the past and future, and that enables our proposed loop-closing mechanism for delivering long-range coherence. Overall, GVS achieves camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and closes loops for a variety of predefined camera paths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best viewed as videos at https://andrewsonga.github.io/gvs.", "published": "2025-10-28T17:59:58Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:27.111220"}
{"arxiv_id": "2510.24711v1", "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit   Routing Guidance", "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity while preserving computational efficiency. Despite its notable success in large language models (LLMs), existing attempts to apply MoE to Diffusion Transformers (DiTs) have yielded limited gains. We attribute this gap to fundamental differences between language and visual tokens. Language tokens are semantically dense with pronounced inter-token variation, while visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization in vision MoE. To this end, we present ProMoE, an MoE framework featuring a two-step router with explicit routing guidance that promotes expert specialization. Specifically, this guidance encourages the router to partition image tokens into conditional and unconditional sets via conditional routing according to their functional roles, and refine the assignments of conditional image tokens through prototypical routing with learnable prototypes based on semantic content. Moreover, the similarity-based expert allocation in latent space enabled by prototypical routing offers a natural mechanism for incorporating explicit semantic guidance, and we validate that such guidance is crucial for vision MoE. Building on this, we propose a routing contrastive loss that explicitly enhances the prototypical routing process, promoting intra-expert coherence and inter-expert diversity. Extensive experiments on ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives. Code and models will be made publicly available.", "published": "2025-10-28T17:59:02Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:27.111681"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "spike train analysis", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:27.112068"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:27.112241"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "spike train analysis", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:27.112408"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:27.112594"}
{"arxiv_id": "2510.24701v1", "title": "Tongyi DeepResearch Technical Report", "summary": "We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community.", "published": "2025-10-28T17:53:02Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:27.112741"}
{"arxiv_id": "2510.24700v1", "title": "Greedy Sampling Is Provably Efficient for RLHF", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique for post-training large language models. Despite its empirical success, the theoretical understanding of RLHF is still limited, as learning the KL-regularized target with only preference feedback poses additional challenges compared with canonical RL. Existing works mostly study the reward-based Bradley-Terry (BT) preference model, and extend classical designs utilizing optimism or pessimism. This work, instead, considers the general preference model (whose practical relevance has been observed recently) and obtains performance guarantees with major, order-wise improvements over existing ones. Surprisingly, these results are derived from algorithms that directly use the empirical estimates (i.e., greedy sampling), as opposed to constructing optimistic or pessimistic estimates in previous works. This insight has a deep root in the unique structural property of the optimal policy class under the KL-regularized target, and we further specialize it to the BT model, highlighting the surprising sufficiency of greedy sampling in RLHF.", "published": "2025-10-28T17:52:08Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:27.112860"}
{"arxiv_id": "2510.24699v1", "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "summary": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.", "published": "2025-10-28T17:51:50Z", "query": "spike train analysis", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:27.113033"}
{"arxiv_id": "2510.24697v1", "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling   Info-Rich Seeking", "summary": "Large Language Model (LLM)-based agents have emerged as a transformative approach for open-ended problem solving, with information seeking (IS) being a core capability that enables autonomous reasoning and decision-making. While prior research has largely focused on improving retrieval depth, we observe that current IS agents often suffer from low search efficiency, which in turn constrains overall performance. A key factor underlying this inefficiency is the sparsity of target entities in training tasks, which limits opportunities for agents to learn and generalize efficient search behaviors. To address these challenges, we propose WebLeaper, a framework for constructing high-coverage IS tasks and generating efficient solution trajectories. We formulate IS as a tree-structured reasoning problem, enabling a substantially larger set of target entities to be embedded within a constrained context. Leveraging curated Wikipedia tables, we propose three variants for synthesizing IS tasks, Basic, Union, and Reverse-Union, to systematically increase both IS efficiency and efficacy. Finally, we curate training trajectories by retaining only those that are simultaneously accurate and efficient, ensuring that the model is optimized for both correctness and search performance. Extensive experiments on both basic and comprehensive settings, conducted on five IS benchmarks, BrowserComp, GAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method consistently achieves improvements in both effectiveness and efficiency over strong baselines.", "published": "2025-10-28T17:51:42Z", "query": "spike train analysis", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:27.113225"}
{"arxiv_id": "2510.24706v1", "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?", "summary": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.", "published": "2025-10-28T17:55:42Z", "query": "virtual reality neuroscience", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:17:30.550323"}
{"arxiv_id": "2510.24683v1", "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and   Object-Aware Controllers", "summary": "Real-time control is an essential aspect of safe robot operation in the real world with dynamic objects. We present a framework for the analysis of object-aware controllers, methods for altering a robot's motion to anticipate and avoid possible collisions. This framework is focused on three design considerations: kinematics, motion profiles, and virtual constraints. Additionally, the analysis in this work relies on verification of robot behaviors using fundamental robot-obstacle experimental scenarios. To showcase the effectiveness of our method we compare three representative object-aware controllers. The comparison uses metrics originating from the design considerations. From the analysis, we find that the design of object-aware controllers often lacks kinematic considerations, continuity of control points, and stability in movement profiles. We conclude that this framework can be used in the future to design, compare, and benchmark obstacle avoidance methods.", "published": "2025-10-28T17:46:06Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:17:30.551034"}
{"arxiv_id": "2510.24671v1", "title": "Multi-Agent Scenario Generation in Roundabouts with a   Transformer-enhanced Conditional Variational Autoencoder", "summary": "With the increasing integration of intelligent driving functions into serial-produced vehicles, ensuring their functionality and robustness poses greater challenges. Compared to traditional road testing, scenario-based virtual testing offers significant advantages in terms of time and cost efficiency, reproducibility, and exploration of edge cases. We propose a Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for generating multi-agent traffic scenarios in roundabouts, which are characterized by high vehicle dynamics and complex layouts, yet remain relatively underexplored in current research. The results show that the proposed model can accurately reconstruct original scenarios and generate realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators (KPIs) are employed to evaluate the interactive behavior in the generated scenarios. Analysis of the latent space reveals partial disentanglement, with several latent dimensions exhibiting distinct and interpretable effects on scenario attributes such as vehicle entry timing, exit timing, and velocity profiles. The results demonstrate the model's capability to generate scenarios for the validation of intelligent driving functions involving multi-agent interactions, as well as to augment data for their development and iterative improvement.", "published": "2025-10-28T17:36:52Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:30.551436"}
{"arxiv_id": "2510.24668v1", "title": "InteractComp: Evaluating Search Agents With Ambiguous Queries", "summary": "Language agents have demonstrated remarkable potential in web search and information retrieval. However, these search agents assume user queries are complete and unambiguous, an assumption that diverges from reality where users begin with incomplete queries requiring clarification through interaction. Yet most agents lack interactive mechanisms during the search process, and existing benchmarks cannot assess this capability. To address this gap, we introduce InteractComp, a benchmark designed to evaluate whether search agents can recognize query ambiguity and actively interact to resolve it during search. Following the principle of easy to verify, interact to disambiguate, we construct 210 expert-curated questions across 9 domains through a target-distractor methodology that creates genuine ambiguity resolvable only through interaction. Evaluation of 17 models reveals striking failure: the best model achieves only 13.73% accuracy despite 71.50% with complete context, exposing systematic overconfidence rather than reasoning deficits. Forced interaction produces dramatic gains, demonstrating latent capability current strategies fail to engage. Longitudinal analysis shows interaction capabilities stagnated over 15 months while search performance improved seven-fold, revealing a critical blind spot. This stagnation, coupled with the immediate feedback inherent to search tasks, makes InteractComp a valuable resource for both evaluating and training interaction capabilities in search agents. The code is available at https://github.com/FoundationAgents/InteractComp.", "published": "2025-10-28T17:35:54Z", "query": "virtual reality neuroscience", "relevance": 0.15, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:17:30.551706"}
{"arxiv_id": "2510.24656v1", "title": "Virtual Gates Enabled by Digital Surrogate of Quantum Dot Devices", "summary": "Advances in quantum technologies are often limited by slow device characterization, complex tuning require- ments, and scalability challenges. Spin qubits in electrostatically defined quantum dots provide a promising platform but are not exempt from these limitations. Simulations enhance our understanding of such devices, and in many cases, rapid feedback between measurements and simulations can guide the development of op- timal design and control strategies. Here, we introduce a modular, graph-based simulator that acts as a digital surrogate for a semiconductor quantum dot device, where computationally expensive processes are accelerated using deep learning. We demonstrate its potential by estimating crosstalk effects between gate electrodes and applying these estimates to construct virtual gates in a quantum dot device. We validate our approach through comparison with experiments on a double quantum dot defined in a Ge/SiGe heterostructure. We envision that this simulation framework will advance semiconductor-based quantum technologies by enabling more efficient design, characterization, and control of complex devices.", "published": "2025-10-28T17:22:20Z", "query": "virtual reality neuroscience", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:17:30.551906"}
{"arxiv_id": "2510.24654v1", "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment", "summary": "In this paper, we present a framework for training large language models (LLMs) as diagnostic agents with reinforcement learning, enabling them to manage multi-turn diagnostic processes, adaptively select examinations, and commit to final diagnoses. Unlike instruction-tuned models trained on static case summaries, our method acquires diagnostic strategies through interactive exploration and outcome-based feedback. Our contributions are fourfold: (i) We present DiagGym, a diagnostics world model trained with electronic health records that emits examination outcomes conditioned on patient history and recommended examination, serving as a virtual clinical environment for realistic diagnosis training and evaluation; (ii) We train DiagAgent via end-to-end, multi-turn reinforcement learning to learn diagnostic policies that optimize both information yield and diagnostic accuracy; (iii) We introduce DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated examination recommendations and 99 cases annotated with 973 physician-written rubrics on diagnosis process; (iv) we demonstrate superior performance across diverse diagnostic settings. DiagAgent significantly outperforms 10 state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34% higher diagnostic accuracy and 44.03% improvement in examination recommendation hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic accuracy and 23.09% boost in examination recommendation F1 score. In rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by 7.1% in weighted rubric score. These findings indicate that learning policies in interactive clinical environments confers dynamic and clinically meaningful diagnostic management abilities unattainable through passive training alone.", "published": "2025-10-28T17:19:47Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:17:30.552146"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "virtual reality neuroscience", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:30.552318"}
{"arxiv_id": "2510.24581v1", "title": "Rigidity and flexibility results for groups with a common cocompact   envelope", "summary": "A locally compact group $G$ is a cocompact envelope of a group $\\Gamma$ if $G$ contains a copy of $\\Gamma$ as a discrete and cocompact subgroup. We study the problem that takes two finitely generated groups $\\Gamma,\\Lambda$ having a common cocompact envelope, and asks what properties must be shared between $\\Gamma$ and $\\Lambda$.   We first consider the setting where the common cocompact envelope is totally disconnected. In that situation we show that if $\\Gamma$ admits a finitely generated nilpotent normal subgroup $A$, then virtually $\\Lambda$ admits a normal subgroup $B$ such that $A$ and $B$ are virtually isomorphic.   We establish both rigidity and flexibility results when $\\Gamma$ belongs to the class of solvable groups of finite rank. On the rigidity perspective, we show that if $\\Gamma$ is solvable of finite rank, and the locally finite radical of $\\Lambda$ is finite, then $\\Lambda$ must be virtually solvable of finite rank. On the flexibility perspective, we exhibit groups $\\Gamma,\\Lambda$ with a common cocompact envelope such that $\\Gamma$ is solvable of finite rank, while $\\Lambda$ is not virtually solvable. In particular the class of solvable groups of finite rank is not QI-rigid. We also exhibit flexibility behaviours among finitely presented groups, and more generally among groups with type $F_n$ for arbitrary $n \\geq 1$.", "published": "2025-10-28T16:13:41Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:30.552517"}
{"arxiv_id": "2510.24531v1", "title": "A virtual structure for symplectic Higgs bundles", "summary": "We propose a virtual structure for a moduli of symplectic Higgs sheaves $(E,\\phi)$ on projective surfaces $S$. Key to this is a minimality assumption on $\\textrm{ch}(E)$ that forces all $E$ to be locally free. This might have implications to define a virtual count and $Sp(r)$-Vafa-Witten invariants.", "published": "2025-10-28T15:38:43Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:30.552642"}
{"arxiv_id": "2510.24447v1", "title": "Pair Approximation Meets Reality: Diffusion of Innovation in   Organizational Networks within the biased-independence q-Voter Model", "summary": "Collective adaptation, whether in innovation adoption, pro-environmental or organizational change, emerges from the interplay between individual decisions and social influence. Agent-based modeling provides a useful tool for studying such processes. Here, we introduce the biased-independence $q$-voter model, a generalization of the $q$-voter model with independence, one of the most popular agent-based models of opinion dynamics. In our model, individuals choose between two options, adopt or not adopt, under the competing influences of conformity and independent choice. Independent choice between two options is determined by an engagement parameter, inspired by earlier agent-based model of eco-innovation diffusion. When the engagement parameter equals $0.5$, the model reduces to the original $q$-voter model with independence; values different from $0.5$ break the symmetry between the two options. To place our study in a broader context, we briefly review asymmetric versions of the $q$-voter model proposed to date. The novelty of this work goes beyond introducing a generalized model: we develop the pair approximation (PA) for an asymmetric $q$-voter model and, for the first time, validate it on empirical organizational networks. Our results show that the interplay of social influence, independence, and option preference generates discontinuous phase transitions and irreversible hysteresis, reflecting path-dependent adoption dynamics. Surprisingly, the PA agrees well with Monte Carlo simulations on some empirical networks, even small ones, highlighting its potential as a computationally efficient bridge between individual decision-making and collective actions.", "published": "2025-10-28T14:10:11Z", "query": "virtual reality neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:30.552856"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:34.235861"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "immersive VR brain", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:34.236608"}
{"arxiv_id": "2510.24706v1", "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?", "summary": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.", "published": "2025-10-28T17:55:42Z", "query": "immersive VR brain", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:17:34.236972"}
{"arxiv_id": "2510.24639v1", "title": "Causal Ordering for Structure Learning From Time Series", "summary": "Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.", "published": "2025-10-28T17:06:15Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:34.237311"}
{"arxiv_id": "2510.24398v1", "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "summary": "Post-stroke MRI not only delineates focal lesions but also reveals secondary structural changes, such as atrophy and ventricular enlargement. These abnormalities, increasingly recognised as imaging biomarkers of recovery and outcome, remain poorly captured by supervised segmentation methods. We evaluate REFLECT, a flow-based generative model, for unsupervised detection of both focal and non-lesional abnormalities in post-stroke patients. Using dual-expert central-slice annotations on ATLAS data, performance was assessed at the object level with Free-Response ROC analysis for anomaly maps. Two models were trained on lesion-free slices from stroke patients (ATLAS) and on healthy controls (IXI) to test the effect of training data. On ATLAS test subjects, the IXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and improved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43). Training on fully healthy anatomy improves the modelling of normal variability, enabling broader and more reliable detection of structural abnormalities.", "published": "2025-10-28T13:13:01Z", "query": "immersive VR brain", "relevance": 0.2, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:34.237548"}
{"arxiv_id": "2510.24378v1", "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular,   Lightweight, and Deployment-Ready Tool", "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance in brain lesion segmentation but remain difficult to deploy clinically due to heavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a modular and lightweight framework that translates research-grade stroke lesion segmentation models into deployable applications. Preprocessing, inference, and postprocessing are decoupled: preprocessing relies on the Anima toolbox with BIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16} quantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides both graphical and command-line interfaces and is distributed as Python scripts and as a standalone Windows executable. On a held-out set of 300 sub-acute and chronic stroke subjects, segmentation performance was equivalent to the original PyTorch pipeline (Dice difference $&lt;10^{-3}$), demonstrating that high-performing research pipelines can be transformed into portable, clinically usable tools.", "published": "2025-10-28T12:56:48Z", "query": "immersive VR brain", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:34.237765"}
{"arxiv_id": "2510.24342v1", "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "summary": "For decades, neuroscientists and computer scientists have pursued a shared ambition: to understand intelligence and build it. Modern artificial neural networks now rival humans in language, perception, and reasoning, yet it is still largely unknown whether these artificial systems organize information as the brain does. Existing brain-AI alignment studies have shown the striking correspondence between the two systems, but such comparisons remain bound to specific inputs and tasks, offering no common ground for comparing how AI models with different kinds of modalities-vision, language, or multimodal-are intrinsically organized. Here we introduce a groundbreaking concept of Brain-like Space: a unified geometric space in which every AI model can be precisely situated and compared by mapping its intrinsic spatial attention topological organization onto canonical human functional brain networks, regardless of input modality, task, or sensory domain. Our extensive analysis of 151 Transformer-based models spanning state-of-the-art large vision models, large language models, and large multimodal models uncovers a continuous arc-shaped geometry within this space, reflecting a gradual increase of brain-likeness; different models exhibit distinct distribution patterns within this geometry associated with different degrees of brain-likeness, shaped not merely by their modality but by whether the pretraining paradigm emphasizes global semantic abstraction and whether the positional encoding scheme facilitates deep fusion across different modalities. Moreover, the degree of brain-likeness for a model and its downstream task performance are not \"identical twins\". The Brain-like Space provides the first unified framework for situating, quantifying, and comparing intelligence across domains, revealing the deep organizational principles that bridge machines and the brain.", "published": "2025-10-28T12:09:23Z", "query": "immersive VR brain", "relevance": 0.15000000000000002, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:17:34.238027"}
{"arxiv_id": "2510.24291v1", "title": "Viscous AC current-driven nanomotors", "summary": "The recent discovery that electrons in nano-scale conductors can act like a highly viscous liquid has triggered a surge of research activities investigating consequences of this surprising fact. Here we demonstrate that the electronic viscosity has an enormous influence on the operation of a prototypical AC-current-driven nano-motor. The design of this prototype consists of a diatomic molecule immersed in an otherwise homogeneous electron liquid which carries an AC current. The motion of the diatomic is determined by a subtle balance between the current-induced forces and electronic friction. By ab-initio time-dependent density-functional simulations we demonstrate that the diatomic performs a continuous rotation provided the amplitude and frequency of the imposed AC current lie within certain islands of stability. Outside these islands the nuclear motion is either chaotic or comes to a stand-still. The proposed design of the nano-motor is the conceptually simplest realization of the idea of an molecular waterwheel sandwiched between conducting leads", "published": "2025-10-28T10:54:49Z", "query": "immersive VR brain", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:17:34.238223"}
{"arxiv_id": "2510.24057v1", "title": "VR-Assisted Guide Dog Training: A 360\u00b0 PanoHaptic System for   Right-Hand Commands Analysis", "summary": "This paper presents a VR-based guide dog training system designed to assist novice trainers in understanding guide dog behavior and issuing appropriate training commands. Guide dogs play a vital role in supporting independent mobility for visually impaired individuals, yet the limited number of skilled trainers restricts their availability. Training is highly demanding, requiring accurate observation of the dog's status and precise command issuance, especially through right-hand gestures. While the trainer's left hand holds the harness to perceive haptic cues, the right hand is used to indicate directions, maintain attention, and provide comfort, with motion patterns varying by scenario and the dog's progress. Currently, novices learn mainly by observing experts or watching videos, which lacks immersion and makes it difficult to adopt the trainer's perspective for understanding behavior or synchronizing command timing.   To address these limitations, the proposed system introduces a VR-based assistive platform integrating panoramic visuals and haptic feedback to create an immersive training environment. The visual module provides contextual guidance, including cues for command execution and real-time comparison of the user's posture with standard actions, while the haptic module delivers tactile feedback for command gestures. Users can re-experience training sessions across diverse scenarios and dog proficiency levels, allowing independent and repeated practice. By improving the timing, accuracy, and expressiveness of right-hand commands, the system aims to accelerate skill acquisition, enhance training quality, and mitigate the shortage of qualified trainers, ultimately increasing the availability of guide dogs for visually impaired individuals.", "published": "2025-10-28T04:34:30Z", "query": "immersive VR brain", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:34.238450"}
{"arxiv_id": "2510.24029v1", "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a   Hippocampus-Inspired Model", "summary": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of vertebrates that encode environmental boundaries at specific distances and allocentric directions, playing a central role in forming place fields in the hippocampus. Most computational BVC models are restricted to two-dimensional (2D) environments, making them prone to spatial ambiguities in the presence of horizontal symmetries in the environment. To address this limitation, we incorporate vertical angular sensitivity into the BVC framework, thereby enabling robust boundary detection in three dimensions, and leading to significantly more accurate spatial localization in a biologically-inspired robot model.   The proposed model processes LiDAR data to capture vertical contours, thereby disambiguating locations that would be indistinguishable under a purely 2D representation. Experimental results show that in environments with minimal vertical variation, the proposed 3D model matches the performance of a 2D baseline; yet, as 3D complexity increases, it yields substantially more distinct place fields and markedly reduces spatial aliasing. These findings show that adding a vertical dimension to BVC-based localization can significantly enhance navigation and mapping in real-world 3D spaces while retaining performance parity in simpler, near-planar scenarios.", "published": "2025-10-28T03:24:02Z", "query": "immersive VR brain", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:34.238689"}
{"arxiv_id": "2510.24564v1", "title": "Evolution of electronic and magnetic properties in Mn- and Co-alloyed   ferromagnetic kagome metal Fe3Sn2", "summary": "Kagome metals are an intriguing class of quantum materials as the presence of both flat bands and Dirac points provides access to functional properties present in strongly correlated and topological materials. To fully harness these electronic features, the ability to tune the Fermi level relative to the band positions is needed. Here we explore the structural, electronic and magnetic impacts of substitutional alloying within ferromagnetic kagome metal Fe3Sn2 in thin films grown by molecular beam epitaxy. Transition metals Mn and Co are chosen as substitutes for Fe to reduce or increase the d-band electron count, thereby moving the Fermi level accordingly. We find that Co is not incorporated into the Fe3Sn2 structure but instead results in a two-phase Fe-Co and (Fe,Co)Sn composite. In contrast, Fe3-xMnxSn2 films are realized with x up to 1.0, retaining crystalline quality comparable to the parent phase. The incorporation of Mn repositions the flat bands relative to the Fermi level in a manner consistent with hole-doping, as revealed by hard x-ray photoemission and density functional theory. The Fe3-xMnxSn2 films retain room temperature ferromagnetism, with x-ray magnetic circular dichroism measurements confirming that the Fe and Mn moments are ferromagnetically aligned. The ability to hole-dope this magnetic kagome metal provides a platform for tuning properties such as anomalous Hall and Nernst responses.", "published": "2025-10-28T15:56:49Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:37.645734"}
{"arxiv_id": "2510.24427v1", "title": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and   Knowledge in Language Models", "summary": "Evaluating the reasoning ability of language models (LMs) is complicated by their extensive parametric world knowledge, where benchmark performance often reflects factual recall rather than genuine reasoning. Existing datasets and approaches (e.g., temporal filtering, paraphrasing, adversarial substitution) cannot cleanly separate the two. We present SynthWorlds, a framework that disentangles task reasoning complexity from factual knowledge. In SynthWorlds, we construct parallel corpora representing two worlds with identical interconnected structure: a real-mapped world, where models may exploit parametric knowledge, and a synthetic-mapped world, where such knowledge is meaningless. On top of these corpora, we design two mirrored tasks as case studies: multi-hop question answering and page navigation, which maintain equal reasoning difficulty across worlds. Experiments in parametric-only (e.g., closed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings reveal a persistent knowledge advantage gap, defined as the performance boost models gain from memorized parametric world knowledge. Knowledge acquisition and integration mechanisms reduce but do not eliminate this gap, highlighting opportunities for system improvements. Fully automatic and scalable, SynthWorlds provides a controlled environment for evaluating LMs in ways that were previously challenging, enabling precise and testable comparisons of reasoning and memorization.", "published": "2025-10-28T13:47:23Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:17:37.646310"}
{"arxiv_id": "2510.24409v1", "title": "Anomalous enhancement of magnetism by nonmagnetic doping in the   honeycomb-lattice antiferromagnet ErOCl", "summary": "Tuning magnetic anisotropy through chemical doping is a powerful strategy for designing functional materials with enhanced magnetic properties. Here, we report an enhanced Er^3+ magnetic moment resulting from nonmagnetic Lu^3+ substitution in the honeycomb-lattice antiferromagnet ErOCl. Unlike the Curie-Weiss type divergence typically observed in diluted magnetic systems, our findings reveal a distinct enhancement of magnetization per Er^3+ ion under high magnetic fields, suggesting an unconventional mechanism. Structural analysis reveals that Lu^3+ doping leads to a pronounced contraction of the c axis, which is attributed to chemical pressure effects, while preserving the layered SmSI-type crystal structure with space group R-3m. High-resolution Raman spectroscopy reveals a systematic blueshift of the first and seventh crystalline electric field (CEF) excitations, indicating an increase in the axial CEF parameter B_2^0. This modification enhances the magnetic anisotropy along the c axis, leading to a significant increase in magnetization at low temperatures and under high magnetic fields, contrary to conventional expectations for magnetic dilution. Our work not only clarifies the intimate connection between magnetism and CEF in rare-earth compounds, but more importantly, it reveals a physical pathway to effectively tune magnetic anisotropy via anisotropic lattice distortion induced by chemical pressure.", "published": "2025-10-28T13:20:51Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:37.646852"}
{"arxiv_id": "2510.24356v1", "title": "Perception Learning: A Formal Separation of Sensory Representation   Learning from Decision Learning", "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's sensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic signals, decoupled from downstream decision learning $g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free perceptual properties, such as stability to nuisances, informativeness without collapse, and controlled geometry, assessed via objective representation-invariant metrics. We formalize the separation of perception and decision, define perceptual properties independent of objectives or reparameterizations, and prove that PeL updates preserving sufficient invariants are orthogonal to Bayes task-risk gradients. Additionally, we provide a suite of task-agnostic evaluation metrics to certify perceptual quality.", "published": "2025-10-28T12:19:49Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:37.647287"}
{"arxiv_id": "2510.24342v1", "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "summary": "For decades, neuroscientists and computer scientists have pursued a shared ambition: to understand intelligence and build it. Modern artificial neural networks now rival humans in language, perception, and reasoning, yet it is still largely unknown whether these artificial systems organize information as the brain does. Existing brain-AI alignment studies have shown the striking correspondence between the two systems, but such comparisons remain bound to specific inputs and tasks, offering no common ground for comparing how AI models with different kinds of modalities-vision, language, or multimodal-are intrinsically organized. Here we introduce a groundbreaking concept of Brain-like Space: a unified geometric space in which every AI model can be precisely situated and compared by mapping its intrinsic spatial attention topological organization onto canonical human functional brain networks, regardless of input modality, task, or sensory domain. Our extensive analysis of 151 Transformer-based models spanning state-of-the-art large vision models, large language models, and large multimodal models uncovers a continuous arc-shaped geometry within this space, reflecting a gradual increase of brain-likeness; different models exhibit distinct distribution patterns within this geometry associated with different degrees of brain-likeness, shaped not merely by their modality but by whether the pretraining paradigm emphasizes global semantic abstraction and whether the positional encoding scheme facilitates deep fusion across different modalities. Moreover, the degree of brain-likeness for a model and its downstream task performance are not \"identical twins\". The Brain-like Space provides the first unified framework for situating, quantifying, and comparing intelligence across domains, revealing the deep organizational principles that bridge machines and the brain.", "published": "2025-10-28T12:09:23Z", "query": "sensory substitution", "relevance": 0.15000000000000002, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:17:37.647771"}
{"arxiv_id": "2510.24323v1", "title": "Optimizing Quantum Compilation via High-Level Quantum Instructions", "summary": "Current quantum programming is dominated by low-level, circuit-centric approaches that limit the potential for compiler optimization. This work presents how a high-level programming construct provides compilers with the semantic information needed for advanced optimizations. We introduce a novel optimization that leverages a quantum-specific instruction to automatically substitute quantum gates with more efficient, approximate decompositions, a process that is transparent to the programmer and significantly reduces quantum resource requirements. Furthermore, we show how this instruction guarantees the correct uncomputation of auxiliary qubits, enabling safe, dynamic quantum memory management. We illustrate these concepts by implementing a V-chain decomposition of the multi-controlled NOT gate, showing that our high-level approach not only simplifies the code but also enables the compiler to generate a circuit with up to a 50% reduction in CNOT gates. Our results suggest that high-level abstractions are crucial for unlocking a new class of powerful compiler optimizations, paving the way for more efficient quantum computation.", "published": "2025-10-28T11:44:38Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:37.648063"}
{"arxiv_id": "2510.23892v1", "title": "Learning-based Spectral Regression for Cocoa Bean Physicochemical   Property Prediction", "summary": "Cocoa bean quality assessment is essential for ensuring compliance with commercial standards, protecting consumer health, and increasing the market value of the cocoa product. The quality assessment estimates key physicochemical properties, such as fermentation level, moisture content, polyphenol concentration, and cadmium content, among others. This assessment has traditionally relied on the accurate estimation of these properties via visual or sensory evaluation, jointly with laboratory-based physicochemical analyses, which are often time-consuming, destructive, and difficult to scale. This creates the need for rapid, reliable, and noninvasive alternatives. Spectroscopy, particularly in the visible and near-infrared ranges, offers a non-invasive alternative by capturing the molecular signatures associated with these properties. Therefore, this work introduces a scalable methodology for evaluating the quality of cocoa beans by predicting key physicochemical properties from the spectral signatures of cocoa beans. This approach utilizes a conveyor belt system integrated with a VIS-NIR spectrometer, coupled with learning-based regression models. Furthermore, a dataset is built using cocoa bean batches from Santander, Colombia. Ground-truth reference values were obtained through standardized laboratory analyses and following commercial cocoa quality regulations. To further evaluate the proposed methodology's generalization, performance is tested on samples collected from other Colombian regions and from Cusco, Peru. Experimental results show that the proposed models achieved R2 scores exceeding 0.98 across all physicochemical properties, and reached 0.96 accuracy on geographically independent samples. This non-destructive approach represents a suitable and scalable alternative to conventional laboratory methods for quality assessment across the cocoa production chain.", "published": "2025-10-27T22:05:01Z", "query": "sensory substitution", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:37.648450"}
{"arxiv_id": "2510.23799v1", "title": "ETZ: A Modeling Principle for Confirmability of Drug-Development Studies", "summary": "Transitioning from Phase 2 to Phase 3 in drug development, at a rate of $\\approx$40%, is the most stringent among phase transitions (Hay et al. (2014)). Yet, success rate at Phase 3 leading to approval is only $\\approx$50% (Arrowsmith (2011b)). To improve Confirmability, we propose a methodological shift: replacing multiple hypothesis testing with inference based on confidence sets, and substituting conventional power and sample size calculations with a Confidently Bounded Quantile (CBQ) framework.   Our confidence set inferences to answer the questions of whether to transition to a Confirmatory study as well as what to designate as the endpoint in that study. Construction of our directed confidence sets follows the Partitioning Principle, taking the best of each of Pivoting and Neyman Confidence Set Construction.   Rooted in Tukey's Confidently Bounded Allowance (CBA) (Tukey (1994a)), our proposed CBQ makes the transitioning decision following the Correct and Useful Inference principle in Hsu (1996). CBQ removes from \"power\" the probability of rejecting for wrong reasons, eliminating the need for informal discounting in power calculation that has existed in the biopharmaceutical industry.   ETZ, the modeling principle proposed in Wang et al. (2025), quantifies the impact of three variability components on confirmability. In repeated-measures RCTs, it separates within-subject and between-subject variability, further dividing the latter into baseline and trajectory components. This enables informed investment decisions for the sponsors on targeting variability reduction to improve confirmability. A Shiny-based Confirmability App supports all computations.", "published": "2025-10-27T19:34:28Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:37.648792"}
{"arxiv_id": "2510.23421v1", "title": "Exploring Vulnerability in AI Industry", "summary": "The rapid ascent of Foundation Models (FMs), enabled by the Transformer architecture, drives the current AI ecosystem. Characterized by large-scale training and downstream adaptability, FMs (as GPT family) have achieved massive public adoption, fueling a turbulent market shaped by platform economics and intense investment. Assessing the vulnerability of this fast-evolving industry is critical yet challenging due to data limitations. This paper proposes a synthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain for FM production, prioritizing publicly available data. We model FM output as a function of five inputs: Compute, Data, Talent, Capital, and Energy, hypothesizing that supply vulnerability in any input threatens the industry. Key vulnerabilities include compute concentration, data scarcity and legal risks, talent bottlenecks, capital intensity and strategic dependencies, as well as escalating energy demands. Acknowledging imperfect input substitutability, we propose a weighted geometrical average of aggregate subindexes, normalized using theoretical or empirical benchmarks. Despite limitations and room for improvement, this preliminary index aims to quantify systemic risks in AI's core production engine, and implicitly shed a light on the risks for downstream value chain.", "published": "2025-10-27T15:26:40Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:37.649019"}
{"arxiv_id": "2510.23208v1", "title": "Increasing LLM Coding Capabilities through Diverse Synthetic Coding   Tasks", "summary": "Large language models (LLMs) have shown impressive promise in code generation, yet their progress remains limited by the shortage of large-scale datasets that are both diverse and well-aligned with human reasoning. Most existing resources pair problems with solutions, but omit the intermediate thought process that guides coding. To close this gap, we present a scalable synthetic data generation pipeline that produces nearly 800k instruction-reasoning-code-test quadruplets. Each sample combines a task, a step-by-step reasoning trace, a working solution, and executable tests, enabling models to learn not just the what but also the how of problem solving. Our pipeline combines four key components: curated contest problems, web-mined content filtered by relevance classifiers, data expansion guided by reasoning patterns, and multi-stage execution-based validation. A genetic mutation algorithm further increases task diversity while maintaining consistency between reasoning traces and code implementations. Our key finding is that fine-tuning LLMs on this dataset yields consistent improvements on coding benchmarks. Beyond raw accuracy, reasoning-aware data can substitute for model scaling, generalize across architectures, and outperform leading open-source alternatives under identical sample budgets. Our work establishes reasoning-centered synthetic data generation as an efficient approach for advancing coding capabilities in LLMs. We publish our dataset and generation pipeline to facilitate further research.", "published": "2025-10-27T10:54:25Z", "query": "sensory substitution", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:37.649264"}
{"arxiv_id": "2510.24716v1", "title": "Positive Feedback Drives Sharp Swelling of Polymer Brushes near   Saturation", "summary": "We resolve the Schr\\\"{o}der paradox for PNiPAAm brushes, showing experimentally that swelling at 100\\% relative humidity (RH) matches the liquid state. This occurs via a sharp increase in swelling above 98\\%~RH, a behavior standard models fail to explain. Our extended mean-field theory explains this via a positive feedback between swelling and solvent quality, driven by a concentration-dependent $\\chi$ parameter. The swelling isotherm quantitatively predicts the dynamic wetting crossover: the advancing contact angle at high velocities drops sharply as ambient humidity surpasses the 98\\%~RH threshold.", "published": "2025-10-28T17:59:51Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:17:41.168101"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural feedback systems", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:41.168606"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "neural feedback systems", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:41.168959"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:41.169203"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:41.169395"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural feedback systems", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:41.169578"}
{"arxiv_id": "2510.24701v1", "title": "Tongyi DeepResearch Technical Report", "summary": "We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community.", "published": "2025-10-28T17:53:02Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:41.169747"}
{"arxiv_id": "2510.24700v1", "title": "Greedy Sampling Is Provably Efficient for RLHF", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique for post-training large language models. Despite its empirical success, the theoretical understanding of RLHF is still limited, as learning the KL-regularized target with only preference feedback poses additional challenges compared with canonical RL. Existing works mostly study the reward-based Bradley-Terry (BT) preference model, and extend classical designs utilizing optimism or pessimism. This work, instead, considers the general preference model (whose practical relevance has been observed recently) and obtains performance guarantees with major, order-wise improvements over existing ones. Surprisingly, these results are derived from algorithms that directly use the empirical estimates (i.e., greedy sampling), as opposed to constructing optimistic or pessimistic estimates in previous works. This insight has a deep root in the unique structural property of the optimal policy class under the KL-regularized target, and we further specialize it to the BT model, highlighting the surprising sufficiency of greedy sampling in RLHF.", "published": "2025-10-28T17:52:08Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:41.169976"}
{"arxiv_id": "2510.24688v1", "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with   Relation-Aware Fusion for 3D Object Detection", "summary": "Infrastructure-based perception plays a crucial role in intelligent transportation systems, offering global situational awareness and enabling cooperative autonomy. However, existing camera-based detection models often underperform in such scenarios due to challenges such as multi-view infrastructure setup, diverse camera configurations, degraded visual inputs, and various road layouts. We introduce MIC-BEV, a Transformer-based bird's-eye-view (BEV) perception framework for infrastructure-based multi-camera 3D object detection. MIC-BEV flexibly supports a variable number of cameras with heterogeneous intrinsic and extrinsic parameters and demonstrates strong robustness under sensor degradation. The proposed graph-enhanced fusion module in MIC-BEV integrates multi-view image features into the BEV space by exploiting geometric relationships between cameras and BEV cells alongside latent visual cues. To support training and evaluation, we introduce M2I, a synthetic dataset for infrastructure-based object detection, featuring diverse camera configurations, road layouts, and environmental conditions. Extensive experiments on both M2I and the real-world dataset RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D object detection. It also remains robust under challenging conditions, including extreme weather and sensor degradation. These results highlight the potential of MIC-BEV for real-world deployment. The dataset and source code are available at: https://github.com/HandsomeYun/MIC-BEV.", "published": "2025-10-28T17:49:42Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:41.170303"}
{"arxiv_id": "2510.24685v1", "title": "Flat bands in ultra-wide gap two-dimensional germanium dioxide", "summary": "We employ first principles density-functional theory (DFT) and the Bethe-Salpeter equation (BSE) in the framework of tight-binding based maximally localized Wannier functions (MLWF-TB) model to investigate the electronic and optical properties of free-standing two-dimensional (2D) germanium dioxide phases. All investigated 2D GeO2 polymorphs exhibit ultra-wide band gaps and strong excitonic effects, with flat O-p-derived valence bands tunable under strain. These features allow the design of flat band materials with ultra large electronic gaps in low-dimensional systems, making these materials promising for devices operation at higher voltages and temperatures than conventional semiconductor materials.", "published": "2025-10-28T17:47:11Z", "query": "neural feedback systems", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:41.170474"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:44.635411"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "brain stimulation VR", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:44.636285"}
{"arxiv_id": "2510.24706v1", "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?", "summary": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.", "published": "2025-10-28T17:55:42Z", "query": "brain stimulation VR", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:17:44.636791"}
{"arxiv_id": "2510.24639v1", "title": "Causal Ordering for Structure Learning From Time Series", "summary": "Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.", "published": "2025-10-28T17:06:15Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:44.637350"}
{"arxiv_id": "2510.24398v1", "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "summary": "Post-stroke MRI not only delineates focal lesions but also reveals secondary structural changes, such as atrophy and ventricular enlargement. These abnormalities, increasingly recognised as imaging biomarkers of recovery and outcome, remain poorly captured by supervised segmentation methods. We evaluate REFLECT, a flow-based generative model, for unsupervised detection of both focal and non-lesional abnormalities in post-stroke patients. Using dual-expert central-slice annotations on ATLAS data, performance was assessed at the object level with Free-Response ROC analysis for anomaly maps. Two models were trained on lesion-free slices from stroke patients (ATLAS) and on healthy controls (IXI) to test the effect of training data. On ATLAS test subjects, the IXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and improved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43). Training on fully healthy anatomy improves the modelling of normal variability, enabling broader and more reliable detection of structural abnormalities.", "published": "2025-10-28T13:13:01Z", "query": "brain stimulation VR", "relevance": 0.2, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:44.637785"}
{"arxiv_id": "2510.24378v1", "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular,   Lightweight, and Deployment-Ready Tool", "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance in brain lesion segmentation but remain difficult to deploy clinically due to heavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a modular and lightweight framework that translates research-grade stroke lesion segmentation models into deployable applications. Preprocessing, inference, and postprocessing are decoupled: preprocessing relies on the Anima toolbox with BIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16} quantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides both graphical and command-line interfaces and is distributed as Python scripts and as a standalone Windows executable. On a held-out set of 300 sub-acute and chronic stroke subjects, segmentation performance was equivalent to the original PyTorch pipeline (Dice difference $&lt;10^{-3}$), demonstrating that high-performing research pipelines can be transformed into portable, clinically usable tools.", "published": "2025-10-28T12:56:48Z", "query": "brain stimulation VR", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:44.638223"}
{"arxiv_id": "2510.24342v1", "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "summary": "For decades, neuroscientists and computer scientists have pursued a shared ambition: to understand intelligence and build it. Modern artificial neural networks now rival humans in language, perception, and reasoning, yet it is still largely unknown whether these artificial systems organize information as the brain does. Existing brain-AI alignment studies have shown the striking correspondence between the two systems, but such comparisons remain bound to specific inputs and tasks, offering no common ground for comparing how AI models with different kinds of modalities-vision, language, or multimodal-are intrinsically organized. Here we introduce a groundbreaking concept of Brain-like Space: a unified geometric space in which every AI model can be precisely situated and compared by mapping its intrinsic spatial attention topological organization onto canonical human functional brain networks, regardless of input modality, task, or sensory domain. Our extensive analysis of 151 Transformer-based models spanning state-of-the-art large vision models, large language models, and large multimodal models uncovers a continuous arc-shaped geometry within this space, reflecting a gradual increase of brain-likeness; different models exhibit distinct distribution patterns within this geometry associated with different degrees of brain-likeness, shaped not merely by their modality but by whether the pretraining paradigm emphasizes global semantic abstraction and whether the positional encoding scheme facilitates deep fusion across different modalities. Moreover, the degree of brain-likeness for a model and its downstream task performance are not \"identical twins\". The Brain-like Space provides the first unified framework for situating, quantifying, and comparing intelligence across domains, revealing the deep organizational principles that bridge machines and the brain.", "published": "2025-10-28T12:09:23Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:17:44.638720"}
{"arxiv_id": "2510.24057v1", "title": "VR-Assisted Guide Dog Training: A 360\u00b0 PanoHaptic System for   Right-Hand Commands Analysis", "summary": "This paper presents a VR-based guide dog training system designed to assist novice trainers in understanding guide dog behavior and issuing appropriate training commands. Guide dogs play a vital role in supporting independent mobility for visually impaired individuals, yet the limited number of skilled trainers restricts their availability. Training is highly demanding, requiring accurate observation of the dog's status and precise command issuance, especially through right-hand gestures. While the trainer's left hand holds the harness to perceive haptic cues, the right hand is used to indicate directions, maintain attention, and provide comfort, with motion patterns varying by scenario and the dog's progress. Currently, novices learn mainly by observing experts or watching videos, which lacks immersion and makes it difficult to adopt the trainer's perspective for understanding behavior or synchronizing command timing.   To address these limitations, the proposed system introduces a VR-based assistive platform integrating panoramic visuals and haptic feedback to create an immersive training environment. The visual module provides contextual guidance, including cues for command execution and real-time comparison of the user's posture with standard actions, while the haptic module delivers tactile feedback for command gestures. Users can re-experience training sessions across diverse scenarios and dog proficiency levels, allowing independent and repeated practice. By improving the timing, accuracy, and expressiveness of right-hand commands, the system aims to accelerate skill acquisition, enhance training quality, and mitigate the shortage of qualified trainers, ultimately increasing the availability of guide dogs for visually impaired individuals.", "published": "2025-10-28T04:34:30Z", "query": "brain stimulation VR", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:44.639239"}
{"arxiv_id": "2510.24029v1", "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a   Hippocampus-Inspired Model", "summary": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of vertebrates that encode environmental boundaries at specific distances and allocentric directions, playing a central role in forming place fields in the hippocampus. Most computational BVC models are restricted to two-dimensional (2D) environments, making them prone to spatial ambiguities in the presence of horizontal symmetries in the environment. To address this limitation, we incorporate vertical angular sensitivity into the BVC framework, thereby enabling robust boundary detection in three dimensions, and leading to significantly more accurate spatial localization in a biologically-inspired robot model.   The proposed model processes LiDAR data to capture vertical contours, thereby disambiguating locations that would be indistinguishable under a purely 2D representation. Experimental results show that in environments with minimal vertical variation, the proposed 3D model matches the performance of a 2D baseline; yet, as 3D complexity increases, it yields substantially more distinct place fields and markedly reduces spatial aliasing. These findings show that adding a vertical dimension to BVC-based localization can significantly enhance navigation and mapping in real-world 3D spaces while retaining performance parity in simpler, near-planar scenarios.", "published": "2025-10-28T03:24:02Z", "query": "brain stimulation VR", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:44.639772"}
{"arxiv_id": "2510.24025v1", "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional   Connectivity Analysis", "summary": "Understanding the evolution of brain functional networks over time is of great significance for the analysis of cognitive mechanisms and the diagnosis of neurological diseases. Existing methods often have difficulty in capturing the temporal evolution characteristics of connections between specific functional communities. To this end, this paper proposes a new path-level trajectory modeling framework (NeuroPathNet) to characterize the dynamic behavior of connection pathways between brain functional partitions. Based on medically supported static partitioning schemes (such as Yeo and Smith ICA), we extract the time series of connection strengths between each pair of functional partitions and model them using a temporal neural network. We validate the model performance on three public functional Magnetic Resonance Imaging (fMRI) datasets, and the results show that it outperforms existing mainstream methods in multiple indicators. This study can promote the development of dynamic graph learning methods for brain network analysis, and provide possible clinical applications for the diagnosis of neurological diseases.", "published": "2025-10-28T03:07:06Z", "query": "brain stimulation VR", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:44.640219"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:48.111609"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:48.112336"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:48.112714"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:17:48.112976"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:48.113336"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:48.113574"}
{"arxiv_id": "2510.24640v1", "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "summary": "The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques, ranging from face swapping and attribute editing to powerful diffusion-based image synthesis, are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function, FSC Loss, that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.", "published": "2025-10-28T17:06:40Z", "query": "neural implants", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:48.113803"}
{"arxiv_id": "2510.24637v1", "title": "All in one timestep: Enhancing Sparsity and Energy efficiency in   Multi-level Spiking Neural Networks", "summary": "Spiking Neural Networks (SNNs) are one of the most promising bio-inspired neural networks models and have drawn increasing attention in recent years. The event-driven communication mechanism of SNNs allows for sparse and theoretically low-power operations on dedicated neuromorphic hardware. However, the binary nature of instantaneous spikes also leads to considerable information loss in SNNs, resulting in accuracy degradation. To address this issue, we propose a multi-level spiking neuron model able to provide both low-quantization error and minimal inference latency while approaching the performance of full precision Artificial Neural Networks (ANNs). Experimental results with popular network architectures and datasets, show that multi-level spiking neurons provide better information compression, allowing therefore a reduction in latency without performance loss. When compared to binary SNNs on image classification scenarios, multi-level SNNs indeed allow reducing by 2 to 3 times the energy consumption depending on the number of quantization intervals. On neuromorphic data, our approach allows us to drastically reduce the inference latency to 1 timestep, which corresponds to a compression factor of 10 compared to previously published results. At the architectural level, we propose a new residual architecture that we call Sparse-ResNet. Through a careful analysis of the spikes propagation in residual connections we highlight a spike avalanche effect, that affects most spiking residual architectures. Using our Sparse-ResNet architecture, we can provide state-of-the-art accuracy results in image classification while reducing by more than 20% the network activity compared to the previous spiking ResNets.", "published": "2025-10-28T17:03:33Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:48.114085"}
{"arxiv_id": "2510.24616v1", "title": "Statistical physics of deep learning: Optimal learning of a multi-layer   perceptron near interpolation", "summary": "For three decades statistical physics has been providing a framework to analyse neural networks. A long-standing question remained on its capacity to tackle deep learning models capturing rich feature learning effects, thus going beyond the narrow networks or kernel methods analysed until now. We positively answer through the study of the supervised learning of a multi-layer perceptron. Importantly, (i) its width scales as the input dimension, making it more prone to feature learning than ultra wide networks, and more expressive than narrow ones or with fixed embedding layers; and (ii) we focus on the challenging interpolation regime where the number of trainable parameters and data are comparable, which forces the model to adapt to the task. We consider the matched teacher-student setting. It provides the fundamental limits of learning random deep neural network targets and helps in identifying the sufficient statistics describing what is learnt by an optimally trained network as the data budget increases. A rich phenomenology emerges with various learning transitions. With enough data optimal performance is attained through model's \"specialisation\" towards the target, but it can be hard to reach for training algorithms which get attracted by sub-optimal solutions predicted by the theory. Specialisation occurs inhomogeneously across layers, propagating from shallow towards deep ones, but also across neurons in each layer. Furthermore, deeper targets are harder to learn. Despite its simplicity, the Bayesian-optimal setting provides insights on how the depth, non-linearity and finite (proportional) width influence neural networks in the feature learning regime that are potentially relevant way beyond it.", "published": "2025-10-28T16:44:34Z", "query": "neural implants", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:48.114326"}
{"arxiv_id": "2510.24602v1", "title": "Learning to generalize in evolution through annealed population   heterogeneity", "summary": "Evolutionary systems must learn to generalize, often extrapolating from a limited set of selective conditions to anticipate future environmental changes. The mechanisms enabling such generalization remain poorly understood, despite their importance to predict ecological robustness, drug resistance, or design future-proof vaccination strategies. Here, we demonstrate that annealed population heterogeneity, wherein distinct individuals in the population experience different instances of a complex environment over time, can act as a form of implicit regularization and facilitate evolutionary generalization. Mathematically, annealed heterogeneity introduces a variance-weighted demographic noise term that penalizes across-environment fitness variance and effectively rescales the population size, thereby biasing evolution toward generalist solutions. This process is indeed analogous to a variant of the mini-batching strategy employed in stochastic gradient descent, where an effective multiplicative noise produces an inductive bias by triggering noise-induced transitions.   Through numerical simulations and theoretical analysis we discuss the conditions under which variation in how individuals experience environmental selection can naturally promote evolutionary strategies that generalize across environments and anticipate novel challenges.", "published": "2025-10-28T16:28:55Z", "query": "neural implants", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:48.114577"}
{"arxiv_id": "2510.24656v1", "title": "Virtual Gates Enabled by Digital Surrogate of Quantum Dot Devices", "summary": "Advances in quantum technologies are often limited by slow device characterization, complex tuning require- ments, and scalability challenges. Spin qubits in electrostatically defined quantum dots provide a promising platform but are not exempt from these limitations. Simulations enhance our understanding of such devices, and in many cases, rapid feedback between measurements and simulations can guide the development of op- timal design and control strategies. Here, we introduce a modular, graph-based simulator that acts as a digital surrogate for a semiconductor quantum dot device, where computationally expensive processes are accelerated using deep learning. We demonstrate its potential by estimating crosstalk effects between gate electrodes and applying these estimates to construct virtual gates in a quantum dot device. We validate our approach through comparison with experiments on a double quantum dot defined in a Ge/SiGe heterostructure. We envision that this simulation framework will advance semiconductor-based quantum technologies by enabling more efficient design, characterization, and control of complex devices.", "published": "2025-10-28T17:22:20Z", "query": "intracortical electrodes", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:17:51.756932"}
{"arxiv_id": "2510.24635v1", "title": "Electrochemical Electron Transfer: Key Concepts, Theories, and   Parameterization via Atomistic Simulations", "summary": "Electron transfer (ET) at electrochemical interfaces is central to energy conversion and storage, yet its theoretical and computational modeling remain active research areas. This review elucidates key concepts and theories of ET kinetics, focusing on coupling between classical solvent fluctuations and quantum electronic states of metallic electrodes and redox species. We begin with fundamental rate theories, reaction coordinates, and electrochemical timescales, then explore weak, strong, and intermediate electronic coupling regimes. Special attention is given to solvent dynamics and the structure of the electrical double layer (EDL), which critically impact ET kinetics. Atomistic simulations, particularly density functional theory (DFT) and molecular dynamics (MD), are highlighted for testing linear response and determining solvent reorganization energy, electronic coupling strengths, and solvent relaxation dynamics. A central theme is linear response enabling tractable treatments across Marcus theory, empirical valence bond (EVB) models, the Anderson-Newns-Schmickler framework, and generalized Langevin dynamics. While linear response offers useful simplifications, we assess its limitations, particularly for strong solvation changes or inner-sphere ET at catalytic interfaces. We discuss advances, including mapping Hamiltonian-based EVB-MD, constrained DFT, and non-Gaussian free energy formulations, enabling rigorous tests and access to diabatic and adiabatic free energy surfaces. We outline opportunities to advance multiscale, quantum-classical models that integrate EDL effects, multiple reaction coordinates, solvent-controlled dynamics, and transitions between adiabatic and nonadiabatic regimes. This review serves as a conceptual guide and practical resource for researchers integrating theory and simulation in studying electrochemical ET across diverse systems.", "published": "2025-10-28T17:02:22Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:51.757516"}
{"arxiv_id": "2510.24627v1", "title": "Enhanced Superconductivity in 2H-TaS2 Devices Through in-situ Molecular   Intercalation", "summary": "The intercalation of guest species into the gap of van der Waals materials often leads to the emergence of intriguing phenomena, such as superconductivity. While intercalation-induced superconductivity has been reported in several bulk crystals, reaching a zero-resistance state in flakes remains challenging. Here, we show a simple method for enhancing the superconducting transition in tens-of-nm thick 2H-TaS2 crystals contacted by gold electrodes through in-situ intercalation. Our approach enables measuring the electrical characteristics of the same flake before and after intercalation, permitting us to precisely identify the effect of the guest species on the TaS2 transport properties. We find that the intercalation of amylamine molecules into TaS2 flakes causes a suppression of the charge density wave and an increase in the superconducting transition, with an onset temperature above 3 K. Additionally, we show that a fully developed zero-resistance state can be achieved in flakes by engineering the conditions of the chemical intercalation. Our findings pave the way for the integration of chemically tailored intercalation compounds in scalable quantum technologies.", "published": "2025-10-28T16:57:29Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:51.757865"}
{"arxiv_id": "2510.24294v1", "title": "Phase-Rotated Altermagnets as Chern Valves for Topological Transport", "summary": "Motivated by the emerging control of Berry-curvature textures in altermagnets, we explore a two-terminal configuration where a topological-insulator film is interfaced with two altermagnetic electrodes whose crystalline phases can be rotated independently. The proximity coupling imprints each momentum-dependent of the altermagnet spin texture onto the Dirac surface states, giving rise to an angular mass whose sign follows the lattice orientation. Adjusting the phase of one electrode redefines this mass pattern, thereby tuning the number and spatial distribution of chiral edge channels. This results in discrete conductance steps and a reversible inversion of the thermoelectric coefficient-achieved without external magnetic fields or net magnetization. A compact Dirac model captures both the quantized switching and its resilience to moderate disorder. Overall, this symmetry-driven mechanism provides a practical and low-dissipation route to programmable topological transport via lattice rotation.", "published": "2025-10-28T10:56:31Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:51.758106"}
{"arxiv_id": "2510.23519v1", "title": "Architecting Scalable Trapped Ion Quantum Computers using Surface Codes", "summary": "Trapped ion (TI) qubits are a leading quantum computing platform. Current TI systems have less than 60 qubits, but a modular architecture known as the Quantum Charge-Coupled Device (QCCD) is a promising path to scale up devices. There is a large gap between the error rates of near-term systems ($10^{-3}$ to $10^{-4}$) and the requirements of practical applications (below $10^{-9}$). To bridge this gap, we require Quantum Error Correction (QEC) to build \\emph{logical qubits} that are composed of multiple physical qubits. While logical qubits have been demonstrated on TI qubits, these demonstrations are restricted to small codes and systems. There is no clarity on how QCCD systems should be designed to implement practical-scale QEC. This paper studies how surface codes, a standard QEC scheme, can be implemented efficiently on QCCD-based systems. To examine how architectural parameters of a QCCD system can be tuned for surface codes, we develop a near-optimal topology-aware compilation method that outperforms existing QCCD compilers by an average of 3.8X in terms of logical clock speed. We use this compiler to examine how hardware trap capacity, connectivity and electrode wiring choices can be optimised for surface code implementation. In particular, we demonstrate that small traps of two ions are surprisingly ideal from both a performance-optimal and hardware-efficiency standpoint. This result runs counter to prior intuition that larger traps (20-30 ions) would be preferable, and has the potential to inform design choices for upcoming systems.", "published": "2025-10-27T16:58:00Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:51.758362"}
{"arxiv_id": "2510.23422v1", "title": "Prospects towards Paired Electrolysis at Industrial Currents", "summary": "Paired electrolysis at industrial current densities offers an energy-efficient and sustainable alternative to thermocatalytic chemical synthesis by leveraging anodic and cathodic valorization. However, its industrial feasibility remains constrained by system integration, including reactor assembly, asymmetric electron transfer kinetics, membrane selection, mass transport limitations, and techno-economic bottlenecks. Addressing these challenges requires an engineering-driven approach that integrates reactor architecture, electrode-electrolyte interactions, reaction pairing, and process optimization. Here, we discuss scale-specific electrochemical reactor assembly strategies, transitioning from half-cell research to full-scale stack validation. We develop reaction pairing frameworks that align electrocatalyst design with electrochemical kinetics, enhancing efficiency and selectivity under industrial operating conditions. We also establish application-dependent key performance indicators (KPIs) and benchmark propylene oxidation coupled with hydrogen evolution reaction (HER) or oxygen reduction reaction (ORR) against existing industrial routes to evaluate process viability. Finally, we propose hybrid integration models that embed paired electrolysis into existing industrial workflows, overcoming adoption barriers.", "published": "2025-10-27T15:26:40Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:51.758623"}
{"arxiv_id": "2510.23417v1", "title": "Filling the Gap: Atom Probe Tomography of Porous Structures Enabled by   Site Specific SEMGlu Curing", "summary": "Porous microstructures, while central to many functional materials, remain difficult to characterize quantitatively by atom probe tomography (APT). Although several strategies have been proposed over the past decade, most remain constrained by significant practical or technical limitations. Here, we introduce an in situ pore filling approach that integrates seamlessly into conventional specimen preparation workflows. The method employs a vacuum compatible resin that is rapidly cured by the electron beam during standard ion beam based preparation, eliminating the need for additional instrumentation or extensive sample handling. We demonstrate the effectiveness of this approach using a porous SnSe + MXene electrode, a material system otherwise difficult to analyze via APT characterisation. This method offers a robust, accessible solution for extending APT analysis to porous materials", "published": "2025-10-27T15:22:09Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:51.759029"}
{"arxiv_id": "2510.23391v1", "title": "Conduction velocity of intracortical axons in monkey primary visual   cortex grows with distance: implications for computation", "summary": "A critical visual computation is to construct global scene properties from activities of early visual cortical neurons which have small receptive fields. Such a computation is enabled by contextual influences, through which a neuron's response to visual inputs is influenced by contextual inputs outside its classical receptive fields. Accordingly, neurons can signal global properties including visual saliencies and figure-ground relationships. Many believe that intracortical axons conduct signals too slowly to bring the contextual information from receptive fields of other neurons. A popular opinion is that much of the contextual influences arise from feedback from higher visual areas whose neurons have larger receptive fields. This paper re-examines pre-existing data to reveal these unexpected findings: the conduction speed of V1 intracortical axons increases approximately linearly with the conduction distance, and is sufficiently high for conveying the contextual influences. Recognizing the importance of intracortical contribution to critical visual computations should enable fresh progress in answering long-standing questions.", "published": "2025-10-27T14:44:12Z", "query": "intracortical electrodes", "relevance": 0.44999999999999996, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:51.759863"}
{"arxiv_id": "2510.23290v1", "title": "Group-Level and Personalized Optimization for the Insula and Hippocampus   Focal Electric Field in Transcranial Temporal Interferential Stimulation: A   Computational Study", "summary": "This study evaluated transcranial temporal interference stimulation (tTIS) for focal targeting of the insula and hippocampus, which are clinically relevant yet anatomically difficult to stimulate. Individualized and group-level electrode optimizations were compared to determine whether generalized montages can provide reliable targeting with reduced modeling demands. Sixty high-resolution head models (30 individuals and their mirrored counterparts) were constructed from T1- and T2-weighted MRI. Electric fields (EFs) were computed using the scalar-potential finite-difference method. Electrode montages and current ratios were optimized to minimize the root-mean-square error between simulated and target EF envelope (EFE) distributions, with a threshold of 0.3 V/m. Subsampling analysis was performed to estimate the number of models required for stable group-level outcomes. For the insula, a montage combining T7-P7 and Fp1-Fp2 achieved the highest focality, comparable to individualized results with reduced variability. For the hippocampus, the F7-T7 and T8-P8 montage gave the best group-level focality, though individualized optimization improved off-target suppression. Stable group-level patterns were obtained using 20 models for the insula and 9 for the hippocampus. Optimal tTIS montages depend on target depth. Group-level optimization suffices for cortical regions like the insula, whereas individualized tuning remains preferable for deeper targets such as the hippocampus.", "published": "2025-10-27T13:00:28Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:17:51.760309"}
{"arxiv_id": "2510.23269v2", "title": "All-Altermagnetic Tunnel Junction of RuO2/NiF2/RuO2", "summary": "Emerging altermagnets offer a promising avenue for spintronics, yet their integration into magnetic tunnel junctions has been hindered by reliance on ferromagnetic electrodes (introducing stray fields) or limited functionality (non-tunable magnetoresistance without spin filtering). Here, we propose an all-altermagnetic tunnel junction (AAMTJ) paradigm composed exclusively of altermagnets-exemplified by experiment-feasible RuO2/NiF2/RuO2. Giant tunneling magnetoresistance of 11704%, and high spin-filtering of ~90% in both spin channels are achieved. This architecture unlocks tunable multistate magnetoresistance and spin filtering via magnetization control of electrode and barrier, stemming from their synergistic and antagonistic alignments of momentum-dependent altermagnetic spin-splitting. Our AAMTJ inherently exhibits low consumption and no stray field, with nonrelativistic spin splitting and zero magnetic moment, combining advantages of both ferromagnetic and antiferromagnetic tunnel junctions. This AAMTJ paradigm provides a realistically versatile platform to develop revolutionarily potential of altermagnets for reconfigurable magnetic memory devices.", "published": "2025-10-27T12:28:31Z", "query": "intracortical electrodes", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:17:51.760693"}
{"arxiv_id": "2510.24597v1", "title": "Multifunctional Wideband Digital Metasurface for Secure Electromagnetic   Manipulation in S-Band", "summary": "Digital metasurfaces have attracted significant attention in recent years due to their ability to manipulate electromagnetic (EM) waves for secure sensing and communication. However, most reported metasurfaces operate at relatively high frequencies, primarily due to the constraints imposed by the physical scale of the dielectric substrate, thus limiting their full-wave system applications. In this work, a wideband digital reflective metasurface is presented for capable of dynamically controlling EM waves, with multifunctional applications in the lower-frequency S-band. The metasurface is composed of electronically reconfigurable meta-atoms with wideband characteristics, and designed by using trapezoidal and M-shaped patches connected by a pin diode. Simulation results show that the proposed digital metasurface could achieve wideband 1-bit phase quantization with a stable phase difference within 180 degree +/- 25 degree and small reflection loss below 0.6 dB from 2.72 to 3.25 GHz. To validate the proposed design, a 20x20-unit metasurface array was designed, simulated and fabricated. By dynamically adjusting the coding sequence, the metasurface could enable multi-mode orbital angular momentum (OAM) beam generation, dynamic beam scanning, and precise direction finding. These capabilities support secure sensing and secure communications through high-resolution target detection and anti-jamming beam steering, as well as physical-layer security. The proposed wideband metasurface may serve as an effective candidate for enhancing spectral efficiency and security performance in radar and wireless systems.", "published": "2025-10-28T16:26:43Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:55.293291"}
{"arxiv_id": "2510.24422v1", "title": "Attack on a PUF-based Secure Binary Neural Network", "summary": "Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays provide energy-efficient solutions for edge computing but are susceptible to physical attacks due to memristor nonvolatility. Recently, Rajendran et al. (IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function (PUF)-based scheme to secure BNNs against theft attacks. Specifically, the weight and bias matrices of the BNN layers were secured by swapping columns based on device's PUF key bits.   In this paper, we demonstrate that this scheme to secure BNNs is vulnerable to PUF-key recovery attack. As a consequence of our attack, we recover the secret weight and bias matrices of the BNN. Our approach is motivated by differential cryptanalysis and reconstructs the PUF key bit-by-bit by observing the change in model accuracy, and eventually recovering the BNN model parameters. Evaluated on a BNN trained on the MNIST dataset, our attack could recover 85% of the PUF key, and recover the BNN model up to 93% classification accuracy compared to the original model's 96% accuracy. Our attack is very efficient and it takes a couple of minutes to recovery the PUF key and the model parameters.", "published": "2025-10-28T13:43:00Z", "query": "microelectrode arrays", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:17:55.294203"}
{"arxiv_id": "2510.24395v1", "title": "Optimising Underwater Neutrino Telescopes for All-Flavour Point Source   Sensitivity", "summary": "High-energy neutrino astronomy has advanced rapidly in recent years, with IceCube, KM3NeT, and Baikal-GVD establishing a diffuse astrophysical flux and pointing to promising source candidates. These achievements mark the transition from first detections to detailed source studies, motivating next-generation detectors with larger volumes, improved angular resolution, and full neutrino-flavour sensitivity. We present a performance study of large underwater neutrino telescopes, taking the proposed TRIDENT array in the South China Sea as a case study, with a focus on comparing the performance of various detector configurations against the TRIDENT baseline design. Both track-like events primarily from muon neutrinos, which provide precise directional information, and cascade events from all flavours, which offer superior energy resolution, diffuse-source sensitivity, and all-sky flavour coverage, are included to achieve a balanced performance across source types. The time to discover potential astrophysical sources with both track- and cascade-like events is used as the figure of merit to compare a variety of detector design choices. Our results show that, for a fixed number of optical modules, simply enlarging the instrumented volume does not inherently lead to improved performance, while taller strings can provide modest gains across all detector channels, within engineering constraints. Distributing dense clusters of strings over a large volume is found to generally worsen discovery potential compared to the baseline layout. Finally, the optical properties of the sea-water emerge as the key factor dictating the optimisation of detector layout, highlighting the need for in-situ measurements and early deployment of optical modules to guide the final array configuration.", "published": "2025-10-28T13:09:08Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:55.294646"}
{"arxiv_id": "2510.24393v1", "title": "Your Microphone Array Retains Your Identity: A Robust Voice Liveness   Detection System for Smart Speakers", "summary": "Though playing an essential role in smart home systems, smart speakers are vulnerable to voice spoofing attacks. Passive liveness detection, which utilizes only the collected audio rather than the deployed sensors to distinguish between live-human and replayed voices, has drawn increasing attention. However, it faces the challenge of performance degradation under the different environmental factors as well as the strict requirement of the fixed user gestures.   In this study, we propose a novel liveness feature, array fingerprint, which utilizes the microphone array inherently adopted by the smart speaker to determine the identity of collected audios. Our theoretical analysis demonstrates that by leveraging the circular layout of microphones, compared with existing schemes, array fingerprint achieves a more robust performance under the environmental change and user's movement. Then, to leverage such a fingerprint, we propose ARRAYID, a lightweight passive detection scheme, and elaborate a series of features working together with array fingerprint. Our evaluation on the dataset containing 32,780 audio samples and 14 spoofing devices shows that ARRAYID achieves an accuracy of 99.84%, which is superior to existing passive liveness detection schemes.", "published": "2025-10-28T13:05:30Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:17:55.294905"}
{"arxiv_id": "2510.24332v1", "title": "Sound Source Localization for Spatial Mapping of Surgical Actions in   Dynamic Scenes", "summary": "Purpose: Surgical scene understanding is key to advancing computer-aided and intelligent surgical systems. Current approaches predominantly rely on visual data or end-to-end learning, which limits fine-grained contextual modeling. This work aims to enhance surgical scene representations by integrating 3D acoustic information, enabling temporally and spatially aware multimodal understanding of surgical environments.   Methods: We propose a novel framework for generating 4D audio-visual representations of surgical scenes by projecting acoustic localization information from a phased microphone array onto dynamic point clouds from an RGB-D camera. A transformer-based acoustic event detection module identifies relevant temporal segments containing tool-tissue interactions which are spatially localized in the audio-visual scene representation. The system was experimentally evaluated in a realistic operating room setup during simulated surgical procedures performed by experts.   Results: The proposed method successfully localizes surgical acoustic events in 3D space and associates them with visual scene elements. Experimental evaluation demonstrates accurate spatial sound localization and robust fusion of multimodal data, providing a comprehensive, dynamic representation of surgical activity.   Conclusion: This work introduces the first approach for spatial sound localization in dynamic surgical scenes, marking a significant advancement toward multimodal surgical scene representations. By integrating acoustic and visual data, the proposed framework enables richer contextual understanding and provides a foundation for future intelligent and autonomous surgical systems.", "published": "2025-10-28T11:55:45Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:55.295150"}
{"arxiv_id": "2510.24212v1", "title": "Tracking the normal modes of an overpass highway bridge using   Distributed Acoustic Sensing", "summary": "Distributed Acoustic Sensing (DAS) of ambient vibrations is a promising technique in the context of structural health monitoring of civil engineering structures. The methodology uses Rayleigh backscattered light from small deformations at different locations of the sensed fiber-optic cable, turning it into a large array of equally distributed strain sensors. In this paper, we demonstrate the feasibility of using DAS technology to record dynamic strain used for modal identification through the Operational Modal Analysis (OMA) of a strut-frame bridge overpassing the A8 highway in southeastern France. Modal identification using DAS data is successful despite its predominantly axial sensitivity (along fiber), though the help of three-component seismometers is useful for discriminating the main motion direction of each identified mode. The identification of 1 bridge's normal modes with unprecedented spatial resolution is obtained from the lowest (transverse and longitudinal) modes to high-order modes that present significant vertical motion. In addition, strong seasonal effects are observed in both the absolute frequency values and the modal shapes of the first transverse and longitudinal modes of the bridge, comparing ambient vibration testing and DAS surveys carried out in the summer and winter periods.", "published": "2025-10-28T09:27:35Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:55.295353"}
{"arxiv_id": "2510.24132v1", "title": "New Nonuniform Group Divisible Designs and Mixed Steiner Systems", "summary": "This paper considers two closely related concepts, mixed Steiner system and nonuniform group divisible design (GDD). The distinction between the two concepts is the minimum Hamming distance, which is required for mixed Steiner systems but not required for nonuniform group divisible $t$-designs. In other words, it means that every mixed Steiner system is a nonuniform GDD, but the converse is not true. A new construction for mixed Steiner systems based on orthogonal arrays and resolvable Steiner systems is presented. Some of the new mixed Steiner systems (also GDDs) depend on the existence of Mersenne primes or Fermat primes. New parameters of nonuniform GDDs derived from large sets of H-designs (which are generalizations of GDDs) are presented, and in particular, many nonuniform group divisible $t$-designs with $t &gt; 3$ are introduced (for which only one family was known before). Some GDDs are with $t &gt; 4$, parameters for which no such design was known before.", "published": "2025-10-28T07:13:56Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:55.295579"}
{"arxiv_id": "2510.24016v1", "title": "The Geometry of Contraction-Induced Flows", "summary": "Peristalsis is the driving mechanism behind a broad array of biological and engineered flows. In peristaltic pumping, a wave-like contraction of the tube wall produces local changes in volume which induce flow. Net flow arises due to geometric nonlinearities in the momentum equation, which must be properly captured to compute the flow accurately. While most previous models focus on radius-imposed peristalsis, they often neglect longitudinal length changes - a natural consequence of radial contraction in elastic materials. In this paper, to capture a more accurate picture of peristaltic pumping, we calculate the flow in an elastic vessel undergoing contractions in the transverse and longitudinal directions simultaneously, keeping the geometric nonlinearities arising in the strain. A careful analysis requires us to study our fluid using the Lagrangian coordinates of the elastic tube. We perform analytic calculations of the flow characteristics by studying the fluid inside a fixed boundary with time-dependent metric. This mathematical manipulation works even for large-amplitude contractions, as we confirm by comparing our analytical results to COMSOL simulations. We demonstrate that transverse and longitudinal contractions induce instantaneous flows at the same order in wall strain, but in opposite directions. We investigate the influence of the wall's Poisson ratio on the flow profile. Incompressible walls suppress flow by minimizing local volume changes, whereas auxetic walls enhance flow. For radius-imposed peristaltic waves, wall incompressibility reduces both reflux and particle trapping. In contrast, length-imposed waves typically generate backflow, although trapping can still occur at large amplitudes for some Poisson ratios. These results yield a more complete description of peristalsis in elastic media and offer a framework for studying contraction-induced flows more broadly.", "published": "2025-10-28T02:51:18Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:55.295878"}
{"arxiv_id": "2510.23837v1", "title": "Coordinated Multipoint Transmission in Pinching Antenna Systems", "summary": "We study a coordinated multi-point (CoMP) transmission where two base stations (BSs), each supported by a pinching antenna system (PASS), are deployed to jointly serve communication users under spatial division multiple access (SDMA) technology. Pinching Antenna technology was introduced as a promising solution to overcome the large-scale fading that has been shown to be an impediment in multiple-input multiple-output (MIMO) systems. To realize the advantages of this technology in CoMP systems, which suffer from an upperbound rate limitation when traditional uniform linear arrays (ULAs) are adopted, we formulate an optimization problem with the aim of maximizing the achievable sum rate by jointly determining the transmit beamforming vectors and pinching locations on the waveguides while respecting the quality of service (QoS) requirements of users. This problem is inherently non-convex due to the strong coupling among its decision parameters, making it challenging to solve using traditional optimization methods. Thus, we utilize a gradient-based meta-learning (GML) strategy specifically designed for large-scale optimization tasks. Finally, numerical analysis demonstrates the effectiveness of the proposed GML approach, achieving 92 percent of the optimal solution, and the superiority of the solution presented compared to other benchmarks. In addition, it achieves a higher upper bound on the achievable rate compared to conventional CoMP systems.", "published": "2025-10-27T20:21:04Z", "query": "microelectrode arrays", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:55.296137"}
{"arxiv_id": "2510.23796v1", "title": "Topological protection of photon-pair generation in nonlinear waveguide   arrays", "summary": "Harnessing topological effects offers a promising route to protect quantum states of light from imperfections, potentially enabling more robust platforms for quantum information processing. This capability is particularly relevant for active photonic circuits that generate quantum light directly on-chip. Here, we explore topological effects on photon-pair generation via spontaneous parametric down-conversion (SPDC) in nonlinear waveguide arrays, both theoretically and experimentally. A systematic comparison of homogeneous, trivial, and topological Su-Schrieffer-Heeger arrays reveals that only the topological configuration preserves a stable SPDC resonance spectrum under disorder in the tunnel couplings, with fluctuations in the resonance position reduced by more than one order of magnitude. An analytical model supports our experimental observations by linking this robustness to the band-structure properties of the interacting modes. These findings establish quadratic nonlinear waveguide arrays as a promising platform to explore the interplay of nonlinearity, topology, and disorder in quantum photonic circuits.", "published": "2025-10-27T19:27:29Z", "query": "microelectrode arrays", "relevance": 0.15, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:55.296357"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.769354"}
{"arxiv_id": "2510.24645v1", "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in   Multi-Turn Function Calling", "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.", "published": "2025-10-28T17:15:26Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.770042"}
{"arxiv_id": "2510.24641v1", "title": "Density-driven scattering and valley splitting in undoped Si/SiGe   two-dimensional electron system", "summary": "Undoped Si-SiGe two-dimensional electron gas (2DEG) provide an ideal platform for hosting quantum-dot spin-qubits owing enhanced spin dephasing times and compatibility with standard CMOS technology. The strained Si quantum well reduces the valley degeneracy into two closely spaced ones. The existence of a near-degenerate valley state act as a leakage channel and compromises gate fidelity. A robust and uniform valley splitting across the entire chip is crucial for achieving scalability in the architecture and reliability in operation. Imperfections such as broadened interfaces, alloy disorders and atomic steps significantly compromise the valley splitting. The associated scattering mechanisms play detrimental roles in the performance of the qubits. In this manuscript, exploiting low-temperature magnetotransport measurements, we investigate the scattering mechanisms and valley splitting in a high-mobility undoped Si-SiGe 2DEG. At lower carrier densities, transport is limited by remote impurity scattering, whereas at higher densities, background impurity scattering near the quantum well dominates. Both the transport and quantum lifetimes of the charge carriers increase with carrier concentration, due to the enhancement in the impurity screening. Magnetic-field-induced confinement effect also is found to improve the valley splitting. Current-biasing measurements reveals the role of carrier heating in the visibility of valley splitting and reveal a temperature limited valley splitting of approximately 100 micro-eV. These results provide critical insight into scattering-dominated regimes and valley splitting in undoped Si-SiGe, advancing its potential for silicon-based quantum devices.", "published": "2025-10-28T17:07:26Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:58.770381"}
{"arxiv_id": "2510.24635v1", "title": "Electrochemical Electron Transfer: Key Concepts, Theories, and   Parameterization via Atomistic Simulations", "summary": "Electron transfer (ET) at electrochemical interfaces is central to energy conversion and storage, yet its theoretical and computational modeling remain active research areas. This review elucidates key concepts and theories of ET kinetics, focusing on coupling between classical solvent fluctuations and quantum electronic states of metallic electrodes and redox species. We begin with fundamental rate theories, reaction coordinates, and electrochemical timescales, then explore weak, strong, and intermediate electronic coupling regimes. Special attention is given to solvent dynamics and the structure of the electrical double layer (EDL), which critically impact ET kinetics. Atomistic simulations, particularly density functional theory (DFT) and molecular dynamics (MD), are highlighted for testing linear response and determining solvent reorganization energy, electronic coupling strengths, and solvent relaxation dynamics. A central theme is linear response enabling tractable treatments across Marcus theory, empirical valence bond (EVB) models, the Anderson-Newns-Schmickler framework, and generalized Langevin dynamics. While linear response offers useful simplifications, we assess its limitations, particularly for strong solvation changes or inner-sphere ET at catalytic interfaces. We discuss advances, including mapping Hamiltonian-based EVB-MD, constrained DFT, and non-Gaussian free energy formulations, enabling rigorous tests and access to diabatic and adiabatic free energy surfaces. We outline opportunities to advance multiscale, quantum-classical models that integrate EDL effects, multiple reaction coordinates, solvent-controlled dynamics, and transitions between adiabatic and nonadiabatic regimes. This review serves as a conceptual guide and practical resource for researchers integrating theory and simulation in studying electrochemical ET across diverse systems.", "published": "2025-10-28T17:02:22Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.770734"}
{"arxiv_id": "2510.24627v1", "title": "Enhanced Superconductivity in 2H-TaS2 Devices Through in-situ Molecular   Intercalation", "summary": "The intercalation of guest species into the gap of van der Waals materials often leads to the emergence of intriguing phenomena, such as superconductivity. While intercalation-induced superconductivity has been reported in several bulk crystals, reaching a zero-resistance state in flakes remains challenging. Here, we show a simple method for enhancing the superconducting transition in tens-of-nm thick 2H-TaS2 crystals contacted by gold electrodes through in-situ intercalation. Our approach enables measuring the electrical characteristics of the same flake before and after intercalation, permitting us to precisely identify the effect of the guest species on the TaS2 transport properties. We find that the intercalation of amylamine molecules into TaS2 flakes causes a suppression of the charge density wave and an increase in the superconducting transition, with an onset temperature above 3 K. Additionally, we show that a fully developed zero-resistance state can be achieved in flakes by engineering the conditions of the chemical intercalation. Our findings pave the way for the integration of chemically tailored intercalation compounds in scalable quantum technologies.", "published": "2025-10-28T16:57:29Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.771006"}
{"arxiv_id": "2510.24452v1", "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable   In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery", "summary": "Time series forecasting and anomaly detection are common tasks for practitioners in industries such as retail, manufacturing, advertising and energy. Two unique challenges stand out: (1) efficiently and accurately forecasting time series or detecting anomalies in large volumes automatically; and (2) ensuring interpretability of results to effectively incorporate business insights. We present ARIMA_PLUS, a novel framework to overcome these two challenges by a unique combination of (a) accurate and interpretable time series models and (b) scalable and fully managed system infrastructure. The model has a sequential and modular structure to handle different components of the time series, including holiday effects, seasonality, trend, and anomalies, which enables high interpretability of the results. Novel enhancements are made to each module, and a unified framework is established to address both forecasting and anomaly detection tasks simultaneously. In terms of accuracy, its comprehensive benchmark on the 42 public datasets in the Monash forecasting repository shows superior performance over not only well-established statistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer neural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms of infrastructure, it is directly built into the query engine of BigQuery in Google Cloud. It uses a simple SQL interface and automates tedious technicalities such as data cleaning and model selection. It automatically scales with managed cloud computational and storage resources, making it possible to forecast 100 million time series using only 1.5 hours with a throughput of more than 18000 time series per second. In terms of interpretability, we present several case studies to demonstrate time series insights it generates and customizability it offers.", "published": "2025-10-28T14:18:50Z", "query": "optogenetics interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:17:58.771276"}
{"arxiv_id": "2510.24378v1", "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular,   Lightweight, and Deployment-Ready Tool", "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance in brain lesion segmentation but remain difficult to deploy clinically due to heavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a modular and lightweight framework that translates research-grade stroke lesion segmentation models into deployable applications. Preprocessing, inference, and postprocessing are decoupled: preprocessing relies on the Anima toolbox with BIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16} quantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides both graphical and command-line interfaces and is distributed as Python scripts and as a standalone Windows executable. On a held-out set of 300 sub-acute and chronic stroke subjects, segmentation performance was equivalent to the original PyTorch pipeline (Dice difference $&lt;10^{-3}$), demonstrating that high-performing research pipelines can be transformed into portable, clinically usable tools.", "published": "2025-10-28T12:56:48Z", "query": "optogenetics interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.771514"}
{"arxiv_id": "2510.24363v1", "title": "Quarkiton: a one-quark state near a boundary of confinement phase of QCD", "summary": "We discuss a one-quark state in the confinement phase near a reflective chromometallic boundary both at finite and zero temperature. Using numerical simulations of lattice Yang-Mills theory, we show that the test quark is confined to the neutral mirror by an attractive potential of the Cornell type, suggesting the existence of a mirror-bound one-quark state, a \"quarkiton\". Surprisingly, the tension of the string spanned between the quark and the mirror is lower than the fundamental string tension. The quarkiton state exhibits a partial confinement: while the quark is localized in the vicinity of the mirror, it can still travel freely along it. Such quarkiton states share similarity with the surface excitons in metals and semiconductors that are bound to their negatively charged images at a boundary. The quarkitons can exist at the hadronic side of the phase interfaces in QCD that arise, for example, in the thermodynamic equilibrium of vortical quark-gluon plasma.", "published": "2025-10-28T12:36:35Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.771721"}
{"arxiv_id": "2510.24356v1", "title": "Perception Learning: A Formal Separation of Sensory Representation   Learning from Decision Learning", "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's sensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic signals, decoupled from downstream decision learning $g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free perceptual properties, such as stability to nuisances, informativeness without collapse, and controlled geometry, assessed via objective representation-invariant metrics. We formalize the separation of perception and decision, define perceptual properties independent of objectives or reparameterizations, and prove that PeL updates preserving sufficient invariants are orthogonal to Bayes task-risk gradients. Additionally, we provide a suite of task-agnostic evaluation metrics to certify perceptual quality.", "published": "2025-10-28T12:19:49Z", "query": "optogenetics interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.771921"}
{"arxiv_id": "2510.24294v1", "title": "Phase-Rotated Altermagnets as Chern Valves for Topological Transport", "summary": "Motivated by the emerging control of Berry-curvature textures in altermagnets, we explore a two-terminal configuration where a topological-insulator film is interfaced with two altermagnetic electrodes whose crystalline phases can be rotated independently. The proximity coupling imprints each momentum-dependent of the altermagnet spin texture onto the Dirac surface states, giving rise to an angular mass whose sign follows the lattice orientation. Adjusting the phase of one electrode redefines this mass pattern, thereby tuning the number and spatial distribution of chiral edge channels. This results in discrete conductance steps and a reversible inversion of the thermoelectric coefficient-achieved without external magnetic fields or net magnetization. A compact Dirac model captures both the quantized switching and its resilience to moderate disorder. Overall, this symmetry-driven mechanism provides a practical and low-dissipation route to programmable topological transport via lattice rotation.", "published": "2025-10-28T10:56:31Z", "query": "optogenetics interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:17:58.772125"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural recording technology", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:02.246640"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural recording technology", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:02.247356"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural recording technology", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:02.247755"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "neural recording technology", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:02.247986"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "neural recording technology", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:02.248261"}
{"arxiv_id": "2510.24656v1", "title": "Virtual Gates Enabled by Digital Surrogate of Quantum Dot Devices", "summary": "Advances in quantum technologies are often limited by slow device characterization, complex tuning require- ments, and scalability challenges. Spin qubits in electrostatically defined quantum dots provide a promising platform but are not exempt from these limitations. Simulations enhance our understanding of such devices, and in many cases, rapid feedback between measurements and simulations can guide the development of op- timal design and control strategies. Here, we introduce a modular, graph-based simulator that acts as a digital surrogate for a semiconductor quantum dot device, where computationally expensive processes are accelerated using deep learning. We demonstrate its potential by estimating crosstalk effects between gate electrodes and applying these estimates to construct virtual gates in a quantum dot device. We validate our approach through comparison with experiments on a double quantum dot defined in a Ge/SiGe heterostructure. We envision that this simulation framework will advance semiconductor-based quantum technologies by enabling more efficient design, characterization, and control of complex devices.", "published": "2025-10-28T17:22:20Z", "query": "neural recording technology", "relevance": 0.05, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:02.248574"}
{"arxiv_id": "2510.24654v1", "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment", "summary": "In this paper, we present a framework for training large language models (LLMs) as diagnostic agents with reinforcement learning, enabling them to manage multi-turn diagnostic processes, adaptively select examinations, and commit to final diagnoses. Unlike instruction-tuned models trained on static case summaries, our method acquires diagnostic strategies through interactive exploration and outcome-based feedback. Our contributions are fourfold: (i) We present DiagGym, a diagnostics world model trained with electronic health records that emits examination outcomes conditioned on patient history and recommended examination, serving as a virtual clinical environment for realistic diagnosis training and evaluation; (ii) We train DiagAgent via end-to-end, multi-turn reinforcement learning to learn diagnostic policies that optimize both information yield and diagnostic accuracy; (iii) We introduce DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated examination recommendations and 99 cases annotated with 973 physician-written rubrics on diagnosis process; (iv) we demonstrate superior performance across diverse diagnostic settings. DiagAgent significantly outperforms 10 state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34% higher diagnostic accuracy and 44.03% improvement in examination recommendation hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic accuracy and 23.09% boost in examination recommendation F1 score. In rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by 7.1% in weighted rubric score. These findings indicate that learning policies in interactive clinical environments confers dynamic and clinically meaningful diagnostic management abilities unattainable through passive training alone.", "published": "2025-10-28T17:19:47Z", "query": "neural recording technology", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:02.248876"}
{"arxiv_id": "2510.24653v1", "title": "Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making   Datasets in Digital Pathology", "summary": "Interpretation of giga-pixel whole-slide images (WSIs) is an important but difficult task for pathologists. Their diagnostic accuracy is estimated to average around 70%. Adding a second pathologist does not substantially improve decision consistency. The field lacks adequate behavioral data to explain diagnostic errors and inconsistencies. To fill in this gap, we present PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual search and decision-making processes of the full diagnostic workflow during cancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse interaction, stimulus tracking, viewport navigation, and diagnostic decision data (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data collection process emphasizes ecological validity through an application-grounded testbed, called PTAH. In total, we recorded 171,909 fixations, 263,320 saccades, and 1,867,362 mouse interaction events. In addition, such data could also be used to improve the training of both pathologists and AI systems that might support human experts. All experiments were preregistered at https://osf.io/hj9a7, and the complete dataset along with analysis code is available at https://go.osu.edu/pathogaze.", "published": "2025-10-28T17:18:43Z", "query": "neural recording technology", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:02.249064"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "neural recording technology", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:02.249270"}
{"arxiv_id": "2510.24641v1", "title": "Density-driven scattering and valley splitting in undoped Si/SiGe   two-dimensional electron system", "summary": "Undoped Si-SiGe two-dimensional electron gas (2DEG) provide an ideal platform for hosting quantum-dot spin-qubits owing enhanced spin dephasing times and compatibility with standard CMOS technology. The strained Si quantum well reduces the valley degeneracy into two closely spaced ones. The existence of a near-degenerate valley state act as a leakage channel and compromises gate fidelity. A robust and uniform valley splitting across the entire chip is crucial for achieving scalability in the architecture and reliability in operation. Imperfections such as broadened interfaces, alloy disorders and atomic steps significantly compromise the valley splitting. The associated scattering mechanisms play detrimental roles in the performance of the qubits. In this manuscript, exploiting low-temperature magnetotransport measurements, we investigate the scattering mechanisms and valley splitting in a high-mobility undoped Si-SiGe 2DEG. At lower carrier densities, transport is limited by remote impurity scattering, whereas at higher densities, background impurity scattering near the quantum well dominates. Both the transport and quantum lifetimes of the charge carriers increase with carrier concentration, due to the enhancement in the impurity screening. Magnetic-field-induced confinement effect also is found to improve the valley splitting. Current-biasing measurements reveals the role of carrier heating in the visibility of valley splitting and reveal a temperature limited valley splitting of approximately 100 micro-eV. These results provide critical insight into scattering-dominated regimes and valley splitting in undoped Si-SiGe, advancing its potential for silicon-based quantum devices.", "published": "2025-10-28T17:07:26Z", "query": "neural recording technology", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:02.249530"}
{"arxiv_id": "2510.24718v1", "title": "Generative View Stitching", "summary": "Autoregressive video diffusion models are capable of long rollouts that are stable and consistent with history, but they are unable to guide the current generation with conditioning from the future. In camera-guided video generation with a predefined camera trajectory, this limitation leads to collisions with the generated scene, after which autoregression quickly collapses. To address this, we propose Generative View Stitching (GVS), which samples the entire sequence in parallel such that the generated scene is faithful to every part of the predefined camera trajectory. Our main contribution is a sampling algorithm that extends prior work on diffusion stitching for robot planning to video generation. While such stitching methods usually require a specially trained model, GVS is compatible with any off-the-shelf video model trained with Diffusion Forcing, a prevalent sequence diffusion framework that we show already provides the affordances necessary for stitching. We then introduce Omni Guidance, a technique that enhances the temporal consistency in stitching by conditioning on both the past and future, and that enables our proposed loop-closing mechanism for delivering long-range coherence. Overall, GVS achieves camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and closes loops for a variety of predefined camera paths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best viewed as videos at https://andrewsonga.github.io/gvs.", "published": "2025-10-28T17:59:58Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:05.731618"}
{"arxiv_id": "2510.24711v1", "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit   Routing Guidance", "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity while preserving computational efficiency. Despite its notable success in large language models (LLMs), existing attempts to apply MoE to Diffusion Transformers (DiTs) have yielded limited gains. We attribute this gap to fundamental differences between language and visual tokens. Language tokens are semantically dense with pronounced inter-token variation, while visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization in vision MoE. To this end, we present ProMoE, an MoE framework featuring a two-step router with explicit routing guidance that promotes expert specialization. Specifically, this guidance encourages the router to partition image tokens into conditional and unconditional sets via conditional routing according to their functional roles, and refine the assignments of conditional image tokens through prototypical routing with learnable prototypes based on semantic content. Moreover, the similarity-based expert allocation in latent space enabled by prototypical routing offers a natural mechanism for incorporating explicit semantic guidance, and we validate that such guidance is crucial for vision MoE. Building on this, we propose a routing contrastive loss that explicitly enhances the prototypical routing process, promoting intra-expert coherence and inter-expert diversity. Extensive experiments on ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives. Code and models will be made publicly available.", "published": "2025-10-28T17:59:02Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:05.732197"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "cognitive enhancement neuroscience", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:05.732536"}
{"arxiv_id": "2510.24706v1", "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?", "summary": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.", "published": "2025-10-28T17:55:42Z", "query": "cognitive enhancement neuroscience", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:05.732801"}
{"arxiv_id": "2510.24698v1", "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking", "summary": "Parallel thinking expands exploration breadth, complementing the deep exploration of information-seeking (IS) agents to further enhance problem-solving capability. However, conventional parallel thinking faces two key challenges in this setting: inefficiency from repeatedly rolling out from scratch, and difficulty in integrating long-horizon reasoning trajectories during answer generation, as limited context capacity prevents full consideration of the reasoning process. To address these issues, we propose ParallelMuse, a two-stage paradigm designed for deep IS agents. The first stage, Functionality-Specified Partial Rollout, partitions generated sequences into functional regions and performs uncertainty-guided path reuse and branching to enhance exploration efficiency. The second stage, Compressed Reasoning Aggregation, exploits reasoning redundancy to losslessly compress information relevant to answer derivation and synthesize a coherent final answer. Experiments across multiple open-source agents and benchmarks demonstrate up to 62% performance improvement with a 10--30% reduction in exploratory token consumption.", "published": "2025-10-28T17:51:50Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:05.733047"}
{"arxiv_id": "2510.24699v1", "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "summary": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.", "published": "2025-10-28T17:51:50Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:05.733296"}
{"arxiv_id": "2510.24690v1", "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework   for In-Context Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools and documents to enhance exemplar artifact generation. Our method begins by constructing a tool knowledge graph from tool schemas,including descriptions, arguments, and output payloads, using a DeepResearch-inspired analysis. In parallel, we derive a complementary knowledge graph from internal documents and SOPs, which is then fused with the tool graph. To generate exemplar plans, we adopt a deep-sparse integration strategy that aligns structural tool dependencies with procedural knowledge. Experiments demonstrate that this unified framework effectively models tool interactions and improves plan generation, underscoring the benefits of linking tool graphs with domain knowledge graphs for tool-augmented reasoning and planning.", "published": "2025-10-28T17:50:15Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:05.733489"}
{"arxiv_id": "2510.24688v1", "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with   Relation-Aware Fusion for 3D Object Detection", "summary": "Infrastructure-based perception plays a crucial role in intelligent transportation systems, offering global situational awareness and enabling cooperative autonomy. However, existing camera-based detection models often underperform in such scenarios due to challenges such as multi-view infrastructure setup, diverse camera configurations, degraded visual inputs, and various road layouts. We introduce MIC-BEV, a Transformer-based bird's-eye-view (BEV) perception framework for infrastructure-based multi-camera 3D object detection. MIC-BEV flexibly supports a variable number of cameras with heterogeneous intrinsic and extrinsic parameters and demonstrates strong robustness under sensor degradation. The proposed graph-enhanced fusion module in MIC-BEV integrates multi-view image features into the BEV space by exploiting geometric relationships between cameras and BEV cells alongside latent visual cues. To support training and evaluation, we introduce M2I, a synthetic dataset for infrastructure-based object detection, featuring diverse camera configurations, road layouts, and environmental conditions. Extensive experiments on both M2I and the real-world dataset RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D object detection. It also remains robust under challenging conditions, including extreme weather and sensor degradation. These results highlight the potential of MIC-BEV for real-world deployment. The dataset and source code are available at: https://github.com/HandsomeYun/MIC-BEV.", "published": "2025-10-28T17:49:42Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:05.733730"}
{"arxiv_id": "2510.24677v1", "title": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation", "summary": "Large language models (LLMs) have gained significant traction in medical decision support systems, particularly in the   context of medical question answering and role-playing simulations. A common practice, Prompt-Based Role Playing (PBRP),   instructs models to adopt different clinical roles (e.g., medical students, residents, attending physicians) to simulate varied   professional behaviors. However, the impact of such role prompts on model reasoning capabilities remains unclear. This   study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to evaluate whether role prompts induce distinct,   role-specific cognitive processes in LLMs or merely modify linguistic style. We test this framework on three medical QA   datasets, employing neuron ablation and representation analysis techniques to assess changes in reasoning pathways. Our   results demonstrate that role prompts do not significantly enhance the medical reasoning abilities of LLMs. Instead, they   primarily affect surface-level linguistic features, with no evidence of distinct reasoning pathways or cognitive differentiation   across clinical roles. Despite superficial stylistic changes, the core decision-making mechanisms of LLMs remain uniform   across roles, indicating that current PBRP methods fail to replicate the cognitive complexity found in real-world medical   practice. This highlights the limitations of role-playing in medical AI and emphasizes the need for models that simulate genuine   cognitive processes rather than linguistic imitation.We have released the related code in the following repository:https:   //github.com/IAAR-Shanghai/RolePlay_LLMDoctor", "published": "2025-10-28T17:40:53Z", "query": "cognitive enhancement neuroscience", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:05.734371"}
{"arxiv_id": "2510.24671v1", "title": "Multi-Agent Scenario Generation in Roundabouts with a   Transformer-enhanced Conditional Variational Autoencoder", "summary": "With the increasing integration of intelligent driving functions into serial-produced vehicles, ensuring their functionality and robustness poses greater challenges. Compared to traditional road testing, scenario-based virtual testing offers significant advantages in terms of time and cost efficiency, reproducibility, and exploration of edge cases. We propose a Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for generating multi-agent traffic scenarios in roundabouts, which are characterized by high vehicle dynamics and complex layouts, yet remain relatively underexplored in current research. The results show that the proposed model can accurately reconstruct original scenarios and generate realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators (KPIs) are employed to evaluate the interactive behavior in the generated scenarios. Analysis of the latent space reveals partial disentanglement, with several latent dimensions exhibiting distinct and interpretable effects on scenario attributes such as vehicle entry timing, exit timing, and velocity profiles. The results demonstrate the model's capability to generate scenarios for the validation of intelligent driving functions involving multi-agent interactions, as well as to augment data for their development and iterative improvement.", "published": "2025-10-28T17:36:52Z", "query": "cognitive enhancement neuroscience", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:05.734767"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "brain augmentation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:09.162608"}
{"arxiv_id": "2510.24710v1", "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel   Optimization", "summary": "We study bilevel optimization problems where the lower-level problems are strongly convex and have coupled linear constraints. To overcome the potential non-smoothness of the hyper-objective and the computational challenges associated with the Hessian matrix, we utilize penalty and augmented Lagrangian methods to reformulate the original problem as a single-level one. Especially, we establish a strong theoretical connection between the reformulated function and the original hyper-objective by characterizing the closeness of their values and derivatives. Based on this reformulation, we propose a single-loop, first-order algorithm for linearly constrained bilevel optimization (SFLCB). We provide rigorous analyses of its non-asymptotic convergence rates, showing an improvement over prior double-loop algorithms -- form $O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments corroborate our theoretical findings and demonstrate the practical efficiency of the proposed SFLCB algorithm. Simulation code is provided at https://github.com/ShenGroup/SFLCB.", "published": "2025-10-28T17:58:17Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:09.163254"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "brain augmentation", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:09.163718"}
{"arxiv_id": "2510.24690v1", "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework   for In-Context Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools and documents to enhance exemplar artifact generation. Our method begins by constructing a tool knowledge graph from tool schemas,including descriptions, arguments, and output payloads, using a DeepResearch-inspired analysis. In parallel, we derive a complementary knowledge graph from internal documents and SOPs, which is then fused with the tool graph. To generate exemplar plans, we adopt a deep-sparse integration strategy that aligns structural tool dependencies with procedural knowledge. Experiments demonstrate that this unified framework effectively models tool interactions and improves plan generation, underscoring the benefits of linking tool graphs with domain knowledge graphs for tool-augmented reasoning and planning.", "published": "2025-10-28T17:50:15Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:09.164043"}
{"arxiv_id": "2510.24671v1", "title": "Multi-Agent Scenario Generation in Roundabouts with a   Transformer-enhanced Conditional Variational Autoencoder", "summary": "With the increasing integration of intelligent driving functions into serial-produced vehicles, ensuring their functionality and robustness poses greater challenges. Compared to traditional road testing, scenario-based virtual testing offers significant advantages in terms of time and cost efficiency, reproducibility, and exploration of edge cases. We propose a Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for generating multi-agent traffic scenarios in roundabouts, which are characterized by high vehicle dynamics and complex layouts, yet remain relatively underexplored in current research. The results show that the proposed model can accurately reconstruct original scenarios and generate realistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators (KPIs) are employed to evaluate the interactive behavior in the generated scenarios. Analysis of the latent space reveals partial disentanglement, with several latent dimensions exhibiting distinct and interpretable effects on scenario attributes such as vehicle entry timing, exit timing, and velocity profiles. The results demonstrate the model's capability to generate scenarios for the validation of intelligent driving functions involving multi-agent interactions, as well as to augment data for their development and iterative improvement.", "published": "2025-10-28T17:36:52Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:09.164415"}
{"arxiv_id": "2510.24652v1", "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning", "summary": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the role of information retrieval (IR) is shifting from retrieving information for human users to retrieving contextual knowledge for artificial intelligence (AI) systems, where relevance becomes difficult to define or annotate beforehand. To address this challenge, we propose R3, a Retrieval framework optimized for RAG through trialand-feedback Reinforced contrastive learning. Unlike prior approaches that rely on annotated or synthetic data for supervised fine-tuning, R3 enables the retriever to dynamically explore and optimize relevance within the RAG environment. During training, the retrieved results interact with the environment to produce contrastive signals that automatically guide the retriever's self-improvement. Extensive experiments across diverse tasks demonstrate that R3 improves RAG performance by 5.2% over the original retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving comparable results to LLM-augmented retrieval and RAG systems built on post-trained or instruction-tuned LLMs. It is both efficient and practical, requiring only 4 GPUs and completing training within a single day.", "published": "2025-10-28T17:18:30Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:09.164731"}
{"arxiv_id": "2510.24639v1", "title": "Causal Ordering for Structure Learning From Time Series", "summary": "Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.", "published": "2025-10-28T17:06:15Z", "query": "brain augmentation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:09.165185"}
{"arxiv_id": "2510.24636v1", "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement   Learning", "summary": "Reward models (RMs) have become essential for aligning large language models (LLMs), serving as scalable proxies for human evaluation in both training and inference. However, existing RMs struggle on knowledge-intensive and long-form tasks, where evaluating correctness requires grounding beyond the model's internal knowledge. This limitation hinders them from reliably discriminating subtle quality differences, especially when external evidence is necessary. To address this, we introduce OpenRM, a tool-augmented long-form reward model that systematically judges open-ended responses by invoking external tools to gather relevant evidence. We train OpenRM with Group Relative Policy Optimization (GRPO) on over 27K synthesized pairwise examples generated through a controllable data synthesis framework. The training objective jointly supervises intermediate tool usage and final outcome accuracy, incentivizing our reward model to learn effective evidence-based judgment strategies. Extensive experiments on three newly-collected datasets and two widely-used benchmarks demonstrate that OpenRM substantially outperforms existing reward modeling approaches. As a further step, we integrate OpenRM into both inference-time response selection and training-time data selection. This yields consistent gains in downstream LLM alignment tasks, highlighting the potential of tool-augmented reward models for scaling reliable long-form evaluation.", "published": "2025-10-28T17:02:46Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:09.165555"}
{"arxiv_id": "2510.24614v1", "title": "Semi-supervised and unsupervised learning for health indicator   extraction from guided waves in aerospace composite structures", "summary": "Health indicators (HIs) are central to diagnosing and prognosing the condition of aerospace composite structures, enabling efficient maintenance and operational safety. However, extracting reliable HIs remains challenging due to variability in material properties, stochastic damage evolution, and diverse damage modes. Manufacturing defects (e.g., disbonds) and in-service incidents (e.g., bird strikes) further complicate this process. This study presents a comprehensive data-driven framework that learns HIs via two learning approaches integrated with multi-domain signal processing. Because ground-truth HIs are unavailable, a semi-supervised and an unsupervised approach are proposed: (i) a diversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach augmented with continuous auxiliary labels used as hypothetical damage proxies, which overcomes the limitation of prior binary labels that only distinguish healthy and failed states while neglecting intermediate degradation, and (ii) a degradation-trend-constrained variational autoencoder (DTC-VAE), in which the monotonicity criterion is embedded via an explicit trend constraint. Guided waves with multiple excitation frequencies are used to monitor single-stiffener composite structures under fatigue loading. Time, frequency, and time-frequency representations are explored, and per-frequency HIs are fused via unsupervised ensemble learning to mitigate frequency dependence and reduce variance. Using fast Fourier transform features, the augmented Diversity-DeepSAD model achieved 81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3% performance, outperforming existing baselines.", "published": "2025-10-28T16:44:11Z", "query": "brain augmentation", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:09.165877"}
{"arxiv_id": "2510.24510v1", "title": "Evaluating Fitness Averaging Strategies in Cooperative NeuroCoEvolution   for Automated Soft Actuator Design", "summary": "Soft robotics are increasingly favoured in specific applications such as healthcare, due to their adaptability, which stems from the non-linear properties of their building materials. However, these properties also pose significant challenges in designing the morphologies and controllers of soft robots. The relatively short history of this field has not yet produced sufficient knowledge to consistently derive optimal solutions. Consequently, an automated process for the design of soft robot morphologies can be extremely helpful. This study focusses on the cooperative NeuroCoEvolution of networks that are indirect representations of soft robot actuators. Both the morphologies and controllers represented by Compositional Pattern Producing Networks are evolved using the well-established method NeuroEvolution of Augmented Topologies (CPPN-NEAT). The CoEvolution of controllers and morphologies is implemented using the top n individuals from the cooperating population, with various averaging methods tested to determine the fitness of the evaluated individuals. The test-case application for this research is the optimisation of a soft actuator for a drug delivery system. The primary metric used is the maximum displacement of one end of the actuator in a specified direction. Additionally, the robustness of the evolved morphologies is assessed against a range of randomly generated controllers to simulate potential noise in real-world applications. The results of this investigation indicate that CPPN-NEAT produces superior morphologies compared to previously published results from multi-objective optimisation, with reduced computational effort and time. Moreover, the best configuration is found to be CoEvolution with the two best individuals from the cooperative population and the averaging of their fitness using the weighted mean method.", "published": "2025-10-28T15:22:26Z", "query": "brain augmentation", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:09.166239"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:12.798848"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:12.799746"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:12.800405"}
{"arxiv_id": "2510.24688v1", "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with   Relation-Aware Fusion for 3D Object Detection", "summary": "Infrastructure-based perception plays a crucial role in intelligent transportation systems, offering global situational awareness and enabling cooperative autonomy. However, existing camera-based detection models often underperform in such scenarios due to challenges such as multi-view infrastructure setup, diverse camera configurations, degraded visual inputs, and various road layouts. We introduce MIC-BEV, a Transformer-based bird's-eye-view (BEV) perception framework for infrastructure-based multi-camera 3D object detection. MIC-BEV flexibly supports a variable number of cameras with heterogeneous intrinsic and extrinsic parameters and demonstrates strong robustness under sensor degradation. The proposed graph-enhanced fusion module in MIC-BEV integrates multi-view image features into the BEV space by exploiting geometric relationships between cameras and BEV cells alongside latent visual cues. To support training and evaluation, we introduce M2I, a synthetic dataset for infrastructure-based object detection, featuring diverse camera configurations, road layouts, and environmental conditions. Extensive experiments on both M2I and the real-world dataset RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D object detection. It also remains robust under challenging conditions, including extreme weather and sensor degradation. These results highlight the potential of MIC-BEV for real-world deployment. The dataset and source code are available at: https://github.com/HandsomeYun/MIC-BEV.", "published": "2025-10-28T17:49:42Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:12.800975"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:12.801478"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:12.802066"}
{"arxiv_id": "2510.24670v1", "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location", "summary": "Accurately predicting the three-dimensional structures of protein-ligand complexes remains a fundamental challenge in computational drug discovery that limits the pace and success of therapeutic design. Deep learning methods have recently shown strong potential as structural prediction tools, achieving promising accuracy across diverse biomolecular systems. However, their performance and utility are constrained by scarce experimental data, inefficient architectures, physically invalid poses, and the limited ability to exploit auxiliary information available at inference. To address these issues, we introduce Pearl (Placing Every Atom in the Right Location), a foundation model for protein-ligand cofolding at scale. Pearl addresses these challenges with three key innovations: (1) training recipes that include large-scale synthetic data to overcome data scarcity; (2) architectures that incorporate an SO(3)-equivariant diffusion module to inherently respect 3D rotational symmetries, improving generalization and sample efficiency, and (3) controllable inference, including a generalized multi-chain templating system supporting both protein and non-polymeric components as well as dual unconditional/conditional modes. Pearl establishes a new state-of-the-art performance in protein-ligand cofolding. On the key metric of generating accurate (RMSD &lt; 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold 3 and other open source baselines on the public Runs N' Poses and PoseBusters benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the next best model. In the pocket-conditional cofolding regime, Pearl delivers $3.6\\times$ improvement on a proprietary set of challenging, real-world drug targets at the more rigorous RMSD &lt; 1 \\r{A} threshold. Finally, we demonstrate that model performance correlates directly with synthetic dataset size used in training.", "published": "2025-10-28T17:36:51Z", "query": "neural modulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:12.802680"}
{"arxiv_id": "2510.24657v1", "title": "Group Relative Attention Guidance for Image Editing", "summary": "Recently, image editing based on Diffusion-in-Transformer models has undergone rapid development. However, existing editing methods often lack effective control over the degree of editing, limiting their ability to achieve more customized results. To address this limitation, we investigate the MM-Attention mechanism within the DiT model and observe that the Query and Key tokens share a bias vector that is only layer-dependent. We interpret this bias as representing the model's inherent editing behavior, while the delta between each token and its corresponding bias encodes the content-specific editing signals. Based on this insight, we propose Group Relative Attention Guidance, a simple yet effective method that reweights the delta values of different tokens to modulate the focus of the model on the input image relative to the editing instruction, enabling continuous and fine-grained control over editing intensity without any tuning. Extensive experiments conducted on existing image editing frameworks demonstrate that GRAG can be integrated with as few as four lines of code, consistently enhancing editing quality. Moreover, compared to the commonly used Classifier-Free Guidance, GRAG achieves smoother and more precise control over the degree of editing. Our code will be released at https://github.com/little-misfit/GRAG-Image-Editing.", "published": "2025-10-28T17:22:44Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:12.803123"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "neural modulation", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:12.803537"}
{"arxiv_id": "2510.24649v1", "title": "Local Electromagnetic Fields Enable Fast Redox Sensing by Physically   Accelerating Cysteine Oxidation", "summary": "Hydrogen peroxide oxidises cysteine residues to control protein function, yet bulk rate constants predict hours for changes that occur in cells in seconds. Here, this work shows that local electromagnetic fields (EMFs), ubiquitous in proteins, membranes and nanodomains, can lawfully modulate the Eyring barrier and orientate reactants, accelerating cysteine oxidation without changing the underlying chemistry. Embedding a field term into the Eyring expression, demonstrated that plausible local EMFs with realistic dipole changes accelerate rate constants by orders of magnitude. This local acceleration reconciles the discrepancy between predicted vs. observed rates of H2O2-mediated cysteine oxidation. The framework generates falsifiable predictions, such as vibrational Stark readouts in thiolate peroxide complexes should fall within predicted ranges, and reframes rate-constants as mutable, field conditioned parameters. Cysteine redox sensing is fast not because the chemistry is exotic, but because the physics is local.", "published": "2025-10-28T17:16:33Z", "query": "neural modulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:12.803962"}
{"arxiv_id": "2510.23290v1", "title": "Group-Level and Personalized Optimization for the Insula and Hippocampus   Focal Electric Field in Transcranial Temporal Interferential Stimulation: A   Computational Study", "summary": "This study evaluated transcranial temporal interference stimulation (tTIS) for focal targeting of the insula and hippocampus, which are clinically relevant yet anatomically difficult to stimulate. Individualized and group-level electrode optimizations were compared to determine whether generalized montages can provide reliable targeting with reduced modeling demands. Sixty high-resolution head models (30 individuals and their mirrored counterparts) were constructed from T1- and T2-weighted MRI. Electric fields (EFs) were computed using the scalar-potential finite-difference method. Electrode montages and current ratios were optimized to minimize the root-mean-square error between simulated and target EF envelope (EFE) distributions, with a threshold of 0.3 V/m. Subsampling analysis was performed to estimate the number of models required for stable group-level outcomes. For the insula, a montage combining T7-P7 and Fp1-Fp2 achieved the highest focality, comparable to individualized results with reduced variability. For the hippocampus, the F7-T7 and T8-P8 montage gave the best group-level focality, though individualized optimization improved off-target suppression. Stable group-level patterns were obtained using 20 models for the insula and 9 for the hippocampus. Optimal tTIS montages depend on target depth. Group-level optimization suffices for cortical regions like the insula, whereas individualized tuning remains preferable for deeper targets such as the hippocampus.", "published": "2025-10-27T13:00:28Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:18:16.311232"}
{"arxiv_id": "2510.22875v1", "title": "Control of Valence Electron Motion in Xe Cation Using Stimulated Raman   Adiabatic Passage Technique", "summary": "This work theoretically investigates possibilities of using the Stimulated Raman Adiabatic Passage (STIRAP) and its variants to control a coherent superposition of quantum states. We present a generalization of the so-called fractional STIRAP (f-STIRAP), demonstrating precise control over the mixing ratio of quantum states in the wave packet. In contrast to conventional f-STIRAP, designed to drive a system from an eigenstate into a coherent superposition, our scheme enables arbitrary control over the composition of an already existing superposition state. We demonstrate that an approximate version of this technique -- where analytically designed laser pulses with composite envelopes are replaced by simple Gaussian pulses -- achieves comparable performance in controlling the dynamics of the wave packet. A limiting case of this scheme, utilizing two pulses with identical Gaussians envelopes and tuned delay and relative phase, is also explored, revealing experimentally accessible pathways for manipulating quantum coherence. We apply our developed techniques to control the ultrafast charge migration in the spin-orbit split ground electronic states of xenon cation via intermediate valence- and core-excited states. Finally, we propose concrete experimental realizations of the developed control schemes in combination with attosecond transient absorption spectroscopy as a method to probe the system.", "published": "2025-10-26T23:57:18Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:16.312205"}
{"arxiv_id": "2510.21692v1", "title": "Can Bose-Einstein condensates enhance radioactive decay?", "summary": "This paper lays out the principles of how Bose-Einstein condensates can modify radioactive decay. We highlight the challenges of many modes and short coherence times due to the $\\approx$ MeV energies of the emitted radiation. Recent proposals for gamma ray and neutrino lasers claim that using a Bose-Einstein condensate as a source would solve these issues. We show that this is not the case, and the proposed experiments would have a gain of only $10^{-20}$ or smaller. We also analyze proposals for gamma ray lasers based on stimulated annihilation of positronium Bose-Einstein condensates.", "published": "2025-10-24T17:51:05Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:16.312668"}
{"arxiv_id": "2510.21265v1", "title": "EEG Dynamic Microstate Patterns Induced by Pulsed Wave Transcranial   Photobiomodulation Therapy", "summary": "Transcranial photobiomodulation (tPBM) therapy is an emerging, non-invasive neuromodulation technique that has demonstrated considerable potential in the field of neuropsychiatric disorders. Several studies have found that pulsed wave (PW) tPBM therapy yields superior biomodulatory effects. However, its neural mechanisms are still unknown which poses a significant barrier to the development of an optimized protocol. A randomized, single-blind study including 29 participants was conducted using a crossover design, with sham and continuous wave (CW) groups as controls. The EEG microstate analysis was utilized to explore the relative variations in temporal parameters and brain functional connectivity. To further elucidate the dynamic activity patterns of microstates, a 10-repeat 10-fold cross-validation with nine machine learning algorithms and kernel Shapley additive explanations analysis was employed. Results indicated that the pulsed wave mode enhanced the global efficiency, local efficiency, and betweenness centrality of microstate C in brain functional networks as well as the mean durations parameter achieving a middle to large effect size, with superior effects compared to the sham and continuous wave groups. Furthermore, the support vector machine based on the radial basis function method with kernel Shapley additive explanations analysis demonstrated the best performance with an area under the curve (AUC) reaching 0.956, and found that the 8 of top-10 microstate features related to microstate C contributed most significantly to the PW mode. In conclusion, the EEG microstate analysis found that PW tPBM therapy modulates the microstate C-specific patterns in the human brain, suggesting that microstate dynamics may serve as a state-dependent biomarker for the optimization of tPBM protocol.", "published": "2025-10-24T08:52:28Z", "query": "transcranial stimulation", "relevance": 0.3, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:18:16.313206"}
{"arxiv_id": "2510.21061v1", "title": "The spinterface mechanism for the chiral-induced spin selectivity   effect: A Critical Perspective", "summary": "The chiral-induced spin selectivity (CISS) effect, whereby chiral molecules preferentially transmit electrons of one spin orientation, remains one of the most intriguing and debated phenomena at the interface of spintronics, molecular electronics, and quantum materials. Despite extensive experimental observations across diverse platforms - including transport junctions, photoemission, and enantioselective chemistry - a comprehensive theoretical framework is still lacking. In this perspective, we critically examine the spinterface mechanism as a unifying explanation for the CISS effect. The spinterface model, which hypothesizes a feedback interaction between electron motion in chiral molecules and fluctuating surface magnetic moments, is shown to quantitatively reproduce experimental data across various systems and conditions. We contrast it with some existing theoretical models, highlighting key experimental features. Importantly, we also address open questions and criticisms of this model, including the nature of surface magnetism, the role of dissipation, and the applicability of the mechanism to non-helical or electrode-free systems. By offering falsifiable predictions and reconciling theory with experimental raw data, this work aims to sharpen the dialogue surrounding the microscopic origin of CISS and stimulate further experimental and theoretical progress.", "published": "2025-10-24T00:27:16Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:16.313684"}
{"arxiv_id": "2510.20029v1", "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for   Transcranial Ultrasound Tomography", "summary": "Ultrasound brain imaging remains challenging due to the large difference in sound speed between the skull and brain tissues and the difficulty of coupling large probes to the skull. This work aims to achieve quantitative transcranial ultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain. Traditional physics-based full-waveform inversion (FWI) is limited by weak signals caused by skull-induced attenuation, mode conversion, and phase aberration, as well as incomplete spatial coverage since full-aperture arrays are clinically impractical. In contrast, purely data-driven methods that learn directly from raw ultrasound data often fail to model the complex nonlinear and nonlocal wave propagation through bone, leading to anatomically plausible but quantitatively biased SoS maps under low signal-to-noise and sparse-aperture conditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage framework that combines physical modeling with machine learning. In the first stage, reverse time migration (time-reversal acoustics) is applied to multi-angle acquisitions to produce migration fragments that preserve structural details even under low SNR. In the second stage, a transformer-based super-resolution encoder-decoder with a graph-based attention unit (GAU) fuses these fragments into a coherent and quantitatively accurate SoS image. A partial-array acquisition strategy using a movable low-count transducer set improves feasibility and coupling, while the hybrid algorithm compensates for the missing aperture. Experiments on two synthetic datasets show that BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness, demonstrating its potential for advancing quantitative ultrasound brain imaging.", "published": "2025-10-22T21:15:55Z", "query": "transcranial stimulation", "relevance": 0.1, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:16.314034"}
{"arxiv_id": "2510.18640v1", "title": "Towards an Optimized Benchmarking Platform for CI/CD Pipelines", "summary": "Performance regressions in large-scale software systems can lead to substantial resource inefficiencies, making their early detection critical. Frequent benchmarking is essential for identifying these regressions and maintaining service-level agreements (SLAs). Performance benchmarks, however, are resource-intensive and time-consuming, which is a major challenge for integration into Continuous Integration / Continuous Deployment (CI/CD) pipelines. Although numerous benchmark optimization techniques have been proposed to accelerate benchmark execution, there is currently no practical system that integrates these optimizations seamlessly into real-world CI/CD pipelines. In this vision paper, we argue that the field of benchmark optimization remains under-explored in key areas that hinder its broader adoption. We identify three central challenges to enabling frequent and efficient benchmarking: (a) the composability of benchmark optimization strategies, (b) automated evaluation of benchmarking results, and (c) the usability and complexity of applying these strategies as part of CI/CD systems in practice. We also introduce a conceptual cloud-based benchmarking framework handling these challenges transparently. By presenting these open problems, we aim to stimulate research toward making performance regression detection in CI/CD systems more practical and effective.", "published": "2025-10-21T13:43:20Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:16.314358"}
{"arxiv_id": "2510.18570v1", "title": "Electromagnetic Field Exposure Assessment and Mitigation Strategies for   Wireless Power Transfer Systems: A Review and Future Perspectives", "summary": "Wireless power transfer (WPT) technologies are increasingly being applied in fields ranging from consumer electronics and electric vehicles to space-based energy systems and medical implants. While WPT offers contactless power delivery, it introduces electromagnetic field (EMF) emissions, necessitating careful assessment to address safety and public health concerns. Exposure guidelines developed by ICNIRP and IEEE define frequency-dependent limits based on internal quantities, such as electric field strength and specific absorption rate, intended to prevent tissue nerve stimulation &lt; 100 kHz and heating &gt; 100 kHz, respectively. Complementing these guidelines, assessment standards including the International Electrotechnical Commission (IEC)/IEEE 63184 and IEC Technical Report 63377, provide practical procedures for evaluating the EMF exposure in WPT systems. This review offers a comparative overview of major WPT modalities, with a focus on recent developments in computational dosimetry and standardized assessment techniques for the complex, non-uniform fields typical of WPT environments. It also discusses electromagnetic interference with medical devices and exposure scenarios involving partial body proximity and various postures. A notable observation across modalities is the considerable variability, often spanning an order of magnitude, in the allowable transfer power, depending on the field distribution and assessment approach. Remaining challenges include the lack of harmonized guidance for intermediate frequencies and localized exposure, underscoring the importance of further coordination in international standardization efforts. Addressing these issues is essential for the safe and widespread deployment of WPT technologies.", "published": "2025-10-21T12:25:44Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:18:16.314711"}
{"arxiv_id": "2510.18492v1", "title": "Electromagnetic characteristics as probes into the inner structures of   the predicted $\u039e_c^{(',*)}D^{(*)}_s$ molecular states", "summary": "In this work, we conduct a systematic investigation of the electromagnetic properties, specifically the magnetic moments and the M1 radiative decay behavior, of the predicted $\\Xi_c^{(',*)}D^{(*)}_s$-type double-charm hidden-strangeness molecular pentaquarks. The study is carried out within the framework of the constituent quark model to evaluate these electromagnetic observables, and our analysis incorporates three distinct scenarios: single-channel analysis, $S$-$D$ wave mixing analysis, and coupled-channel analysis. The calculated magnetic moments reveal characteristic patterns that reflect their underlying constituent configurations and provide sensitive probes for their quantum number assignments. Furthermore, we identify several M1 radiative decay channels with sizable widths that may offer promising signatures for future experimental detection. These M1 transitions also act as sensitive probes into their inner structures, displaying distinctive features that help differentiate between their constituent configurations and quantum number assignments. We anticipate that this study will stimulate experimental interest in exploring the electromagnetic properties of the $\\Xi_c^{(',*)}D^{(*)}_s$ molecular states, thereby advancing our structural understanding of these exotic hadronic states.", "published": "2025-10-21T10:30:12Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:16.315122"}
{"arxiv_id": "2510.18303v1", "title": "Proactive Reasoning-with-Retrieval Framework for Medical Multimodal   Large Language Models", "summary": "Incentivizing the reasoning ability of Multimodal Large Language Models (MLLMs) is essential for medical applications to transparently analyze medical scans and provide reliable diagnosis. However, existing medical MLLMs rely solely on internal knowledge during reasoning, leading to hallucinated reasoning and factual inaccuracies when encountering cases beyond their training scope. Although recent Agentic Retrieval-Augmented Generation (RAG) methods elicit the medical model's proactive retrieval ability during reasoning, they are confined to unimodal LLMs, neglecting the crucial visual information during reasoning and retrieval. Consequently, we propose the first Multimodal Medical Reasoning-with-Retrieval framework, Med-RwR, which actively retrieves external knowledge by querying observed symptoms or domain-specific medical concepts during reasoning. Specifically, we design a two-stage reinforcement learning strategy with tailored rewards that stimulate the model to leverage both visual diagnostic findings and textual clinical information for effective retrieval. Building on this foundation, we further propose a Confidence-Driven Image Re-retrieval (CDIR) method for test-time scaling when low prediction confidence is detected. Evaluation on various public medical benchmarks demonstrates Med-RwR's significant improvements over baseline models, proving the effectiveness of enhancing reasoning capabilities with external knowledge integration. Furthermore, Med-RwR demonstrates remarkable generalizability to unfamiliar domains, evidenced by 8.8% performance gain on our proposed EchoCardiography Benchmark (ECBench), despite the scarcity of echocardiography data in the training corpus. Our data, model, and codes will be made publicly available at https://github.com/xmed-lab/Med-RwR.", "published": "2025-10-21T05:18:18Z", "query": "transcranial stimulation", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:16.315528"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:19.745972"}
{"arxiv_id": "2510.24356v1", "title": "Perception Learning: A Formal Separation of Sensory Representation   Learning from Decision Learning", "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's sensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic signals, decoupled from downstream decision learning $g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free perceptual properties, such as stability to nuisances, informativeness without collapse, and controlled geometry, assessed via objective representation-invariant metrics. We formalize the separation of perception and decision, define perceptual properties independent of objectives or reparameterizations, and prove that PeL updates preserving sufficient invariants are orthogonal to Bayes task-risk gradients. Additionally, we provide a suite of task-agnostic evaluation metrics to certify perceptual quality.", "published": "2025-10-28T12:19:49Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:19.746792"}
{"arxiv_id": "2510.24342v1", "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "summary": "For decades, neuroscientists and computer scientists have pursued a shared ambition: to understand intelligence and build it. Modern artificial neural networks now rival humans in language, perception, and reasoning, yet it is still largely unknown whether these artificial systems organize information as the brain does. Existing brain-AI alignment studies have shown the striking correspondence between the two systems, but such comparisons remain bound to specific inputs and tasks, offering no common ground for comparing how AI models with different kinds of modalities-vision, language, or multimodal-are intrinsically organized. Here we introduce a groundbreaking concept of Brain-like Space: a unified geometric space in which every AI model can be precisely situated and compared by mapping its intrinsic spatial attention topological organization onto canonical human functional brain networks, regardless of input modality, task, or sensory domain. Our extensive analysis of 151 Transformer-based models spanning state-of-the-art large vision models, large language models, and large multimodal models uncovers a continuous arc-shaped geometry within this space, reflecting a gradual increase of brain-likeness; different models exhibit distinct distribution patterns within this geometry associated with different degrees of brain-likeness, shaped not merely by their modality but by whether the pretraining paradigm emphasizes global semantic abstraction and whether the positional encoding scheme facilitates deep fusion across different modalities. Moreover, the degree of brain-likeness for a model and its downstream task performance are not \"identical twins\". The Brain-like Space provides the first unified framework for situating, quantifying, and comparing intelligence across domains, revealing the deep organizational principles that bridge machines and the brain.", "published": "2025-10-28T12:09:23Z", "query": "sensory cortex stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:18:19.747419"}
{"arxiv_id": "2510.23892v1", "title": "Learning-based Spectral Regression for Cocoa Bean Physicochemical   Property Prediction", "summary": "Cocoa bean quality assessment is essential for ensuring compliance with commercial standards, protecting consumer health, and increasing the market value of the cocoa product. The quality assessment estimates key physicochemical properties, such as fermentation level, moisture content, polyphenol concentration, and cadmium content, among others. This assessment has traditionally relied on the accurate estimation of these properties via visual or sensory evaluation, jointly with laboratory-based physicochemical analyses, which are often time-consuming, destructive, and difficult to scale. This creates the need for rapid, reliable, and noninvasive alternatives. Spectroscopy, particularly in the visible and near-infrared ranges, offers a non-invasive alternative by capturing the molecular signatures associated with these properties. Therefore, this work introduces a scalable methodology for evaluating the quality of cocoa beans by predicting key physicochemical properties from the spectral signatures of cocoa beans. This approach utilizes a conveyor belt system integrated with a VIS-NIR spectrometer, coupled with learning-based regression models. Furthermore, a dataset is built using cocoa bean batches from Santander, Colombia. Ground-truth reference values were obtained through standardized laboratory analyses and following commercial cocoa quality regulations. To further evaluate the proposed methodology's generalization, performance is tested on samples collected from other Colombian regions and from Cusco, Peru. Experimental results show that the proposed models achieved R2 scores exceeding 0.98 across all physicochemical properties, and reached 0.96 accuracy on geographically independent samples. This non-destructive approach represents a suitable and scalable alternative to conventional laboratory methods for quality assessment across the cocoa production chain.", "published": "2025-10-27T22:05:01Z", "query": "sensory cortex stimulation", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:19.747904"}
{"arxiv_id": "2510.23391v1", "title": "Conduction velocity of intracortical axons in monkey primary visual   cortex grows with distance: implications for computation", "summary": "A critical visual computation is to construct global scene properties from activities of early visual cortical neurons which have small receptive fields. Such a computation is enabled by contextual influences, through which a neuron's response to visual inputs is influenced by contextual inputs outside its classical receptive fields. Accordingly, neurons can signal global properties including visual saliencies and figure-ground relationships. Many believe that intracortical axons conduct signals too slowly to bring the contextual information from receptive fields of other neurons. A popular opinion is that much of the contextual influences arise from feedback from higher visual areas whose neurons have larger receptive fields. This paper re-examines pre-existing data to reveal these unexpected findings: the conduction speed of V1 intracortical axons increases approximately linearly with the conduction distance, and is sufficiently high for conveying the contextual influences. Recognizing the importance of intracortical contribution to critical visual computations should enable fresh progress in answering long-standing questions.", "published": "2025-10-27T14:44:12Z", "query": "sensory cortex stimulation", "relevance": 0.44999999999999996, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:19.748281"}
{"arxiv_id": "2510.23290v1", "title": "Group-Level and Personalized Optimization for the Insula and Hippocampus   Focal Electric Field in Transcranial Temporal Interferential Stimulation: A   Computational Study", "summary": "This study evaluated transcranial temporal interference stimulation (tTIS) for focal targeting of the insula and hippocampus, which are clinically relevant yet anatomically difficult to stimulate. Individualized and group-level electrode optimizations were compared to determine whether generalized montages can provide reliable targeting with reduced modeling demands. Sixty high-resolution head models (30 individuals and their mirrored counterparts) were constructed from T1- and T2-weighted MRI. Electric fields (EFs) were computed using the scalar-potential finite-difference method. Electrode montages and current ratios were optimized to minimize the root-mean-square error between simulated and target EF envelope (EFE) distributions, with a threshold of 0.3 V/m. Subsampling analysis was performed to estimate the number of models required for stable group-level outcomes. For the insula, a montage combining T7-P7 and Fp1-Fp2 achieved the highest focality, comparable to individualized results with reduced variability. For the hippocampus, the F7-T7 and T8-P8 montage gave the best group-level focality, though individualized optimization improved off-target suppression. Stable group-level patterns were obtained using 20 models for the insula and 9 for the hippocampus. Optimal tTIS montages depend on target depth. Group-level optimization suffices for cortical regions like the insula, whereas individualized tuning remains preferable for deeper targets such as the hippocampus.", "published": "2025-10-27T13:00:28Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:18:19.748722"}
{"arxiv_id": "2510.23262v1", "title": "Moderating Role of Presence in EEG Responses to Visuo-haptic Prediction   Error in Virtual Reality", "summary": "Virtual reality (VR) can create compelling experiences that evoke presence, the sense of ``being there.'' However, problems in rendering can create sensorimotor disruptions that undermine presence and task performance. Presence is typically assessed with post-hoc questionnaires, but their coarse temporal resolution limits insight into how sensorimotor disruptions shape user experience. Here, we combined questionnaires with electroencephalography (EEG) to identify neural markers of presence-affecting prediction error in immersive VR. Twenty-five participants performed a grasp-and-place task under two levels of immersion (visual-only vs.~visuo-haptic). Occasional oddball-like sensorimotor disruptions introduced premature feedback to elicit prediction errors. Overall, higher immersion enhanced self-presence but not physical presence, while accuracy and speed improved over time irrespective of immersion. At the neural level, sensorimotor disruptions elicited robust event-related potential effects at FCz and Pz, accompanied by increases in frontal midline $\\theta$ and posterior $\\alpha$ suppression. Through source analyses localized to anterior- and posterior cingulate cortex (ACC/PCC) we found that PCC $\\alpha$ activity showed heightened sensitivity to disruptions exclusively in visuo-haptic immersion. Exploratory moderation analyses by presence scores revealed no consistent patterns. Together, these results suggest that higher immersion amplifies both the benefits and costs of sensorimotor coherence.", "published": "2025-10-27T12:23:40Z", "query": "sensory cortex stimulation", "relevance": 0.49999999999999994, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:19.749091"}
{"arxiv_id": "2510.22875v1", "title": "Control of Valence Electron Motion in Xe Cation Using Stimulated Raman   Adiabatic Passage Technique", "summary": "This work theoretically investigates possibilities of using the Stimulated Raman Adiabatic Passage (STIRAP) and its variants to control a coherent superposition of quantum states. We present a generalization of the so-called fractional STIRAP (f-STIRAP), demonstrating precise control over the mixing ratio of quantum states in the wave packet. In contrast to conventional f-STIRAP, designed to drive a system from an eigenstate into a coherent superposition, our scheme enables arbitrary control over the composition of an already existing superposition state. We demonstrate that an approximate version of this technique -- where analytically designed laser pulses with composite envelopes are replaced by simple Gaussian pulses -- achieves comparable performance in controlling the dynamics of the wave packet. A limiting case of this scheme, utilizing two pulses with identical Gaussians envelopes and tuned delay and relative phase, is also explored, revealing experimentally accessible pathways for manipulating quantum coherence. We apply our developed techniques to control the ultrafast charge migration in the spin-orbit split ground electronic states of xenon cation via intermediate valence- and core-excited states. Finally, we propose concrete experimental realizations of the developed control schemes in combination with attosecond transient absorption spectroscopy as a method to probe the system.", "published": "2025-10-26T23:57:18Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:19.749560"}
{"arxiv_id": "2510.22128v1", "title": "What Exactly is a Deepfake?", "summary": "Deepfake technologies are often associated with deception, misinformation, and identity fraud, raising legitimate societal concerns. Yet such narratives may obscure a key insight: deepfakes embody sophisticated capabilities for sensory manipulation that can alter human perception, potentially enabling beneficial applications in domains such as healthcare and education. Realizing this potential, however, requires understanding how the technology is conceptualized across disciplines. This paper analyzes 826 peer-reviewed publications from 2017 to 2025 to examine how deepfakes are defined and understood in the literature. Using large language models for content analysis, we categorize deepfake conceptualizations along three dimensions: Identity Source (the relationship between original and generated content), Intent (deceptive versus non-deceptive purposes), and Manipulation Granularity (holistic versus targeted modifications). Results reveal substantial heterogeneity that challenges simplified public narratives. Notably, a subset of studies discuss non-deceptive applications, highlighting an underexplored potential for social good. Temporal analysis shows an evolution from predominantly threat-focused views (2017 to 2019) toward recognition of beneficial applications (2022 to 2025). This study provides an empirical foundation for developing nuanced governance and research frameworks that distinguish applications warranting prohibition from those deserving support, showing that, with safeguards, deepfakes' realism can serve important social purposes beyond deception.", "published": "2025-10-25T03:02:39Z", "query": "sensory cortex stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:19.749948"}
{"arxiv_id": "2510.22100v1", "title": "Lightweight and Breach-Resilient Authenticated Encryption Framework for   Internet of Things", "summary": "The Internet of Things (IoT) relies heavily on resource-limited devices to communicate critical (e.g., military data) information under low-energy adversarial environments and low-latency wireless channels. Authenticated Encryption (AE) guarantees confidentiality, authenticity, and integrity, making it a vital security service for IoT. However, current deployed (lightweight) AE standards lack essential features like key compromise resiliency and compact authentication tags, as well as performance enhancements such as offline-online cryptography. To address these gaps, we propose Graphene, the first (to our knowledge) symmetric Forward-secure and Aggregate Authenticated Encryption (FAAE) framework designed for the performance and security demands of low-end IoT infrastructures. Graphene innovates by synergizing key evolution strategies and offline-online cryptographic processing with Universal Message Authentication Codes (UMACs) to guarantee breach-resiliency, near-optimal online latency, and compactness. We demonstrate Graphene efficiency through two distinct instantiations, each balancing unique performance trade-offs with extensibility for diverse MACs. Our experimental evaluation on commodity hardware and 32-bit ARM Cortex-M4 microcontroller shows Graphene significant performance gains over existing alternatives. Graphene is also backward compatible with standard-compliant cryptographic implementations. We release our implementation as open source for public testing and adaptation.", "published": "2025-10-25T00:51:34Z", "query": "sensory cortex stimulation", "relevance": 0.0, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:19.750425"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:23.155529"}
{"arxiv_id": "2510.24711v1", "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit   Routing Guidance", "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model capacity while preserving computational efficiency. Despite its notable success in large language models (LLMs), existing attempts to apply MoE to Diffusion Transformers (DiTs) have yielded limited gains. We attribute this gap to fundamental differences between language and visual tokens. Language tokens are semantically dense with pronounced inter-token variation, while visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization in vision MoE. To this end, we present ProMoE, an MoE framework featuring a two-step router with explicit routing guidance that promotes expert specialization. Specifically, this guidance encourages the router to partition image tokens into conditional and unconditional sets via conditional routing according to their functional roles, and refine the assignments of conditional image tokens through prototypical routing with learnable prototypes based on semantic content. Moreover, the similarity-based expert allocation in latent space enabled by prototypical routing offers a natural mechanism for incorporating explicit semantic guidance, and we validate that such guidance is crucial for vision MoE. Building on this, we propose a routing contrastive loss that explicitly enhances the prototypical routing process, promoting intra-expert coherence and inter-expert diversity. Extensive experiments on ImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives. Code and models will be made publicly available.", "published": "2025-10-28T17:59:02Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.156088"}
{"arxiv_id": "2510.24688v1", "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with   Relation-Aware Fusion for 3D Object Detection", "summary": "Infrastructure-based perception plays a crucial role in intelligent transportation systems, offering global situational awareness and enabling cooperative autonomy. However, existing camera-based detection models often underperform in such scenarios due to challenges such as multi-view infrastructure setup, diverse camera configurations, degraded visual inputs, and various road layouts. We introduce MIC-BEV, a Transformer-based bird's-eye-view (BEV) perception framework for infrastructure-based multi-camera 3D object detection. MIC-BEV flexibly supports a variable number of cameras with heterogeneous intrinsic and extrinsic parameters and demonstrates strong robustness under sensor degradation. The proposed graph-enhanced fusion module in MIC-BEV integrates multi-view image features into the BEV space by exploiting geometric relationships between cameras and BEV cells alongside latent visual cues. To support training and evaluation, we introduce M2I, a synthetic dataset for infrastructure-based object detection, featuring diverse camera configurations, road layouts, and environmental conditions. Extensive experiments on both M2I and the real-world dataset RoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D object detection. It also remains robust under challenging conditions, including extreme weather and sensor degradation. These results highlight the potential of MIC-BEV for real-world deployment. The dataset and source code are available at: https://github.com/HandsomeYun/MIC-BEV.", "published": "2025-10-28T17:49:42Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.156596"}
{"arxiv_id": "2510.24680v1", "title": "Fare: Failure Resilience in Learned Visual Navigation Control", "summary": "While imitation learning (IL) enables effective visual navigation, IL policies are prone to unpredictable failures in out-of-distribution (OOD) scenarios. We advance the notion of failure-resilient policies, which not only detect failures but also recover from them automatically. Failure recognition that identifies the factors causing failure is key to informing recovery: e.g. pinpointing image regions triggering failure detections can provide cues to guide recovery. We present Fare, a framework to construct failure-resilient IL policies, embedding OOD-detection and recognition in them without using explicit failure data, and pairing them with recovery heuristics. Real-world experiments show that Fare enables failure recovery across two different policy architectures, enabling robust long-range navigation in complex environments.", "published": "2025-10-28T17:45:26Z", "query": "visual cortex prosthesis", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.156928"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:23.157256"}
{"arxiv_id": "2510.24667v1", "title": "SAGE: Structure-Aware Generative Video Transitions between Diverse Clips", "summary": "Video transitions aim to synthesize intermediate frames between two clips, but naive approaches such as linear blending introduce artifacts that limit professional use or break temporal coherence. Traditional techniques (cross-fades, morphing, frame interpolation) and recent generative inbetweening methods can produce high-quality plausible intermediates, but they struggle with bridging diverse clips involving large temporal gaps or significant semantic differences, leaving a gap for content-aware and visually coherent transitions. We address this challenge by drawing on artistic workflows, distilling strategies such as aligning silhouettes and interpolating salient features to preserve structure and perceptual continuity. Building on this, we propose SAGE (Structure-Aware Generative vidEo transitions) as a zeroshot approach that combines structural guidance, provided via line maps and motion flow, with generative synthesis, enabling smooth, semantically consistent transitions without fine-tuning. Extensive experiments and comparison with current alternatives, namely [FILM, TVG, DiffMorpher, VACE, GI], demonstrate that SAGE outperforms both classical and generative baselines on quantitative metrics and user studies for producing transitions between diverse clips. Code to be released on acceptance.", "published": "2025-10-28T17:35:02Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.157574"}
{"arxiv_id": "2510.24653v1", "title": "Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making   Datasets in Digital Pathology", "summary": "Interpretation of giga-pixel whole-slide images (WSIs) is an important but difficult task for pathologists. Their diagnostic accuracy is estimated to average around 70%. Adding a second pathologist does not substantially improve decision consistency. The field lacks adequate behavioral data to explain diagnostic errors and inconsistencies. To fill in this gap, we present PathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual search and decision-making processes of the full diagnostic workflow during cancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse interaction, stimulus tracking, viewport navigation, and diagnostic decision data (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data collection process emphasizes ecological validity through an application-grounded testbed, called PTAH. In total, we recorded 171,909 fixations, 263,320 saccades, and 1,867,362 mouse interaction events. In addition, such data could also be used to improve the training of both pathologists and AI systems that might support human experts. All experiments were preregistered at https://osf.io/hj9a7, and the complete dataset along with analysis code is available at https://go.osu.edu/pathogaze.", "published": "2025-10-28T17:18:43Z", "query": "visual cortex prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.157876"}
{"arxiv_id": "2510.24650v1", "title": "Advancing site-specific disease and pest management in precision   agriculture: From reasoning-driven foundation models to adaptive,   feedback-based learning", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through machine and deep learning (ML and DL) for real-time computer vision. Research evolved from handcrafted feature extraction to large-scale automated feature learning. With foundation models (FMs), crop disease datasets are now processed in fundamentally new ways. Unlike traditional neural networks, FMs integrate visual and textual data, interpret symptoms in text, reason about symptom-management relationships, and support interactive QA for growers and educators. Adaptive and imitation learning in robotics further enables field-based disease management. This review screened approx. 40 articles on FM applications for SSDM, focusing on large-language models (LLMs) and vision-language models (VLMs), and discussing their role in adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying. Key findings: (a) FMs are gaining traction with surging literature in 2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can simulate targeted spraying virtually; (e) addressing the sim-to-real gap is critical for real-world deployment; (f) human-robot collaboration remains limited, especially in human-in-the-loop approaches where robots detect early symptoms and humans validate uncertain cases; (g) multi-modal FMs with real-time feedback will drive next-gen SSDM. For updates, resources, and contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to submit papers, code, or datasets.", "published": "2025-10-28T17:16:47Z", "query": "visual cortex prosthesis", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.158215"}
{"arxiv_id": "2510.24640v1", "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "summary": "The rapid advancement of generative AI has enabled the creation of highly realistic forged facial images, posing significant threats to AI security, digital media integrity, and public trust. Face forgery techniques, ranging from face swapping and attribute editing to powerful diffusion-based image synthesis, are increasingly being used for malicious purposes such as misinformation, identity fraud, and defamation. This growing challenge underscores the urgent need for robust and generalizable face forgery detection methods as a critical component of AI security infrastructure. In this work, we propose a novel dual-branch convolutional neural network for face forgery detection that leverages complementary cues from both spatial and frequency domains. The RGB branch captures semantic information, while the frequency branch focuses on high-frequency artifacts that are difficult for generative models to suppress. A channel attention module is introduced to adaptively fuse these heterogeneous features, highlighting the most informative channels for forgery discrimination. To guide the network's learning process, we design a unified loss function, FSC Loss, that combines focal loss, supervised contrastive loss, and a frequency center margin loss to enhance class separability and robustness. We evaluate our model on the DiFF benchmark, which includes forged images generated from four representative methods: text-to-image, image-to-image, face swap, and face edit. Our method achieves strong performance across all categories and outperforms average human accuracy. These results demonstrate the model's effectiveness and its potential contribution to safeguarding AI ecosystems against visual forgery attacks.", "published": "2025-10-28T17:06:40Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.158574"}
{"arxiv_id": "2510.24633v1", "title": "Symbolic Snapshot Ensembles", "summary": "Inductive logic programming (ILP) is a form of logical machine learning. Most ILP algorithms learn a single hypothesis from a single training run. Ensemble methods train an ILP algorithm multiple times to learn multiple hypotheses. In this paper, we train an ILP algorithm only once and save intermediate hypotheses. We then combine the hypotheses using a minimum description length weighting scheme. Our experiments on multiple benchmarks, including game playing and visual reasoning, show that our approach improves predictive accuracy by 4% with less than 1% computational overhead.", "published": "2025-10-28T17:01:38Z", "query": "visual cortex prosthesis", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:23.158832"}
{"arxiv_id": "2510.24519v1", "title": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet   Coefficient", "summary": "Extracting features from the speech is the most critical process in speech signal processing. Mel Frequency Cepstral Coefficients (MFCC) are the most widely used features in the majority of the speaker and speech recognition applications, as the filtering in this feature is similar to the filtering taking place in the human ear. But the main drawback of this feature is that it provides only the frequency information of the signal but does not provide the information about at what time which frequency is present. The wavelet transform, with its flexible time-frequency window, provides time and frequency information of the signal and is an appropriate tool for the analysis of non-stationary signals like speech. On the other hand, because of its uniform frequency scaling, a typical wavelet transform may be less effective in analysing speech signals, have poorer frequency resolution in low frequencies, and be less in line with human auditory perception. Hence, it is necessary to develop a feature that incorporates the merits of both MFCC and wavelet transform. A great deal of studies are trying to combine both these features. The present Wavelet Transform based Mel-scaled feature extraction methods require more computation when a wavelet transform is applied on top of Mel-scale filtering, since it adds extra processing steps. Here we are proposing a method to extract Mel scale features in time domain combining the concept of wavelet transform, thus reducing the computational burden of time-frequency conversion and the complexity of wavelet extraction. Combining our proposed Time domain Mel frequency Wavelet Coefficient(TMFWC) technique with the reservoir computing methodology has significantly improved the efficiency of audio signal processing.", "published": "2025-10-28T15:31:52Z", "query": "auditory brainstem implant", "relevance": 0.2, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:26.699301"}
{"arxiv_id": "2510.23763v1", "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid progress in Vision-Language-Action (VLA) models for robotic manipulation. Although effective in many scenarios, current approaches largely rely on explicit instructions, whereas in real-world interactions, humans rarely issue instructions directly. Effective collaboration requires robots to infer user intentions proactively. In this work, we introduce cross-modal contextual instructions, a new setting where intent is derived from spoken dialogue, environmental sounds, and visual cues rather than explicit commands. To address this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor framework based on end-to-end omni-modal LLMs that unifies intention recognition, interaction confirmation, and action execution. RoboOmni fuses auditory and visual signals spatiotemporally for robust intention recognition, while supporting direct speech interaction. To address the absence of training data for proactive intention recognition in robotic manipulation, we build OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640 backgrounds, and six contextual instruction types. Experiments in simulation and real-world settings show that RoboOmni surpasses text- and ASR-based baselines in success rate, inference speed, intention recognition, and proactive assistance.", "published": "2025-10-27T18:49:03Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:26.699898"}
{"arxiv_id": "2510.23158v1", "title": "Matching Reverberant Speech Through Learned Acoustic Embeddings and   Feedback Delay Networks", "summary": "Reverberation conveys critical acoustic cues about the environment, supporting spatial awareness and immersion. For auditory augmented reality (AAR) systems, generating perceptually plausible reverberation in real time remains a key challenge, especially when explicit acoustic measurements are unavailable. We address this by formulating blind estimation of artificial reverberation parameters as a reverberant signal matching task, leveraging a learned room-acoustic prior. Furthermore, we propose a feedback delay network (FDN) structure that reproduces both frequency-dependent decay times and the direct-to-reverberation ratio of a target space. Experimental evaluation against a leading automatic FDN tuning method demonstrates improvements in estimated room-acoustic parameters and perceptual plausibility of artificial reverberant speech. These results highlight the potential of our approach for efficient, perceptually consistent reverberation rendering in AAR applications.", "published": "2025-10-27T09:33:52Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:26.700300"}
{"arxiv_id": "2510.22961v1", "title": "Adapting Speech Foundation Models with Large Language Models for Unified   Speech Recognition", "summary": "Unified speech recognition aims to perform auditory, visual, and audiovisual speech recognition within a single model framework. While speech foundation models (SFMs) have demonstrated remarkable performance in auditory tasks, their adaptation to multimodal scenarios remains underexplored. This paper presents UASR-LLM, a novel framework that adapts frozen SFMs to unified VSR, ASR, and AVSR tasks by leveraging large language models (LLMs) as text decoders. Our approach introduces visual representations into multiple SFM layers through visual injection modules, enabling multimodal input processing and unified hidden representations. The augmented SFMs connect with decoder-only LLMs via a feed-forward adaptor, where concatenated representations and instruction prompts guide speech transcription. We implement a twostage training strategy: visual injection pretraining followed by speech recognition finetuning. SFM parameters remain frozen throughout training, with only visual injection modules optimized initially, and LLMs finetuned using LoRA parameters subsequently. Experimental results demonstrate superior performance over state-of-the-art baselines across VSR, ASR, and AVSR tasks under both clean and noisy conditions. Ablation studies confirm generalization across various SFMs and LLMs, validating the proposed training strategy.", "published": "2025-10-27T03:36:05Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:26.700584"}
{"arxiv_id": "2510.22924v1", "title": "Neural Recording Power Optimization Through Machine Learning Guided   Resolution Reconfiguration", "summary": "Neural recording implants are a crucial tool for both neuroscience research and enabling new clinical applications. The power consumption of high channel count implants is dominated by the circuits used to amplify and digitize neural signals. Since circuit designers have pushed the efficiency of these circuits close to the theoretical physical limits, reducing power further requires system level optimization. Recent advances use a strategy called channel selection, in which less important channels are turned off to save power. We demonstrate resolution reconfiguration, in which the resolution of less important channels is scaled down to save power. Our approach leverages variable importance of each channel inside machine-learning-based decoders and we trial this methodology across three applications: seizure detection, gesture recognition, and force regression. With linear decoders, resolution reconfiguration saves 8.7x, 12.8x, and 23.0x power compared to a traditional recording array for each task respectively. It further saves 1.6x, 3.4x, and 5.2x power compared to channel selection. The results demonstrate the power benefits of resolution reconfigurable front-ends and their wide applicability to neural decoding problems.", "published": "2025-10-27T02:04:00Z", "query": "auditory brainstem implant", "relevance": 0.6, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:26.700826"}
{"arxiv_id": "2510.22603v1", "title": "Mitigating Attention Sinks and Massive Activations in Audio-Visual   Speech Recognition with LLMS", "summary": "Large language models (LLMs) have recently advanced auditory speech recognition (ASR), visual speech recognition (VSR), and audio-visual speech recognition (AVSR). However, understanding of their internal dynamics under fine-tuning remains limited. In natural language processing, recent work has revealed attention sinks, tokens that attract disproportionately high attention, and associated massive activations in which some features of sink tokens exhibit huge activation in LLMs. In this work, we are the first to study these phenomena in multimodal speech recognition. Through a detailed analysis of audio-visual LLMs, we identify attention sinks and massive activations not only at the BOS token but also at intermediate low-semantic tokens across ASR, VSR, and AVSR. We show that massive activations originate in the MLP layers and correspond to fixed feature indices across all sink tokens. We further show that intermediate sink tokens exhibit high cosine similarity to the BOS token, thereby amplifying attention and activation. Building on these insights, we introduce a simple decorrelation loss that reduces cosine similarity between BOS and other tokens, effectively mitigating intermediate sinks and massive activations. Furthermore, our method improves word error rate (WER) under high audio-visual feature downsampling while remaining stable at lower downsampling rates.", "published": "2025-10-26T09:44:20Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:26.701057"}
{"arxiv_id": "2510.22555v1", "title": "Cross-Paradigm Graph Backdoor Attacks with Promptable Subgraph Triggers", "summary": "Graph Neural Networks(GNNs) are vulnerable to backdoor attacks, where adversaries implant malicious triggers to manipulate model predictions.   Existing trigger generators are often simplistic in structure and overly reliant on specific features, confining them to a single graph learning paradigm, such as graph supervised learning, graph contrastive learning, or graph prompt learning.   This specialized design, which aligns the trigger with one learning objective, results in poor transferability when applied to other learning paradigms.   For instance, triggers generated for the graph supervised learning paradigm perform poorly when tested within graph contrastive learning or graph prompt learning environments.   Furthermore, these simple generators often fail to utilize complex structural information or node diversity within the graph data.   These constraints limit the attack success rates of such methods in general testing scenarios.   Therefore, to address these limitations, we propose Cross-Paradigm Graph Backdoor Attacks with Promptable Subgraph Triggers(CP-GBA), a new transferable graph backdoor attack that employs graph prompt learning(GPL) to train a set of universal subgraph triggers.   First, we distill a compact yet expressive trigger set from target graphs, which is structured as a queryable repository, by jointly enforcing class-awareness, feature richness, and structural fidelity.   Second, we conduct the first exploration of the theoretical transferability of GPL to train these triggers under prompt-based objectives, enabling effective generalization to diverse and unseen test-time paradigms.   Extensive experiments across multiple real-world datasets and defense scenarios show that CP-GBA achieves state-of-the-art attack success rates.", "published": "2025-10-26T07:10:07Z", "query": "auditory brainstem implant", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:26.701361"}
{"arxiv_id": "2510.22262v1", "title": "Lateral Ventricular Brain-Computer Interface System with   Lantern-Inspired Electrode for Stable Performance and Memory Decoding", "summary": "We present a lateral ventricular brain-computer interface (LV-BCI) that deploys an expandable, flexible electrode into the lateral ventricle through a minimally invasive external ventricular drainage pathway. Inspired by the framework of traditional Chinese lanterns, the electrode expands uniformly within the ventricle and conforms to the ependymal wall. Compared with conventional subdural ECoG electrodes, the LV-BCI shows superior signal stability and immunocompatibility. Resting-state spectral analyses revealed a maximum effective bandwidth comparable to subdural ECoG. In evoked potential tests, the LV-BCI maintained a consistently higher signal-to-noise ratio over 112 days without the decline typically associated with scarring or other immune responses. Immunohistochemistry showed only a transient, early microglial activation after implantation, returning to control levels and remaining stable through 168 days. We further designed an \"action-memory T-maze\" task and developed a microstate sequence classifier (MSSC) to predict rats' turn decisions. The LV-BCI achieved prediction accuracy up to 98%, significantly outperforming subdural ECoG, indicating enhanced access to decision-related information from deep structures such as the hippocampus. These results establish the lateral ventricle as a viable route for neural signal acquisition. Using a lantern-inspired flexible electrode, we achieve long-term stable recordings and robust memory decision decoding from within the ventricular system, opening new directions for BCI technology and systems neuroscience.", "published": "2025-10-25T12:00:23Z", "query": "auditory brainstem implant", "relevance": 0.6, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:26.701609"}
{"arxiv_id": "2510.20792v1", "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for   Text-Guided Graph Generation", "summary": "The rapid progress of graph generation has raised new security concerns, particularly regarding backdoor vulnerabilities. While prior work has explored backdoor attacks in image diffusion and unconditional graph generation, conditional, especially text-guided graph generation remains largely unexamined. This paper proposes BadGraph, a backdoor attack method targeting latent diffusion models for text-guided graph generation. BadGraph leverages textual triggers to poison training data, covertly implanting backdoors that induce attacker-specified subgraphs during inference when triggers appear, while preserving normal performance on clean inputs. Extensive experiments on four benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the effectiveness and stealth of the attack: less than 10% poisoning rate can achieves 50% attack success rate, while 24% suffices for over 80% success rate, with negligible performance degradation on benign samples. Ablation studies further reveal that the backdoor is implanted during VAE and diffusion training rather than pretraining. These findings reveal the security vulnerabilities in latent diffusion models of text-guided graph generation, highlight the serious risks in models' applications such as drug discovery and underscore the need for robust defenses against the backdoor attack in such diffusion models.", "published": "2025-10-23T17:54:17Z", "query": "auditory brainstem implant", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:26.701865"}
{"arxiv_id": "2510.20602v1", "title": "Resounding Acoustic Fields with Reciprocity", "summary": "Achieving immersive auditory experiences in virtual environments requires flexible sound modeling that supports dynamic source positions. In this paper, we introduce a task called resounding, which aims to estimate room impulse responses at arbitrary emitter location from a sparse set of measured emitter positions, analogous to the relighting problem in vision. We leverage the reciprocity property and introduce Versa, a physics-inspired approach to facilitating acoustic field learning. Our method creates physically valid samples with dense virtual emitter positions by exchanging emitter and listener poses. We also identify challenges in deploying reciprocity due to emitter/listener gain patterns and propose a self-supervised learning approach to address them. Results show that Versa substantially improve the performance of acoustic field learning on both simulated and real-world datasets across different metrics. Perceptual user studies show that Versa can greatly improve the immersive spatial sound experience. Code, dataset and demo videos are available on the project website: https://waves.seas.upenn.edu/projects/versa.", "published": "2025-10-23T14:30:09Z", "query": "auditory brainstem implant", "relevance": 0.15, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:26.702046"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "somatosensory prosthesis", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:30.207763"}
{"arxiv_id": "2510.14414v1", "title": "RoboANKLE: Design, Development, and Functional Evaluation of a Robotic   Ankle with a Motorized Compliant Unit", "summary": "This study presents a powered transtibial prosthesis with complete push-off assistance, RoboANKLE. The design aims to fulfill specific requirements, such as a sufficient range of motion (RoM) while providing the necessary torque for achieving natural ankle motion in daily activities. Addressing the challenges faced in designing active transtibial prostheses, such as maintaining energetic autonomy and minimizing weight, is vital for the study. With this aim, we try to imitate the human ankle by providing extensive push-off assistance to achieve a natural-like torque profile. Thus, Energy Store and Extended Release mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism. Kinematic and kinetic analyses are carried out to determine the design parameters and assess the design performance. Subsequently, a Computer-Aided Design (CAD) model is built and used in comprehensive dynamic and structural analyses. These analyses are used for the design performance evaluation and determine the forces and torques applied to the prosthesis, which aids in optimizing the design for minimal weight via structural analysis and topology optimization. The design of the prototype is then finalized and manufactured for experimental evaluation to validate the design and functionality. The prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm. The Functional evaluations of the RoboANKLE revealed that it is capable of achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also, Thanks to the implemented mechanisms, the results show that RoboANKLE can generate 57% higher than the required torque for natural walking. The result of the power generation capacity of the RoboANKLE is 10% more than the natural power during the gait cycle.", "published": "2025-10-16T08:18:51Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:18:30.208665"}
{"arxiv_id": "2510.09209v1", "title": "PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling   Precision-Lateral Dexterous Manipulation", "summary": "Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and have motors inside to protect them from damage and dirt. In addition to the ability to perform daily activities, these features are essential for everyday use of the hand. In-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting cards before slot insertion and operating tools such as screwdrivers. However, currently used electric prosthetic hands only achieve static grasp postures, and existing manipulation approaches require either many motors, which makes the prosthesis heavy for daily use in the hand, or complex mechanisms that demand a large internal space and force external motor placement, complicating attachment and exposing the components to damage. Alternatively, we combine a single-axis thumb and optimized thumb positioning to achieve basic posture and in-hand manipulation, that is, the reorientation between precision and lateral grasps, using only four motors in a lightweight (311 g) prosthetic hand. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success rates of 90-100% for reorientation tasks. The hand performed seal stamping and USB device insertion, as well as rotation to operate a screwdriver.", "published": "2025-10-10T09:44:53Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:18:30.209037"}
{"arxiv_id": "2510.06091v1", "title": "Learning Mixtures of Linear Dynamical Systems (MoLDS) via Hybrid   Tensor-EM Method", "summary": "Mixtures of linear dynamical systems (MoLDS) provide a path to model time-series data that exhibit diverse temporal dynamics across trajectories. However, its application remains challenging in complex and noisy settings, limiting its effectiveness for neural data analysis. Tensor-based moment methods can provide global identifiability guarantees for MoLDS, but their performance degrades under noise and complexity. Commonly used expectation-maximization (EM) methods offer flexibility in fitting latent models but are highly sensitive to initialization and prone to poor local minima. Here, we propose a tensor-based method that provides identifiability guarantees for learning MoLDS, which is followed by EM updates to combine the strengths of both approaches. The novelty in our approach lies in the construction of moment tensors using the input-output data to recover globally consistent estimates of mixture weights and system parameters. These estimates can then be refined through a Kalman EM algorithm, with closed-form updates for all LDS parameters. We validate our framework on synthetic benchmarks and real-world datasets. On synthetic data, the proposed Tensor-EM method achieves more reliable recovery and improved robustness compared to either pure tensor or randomly initialized EM methods. We then analyze neural recordings from the primate somatosensory cortex while a non-human primate performs reaches in different directions. Our method successfully models and clusters different conditions as separate subsystems, consistent with supervised single-LDS fits for each condition. Finally, we apply this approach to another neural dataset where monkeys perform a sequential reaching task. These results demonstrate that MoLDS provides an effective framework for modeling complex neural data, and that Tensor-EM is a reliable approach to MoLDS learning for these applications.", "published": "2025-10-07T16:17:52Z", "query": "somatosensory prosthesis", "relevance": 0.25, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-28T21:18:30.209356"}
{"arxiv_id": "2509.20523v1", "title": "A Compound Classification System Based on Fuzzy Relations Applied to the   Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition", "summary": "Modern anthropomorphic upper limb bioprostheses are typically controlled by electromyographic (EMG) biosignals using a pattern recognition scheme. Unfortunately, there are many factors originating from the human source of objects to be classified and from the human-prosthesis interface that make it difficult to obtain an acceptable classification quality. One of these factors is the high susceptibility of biosignals to contamination, which can considerably reduce the quality of classification of a recognition system.   In the paper, the authors propose a new recognition system intended for EMG based control of the hand prosthesis with detection of contaminated biosignals in order to mitigate the adverse effect of contaminations. The system consists of two ensembles: the set of one-class classifiers (OCC) to assess the degree of contamination of individual channels and the ensemble of K-nearest neighbours (KNN) classifier to recognise the patient's intent. For all recognition systems, an original, coherent fuzzy model was developed, which allows the use of a uniform soft (fuzzy) decision scheme throughout the recognition process. The experimental evaluation was conducted using real biosignals from a public repository. The goal was to provide an experimental comparative analysis of the parameters and procedures of the developed method on which the quality of the recognition system depends. The proposed fuzzy recognition system was also compared with similar systems described in the literature.", "published": "2025-09-24T19:48:21Z", "query": "somatosensory prosthesis", "relevance": 0.2, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:18:30.209621"}
{"arxiv_id": "2509.02275v1", "title": "Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object   and Pose Recognition Using Multimodal Signals", "summary": "The human somatosensory system integrates multimodal sensory feedback, including tactile, proprioceptive, and thermal signals, to enable comprehensive perception and effective interaction with the environment. Inspired by the biological mechanism, we present a sensorized soft anthropomorphic hand equipped with diverse sensors designed to emulate the sensory modalities of the human hand. This system incorporates biologically inspired encoding schemes that convert multimodal sensory data into spike trains, enabling highly-efficient processing through Spiking Neural Networks (SNNs). By utilizing these neuromorphic signals, the proposed framework achieves 97.14% accuracy in object recognition across varying poses, significantly outperforming previous studies on soft hands. Additionally, we introduce a novel differentiator neuron model to enhance material classification by capturing dynamic thermal responses. Our results demonstrate the benefits of multimodal sensory fusion and highlight the potential of neuromorphic approaches for achieving efficient, robust, and human-like perception in robotic systems.", "published": "2025-09-02T12:52:53Z", "query": "somatosensory prosthesis", "relevance": 0.3, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-28T21:18:30.209841"}
{"arxiv_id": "2509.00787v3", "title": "Image-to-Brain Signal Generation for Visual Prosthesis with CLIP Guided   Multimodal Diffusion Models", "summary": "Visual prostheses hold great promise for restoring vision in blind individuals. While researchers have successfully utilized M/EEG signals to evoke visual perceptions during the brain decoding stage of visual prostheses, the complementary process of converting images into M/EEG signals in the brain encoding stage remains largely unexplored, hindering the formation of a complete functional pipeline. In this work, we present, to our knowledge, the first image-to-brain signal framework that generates M/EEG from images by leveraging denoising diffusion probabilistic models enhanced with cross-attention mechanisms. Specifically, the proposed framework comprises two key components: a pretrained CLIP visual encoder that extracts rich semantic representations from input images, and a cross-attention enhanced U-Net diffusion model that reconstructs brain signals through iterative denoising. Unlike conventional generative models that rely on simple concatenation for conditioning, our cross-attention modules capture the complex interplay between visual features and brain signal representations, enabling fine-grained alignment during generation. We evaluate the framework on two multimodal benchmark datasets and demonstrate that it generates biologically plausible brain signals. We also present visualizations of M/EEG topographies across all subjects in both datasets, providing intuitive demonstrations of intra-subject and inter-subject variations in brain signals.", "published": "2025-08-31T10:29:58Z", "query": "somatosensory prosthesis", "relevance": 0.65, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:30.210052"}
{"arxiv_id": "2508.01808v1", "title": "Learning to Perform Low-Contact Autonomous Nasotracheal Intubation by   Recurrent Action-Confidence Chunking with Transformer", "summary": "Nasotracheal intubation (NTI) is critical for establishing artificial airways in clinical anesthesia and critical care. Current manual methods face significant challenges, including cross-infection, especially during respiratory infection care, and insufficient control of endoluminal contact forces, increasing the risk of mucosal injuries. While existing studies have focused on automated endoscopic insertion, the automation of NTI remains unexplored despite its unique challenges: Nasotracheal tubes exhibit greater diameter and rigidity than standard endoscopes, substantially increasing insertion complexity and patient risks. We propose a novel autonomous NTI system with two key components to address these challenges. First, an autonomous NTI system is developed, incorporating a prosthesis embedded with force sensors, allowing for safety assessment and data filtering. Then, the Recurrent Action-Confidence Chunking with Transformer (RACCT) model is developed to handle complex tube-tissue interactions and partial visual observations. Experimental results demonstrate that the RACCT model outperforms the ACT model in all aspects and achieves a 66% reduction in average peak insertion force compared to manual operations while maintaining equivalent success rates. This validates the system's potential for reducing infection risks and improving procedural safety.", "published": "2025-08-03T15:43:58Z", "query": "somatosensory prosthesis", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:30.210274"}
{"arxiv_id": "2508.00491v1", "title": "HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation   Learning", "summary": "Recent advancements in control of prosthetic hands have focused on increasing autonomy through the use of cameras and other sensory inputs. These systems aim to reduce the cognitive load on the user by automatically controlling certain degrees of freedom. In robotics, imitation learning has emerged as a promising approach for learning grasping and complex manipulation tasks while simplifying data collection. Its application to the control of prosthetic hands remains, however, largely unexplored. Bridging this gap could enhance dexterity restoration and enable prosthetic devices to operate in more unconstrained scenarios, where tasks are learned from demonstrations rather than relying on manually annotated sequences. To this end, we present HannesImitationPolicy, an imitation learning-based method to control the Hannes prosthetic hand, enabling object grasping in unstructured environments. Moreover, we introduce the HannesImitationDataset comprising grasping demonstrations in table, shelf, and human-to-prosthesis handover scenarios. We leverage such data to train a single diffusion policy and deploy it on the prosthetic hand to predict the wrist orientation and hand closure for grasping. Experimental evaluation demonstrates successful grasps across diverse objects and conditions. Finally, we show that the policy outperforms a segmentation-based visual servo controller in unstructured scenarios. Additional material is provided on our project page: https://hsp-iit.github.io/HannesImitation", "published": "2025-08-01T10:09:38Z", "query": "somatosensory prosthesis", "relevance": 0.1, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:30.210486"}
{"arxiv_id": "2507.23450v1", "title": "The Effect of Prior Parameters on Standardized Kalman Filter-Based EEG   Source Localization", "summary": "EEG Source localization is a critical tool in neuroscience, with applications ranging from epilepsy diagnosis to cognitive research. It involves solving an ill-posed inverse problem that lacks a unique solution unless constrained by prior knowledge. The Bayesian framework enables the incorporation of such knowledge, typically encoded through prior models. Various algorithms have been proposed for source localization, and they differ significantly in how prior knowledge is incorporated. Some approaches rely on anatomical or functional constraints, while others use statistical distributions or sampling-based techniques. In this landscape, the Standardized Kalman Filter (SKF) represents a dynamic Bayesian approach that integrates temporal modeling with a Gaussian prior structure. It addresses the depth bias, a common limitation in source localization, through a post-hoc standardization step that equalizes sensitivity across cortical depths and makes deep activity detection feasible.   This study focuses on the development and optimization of Gaussian prior models within the SKF framework for simultaneous cortical and sub-cortical activity detection. Synthetic data similar to the P20 / N20 component of the somatosensory evoked potentials (SEP) was used to identify effective prior parameter configurations for reconstructing both deep and superficial sources under different noise levels. We also investigated the role of RTS smoothing in enhancing source separability. Our results indicate that raising the standardization exponent to 1.25, along with smoothing, significantly improves depth localization accuracy at low noise levels.", "published": "2025-07-31T11:27:02Z", "query": "somatosensory prosthesis", "relevance": 0.44999999999999996, "3d3n_category": "Somatosensory Prosthesis", "scraped_at": "2025-10-28T21:18:30.210697"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:33.700206"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:33.701138"}
{"arxiv_id": "2510.24639v1", "title": "Causal Ordering for Structure Learning From Time Series", "summary": "Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.", "published": "2025-10-28T17:06:15Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:33.701787"}
{"arxiv_id": "2510.24398v1", "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "summary": "Post-stroke MRI not only delineates focal lesions but also reveals secondary structural changes, such as atrophy and ventricular enlargement. These abnormalities, increasingly recognised as imaging biomarkers of recovery and outcome, remain poorly captured by supervised segmentation methods. We evaluate REFLECT, a flow-based generative model, for unsupervised detection of both focal and non-lesional abnormalities in post-stroke patients. Using dual-expert central-slice annotations on ATLAS data, performance was assessed at the object level with Free-Response ROC analysis for anomaly maps. Two models were trained on lesion-free slices from stroke patients (ATLAS) and on healthy controls (IXI) to test the effect of training data. On ATLAS test subjects, the IXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and improved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43). Training on fully healthy anatomy improves the modelling of normal variability, enabling broader and more reliable detection of structural abnormalities.", "published": "2025-10-28T13:13:01Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:33.702187"}
{"arxiv_id": "2510.24378v1", "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular,   Lightweight, and Deployment-Ready Tool", "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance in brain lesion segmentation but remain difficult to deploy clinically due to heavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a modular and lightweight framework that translates research-grade stroke lesion segmentation models into deployable applications. Preprocessing, inference, and postprocessing are decoupled: preprocessing relies on the Anima toolbox with BIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16} quantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides both graphical and command-line interfaces and is distributed as Python scripts and as a standalone Windows executable. On a held-out set of 300 sub-acute and chronic stroke subjects, segmentation performance was equivalent to the original PyTorch pipeline (Dice difference $&lt;10^{-3}$), demonstrating that high-performing research pipelines can be transformed into portable, clinically usable tools.", "published": "2025-10-28T12:56:48Z", "query": "closed-loop brain stimulation", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:33.702432"}
{"arxiv_id": "2510.24342v1", "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "summary": "For decades, neuroscientists and computer scientists have pursued a shared ambition: to understand intelligence and build it. Modern artificial neural networks now rival humans in language, perception, and reasoning, yet it is still largely unknown whether these artificial systems organize information as the brain does. Existing brain-AI alignment studies have shown the striking correspondence between the two systems, but such comparisons remain bound to specific inputs and tasks, offering no common ground for comparing how AI models with different kinds of modalities-vision, language, or multimodal-are intrinsically organized. Here we introduce a groundbreaking concept of Brain-like Space: a unified geometric space in which every AI model can be precisely situated and compared by mapping its intrinsic spatial attention topological organization onto canonical human functional brain networks, regardless of input modality, task, or sensory domain. Our extensive analysis of 151 Transformer-based models spanning state-of-the-art large vision models, large language models, and large multimodal models uncovers a continuous arc-shaped geometry within this space, reflecting a gradual increase of brain-likeness; different models exhibit distinct distribution patterns within this geometry associated with different degrees of brain-likeness, shaped not merely by their modality but by whether the pretraining paradigm emphasizes global semantic abstraction and whether the positional encoding scheme facilitates deep fusion across different modalities. Moreover, the degree of brain-likeness for a model and its downstream task performance are not \"identical twins\". The Brain-like Space provides the first unified framework for situating, quantifying, and comparing intelligence across domains, revealing the deep organizational principles that bridge machines and the brain.", "published": "2025-10-28T12:09:23Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Neural Encoding", "scraped_at": "2025-10-28T21:18:33.702706"}
{"arxiv_id": "2510.24029v1", "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a   Hippocampus-Inspired Model", "summary": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of vertebrates that encode environmental boundaries at specific distances and allocentric directions, playing a central role in forming place fields in the hippocampus. Most computational BVC models are restricted to two-dimensional (2D) environments, making them prone to spatial ambiguities in the presence of horizontal symmetries in the environment. To address this limitation, we incorporate vertical angular sensitivity into the BVC framework, thereby enabling robust boundary detection in three dimensions, and leading to significantly more accurate spatial localization in a biologically-inspired robot model.   The proposed model processes LiDAR data to capture vertical contours, thereby disambiguating locations that would be indistinguishable under a purely 2D representation. Experimental results show that in environments with minimal vertical variation, the proposed 3D model matches the performance of a 2D baseline; yet, as 3D complexity increases, it yields substantially more distinct place fields and markedly reduces spatial aliasing. These findings show that adding a vertical dimension to BVC-based localization can significantly enhance navigation and mapping in real-world 3D spaces while retaining performance parity in simpler, near-planar scenarios.", "published": "2025-10-28T03:24:02Z", "query": "closed-loop brain stimulation", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:33.702978"}
{"arxiv_id": "2510.24025v1", "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional   Connectivity Analysis", "summary": "Understanding the evolution of brain functional networks over time is of great significance for the analysis of cognitive mechanisms and the diagnosis of neurological diseases. Existing methods often have difficulty in capturing the temporal evolution characteristics of connections between specific functional communities. To this end, this paper proposes a new path-level trajectory modeling framework (NeuroPathNet) to characterize the dynamic behavior of connection pathways between brain functional partitions. Based on medically supported static partitioning schemes (such as Yeo and Smith ICA), we extract the time series of connection strengths between each pair of functional partitions and model them using a temporal neural network. We validate the model performance on three public functional Magnetic Resonance Imaging (fMRI) datasets, and the results show that it outperforms existing mainstream methods in multiple indicators. This study can promote the development of dynamic graph learning methods for brain network analysis, and provide possible clinical applications for the diagnosis of neurological diseases.", "published": "2025-10-28T03:07:06Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:33.703201"}
{"arxiv_id": "2510.23906v1", "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems", "summary": "Causal discovery uncovers complex relationships between variables, enhancing predictions, decision-making, and insights into real-world systems, especially in nonlinear multivariate time series. However, most existing methods primarily focus on pairwise cause-effect relationships, overlooking interactions among groups of variables, i.e., subsystems and their collective causal influence. In this study, we introduce gCDMI, a novel multi-group causal discovery method that leverages group-level interventions on trained deep neural networks and employs model invariance testing to infer causal relationships. Our approach involves three key steps. First, we use deep learning to jointly model the structural relationships among groups of all time series. Second, we apply group-wise interventions to the trained model. Finally, we conduct model invariance testing to determine the presence of causal links among variable groups. We evaluate our method on simulated datasets, demonstrating its superior performance in identifying group-level causal relationships compared to existing methods. Additionally, we validate our approach on real-world datasets, including brain networks and climate ecosystems. Our results highlight that applying group-level interventions to deep learning models, combined with invariance testing, can effectively reveal complex causal structures, offering valuable insights for domains such as neuroscience and climate science.", "published": "2025-10-27T22:26:20Z", "query": "closed-loop brain stimulation", "relevance": 0.2, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:33.703409"}
{"arxiv_id": "2510.23781v1", "title": "Connectome-Guided Automatic Learning Rates for Deep Networks", "summary": "The human brain is highly adaptive: its functional connectivity reconfigures on multiple timescales during cognition and learning, enabling flexible information processing. By contrast, artificial neural networks typically rely on manually-tuned learning-rate schedules or generic adaptive optimizers whose hyperparameters remain largely agnostic to a model's internal dynamics. In this paper, we propose Connectome-Guided Automatic Learning Rate (CG-ALR) that dynamically constructs a functional connectome of the neural network from neuron co-activations at each training iteration and adjusts learning rates online as this connectome reconfigures. This connectomics-inspired mechanism adapts step sizes to the network's dynamic functional organization, slowing learning during unstable reconfiguration and accelerating it when stable organization emerges. Our results demonstrate that principles inspired by brain connectomes can inform the design of adaptive learning rates in deep learning, generally outperforming traditional SGD-based schedules and recent methods.", "published": "2025-10-27T19:11:49Z", "query": "closed-loop brain stimulation", "relevance": 0.15000000000000002, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:33.703608"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:37.276112"}
{"arxiv_id": "2510.24707v1", "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task", "summary": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.", "published": "2025-10-28T17:56:20Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:37.276847"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:37.277412"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "adaptive neural interface", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:37.277809"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:37.278223"}
{"arxiv_id": "2510.24684v1", "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning", "summary": "Self-improving systems require environmental interaction for continuous adaptation. We introduce SPICE (Self-Play In Corpus Environments), a reinforcement learning framework where a single model acts in two roles: a Challenger that mines documents from a large corpus to generate diverse reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics, the Challenger creates an automatic curriculum at the frontier of the Reasoner's capability, while corpus grounding provides the rich, near-inexhaustible external signal necessary for sustained improvement. Unlike existing ungrounded self-play methods that offer more limited benefits, SPICE achieves consistent gains across mathematical (+8.9%) and general reasoning (+9.8%) benchmarks on multiple model families. Our analysis reveals how document grounding is a key ingredient in SPICE to continuously generate its own increasingly challenging goals and achieve them, enabling sustained self-improvement.", "published": "2025-10-28T17:46:16Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:37.278520"}
{"arxiv_id": "2510.24676v1", "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing   Control of Powered Transfemoral Prosthesis", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\\% and knee angle prediction error being 6.78\\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.", "published": "2025-10-28T17:40:52Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "Auditory Prosthesis", "scraped_at": "2025-10-28T21:18:37.278757"}
{"arxiv_id": "2510.24673v1", "title": "Learning constitutive models and rheology from partial flow measurements", "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid stress to its deformation rate. Unlike Newtonian fluids, most industrial and biological fluids are non-Newtonian, exhibiting a nonlinear relation. Accurately characterizing this nonlinearity is essential for predicting flow behavior in real-world engineering and translational applications. Yet current methods fall short by relying on bulk rheometer data and simple fits that fail to capture behaviors relevant in complex geometries and flow conditions. Data-driven approaches can capture more complex behaviors, but lack interpretability or consistency. To close this gap, we leverage automatic differentiation to build an end-to-end framework for robust rheological learning. We develop a differentiable non-Newtonian fluid solver with a tensor basis neural network closure that learns stress directly from arbitrary flow measurements, such as velocimetry data. In parallel, we implement differentiable versions of major constitutive relations, enabling Bayesian model parametrization and selection from rheometer data. Our framework predicts flows in unseen geometries and ensures physical consistency and interpretability by matching neural network responses to known constitutive laws. Ultimately, this work lays the groundwork for advanced digital rheometry capable of comprehensively characterizing non-Newtonian and viscoelastic fluids under realistic in-situ or in-line operating conditions.", "published": "2025-10-28T17:38:33Z", "query": "adaptive neural interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:37.279032"}
{"arxiv_id": "2510.24672v1", "title": "Eigenfunction Extraction for Ordered Representation Learning", "summary": "Recent advances in representation learning reveal that widely used objectives, such as contrastive and non-contrastive, implicitly perform spectral decomposition of a contextual kernel, induced by the relationship between inputs and their contexts. Yet, these methods recover only the linear span of top eigenfunctions of the kernel, whereas exact spectral decomposition is essential for understanding feature ordering and importance. In this work, we propose a general framework to extract ordered and identifiable eigenfunctions, based on modular building blocks designed to satisfy key desiderata, including compatibility with the contextual kernel and scalability to modern settings. We then show how two main methodological paradigms, low-rank approximation and Rayleigh quotient optimization, align with this framework for eigenfunction extraction. Finally, we validate our approach on synthetic kernels and demonstrate on real-world image datasets that the recovered eigenvalues act as effective importance scores for feature selection, enabling principled efficiency-accuracy tradeoffs via adaptive-dimensional representations.", "published": "2025-10-28T17:37:12Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:37.279259"}
{"arxiv_id": "2510.24654v1", "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment", "summary": "In this paper, we present a framework for training large language models (LLMs) as diagnostic agents with reinforcement learning, enabling them to manage multi-turn diagnostic processes, adaptively select examinations, and commit to final diagnoses. Unlike instruction-tuned models trained on static case summaries, our method acquires diagnostic strategies through interactive exploration and outcome-based feedback. Our contributions are fourfold: (i) We present DiagGym, a diagnostics world model trained with electronic health records that emits examination outcomes conditioned on patient history and recommended examination, serving as a virtual clinical environment for realistic diagnosis training and evaluation; (ii) We train DiagAgent via end-to-end, multi-turn reinforcement learning to learn diagnostic policies that optimize both information yield and diagnostic accuracy; (iii) We introduce DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated examination recommendations and 99 cases annotated with 973 physician-written rubrics on diagnosis process; (iv) we demonstrate superior performance across diverse diagnostic settings. DiagAgent significantly outperforms 10 state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34% higher diagnostic accuracy and 44.03% improvement in examination recommendation hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic accuracy and 23.09% boost in examination recommendation F1 score. In rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by 7.1% in weighted rubric score. These findings indicate that learning policies in interactive clinical environments confers dynamic and clinically meaningful diagnostic management abilities unattainable through passive training alone.", "published": "2025-10-28T17:19:47Z", "query": "adaptive neural interface", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:37.279651"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:40.964180"}
{"arxiv_id": "2510.24709v1", "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?", "summary": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.", "published": "2025-10-28T17:57:05Z", "query": "bidirectional brain interface", "relevance": 0.2, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:40.965058"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:40.965595"}
{"arxiv_id": "2510.24645v1", "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in   Multi-Turn Function Calling", "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.", "published": "2025-10-28T17:15:26Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:40.966036"}
{"arxiv_id": "2510.24641v1", "title": "Density-driven scattering and valley splitting in undoped Si/SiGe   two-dimensional electron system", "summary": "Undoped Si-SiGe two-dimensional electron gas (2DEG) provide an ideal platform for hosting quantum-dot spin-qubits owing enhanced spin dephasing times and compatibility with standard CMOS technology. The strained Si quantum well reduces the valley degeneracy into two closely spaced ones. The existence of a near-degenerate valley state act as a leakage channel and compromises gate fidelity. A robust and uniform valley splitting across the entire chip is crucial for achieving scalability in the architecture and reliability in operation. Imperfections such as broadened interfaces, alloy disorders and atomic steps significantly compromise the valley splitting. The associated scattering mechanisms play detrimental roles in the performance of the qubits. In this manuscript, exploiting low-temperature magnetotransport measurements, we investigate the scattering mechanisms and valley splitting in a high-mobility undoped Si-SiGe 2DEG. At lower carrier densities, transport is limited by remote impurity scattering, whereas at higher densities, background impurity scattering near the quantum well dominates. Both the transport and quantum lifetimes of the charge carriers increase with carrier concentration, due to the enhancement in the impurity screening. Magnetic-field-induced confinement effect also is found to improve the valley splitting. Current-biasing measurements reveals the role of carrier heating in the visibility of valley splitting and reveal a temperature limited valley splitting of approximately 100 micro-eV. These results provide critical insight into scattering-dominated regimes and valley splitting in undoped Si-SiGe, advancing its potential for silicon-based quantum devices.", "published": "2025-10-28T17:07:26Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:40.966530"}
{"arxiv_id": "2510.24639v1", "title": "Causal Ordering for Structure Learning From Time Series", "summary": "Predicting causal structure from time series data is crucial for understanding complex phenomena in physiology, brain connectivity, climate dynamics, and socio-economic behaviour. Causal discovery in time series is hindered by the combinatorial complexity of identifying true causal relationships, especially as the number of variables and time points grow. A common approach to simplify the task is the so-called ordering-based methods. Traditional ordering methods inherently limit the representational capacity of the resulting model. In this work, we fix this issue by leveraging multiple valid causal orderings, instead of a single one as standard practice. We propose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based causal discovery for temporal data. By integrating multiple orderings, DOTS effectively recovers the transitive closure of the underlying directed acyclic graph, mitigating spurious artifacts inherent in single-ordering approaches. We formalise the problem under standard assumptions such as stationarity and the additive noise model, and leverage score matching with diffusion processes to enable efficient Hessian estimation. Extensive experiments validate the approach. Empirical evaluations on synthetic and real-world datasets demonstrate that DOTS outperforms state-of-the-art baselines, offering a scalable and robust approach to temporal causal discovery. On synthetic benchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS improves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the CausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the best on individual datasets, DOTS attains the highest average summary-graph $F1$ while halving runtime relative to graph-optimisation methods. These results establish DOTS as a scalable and accurate solution for temporal causal discovery.", "published": "2025-10-28T17:06:15Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:40.967125"}
{"arxiv_id": "2510.24635v1", "title": "Electrochemical Electron Transfer: Key Concepts, Theories, and   Parameterization via Atomistic Simulations", "summary": "Electron transfer (ET) at electrochemical interfaces is central to energy conversion and storage, yet its theoretical and computational modeling remain active research areas. This review elucidates key concepts and theories of ET kinetics, focusing on coupling between classical solvent fluctuations and quantum electronic states of metallic electrodes and redox species. We begin with fundamental rate theories, reaction coordinates, and electrochemical timescales, then explore weak, strong, and intermediate electronic coupling regimes. Special attention is given to solvent dynamics and the structure of the electrical double layer (EDL), which critically impact ET kinetics. Atomistic simulations, particularly density functional theory (DFT) and molecular dynamics (MD), are highlighted for testing linear response and determining solvent reorganization energy, electronic coupling strengths, and solvent relaxation dynamics. A central theme is linear response enabling tractable treatments across Marcus theory, empirical valence bond (EVB) models, the Anderson-Newns-Schmickler framework, and generalized Langevin dynamics. While linear response offers useful simplifications, we assess its limitations, particularly for strong solvation changes or inner-sphere ET at catalytic interfaces. We discuss advances, including mapping Hamiltonian-based EVB-MD, constrained DFT, and non-Gaussian free energy formulations, enabling rigorous tests and access to diabatic and adiabatic free energy surfaces. We outline opportunities to advance multiscale, quantum-classical models that integrate EDL effects, multiple reaction coordinates, solvent-controlled dynamics, and transitions between adiabatic and nonadiabatic regimes. This review serves as a conceptual guide and practical resource for researchers integrating theory and simulation in studying electrochemical ET across diverse systems.", "published": "2025-10-28T17:02:22Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:40.967692"}
{"arxiv_id": "2510.24627v1", "title": "Enhanced Superconductivity in 2H-TaS2 Devices Through in-situ Molecular   Intercalation", "summary": "The intercalation of guest species into the gap of van der Waals materials often leads to the emergence of intriguing phenomena, such as superconductivity. While intercalation-induced superconductivity has been reported in several bulk crystals, reaching a zero-resistance state in flakes remains challenging. Here, we show a simple method for enhancing the superconducting transition in tens-of-nm thick 2H-TaS2 crystals contacted by gold electrodes through in-situ intercalation. Our approach enables measuring the electrical characteristics of the same flake before and after intercalation, permitting us to precisely identify the effect of the guest species on the TaS2 transport properties. We find that the intercalation of amylamine molecules into TaS2 flakes causes a suppression of the charge density wave and an increase in the superconducting transition, with an onset temperature above 3 K. Additionally, we show that a fully developed zero-resistance state can be achieved in flakes by engineering the conditions of the chemical intercalation. Our findings pave the way for the integration of chemically tailored intercalation compounds in scalable quantum technologies.", "published": "2025-10-28T16:57:29Z", "query": "bidirectional brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:40.968176"}
{"arxiv_id": "2510.24452v1", "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable   In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery", "summary": "Time series forecasting and anomaly detection are common tasks for practitioners in industries such as retail, manufacturing, advertising and energy. Two unique challenges stand out: (1) efficiently and accurately forecasting time series or detecting anomalies in large volumes automatically; and (2) ensuring interpretability of results to effectively incorporate business insights. We present ARIMA_PLUS, a novel framework to overcome these two challenges by a unique combination of (a) accurate and interpretable time series models and (b) scalable and fully managed system infrastructure. The model has a sequential and modular structure to handle different components of the time series, including holiday effects, seasonality, trend, and anomalies, which enables high interpretability of the results. Novel enhancements are made to each module, and a unified framework is established to address both forecasting and anomaly detection tasks simultaneously. In terms of accuracy, its comprehensive benchmark on the 42 public datasets in the Monash forecasting repository shows superior performance over not only well-established statistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer neural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms of infrastructure, it is directly built into the query engine of BigQuery in Google Cloud. It uses a simple SQL interface and automates tedious technicalities such as data cleaning and model selection. It automatically scales with managed cloud computational and storage resources, making it possible to forecast 100 million time series using only 1.5 hours with a throughput of more than 18000 time series per second. In terms of interpretability, we present several case studies to demonstrate time series insights it generates and customizability it offers.", "published": "2025-10-28T14:18:50Z", "query": "bidirectional brain interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:40.968654"}
{"arxiv_id": "2510.24398v1", "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "summary": "Post-stroke MRI not only delineates focal lesions but also reveals secondary structural changes, such as atrophy and ventricular enlargement. These abnormalities, increasingly recognised as imaging biomarkers of recovery and outcome, remain poorly captured by supervised segmentation methods. We evaluate REFLECT, a flow-based generative model, for unsupervised detection of both focal and non-lesional abnormalities in post-stroke patients. Using dual-expert central-slice annotations on ATLAS data, performance was assessed at the object level with Free-Response ROC analysis for anomaly maps. Two models were trained on lesion-free slices from stroke patients (ATLAS) and on healthy controls (IXI) to test the effect of training data. On ATLAS test subjects, the IXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and improved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43). Training on fully healthy anatomy improves the modelling of normal variability, enabling broader and more reliable detection of structural abnormalities.", "published": "2025-10-28T13:13:01Z", "query": "bidirectional brain interface", "relevance": 0.2, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:40.969099"}
{"arxiv_id": "2510.24716v1", "title": "Positive Feedback Drives Sharp Swelling of Polymer Brushes near   Saturation", "summary": "We resolve the Schr\\\"{o}der paradox for PNiPAAm brushes, showing experimentally that swelling at 100\\% relative humidity (RH) matches the liquid state. This occurs via a sharp increase in swelling above 98\\%~RH, a behavior standard models fail to explain. Our extended mean-field theory explains this via a positive feedback between swelling and solvent quality, driven by a concentration-dependent $\\chi$ parameter. The swelling isotherm quantitatively predicts the dynamic wetting crossover: the advancing contact angle at high velocities drops sharply as ambient humidity surpasses the 98\\%~RH threshold.", "published": "2025-10-28T17:59:51Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Closed-Loop Systems", "scraped_at": "2025-10-28T21:18:44.426154"}
{"arxiv_id": "2510.24712v1", "title": "Memory-induced long-range order drag", "summary": "Recent research has shown that memory, in the form of slow degrees of freedom, can induce a phase of long-range order (LRO) in locally-coupled fast degrees of freedom, producing power-law distributions of avalanches. In fact, such memory-induced LRO (MILRO) arises in a wide range of physical systems. Here, we show that MILRO can be transferred to coupled systems that have no memory of their own. As an example, we consider a stack of layers of spins with local feedforward couplings: only the first layer contains memory, while downstream layers are memory-free and locally interacting. Analytical arguments and simulations reveal that MILRO can indeed drag across the layers, enabling downstream layers to sustain intra-layer LRO despite having neither memory nor long-range interactions. This establishes a simple, yet generic mechanism for propagating collective activity through media without fine tuning to criticality, with testable implications for neuromorphic systems and laminar information flow in the brain cortex.", "published": "2025-10-28T17:59:04Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "Cognitive Enhancement", "scraped_at": "2025-10-28T21:18:44.427114"}
{"arxiv_id": "2510.24710v1", "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel   Optimization", "summary": "We study bilevel optimization problems where the lower-level problems are strongly convex and have coupled linear constraints. To overcome the potential non-smoothness of the hyper-objective and the computational challenges associated with the Hessian matrix, we utilize penalty and augmented Lagrangian methods to reformulate the original problem as a single-level one. Especially, we establish a strong theoretical connection between the reformulated function and the original hyper-objective by characterizing the closeness of their values and derivatives. Based on this reformulation, we propose a single-loop, first-order algorithm for linearly constrained bilevel optimization (SFLCB). We provide rigorous analyses of its non-asymptotic convergence rates, showing an improvement over prior double-loop algorithms -- form $O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments corroborate our theoretical findings and demonstrate the practical efficiency of the proposed SFLCB algorithm. Simulation code is provided at https://github.com/ShenGroup/SFLCB.", "published": "2025-10-28T17:58:17Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:44.427582"}
{"arxiv_id": "2510.24706v1", "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?", "summary": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.", "published": "2025-10-28T17:55:42Z", "query": "neural feedback control", "relevance": 0.15, "3d3n_category": "Virtual Reality Interface", "scraped_at": "2025-10-28T21:18:44.428003"}
{"arxiv_id": "2510.24704v1", "title": "Long-range resonances in quasiperiodic many-body localization", "summary": "We investigate long-range resonances in quasiperiodic many-body localized (MBL) systems. Focusing on the Heisenberg chain in a deterministic Aubry-Andr\\'{e} potential, we complement standard diagnostics by analyzing the structure of long-distance pairwise correlations at high energy. Contrary to the expectation that the ergodic-MBL transition in quasiperiodic systems should be sharper due to the absence of Griffiths regions, we uncover a broad unconventional regime at strong quasiperiodic potential, characterized by fat-tailed distributions of longitudinal correlations at long distance. This reveals the presence of atypical eigenstates with strong long-range correlations in a regime where standard diagnostics indicate stable MBL. We further identify these anomalous eigenstates as quasi-degenerate pairs of resonant cat states, which exhibit entanglement at long distance. These findings advance the understanding of quasiperiodic MBL and identify density-correlation measurements in ultracold atomic systems as a probe of long-range resonances.", "published": "2025-10-28T17:55:20Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:44.428389"}
{"arxiv_id": "2510.24703v1", "title": "Cluster Dose Prediction in Carbon Ion Therapy: Using Transfer Learning   from a Pretrained Dose Prediction U-Net", "summary": "The cluster dose concept offers an alternative to the radiobiological effectiveness (RBE)-based model for describing radiation-induced biological effects. This study examines the application of a neural network to predict cluster dose distributions, with the goal of replacing the computationally intensive simulations currently required. Cluster dose distributions are predicted using a U-Net that was initially pretrained on conventional dose distributions. Using transfer learning techniques, the decoder path is adapted for cluster dose estimation. Both the training and pretraining datasets include head and neck regions from multiple patients and carbon ion beams of varying energies and positions. Monte Carlo (MC) simulations were used to generate the ground truth cluster dose distributions. The U-Net enables cluster dose estimation for a single pencil beam within milliseconds using a graphics processing unit (GPU). The predicted cluster dose distributions deviate from the ground truth by less than 0.35%. This proof-of-principle study demonstrates the feasibility of accurately estimating cluster doses within clinically acceptable computation times using machine learning (ML). By leveraging a pretrained neural network and applying transfer learning techniques, the approach significantly reduces the need for large-scale, computationally expensive training data.", "published": "2025-10-28T17:54:04Z", "query": "neural feedback control", "relevance": 0.1, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:44.428776"}
{"arxiv_id": "2510.24700v1", "title": "Greedy Sampling Is Provably Efficient for RLHF", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique for post-training large language models. Despite its empirical success, the theoretical understanding of RLHF is still limited, as learning the KL-regularized target with only preference feedback poses additional challenges compared with canonical RL. Existing works mostly study the reward-based Bradley-Terry (BT) preference model, and extend classical designs utilizing optimism or pessimism. This work, instead, considers the general preference model (whose practical relevance has been observed recently) and obtains performance guarantees with major, order-wise improvements over existing ones. Surprisingly, these results are derived from algorithms that directly use the empirical estimates (i.e., greedy sampling), as opposed to constructing optimistic or pessimistic estimates in previous works. This insight has a deep root in the unique structural property of the optimal policy class under the KL-regularized target, and we further specialize it to the BT model, highlighting the surprising sufficiency of greedy sampling in RLHF.", "published": "2025-10-28T17:52:08Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:44.429080"}
{"arxiv_id": "2510.24692v1", "title": "Embodying Physical Computing into Soft Robots", "summary": "Softening and onboarding computers and controllers is one of the final frontiers in soft robotics towards their robustness and intelligence for everyday use. In this regard, embodying soft and physical computing presents exciting potential. Physical computing seeks to encode inputs into a mechanical computing kernel and leverage the internal interactions among this kernel's constituent elements to compute the output. Moreover, such input-to-output evolution can be re-programmable. This perspective paper proposes a framework for embodying physical computing into soft robots and discusses three unique strategies in the literature: analog oscillators, physical reservoir computing, and physical algorithmic computing. These embodied computers enable the soft robot to perform complex behaviors that would otherwise require CMOS-based electronics -- including coordinated locomotion with obstacle avoidance, payload weight and orientation classification, and programmable operation based on logical rules. This paper will detail the working principles of these embodied physical computing methods, survey the current state-of-the-art, and present a perspective for future development.", "published": "2025-10-28T17:50:30Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "Neural Decoding", "scraped_at": "2025-10-28T21:18:44.429422"}
{"arxiv_id": "2510.24687v1", "title": "Fast algorithms enabling optimization and deep learning for   photoacoustic tomography in a circular detection geometry", "summary": "The inverse source problem arising in photoacoustic tomography and in several other coupled-physics modalities is frequently solved by iterative algorithms. Such algorithms are based on the minimization of a certain cost functional. In addition, novel deep learning techniques are currently being investigated to further improve such optimization approaches. All such methods require multiple applications of the operator defining the forward problem, and of its adjoint. In this paper, we present new asymptotically fast algorithms for numerical evaluation of the forward and adjoint operators, applicable in the circular acquisition geometry. For an $(n \\times n)$ image, our algorithms compute these operators in $\\mathcal{O}(n^2 \\log n)$ floating point operations. We demonstrate the performance of our algorithms in numerical simulations, where they are used as an integral part of several iterative image reconstruction techniques: classic variational methods, such as non-negative least squares and total variation regularized least squares, as well as deep learning methods, such as learned primal dual. A Python implementation of our algorithms and computational examples is available to the general public.", "published": "2025-10-28T17:49:31Z", "query": "neural feedback control", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:44.429823"}
{"arxiv_id": "2510.24683v1", "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and   Object-Aware Controllers", "summary": "Real-time control is an essential aspect of safe robot operation in the real world with dynamic objects. We present a framework for the analysis of object-aware controllers, methods for altering a robot's motion to anticipate and avoid possible collisions. This framework is focused on three design considerations: kinematics, motion profiles, and virtual constraints. Additionally, the analysis in this work relies on verification of robot behaviors using fundamental robot-obstacle experimental scenarios. To showcase the effectiveness of our method we compare three representative object-aware controllers. The comparison uses metrics originating from the design considerations. From the analysis, we find that the design of object-aware controllers often lacks kinematic considerations, continuity of control points, and stability in movement profiles. We conclude that this framework can be used in the future to design, compare, and benchmark obstacle avoidance methods.", "published": "2025-10-28T17:46:06Z", "query": "neural feedback control", "relevance": 0.0, "3d3n_category": "Motor Prosthesis", "scraped_at": "2025-10-28T21:18:44.430179"}
{"arxiv_id": "2510.24702v1", "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents", "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.", "published": "2025-10-28T17:53:13Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.953604"}
{"arxiv_id": "2510.24645v1", "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in   Multi-Turn Function Calling", "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.", "published": "2025-10-28T17:15:26Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.954490"}
{"arxiv_id": "2510.24641v1", "title": "Density-driven scattering and valley splitting in undoped Si/SiGe   two-dimensional electron system", "summary": "Undoped Si-SiGe two-dimensional electron gas (2DEG) provide an ideal platform for hosting quantum-dot spin-qubits owing enhanced spin dephasing times and compatibility with standard CMOS technology. The strained Si quantum well reduces the valley degeneracy into two closely spaced ones. The existence of a near-degenerate valley state act as a leakage channel and compromises gate fidelity. A robust and uniform valley splitting across the entire chip is crucial for achieving scalability in the architecture and reliability in operation. Imperfections such as broadened interfaces, alloy disorders and atomic steps significantly compromise the valley splitting. The associated scattering mechanisms play detrimental roles in the performance of the qubits. In this manuscript, exploiting low-temperature magnetotransport measurements, we investigate the scattering mechanisms and valley splitting in a high-mobility undoped Si-SiGe 2DEG. At lower carrier densities, transport is limited by remote impurity scattering, whereas at higher densities, background impurity scattering near the quantum well dominates. Both the transport and quantum lifetimes of the charge carriers increase with carrier concentration, due to the enhancement in the impurity screening. Magnetic-field-induced confinement effect also is found to improve the valley splitting. Current-biasing measurements reveals the role of carrier heating in the visibility of valley splitting and reveal a temperature limited valley splitting of approximately 100 micro-eV. These results provide critical insight into scattering-dominated regimes and valley splitting in undoped Si-SiGe, advancing its potential for silicon-based quantum devices.", "published": "2025-10-28T17:07:26Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:47.954967"}
{"arxiv_id": "2510.24635v1", "title": "Electrochemical Electron Transfer: Key Concepts, Theories, and   Parameterization via Atomistic Simulations", "summary": "Electron transfer (ET) at electrochemical interfaces is central to energy conversion and storage, yet its theoretical and computational modeling remain active research areas. This review elucidates key concepts and theories of ET kinetics, focusing on coupling between classical solvent fluctuations and quantum electronic states of metallic electrodes and redox species. We begin with fundamental rate theories, reaction coordinates, and electrochemical timescales, then explore weak, strong, and intermediate electronic coupling regimes. Special attention is given to solvent dynamics and the structure of the electrical double layer (EDL), which critically impact ET kinetics. Atomistic simulations, particularly density functional theory (DFT) and molecular dynamics (MD), are highlighted for testing linear response and determining solvent reorganization energy, electronic coupling strengths, and solvent relaxation dynamics. A central theme is linear response enabling tractable treatments across Marcus theory, empirical valence bond (EVB) models, the Anderson-Newns-Schmickler framework, and generalized Langevin dynamics. While linear response offers useful simplifications, we assess its limitations, particularly for strong solvation changes or inner-sphere ET at catalytic interfaces. We discuss advances, including mapping Hamiltonian-based EVB-MD, constrained DFT, and non-Gaussian free energy formulations, enabling rigorous tests and access to diabatic and adiabatic free energy surfaces. We outline opportunities to advance multiscale, quantum-classical models that integrate EDL effects, multiple reaction coordinates, solvent-controlled dynamics, and transitions between adiabatic and nonadiabatic regimes. This review serves as a conceptual guide and practical resource for researchers integrating theory and simulation in studying electrochemical ET across diverse systems.", "published": "2025-10-28T17:02:22Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.955367"}
{"arxiv_id": "2510.24627v1", "title": "Enhanced Superconductivity in 2H-TaS2 Devices Through in-situ Molecular   Intercalation", "summary": "The intercalation of guest species into the gap of van der Waals materials often leads to the emergence of intriguing phenomena, such as superconductivity. While intercalation-induced superconductivity has been reported in several bulk crystals, reaching a zero-resistance state in flakes remains challenging. Here, we show a simple method for enhancing the superconducting transition in tens-of-nm thick 2H-TaS2 crystals contacted by gold electrodes through in-situ intercalation. Our approach enables measuring the electrical characteristics of the same flake before and after intercalation, permitting us to precisely identify the effect of the guest species on the TaS2 transport properties. We find that the intercalation of amylamine molecules into TaS2 flakes causes a suppression of the charge density wave and an increase in the superconducting transition, with an onset temperature above 3 K. Additionally, we show that a fully developed zero-resistance state can be achieved in flakes by engineering the conditions of the chemical intercalation. Our findings pave the way for the integration of chemically tailored intercalation compounds in scalable quantum technologies.", "published": "2025-10-28T16:57:29Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.955706"}
{"arxiv_id": "2510.24452v1", "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable   In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery", "summary": "Time series forecasting and anomaly detection are common tasks for practitioners in industries such as retail, manufacturing, advertising and energy. Two unique challenges stand out: (1) efficiently and accurately forecasting time series or detecting anomalies in large volumes automatically; and (2) ensuring interpretability of results to effectively incorporate business insights. We present ARIMA_PLUS, a novel framework to overcome these two challenges by a unique combination of (a) accurate and interpretable time series models and (b) scalable and fully managed system infrastructure. The model has a sequential and modular structure to handle different components of the time series, including holiday effects, seasonality, trend, and anomalies, which enables high interpretability of the results. Novel enhancements are made to each module, and a unified framework is established to address both forecasting and anomaly detection tasks simultaneously. In terms of accuracy, its comprehensive benchmark on the 42 public datasets in the Monash forecasting repository shows superior performance over not only well-established statistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer neural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms of infrastructure, it is directly built into the query engine of BigQuery in Google Cloud. It uses a simple SQL interface and automates tedious technicalities such as data cleaning and model selection. It automatically scales with managed cloud computational and storage resources, making it possible to forecast 100 million time series using only 1.5 hours with a throughput of more than 18000 time series per second. In terms of interpretability, we present several case studies to demonstrate time series insights it generates and customizability it offers.", "published": "2025-10-28T14:18:50Z", "query": "brain-to-brain interface", "relevance": 0.05, "3d3n_category": "Visual Prosthesis", "scraped_at": "2025-10-28T21:18:47.955985"}
{"arxiv_id": "2510.24378v1", "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular,   Lightweight, and Deployment-Ready Tool", "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance in brain lesion segmentation but remain difficult to deploy clinically due to heavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a modular and lightweight framework that translates research-grade stroke lesion segmentation models into deployable applications. Preprocessing, inference, and postprocessing are decoupled: preprocessing relies on the Anima toolbox with BIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16} quantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides both graphical and command-line interfaces and is distributed as Python scripts and as a standalone Windows executable. On a held-out set of 300 sub-acute and chronic stroke subjects, segmentation performance was equivalent to the original PyTorch pipeline (Dice difference $&lt;10^{-3}$), demonstrating that high-performing research pipelines can be transformed into portable, clinically usable tools.", "published": "2025-10-28T12:56:48Z", "query": "brain-to-brain interface", "relevance": 0.1, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.956230"}
{"arxiv_id": "2510.24363v1", "title": "Quarkiton: a one-quark state near a boundary of confinement phase of QCD", "summary": "We discuss a one-quark state in the confinement phase near a reflective chromometallic boundary both at finite and zero temperature. Using numerical simulations of lattice Yang-Mills theory, we show that the test quark is confined to the neutral mirror by an attractive potential of the Cornell type, suggesting the existence of a mirror-bound one-quark state, a \"quarkiton\". Surprisingly, the tension of the string spanned between the quark and the mirror is lower than the fundamental string tension. The quarkiton state exhibits a partial confinement: while the quark is localized in the vicinity of the mirror, it can still travel freely along it. Such quarkiton states share similarity with the surface excitons in metals and semiconductors that are bound to their negatively charged images at a boundary. The quarkitons can exist at the hadronic side of the phase interfaces in QCD that arise, for example, in the thermodynamic equilibrium of vortical quark-gluon plasma.", "published": "2025-10-28T12:36:35Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.956454"}
{"arxiv_id": "2510.24356v1", "title": "Perception Learning: A Formal Separation of Sensory Representation   Learning from Decision Learning", "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's sensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic signals, decoupled from downstream decision learning $g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free perceptual properties, such as stability to nuisances, informativeness without collapse, and controlled geometry, assessed via objective representation-invariant metrics. We formalize the separation of perception and decision, define perceptual properties independent of objectives or reparameterizations, and prove that PeL updates preserving sufficient invariants are orthogonal to Bayes task-risk gradients. Additionally, we provide a suite of task-agnostic evaluation metrics to certify perceptual quality.", "published": "2025-10-28T12:19:49Z", "query": "brain-to-brain interface", "relevance": 0.05, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.956655"}
{"arxiv_id": "2510.24294v1", "title": "Phase-Rotated Altermagnets as Chern Valves for Topological Transport", "summary": "Motivated by the emerging control of Berry-curvature textures in altermagnets, we explore a two-terminal configuration where a topological-insulator film is interfaced with two altermagnetic electrodes whose crystalline phases can be rotated independently. The proximity coupling imprints each momentum-dependent of the altermagnet spin texture onto the Dirac surface states, giving rise to an angular mass whose sign follows the lattice orientation. Adjusting the phase of one electrode redefines this mass pattern, thereby tuning the number and spatial distribution of chiral edge channels. This results in discrete conductance steps and a reversible inversion of the thermoelectric coefficient-achieved without external magnetic fields or net magnetization. A compact Dirac model captures both the quantized switching and its resilience to moderate disorder. Overall, this symmetry-driven mechanism provides a practical and low-dissipation route to programmable topological transport via lattice rotation.", "published": "2025-10-28T10:56:31Z", "query": "brain-to-brain interface", "relevance": 0.0, "3d3n_category": "General BCI", "scraped_at": "2025-10-28T21:18:47.956867"}
